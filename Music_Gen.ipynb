{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "music21: Certain music21 functions might need these optional packages: matplotlib, scipy;\n",
      "                   if you run into errors, install them by following the instructions at\n",
      "                   http://mit.edu/music21/doc/installing/installAdditional.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from util import data\n",
    "from pdb import set_trace\n",
    "from multiprocessing import pool\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "default_pool_size = max(1, os.cpu_count()-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialized scores found, loading...\n",
      "Scores loaded in 26.69 seconds.\n"
     ]
    }
   ],
   "source": [
    "scores = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset...\n",
      "Finished building dataset in 7.59 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = data.HaydnDataset(data=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81 final corpi with a total of 144076 ticks.\n"
     ]
    }
   ],
   "source": [
    "states = list(filter(lambda ds: ds.shape[1] != 0, dataset))\n",
    "total_ticks = sum(map(lambda state: state.shape[1], states))\n",
    "print(\"There are {} final corpi with a total of {} ticks.\".format(len(states), total_ticks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "import numpy as np\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Music_Gen_Model(nn.Module):\n",
    "    def __init__(self, lstm_input_size, lstm_hidden_size , center_input_size, center_output_size, output_size):\n",
    "        super(Music_Gen_Model, self).__init__()\n",
    "        \n",
    "        #TODO: Could make lastm as stacked models with layers=2\n",
    "        self.left_lstm = nn.LSTM(lstm_input_size, lstm_hidden_size)\n",
    "        self.right_lstm = nn.LSTM(lstm_input_size, lstm_hidden_size)\n",
    "        self.center_affine = nn.Linear(center_input_size, center_output_size)\n",
    "        self.pred_affine = nn.Linear(lstm_hidden_size * 2 + center_output_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, left_seq, center_input, right_seq):\n",
    "        \n",
    "        T, N, D = left_seq.size()\n",
    "        \n",
    "        '''\n",
    "        input_size = 66*3\n",
    "        LSTM input shape: [sqd_len, batch=1, input_size]\n",
    "        1 = num_layers * num_directions\n",
    "        LSTM hn output shape: [1, batch, hidden_size]\n",
    "        \n",
    "        center_input_size = 66*3\n",
    "        centerAffine input shape: [batch, center_input_size]\n",
    "        centerAffine output shape: [batch, center_output_shape]\n",
    "        \n",
    "        '''        \n",
    "        left_out, (left_hn, left_cn) = self.left_lstm(left_seq)\n",
    "        right_out, (right_hn, right_cn) = self.right_lstm(right_seq)\n",
    "        \n",
    "        center_out = self.center_affine(center_input)\n",
    "        \n",
    "        left_hn = left_hn.view(N, -1)\n",
    "        right_hn = right_hn.view(N, -1)\n",
    "        \n",
    "        '''\n",
    "        left_hn shape: [batch, hidden_size]\n",
    "        right_hn shape: [batch, hidden_size]\n",
    "        center_out shape: [batch, center_out_size]\n",
    "        '''\n",
    "        merge_input = torch.cat((left_hn, center_out, right_hn), 1)\n",
    "        pred_output = self.pred_affine(merge_input)\n",
    "        output = self.relu(pred_output)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, self.hidden_size, dtype=torch.long)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, left_tensor, right_tensor, center_tensor, target_tensor, optimizer):\n",
    "        \n",
    "    output = model(left_tensor, center_tensor, right_tensor)\n",
    "\n",
    "    target = target_tensor[:, 0:65]\n",
    "    target_index_tensor = (target.flatten()==1).nonzero()[0]\n",
    "#     print(target_index_tensor)\n",
    "    loss = F.nll_loss(output, target_index_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateMiniBatchFromOneMusicForPart(music_data, seq_length, part):\n",
    "    '''    \n",
    "    input: music_data. A numpy array with shape [4, tick, 66]\n",
    "    return: a list contains miniBatch data for one part. Each item in the miniBatch list contains:\n",
    "            - left_tensor: shape [seq_length, 1, D]\n",
    "            - right_tensor: shape [seq_length, 1, D]\n",
    "            - center_tensor: shape [1, D]\n",
    "            - target_tensor: shape [1, 66]\n",
    "        D = size of array contains the data from three other parts\n",
    "        \n",
    "    TODO: (1) tempo is currently not added\n",
    "        \n",
    "    '''\n",
    "    miniBatches = []\n",
    "    \n",
    "    music_length = music_data.shape[1]\n",
    "    i = seq_length # TODO: maybe add functinality to pad the beginning and end.\n",
    "    \n",
    "    while (i + seq_length) < music_length:\n",
    "        left_range_start = i-seq_length\n",
    "        left_range_end = i\n",
    "        center_index = i\n",
    "        right_range_start = i + 1\n",
    "        right_range_end = right_range_start + seq_length\n",
    "        \n",
    "        target_result = music_data[part, i+1, :]\n",
    "        target_tensor = torch.from_numpy(target_result.reshape(1, -1)).float()\n",
    "        \n",
    "        left_range = music_data[:, left_range_start:left_range_end, :]\n",
    "        left_result = np.delete(left_range, part, axis=0)\n",
    "        left_result = np.swapaxes(left_result, 0, 1)\n",
    "        seq_l, part_l, notes_l = left_result.shape\n",
    "        left_tensor = torch.from_numpy(left_result.reshape(seq_l, 1, part_l*notes_l)).float()\n",
    "        \n",
    "        right_range = music_data[:, right_range_start:right_range_end, :]\n",
    "        right_result = np.delete(right_range, part, axis=0)     \n",
    "        right_result = np.swapaxes(right_result, 0, 1)\n",
    "        seq_r, part_r, notes_r = right_result.shape    \n",
    "        right_tensor = torch.from_numpy(right_result.reshape(seq_r, 1, part_r*notes_r)).float()\n",
    "        \n",
    "        center_result = music_data[:, i, :]\n",
    "        center_result = np.delete(center_result, part, axis=0)\n",
    "        part_c, notes_c = center_result.shape\n",
    "        center_tensor = torch.from_numpy(center_result.reshape(1, part_c * notes_c)).float()\n",
    "        \n",
    "        miniBatches.append((left_tensor, right_tensor, center_tensor, target_tensor))\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return miniBatches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmini generateMiniBatchFromOneMusicForPart test\\n'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "mini generateMiniBatchFromOneMusicForPart test\n",
    "'''\n",
    "# fake_data = np.random.rand(4, 7, 3)\n",
    "# r = generateMiniBatchFromOneMusicForPart(fake_data, 3, 0)\n",
    "# left_tensor, right_tensor, center_tensor, target_tensor = r[0]\n",
    "# print(left_tensor.shape)\n",
    "\n",
    "# print('fake_data')\n",
    "# print(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1541, 66)\n",
      "minibatch list length: 1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/cs682project/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (99 4%) loss: -0.0148\n",
      "output: tensor([[0.0163, 0.0151, 0.0152, 0.0160, 0.0148, 0.0148, 0.0153, 0.0151, 0.0154,\n",
      "         0.0155, 0.0148, 0.0148, 0.0148, 0.0148, 0.0152, 0.0148, 0.0148, 0.0161,\n",
      "         0.0148, 0.0148, 0.0148, 0.0161, 0.0148, 0.0148, 0.0156, 0.0148, 0.0148,\n",
      "         0.0154, 0.0154, 0.0158, 0.0148, 0.0149, 0.0149, 0.0162, 0.0151, 0.0161,\n",
      "         0.0151, 0.0159, 0.0148, 0.0150, 0.0148, 0.0155, 0.0157, 0.0153, 0.0148,\n",
      "         0.0153, 0.0151, 0.0148, 0.0148, 0.0148, 0.0156, 0.0148, 0.0150, 0.0148,\n",
      "         0.0148, 0.0148, 0.0148, 0.0148, 0.0149, 0.0154, 0.0148, 0.0157, 0.0148,\n",
      "         0.0156, 0.0148, 0.0148]], grad_fn=<SoftmaxBackward>)\n",
      "0m 1s (199 9%) loss: -0.0149\n",
      "output: tensor([[0.0166, 0.0158, 0.0149, 0.0153, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149,\n",
      "         0.0155, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149, 0.0153, 0.0156, 0.0158,\n",
      "         0.0149, 0.0158, 0.0149, 0.0153, 0.0149, 0.0149, 0.0149, 0.0149, 0.0149,\n",
      "         0.0154, 0.0159, 0.0154, 0.0149, 0.0149, 0.0160, 0.0151, 0.0158, 0.0152,\n",
      "         0.0149, 0.0155, 0.0149, 0.0151, 0.0149, 0.0150, 0.0152, 0.0149, 0.0150,\n",
      "         0.0159, 0.0155, 0.0152, 0.0149, 0.0149, 0.0151, 0.0153, 0.0149, 0.0149,\n",
      "         0.0149, 0.0150, 0.0149, 0.0151, 0.0150, 0.0149, 0.0149, 0.0149, 0.0149,\n",
      "         0.0162, 0.0150, 0.0149]], grad_fn=<SoftmaxBackward>)\n",
      "0m 3s (299 14%) loss: -0.0150\n",
      "output: tensor([[0.0158, 0.0155, 0.0156, 0.0161, 0.0147, 0.0147, 0.0147, 0.0150, 0.0150,\n",
      "         0.0162, 0.0147, 0.0147, 0.0147, 0.0147, 0.0154, 0.0153, 0.0147, 0.0163,\n",
      "         0.0147, 0.0148, 0.0147, 0.0154, 0.0147, 0.0148, 0.0147, 0.0153, 0.0150,\n",
      "         0.0150, 0.0162, 0.0153, 0.0147, 0.0147, 0.0147, 0.0155, 0.0151, 0.0147,\n",
      "         0.0151, 0.0148, 0.0159, 0.0147, 0.0147, 0.0149, 0.0169, 0.0153, 0.0157,\n",
      "         0.0149, 0.0164, 0.0161, 0.0147, 0.0147, 0.0147, 0.0150, 0.0147, 0.0148,\n",
      "         0.0147, 0.0164, 0.0147, 0.0150, 0.0160, 0.0148, 0.0147, 0.0147, 0.0147,\n",
      "         0.0162, 0.0147, 0.0147]], grad_fn=<SoftmaxBackward>)\n",
      "0m 4s (399 19%) loss: -0.0149\n",
      "output: tensor([[0.0170, 0.0150, 0.0149, 0.0153, 0.0149, 0.0149, 0.0151, 0.0149, 0.0149,\n",
      "         0.0155, 0.0150, 0.0151, 0.0149, 0.0151, 0.0150, 0.0149, 0.0150, 0.0149,\n",
      "         0.0149, 0.0162, 0.0149, 0.0153, 0.0149, 0.0152, 0.0149, 0.0149, 0.0149,\n",
      "         0.0154, 0.0149, 0.0163, 0.0149, 0.0149, 0.0149, 0.0156, 0.0154, 0.0155,\n",
      "         0.0149, 0.0159, 0.0149, 0.0149, 0.0149, 0.0150, 0.0160, 0.0149, 0.0156,\n",
      "         0.0154, 0.0149, 0.0156, 0.0149, 0.0149, 0.0149, 0.0155, 0.0154, 0.0149,\n",
      "         0.0150, 0.0158, 0.0149, 0.0149, 0.0149, 0.0154, 0.0149, 0.0151, 0.0149,\n",
      "         0.0153, 0.0154, 0.0149]], grad_fn=<SoftmaxBackward>)\n",
      "0m 5s (499 24%) loss: -0.0150\n",
      "output: tensor([[0.0166, 0.0148, 0.0148, 0.0162, 0.0148, 0.0148, 0.0148, 0.0156, 0.0149,\n",
      "         0.0149, 0.0151, 0.0152, 0.0148, 0.0150, 0.0148, 0.0148, 0.0150, 0.0151,\n",
      "         0.0148, 0.0155, 0.0148, 0.0148, 0.0148, 0.0158, 0.0156, 0.0150, 0.0148,\n",
      "         0.0155, 0.0164, 0.0148, 0.0148, 0.0148, 0.0155, 0.0148, 0.0156, 0.0152,\n",
      "         0.0156, 0.0159, 0.0148, 0.0150, 0.0148, 0.0155, 0.0164, 0.0151, 0.0154,\n",
      "         0.0155, 0.0154, 0.0154, 0.0148, 0.0148, 0.0151, 0.0148, 0.0151, 0.0155,\n",
      "         0.0152, 0.0156, 0.0148, 0.0148, 0.0148, 0.0148, 0.0148, 0.0156, 0.0148,\n",
      "         0.0156, 0.0151, 0.0148]], grad_fn=<SoftmaxBackward>)\n",
      "0m 6s (599 29%) loss: -0.0149\n",
      "output: tensor([[0.0157, 0.0149, 0.0149, 0.0154, 0.0149, 0.0149, 0.0150, 0.0149, 0.0163,\n",
      "         0.0149, 0.0149, 0.0149, 0.0149, 0.0158, 0.0156, 0.0149, 0.0149, 0.0161,\n",
      "         0.0149, 0.0149, 0.0149, 0.0154, 0.0149, 0.0149, 0.0153, 0.0149, 0.0149,\n",
      "         0.0152, 0.0156, 0.0154, 0.0149, 0.0149, 0.0152, 0.0154, 0.0149, 0.0150,\n",
      "         0.0151, 0.0158, 0.0149, 0.0150, 0.0149, 0.0149, 0.0163, 0.0149, 0.0157,\n",
      "         0.0159, 0.0153, 0.0149, 0.0150, 0.0156, 0.0149, 0.0149, 0.0149, 0.0149,\n",
      "         0.0155, 0.0154, 0.0149, 0.0149, 0.0153, 0.0149, 0.0149, 0.0149, 0.0149,\n",
      "         0.0157, 0.0149, 0.0163]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-316-2ec0f8328331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#     print(\"train left_tensor size: {x}\".format(x=left_tensor.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_Pt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_pt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-312-73c26958cf73>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, left_tensor, right_tensor, center_tensor, target_tensor, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs682project/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/cs682project/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_input_size = 66 * 3\n",
    "lstm_hidden_size = 200\n",
    "center_input_size = 66 * 3\n",
    "center_output_size = 100\n",
    "output_size = 66\n",
    "\n",
    "n_iters = 2000\n",
    "print_every = 100\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "learning_rate = 0.005\n",
    "\n",
    "\n",
    "model_Pt1 = Music_Gen_Model(lstm_input_size, lstm_hidden_size, center_input_size, center_output_size, output_size)\n",
    "model_Pt2 = Music_Gen_Model(lstm_input_size, lstm_hidden_size, center_input_size, center_output_size, output_size)\n",
    "model_Pt3 = Music_Gen_Model(lstm_input_size, lstm_hidden_size, center_input_size, center_output_size, output_size)\n",
    "model_Pt4 = Music_Gen_Model(lstm_input_size, lstm_hidden_size, center_input_size, center_output_size, output_size)\n",
    "\n",
    "\n",
    "optimizer_pt1 = optim.SGD(model_Pt1.parameters(), lr=learning_rate)\n",
    "optimizer_pt2 = optim.SGD(model_Pt2.parameters(), lr=learning_rate)\n",
    "optimizer_pt3 = optim.SGD(model_Pt3.parameters(), lr=learning_rate)\n",
    "optimizer_pt4 = optim.SGD(model_Pt4.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "seq_length = 8\n",
    "demo_piece = dataset.__getitem__(3) #numpy array\n",
    "print(demo_piece.shape)\n",
    "demo_piece_minibatch_pt1 = generateMiniBatchFromOneMusicForPart(demo_piece, seq_length, 0)\n",
    "demo_piece_minibatch_pt2 = generateMiniBatchFromOneMusicForPart(demo_piece, seq_length, 1)\n",
    "demo_piece_minibatch_pt3 = generateMiniBatchFromOneMusicForPart(demo_piece, seq_length, 2)\n",
    "demo_piece_minibatch_pt4 = generateMiniBatchFromOneMusicForPart(demo_piece, seq_length, 3)\n",
    "miniBatch_length = len(demo_piece_minibatch_pt1)\n",
    "print(\"minibatch list length: {x}\".format(x=miniBatch_length))\n",
    "\n",
    "#Training for Part 1\n",
    "start = time.time()\n",
    "ite = 0\n",
    "'''\n",
    "IMPORTANT: Model, Optimizer, and demo_miniBatch must match!!!\n",
    "'''\n",
    "\n",
    "'''\n",
    "NOTE: This is only trainning for part 1, with data from one music piece.\n",
    "\n",
    "TODO:\n",
    "(1) generate minibatch from other pieces\n",
    "(2) train for other parts\n",
    "(3) write sampling function\n",
    "\n",
    "'''\n",
    "for n in range(n_iters):\n",
    "    if ite/miniBatch_length >= 1:\n",
    "        ite = 0\n",
    "            \n",
    "    left_tensor, right_tensor, center_tensor, target_tensor = demo_piece_minibatch_pt1[ite]\n",
    "\n",
    "#     print(\"train left_tensor size: {x}\".format(x=left_tensor.size()))\n",
    "    output, loss = train(model_Pt1, left_tensor, right_tensor, center_tensor, target_tensor, optimizer_pt1)\n",
    "    total_loss += loss\n",
    "    \n",
    "    if (n+1) % print_every == 0:\n",
    "            print('%s (%d %d%%) loss: %.4f' % (timeSince(start), n, n / n_iters * 100, loss))\n",
    "            print(\"output: {x}\".format(x=output))\n",
    "            \n",
    "    if (n+1) % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "    \n",
    "    ite += 1\n",
    "    n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "RUN_ID: 4159EF\n",
      "RUN_TIME: 12-10_04-50-43\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util.helpers import *\n",
    "from util.run import train, validate\n",
    "from util.sample import sample\n",
    "from util.dataset import HaydnDataset, ChunksDataset\n",
    "from util.models import PitchEmbedModel, HarmonyModel, JudgeModel, NoteModel\n",
    "\n",
    "from music21 import converter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# number of instrument parts\n",
    "NUM_PARTS = 4\n",
    "\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "RUN_ID = get_unique_id()\n",
    "RUN_TIME = get_formatted_time()\n",
    "\n",
    "print(\"RUN_ID: {}\".format(RUN_ID))\n",
    "print(\"RUN_TIME: {}\".format(RUN_TIME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset...\n",
      "Serialized scores found, loading...\n",
      "Scores loaded in 20.06 seconds.\n"
     ]
    }
   ],
   "source": [
    "# LOAD HAYDN DATASET\n",
    "\n",
    "SKIP_DATA = False\n",
    "\n",
    "if not SKIP_DATA:\n",
    "    haydn_dataset = HaydnDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73 pieces and 828256 chunks in training set,and 8 pieces and 149656 chunks in validation set\n"
     ]
    }
   ],
   "source": [
    "# SETUP DATA LOADERs\n",
    "\n",
    "SEQ_LEN = 32\n",
    "STRIDE = 2\n",
    "BATCH_SIZE = {\n",
    "    \"train\": 1024,\n",
    "    \"val\": 1024\n",
    "}\n",
    "LOADER_PARAMS = {\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": multiprocessing.cpu_count() - 2\n",
    "}\n",
    "TRANSFORMS = []\n",
    "# how mnay pieces to allocate to validation, note that pieces have different length of chunks, so \n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "if not SKIP_DATA:\n",
    "    data_train = ChunksDataset(mode=\"train\",\n",
    "                               seq_len=SEQ_LEN, \n",
    "                               stride=STRIDE, \n",
    "                               dataset=haydn_dataset,\n",
    "                               transforms=TRANSFORMS,\n",
    "                               val_split=VALIDATION_SPLIT)\n",
    "    data_val = ChunksDataset(dataset=data_train.comp_set,\n",
    "                             transforms=TRANSFORMS)\n",
    "\n",
    "    loader_train = DataLoader(data_train,\n",
    "                              batch_size=BATCH_SIZE[\"train\"],\n",
    "                              **LOADER_PARAMS)\n",
    "    loader_val = DataLoader(data_val,\n",
    "                            batch_size=BATCH_SIZE[\"val\"],\n",
    "                            **LOADER_PARAMS)\n",
    "    \n",
    "    print(\"There are {} pieces and {} chunks in training set,\".format(len(data_train.dataset), len(data_train)) +\n",
    "          \"and {} pieces and {} chunks in validation set\".format(len(data_val.dataset), len(data_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter loaded.\n"
     ]
    }
   ],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "# number of epochs to run\n",
    "NUM_EPOCHS = 60\n",
    "# number of dimensions for the embedded pitch vectors\n",
    "EMBED_DIM = 5\n",
    "# dimension of the rhythm\n",
    "RHYTHM_DIM = 1\n",
    "# the total number of pitches plus rest\n",
    "PITCH_VOCAB_SIZE = 140\n",
    "# parameters for the optimizers\n",
    "OPTIM_PARAMS = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 0.0\n",
    "}\n",
    "\n",
    "# weights applied to each of the loss functions\n",
    "# forward pitch\n",
    "fp_loss = 1.0\n",
    "# backward pitch\n",
    "bp_loss = 1.0\n",
    "# harmony pitch\n",
    "hp_loss = 1.0\n",
    "# foward rhythm\n",
    "fr_loss = 1.0\n",
    "# judge\n",
    "j_loss = 1.0\n",
    "# part\n",
    "p_loss = 1.0\n",
    "\n",
    "LOSS_WEIGHTS = [fp_loss, bp_loss, hp_loss, fr_loss, j_loss, p_loss]\n",
    "\n",
    "print(\"Hyperparameter loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded.\n"
     ]
    }
   ],
   "source": [
    "# MODELS AND OPTIMIZERS\n",
    "\n",
    "SKIP_MODELS = False\n",
    "\n",
    "if not SKIP_MODELS:\n",
    "    model_names = [\"forward_\", \"backward_\", \"harmony_\", \"judge_\"]\n",
    "\n",
    "    models = {\n",
    "        \"pitch_embed\": PitchEmbedModel(vocab_size=PITCH_VOCAB_SIZE,\n",
    "                                       embed_dim=EMBED_DIM)\n",
    "    }\n",
    "    optims = {}\n",
    "\n",
    "    for i in range(NUM_PARTS):\n",
    "        note_input_dim = EMBED_DIM + RHYTHM_DIM\n",
    "        note_hidden_dim = 256\n",
    "        note_num_layers = 1\n",
    "        models[model_names[0] + str(i)] = NoteModel(note_input_dim, \n",
    "                                                    note_hidden_dim,\n",
    "                                                    batch_size=BATCH_SIZE['train'],\n",
    "                                                    num_layers=note_num_layers,\n",
    "                                                    vocab_size=PITCH_VOCAB_SIZE)\n",
    "\n",
    "        models[model_names[1] + str(i)] = NoteModel(note_input_dim, \n",
    "                                                    note_hidden_dim,\n",
    "                                                    batch_size=BATCH_SIZE['train'],\n",
    "                                                    num_layers=note_num_layers,\n",
    "                                                    vocab_size=PITCH_VOCAB_SIZE)\n",
    "\n",
    "\n",
    "        harmony_input_shape = (NUM_PARTS, EMBED_DIM + NUM_PARTS)\n",
    "        harmony_hidden_dim = 4 # should be less than 9\n",
    "        models[model_names[2] + str(i)] = HarmonyModel(input_shape=harmony_input_shape,\n",
    "                                                       vocab_size=PITCH_VOCAB_SIZE,\n",
    "                                                       hidden_dim=harmony_hidden_dim)\n",
    "\n",
    "\n",
    "        judge_input_shape = (NUM_PARTS - 1, EMBED_DIM)\n",
    "        judge_hidden_dim = 128\n",
    "        output_dim = PITCH_VOCAB_SIZE\n",
    "        models[model_names[3] + str(i)] = JudgeModel(judge_input_shape,\n",
    "                                                     judge_hidden_dim,\n",
    "                                                     output_dim)\n",
    "\n",
    "        # jointly optimize all of the params, so weights can be assigned to different loss.\n",
    "        embed_params = list(models[\"pitch_embed\"].parameters())\n",
    "        forward_params = list(models[model_names[0] + str(i)].parameters())\n",
    "        backward_params = list(models[model_names[1] + str(i)].parameters())\n",
    "        harmony_params = list(models[model_names[2] + str(i)].parameters())\n",
    "        judge_params = list(models[model_names[3] + str(i)].parameters())\n",
    "        optims[i] = optim.Adam(forward_params + backward_params +\n",
    "                               harmony_params + judge_params, \n",
    "                               **OPTIM_PARAMS)\n",
    "\n",
    "    # send all models to the appropriate device\n",
    "    for key in models:\n",
    "        models[key].to(device=device)\n",
    "        \n",
    "    print(\"Models loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 4.95735/0.00%, bp_loss: 4.92745/0.00%, hp_loss: 4.98123/0.00%, j_loss: 5.49703/1.00%, \n",
      "\t\tfr_loss: 0.49538/57.00%, p_loss: 1.25183/16.00%, \n",
      "\t\ttotal weighted loss: 22.11026\n",
      "\tPart 2 - fp_loss: 4.93271/0.00%, bp_loss: 4.94489/1.00%, hp_loss: 5.15660/0.00%, j_loss: 6.15600/0.00%, \n",
      "\t\tfr_loss: 0.49629/52.00%, p_loss: 1.72173/1.00%, \n",
      "\t\ttotal weighted loss: 23.40822\n",
      "\tPart 3 - fp_loss: 4.92072/0.00%, bp_loss: 4.94812/0.00%, hp_loss: 4.98680/0.00%, j_loss: 5.96280/1.00%, \n",
      "\t\tfr_loss: 0.49706/57.00%, p_loss: 1.58206/0.00%, \n",
      "\t\ttotal weighted loss: 22.89756\n",
      "\tPart 4 - fp_loss: 4.92832/0.00%, bp_loss: 4.94890/0.00%, hp_loss: 5.10936/0.00%, j_loss: 5.51534/0.00%, \n",
      "\t\tfr_loss: 0.49846/52.00%, p_loss: 1.41490/17.00%, \n",
      "\t\ttotal weighted loss: 22.41528\n",
      "\tTraining time elapsed: 1.16 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 2.58618/33.00%, bp_loss: 3.10926/24.00%, hp_loss: 4.08926/4.00%, j_loss: 3.07197/25.00%, \n",
      "\t\tfr_loss: 0.43885/56.00%, p_loss: 0.40611/100.00%, \n",
      "\t\ttotal weighted loss: 13.70162\n",
      "\tPart 2 - fp_loss: 2.32390/42.00%, bp_loss: 2.83435/33.00%, hp_loss: 4.15500/3.00%, j_loss: 2.71221/38.00%, \n",
      "\t\tfr_loss: 0.38562/63.00%, p_loss: 0.59764/97.00%, \n",
      "\t\ttotal weighted loss: 13.00874\n",
      "\tPart 3 - fp_loss: 2.25243/42.00%, bp_loss: 2.75108/35.00%, hp_loss: 4.00184/5.00%, j_loss: 2.70484/37.00%, \n",
      "\t\tfr_loss: 0.36115/65.00%, p_loss: 0.65063/99.00%, \n",
      "\t\ttotal weighted loss: 12.72197\n",
      "\tPart 4 - fp_loss: 2.26904/44.00%, bp_loss: 2.82306/34.00%, hp_loss: 4.02186/17.00%, j_loss: 2.73835/37.00%, \n",
      "\t\tfr_loss: 0.40748/61.00%, p_loss: 0.49221/97.00%, \n",
      "\t\ttotal weighted loss: 12.75200\n",
      "\tTraining time elapsed: 38.72 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 2.40783/40.00%, bp_loss: 3.08831/22.00%, hp_loss: 3.42997/22.00%, j_loss: 2.76161/36.00%, \n",
      "\t\tfr_loss: 0.43072/56.00%, p_loss: 0.08695/100.00%, \n",
      "\t\ttotal weighted loss: 12.20538\n",
      "\tPart 2 - fp_loss: 2.15836/43.00%, bp_loss: 2.87090/31.00%, hp_loss: 3.36968/28.00%, j_loss: 2.56460/39.00%, \n",
      "\t\tfr_loss: 0.37761/62.00%, p_loss: 0.16763/100.00%, \n",
      "\t\ttotal weighted loss: 11.50878\n",
      "\tPart 3 - fp_loss: 1.93725/49.00%, bp_loss: 2.67869/37.00%, hp_loss: 3.08224/36.00%, j_loss: 2.30613/48.00%, \n",
      "\t\tfr_loss: 0.33212/67.00%, p_loss: 0.15008/100.00%, \n",
      "\t\ttotal weighted loss: 10.48652\n",
      "\tPart 4 - fp_loss: 2.08577/51.00%, bp_loss: 2.74573/35.00%, hp_loss: 3.11571/34.00%, j_loss: 2.36385/48.00%, \n",
      "\t\tfr_loss: 0.35644/64.00%, p_loss: 0.13432/100.00%, \n",
      "\t\ttotal weighted loss: 10.80182\n",
      "\tTraining time elapsed: 76.35 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 2.22608/41.00%, bp_loss: 2.97938/24.00%, hp_loss: 3.19758/24.00%, j_loss: 2.63834/39.00%, \n",
      "\t\tfr_loss: 0.40155/60.00%, p_loss: 0.03271/100.00%, \n",
      "\t\ttotal weighted loss: 11.47564\n",
      "\tPart 2 - fp_loss: 1.97455/51.00%, bp_loss: 2.76565/33.00%, hp_loss: 2.95638/32.00%, j_loss: 2.32268/47.00%, \n",
      "\t\tfr_loss: 0.38535/62.00%, p_loss: 0.05559/100.00%, \n",
      "\t\ttotal weighted loss: 10.46020\n",
      "\tPart 3 - fp_loss: 1.78896/54.00%, bp_loss: 2.56350/37.00%, hp_loss: 2.68545/37.00%, j_loss: 2.18170/51.00%, \n",
      "\t\tfr_loss: 0.36850/63.00%, p_loss: 0.05020/100.00%, \n",
      "\t\ttotal weighted loss: 9.63831\n",
      "\tPart 4 - fp_loss: 1.96564/52.00%, bp_loss: 2.71606/32.00%, hp_loss: 2.89345/31.00%, j_loss: 2.30121/47.00%, \n",
      "\t\tfr_loss: 0.34702/67.00%, p_loss: 0.05683/100.00%, \n",
      "\t\ttotal weighted loss: 10.28021\n",
      "\tTraining time elapsed: 114.08 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 2.16272/42.00%, bp_loss: 3.00636/20.00%, hp_loss: 3.22643/21.00%, j_loss: 2.64632/40.00%, \n",
      "\t\tfr_loss: 0.35980/65.00%, p_loss: 0.01581/100.00%, \n",
      "\t\ttotal weighted loss: 11.41744\n",
      "\tPart 2 - fp_loss: 1.85051/51.00%, bp_loss: 2.71102/34.00%, hp_loss: 2.89689/32.00%, j_loss: 2.28277/48.00%, \n",
      "\t\tfr_loss: 0.34466/65.00%, p_loss: 0.02401/100.00%, \n",
      "\t\ttotal weighted loss: 10.10985\n",
      "\tPart 3 - fp_loss: 1.77623/55.00%, bp_loss: 2.60273/35.00%, hp_loss: 2.65526/35.00%, j_loss: 2.10700/51.00%, \n",
      "\t\tfr_loss: 0.31483/69.00%, p_loss: 0.02617/100.00%, \n",
      "\t\ttotal weighted loss: 9.48222\n",
      "\tPart 4 - fp_loss: 1.81007/56.00%, bp_loss: 2.62286/33.00%, hp_loss: 2.80060/33.00%, j_loss: 2.17989/52.00%, \n",
      "\t\tfr_loss: 0.28387/73.00%, p_loss: 0.03124/100.00%, \n",
      "\t\ttotal weighted loss: 9.72852\n",
      "\tTraining time elapsed: 151.75 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 2.13104/41.00%, bp_loss: 2.94286/23.00%, hp_loss: 3.21144/22.00%, j_loss: 2.59318/38.00%, \n",
      "\t\tfr_loss: 0.33118/67.00%, p_loss: 0.00950/100.00%, \n",
      "\t\ttotal weighted loss: 11.21921\n",
      "\tPart 2 - fp_loss: 1.70418/55.00%, bp_loss: 2.56198/37.00%, hp_loss: 2.76785/35.00%, j_loss: 2.08647/52.00%, \n",
      "\t\tfr_loss: 0.32731/67.00%, p_loss: 0.01475/100.00%, \n",
      "\t\ttotal weighted loss: 9.46254\n",
      "\tPart 3 - fp_loss: 1.69791/57.00%, bp_loss: 2.42401/39.00%, hp_loss: 2.49738/39.00%, j_loss: 1.99199/55.00%, \n",
      "\t\tfr_loss: 0.30893/69.00%, p_loss: 0.01469/100.00%, \n",
      "\t\ttotal weighted loss: 8.93491\n",
      "\tPart 4 - fp_loss: 1.69551/57.00%, bp_loss: 2.55460/33.00%, hp_loss: 2.72587/34.00%, j_loss: 2.10611/54.00%, \n",
      "\t\tfr_loss: 0.25861/75.00%, p_loss: 0.01685/100.00%, \n",
      "\t\ttotal weighted loss: 9.35755\n",
      "\tTraining time elapsed: 189.44 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 2.03931/44.00%, bp_loss: 2.86340/23.00%, hp_loss: 3.20560/22.00%, j_loss: 2.53482/42.00%, \n",
      "\t\tfr_loss: 0.30675/70.00%, p_loss: 0.00622/100.00%, \n",
      "\t\ttotal weighted loss: 10.95610\n",
      "\tPart 2 - fp_loss: 1.82003/53.00%, bp_loss: 2.61417/34.00%, hp_loss: 2.88139/31.00%, j_loss: 2.21127/51.00%, \n",
      "\t\tfr_loss: 0.36009/64.00%, p_loss: 0.00977/100.00%, \n",
      "\t\ttotal weighted loss: 9.89672\n",
      "\tPart 3 - fp_loss: 1.59561/59.00%, bp_loss: 2.36594/38.00%, hp_loss: 2.52351/39.00%, j_loss: 1.92329/56.00%, \n",
      "\t\tfr_loss: 0.30844/70.00%, p_loss: 0.01032/100.00%, \n",
      "\t\ttotal weighted loss: 8.72711\n",
      "\tPart 4 - fp_loss: 1.69016/57.00%, bp_loss: 2.53510/34.00%, hp_loss: 2.75532/32.00%, j_loss: 2.08710/54.00%, \n",
      "\t\tfr_loss: 0.25763/74.00%, p_loss: 0.01173/100.00%, \n",
      "\t\ttotal weighted loss: 9.33704\n",
      "\tTraining time elapsed: 227.14 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.94613/45.00%, bp_loss: 2.75395/25.00%, hp_loss: 3.19046/21.00%, j_loss: 2.39771/43.00%, \n",
      "\t\tfr_loss: 0.28294/72.00%, p_loss: 0.00459/100.00%, \n",
      "\t\ttotal weighted loss: 10.57577\n",
      "\tPart 2 - fp_loss: 1.72961/52.00%, bp_loss: 2.53624/35.00%, hp_loss: 2.84268/33.00%, j_loss: 2.18038/51.00%, \n",
      "\t\tfr_loss: 0.28453/73.00%, p_loss: 0.00709/100.00%, \n",
      "\t\ttotal weighted loss: 9.58053\n",
      "\tPart 3 - fp_loss: 1.59575/58.00%, bp_loss: 2.34328/38.00%, hp_loss: 2.51672/38.00%, j_loss: 1.92821/57.00%, \n",
      "\t\tfr_loss: 0.27535/73.00%, p_loss: 0.00698/100.00%, \n",
      "\t\ttotal weighted loss: 8.66628\n",
      "\tPart 4 - fp_loss: 1.67462/57.00%, bp_loss: 2.49239/33.00%, hp_loss: 2.72786/32.00%, j_loss: 2.03557/54.00%, \n",
      "\t\tfr_loss: 0.27227/73.00%, p_loss: 0.00831/100.00%, \n",
      "\t\ttotal weighted loss: 9.21103\n",
      "\tTraining time elapsed: 264.80 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.93673/45.00%, bp_loss: 2.79249/24.00%, hp_loss: 3.15444/22.00%, j_loss: 2.38424/43.00%, \n",
      "\t\tfr_loss: 0.26232/74.00%, p_loss: 0.00344/100.00%, \n",
      "\t\ttotal weighted loss: 10.53367\n",
      "\tPart 2 - fp_loss: 1.70482/53.00%, bp_loss: 2.42446/35.00%, hp_loss: 2.81463/32.00%, j_loss: 2.09545/52.00%, \n",
      "\t\tfr_loss: 0.29231/71.00%, p_loss: 0.00472/100.00%, \n",
      "\t\ttotal weighted loss: 9.33641\n",
      "\tPart 3 - fp_loss: 1.55846/60.00%, bp_loss: 2.18992/41.00%, hp_loss: 2.44991/39.00%, j_loss: 1.81422/59.00%, \n",
      "\t\tfr_loss: 0.25672/74.00%, p_loss: 0.00537/100.00%, \n",
      "\t\ttotal weighted loss: 8.27460\n",
      "\tPart 4 - fp_loss: 1.66342/58.00%, bp_loss: 2.54466/32.00%, hp_loss: 2.81518/29.00%, j_loss: 2.02843/56.00%, \n",
      "\t\tfr_loss: 0.28530/72.00%, p_loss: 0.00556/100.00%, \n",
      "\t\ttotal weighted loss: 9.34256\n",
      "\tTraining time elapsed: 302.45 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.78252/46.00%, bp_loss: 2.81913/22.00%, hp_loss: 3.12397/24.00%, j_loss: 2.33466/43.00%, \n",
      "\t\tfr_loss: 0.27658/74.00%, p_loss: 0.00343/100.00%, \n",
      "\t\ttotal weighted loss: 10.34028\n",
      "\tPart 2 - fp_loss: 1.58122/50.00%, bp_loss: 2.66191/29.00%, hp_loss: 2.85694/30.00%, j_loss: 2.22268/47.00%, \n",
      "\t\tfr_loss: 0.26462/75.00%, p_loss: 0.00466/100.00%, \n",
      "\t\ttotal weighted loss: 9.59204\n",
      "\tPart 3 - fp_loss: 1.17134/68.00%, bp_loss: 2.21213/41.00%, hp_loss: 2.32123/43.00%, j_loss: 1.56051/65.00%, \n",
      "\t\tfr_loss: 0.25420/74.00%, p_loss: 0.00534/100.00%, \n",
      "\t\ttotal weighted loss: 7.52475\n",
      "\tPart 4 - fp_loss: 1.42049/62.00%, bp_loss: 2.59670/37.00%, hp_loss: 2.56922/37.00%, j_loss: 1.86330/60.00%, \n",
      "\t\tfr_loss: 0.26313/75.00%, p_loss: 0.00729/100.00%, \n",
      "\t\ttotal weighted loss: 8.72011\n",
      "\t`Validation time elapsed: 0.70 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.86455/45.00%, bp_loss: 2.75902/23.00%, hp_loss: 3.13252/24.00%, j_loss: 2.37041/42.00%, \n",
      "\t\tfr_loss: 0.27116/75.00%, p_loss: 0.00350/100.00%, \n",
      "\t\ttotal weighted loss: 10.40116\n",
      "\tPart 2 - fp_loss: 1.54542/51.00%, bp_loss: 2.50870/33.00%, hp_loss: 2.87154/29.00%, j_loss: 2.16925/50.00%, \n",
      "\t\tfr_loss: 0.25370/75.00%, p_loss: 0.00473/100.00%, \n",
      "\t\ttotal weighted loss: 9.35335\n",
      "\tPart 3 - fp_loss: 1.28379/64.00%, bp_loss: 2.16549/43.00%, hp_loss: 2.41509/41.00%, j_loss: 1.64892/62.00%, \n",
      "\t\tfr_loss: 0.24873/76.00%, p_loss: 0.00532/100.00%, \n",
      "\t\ttotal weighted loss: 7.76734\n",
      "\tPart 4 - fp_loss: 1.44489/59.00%, bp_loss: 2.46591/36.00%, hp_loss: 2.59391/35.00%, j_loss: 1.94544/58.00%, \n",
      "\t\tfr_loss: 0.27108/74.00%, p_loss: 0.00712/100.00%, \n",
      "\t\ttotal weighted loss: 8.72835\n",
      "\t`Validation time elapsed: 9.47 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 0.\n",
      "\n",
      "EPOCH 1\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.91443/47.00%, bp_loss: 2.93242/22.00%, hp_loss: 3.16284/21.00%, j_loss: 2.39311/45.00%, \n",
      "\t\tfr_loss: 0.29193/71.00%, p_loss: 0.00347/100.00%, \n",
      "\t\ttotal weighted loss: 10.69819\n",
      "\tPart 2 - fp_loss: 1.63218/55.00%, bp_loss: 2.63130/32.00%, hp_loss: 2.81048/32.00%, j_loss: 2.06507/54.00%, \n",
      "\t\tfr_loss: 0.28306/71.00%, p_loss: 0.00486/100.00%, \n",
      "\t\ttotal weighted loss: 9.42694\n",
      "\tPart 3 - fp_loss: 1.63222/57.00%, bp_loss: 2.55041/35.00%, hp_loss: 2.63289/35.00%, j_loss: 2.03178/55.00%, \n",
      "\t\tfr_loss: 0.27288/73.00%, p_loss: 0.00532/100.00%, \n",
      "\t\ttotal weighted loss: 9.12549\n",
      "\tPart 4 - fp_loss: 1.74215/54.00%, bp_loss: 2.67155/31.00%, hp_loss: 2.79120/30.00%, j_loss: 2.14748/53.00%, \n",
      "\t\tfr_loss: 0.26114/74.00%, p_loss: 0.00549/100.00%, \n",
      "\t\ttotal weighted loss: 9.61901\n",
      "\tTraining time elapsed: 1.03 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.83593/48.00%, bp_loss: 2.73950/23.00%, hp_loss: 3.22788/19.00%, j_loss: 2.31154/46.00%, \n",
      "\t\tfr_loss: 0.27668/73.00%, p_loss: 0.00257/100.00%, \n",
      "\t\ttotal weighted loss: 10.39409\n",
      "\tPart 2 - fp_loss: 1.64061/54.00%, bp_loss: 2.46879/34.00%, hp_loss: 2.86118/31.00%, j_loss: 2.03320/54.00%, \n",
      "\t\tfr_loss: 0.29377/71.00%, p_loss: 0.00407/100.00%, \n",
      "\t\ttotal weighted loss: 9.30160\n",
      "\tPart 3 - fp_loss: 1.58429/57.00%, bp_loss: 2.31357/37.00%, hp_loss: 2.55490/34.00%, j_loss: 1.91003/56.00%, \n",
      "\t\tfr_loss: 0.25043/75.00%, p_loss: 0.00393/100.00%, \n",
      "\t\ttotal weighted loss: 8.61714\n",
      "\tPart 4 - fp_loss: 1.58445/59.00%, bp_loss: 2.41212/35.00%, hp_loss: 2.70727/32.00%, j_loss: 1.91067/58.00%, \n",
      "\t\tfr_loss: 0.24564/75.00%, p_loss: 0.00557/100.00%, \n",
      "\t\ttotal weighted loss: 8.86573\n",
      "\tTraining time elapsed: 38.65 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.81112/48.00%, bp_loss: 2.65116/29.00%, hp_loss: 3.16762/21.00%, j_loss: 2.25778/46.00%, \n",
      "\t\tfr_loss: 0.26098/74.00%, p_loss: 0.00223/100.00%, \n",
      "\t\ttotal weighted loss: 10.15089\n",
      "\tPart 2 - fp_loss: 1.52077/58.00%, bp_loss: 2.44507/33.00%, hp_loss: 2.84858/30.00%, j_loss: 1.92155/57.00%, \n",
      "\t\tfr_loss: 0.27796/72.00%, p_loss: 0.00296/100.00%, \n",
      "\t\ttotal weighted loss: 9.01688\n",
      "\tPart 3 - fp_loss: 1.37201/64.00%, bp_loss: 2.14903/42.00%, hp_loss: 2.43268/39.00%, j_loss: 1.62726/62.00%, \n",
      "\t\tfr_loss: 0.24015/76.00%, p_loss: 0.00353/100.00%, \n",
      "\t\ttotal weighted loss: 7.82466\n",
      "\tPart 4 - fp_loss: 1.54553/59.00%, bp_loss: 2.40191/33.00%, hp_loss: 2.73298/31.00%, j_loss: 1.93455/58.00%, \n",
      "\t\tfr_loss: 0.22418/78.00%, p_loss: 0.00402/100.00%, \n",
      "\t\ttotal weighted loss: 8.84318\n",
      "\tTraining time elapsed: 76.26 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.79696/49.00%, bp_loss: 2.66723/27.00%, hp_loss: 3.18803/20.00%, j_loss: 2.22324/47.00%, \n",
      "\t\tfr_loss: 0.24849/75.00%, p_loss: 0.00182/100.00%, \n",
      "\t\ttotal weighted loss: 10.12576\n",
      "\tPart 2 - fp_loss: 1.54131/58.00%, bp_loss: 2.32062/35.00%, hp_loss: 2.85419/30.00%, j_loss: 1.95130/57.00%, \n",
      "\t\tfr_loss: 0.24608/75.00%, p_loss: 0.00240/100.00%, \n",
      "\t\ttotal weighted loss: 8.91590\n",
      "\tPart 3 - fp_loss: 1.50318/60.00%, bp_loss: 2.19845/40.00%, hp_loss: 2.52449/37.00%, j_loss: 1.86103/60.00%, \n",
      "\t\tfr_loss: 0.24168/76.00%, p_loss: 0.00268/100.00%, \n",
      "\t\ttotal weighted loss: 8.33152\n",
      "\tPart 4 - fp_loss: 1.42807/62.00%, bp_loss: 2.30005/35.00%, hp_loss: 2.72147/32.00%, j_loss: 1.81302/61.00%, \n",
      "\t\tfr_loss: 0.23761/76.00%, p_loss: 0.00346/100.00%, \n",
      "\t\ttotal weighted loss: 8.50368\n",
      "\tTraining time elapsed: 113.85 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.77979/49.00%, bp_loss: 2.61906/26.00%, hp_loss: 3.19305/20.00%, j_loss: 2.24243/48.00%, \n",
      "\t\tfr_loss: 0.24979/75.00%, p_loss: 0.00158/100.00%, \n",
      "\t\ttotal weighted loss: 10.08569\n",
      "\tPart 2 - fp_loss: 1.59856/55.00%, bp_loss: 2.28199/36.00%, hp_loss: 2.81791/32.00%, j_loss: 1.96149/55.00%, \n",
      "\t\tfr_loss: 0.26035/74.00%, p_loss: 0.00202/100.00%, \n",
      "\t\ttotal weighted loss: 8.92232\n",
      "\tPart 3 - fp_loss: 1.48461/61.00%, bp_loss: 2.20094/41.00%, hp_loss: 2.51005/37.00%, j_loss: 1.78923/60.00%, \n",
      "\t\tfr_loss: 0.25727/74.00%, p_loss: 0.00251/100.00%, \n",
      "\t\ttotal weighted loss: 8.24462\n",
      "\tPart 4 - fp_loss: 1.51268/59.00%, bp_loss: 2.32571/36.00%, hp_loss: 2.73427/32.00%, j_loss: 1.89545/57.00%, \n",
      "\t\tfr_loss: 0.23973/76.00%, p_loss: 0.00226/100.00%, \n",
      "\t\ttotal weighted loss: 8.71010\n",
      "\tTraining time elapsed: 151.49 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.71359/51.00%, bp_loss: 2.62618/29.00%, hp_loss: 3.14305/21.00%, j_loss: 2.12813/50.00%, \n",
      "\t\tfr_loss: 0.23388/77.00%, p_loss: 0.00126/100.00%, \n",
      "\t\ttotal weighted loss: 9.84610\n",
      "\tPart 2 - fp_loss: 1.56776/57.00%, bp_loss: 2.31085/35.00%, hp_loss: 2.80992/30.00%, j_loss: 1.91265/57.00%, \n",
      "\t\tfr_loss: 0.25215/75.00%, p_loss: 0.00173/100.00%, \n",
      "\t\ttotal weighted loss: 8.85506\n",
      "\tPart 3 - fp_loss: 1.43098/61.00%, bp_loss: 2.16688/41.00%, hp_loss: 2.46821/39.00%, j_loss: 1.70990/61.00%, \n",
      "\t\tfr_loss: 0.23413/76.00%, p_loss: 0.00195/100.00%, \n",
      "\t\ttotal weighted loss: 8.01205\n",
      "\tPart 4 - fp_loss: 1.48432/60.00%, bp_loss: 2.34255/35.00%, hp_loss: 2.68276/31.00%, j_loss: 1.86059/59.00%, \n",
      "\t\tfr_loss: 0.22645/77.00%, p_loss: 0.00226/100.00%, \n",
      "\t\ttotal weighted loss: 8.59894\n",
      "\tTraining time elapsed: 189.09 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.62275/55.00%, bp_loss: 2.55189/30.00%, hp_loss: 3.06666/24.00%, j_loss: 2.02413/53.00%, \n",
      "\t\tfr_loss: 0.24747/75.00%, p_loss: 0.00109/100.00%, \n",
      "\t\ttotal weighted loss: 9.51398\n",
      "\tPart 2 - fp_loss: 1.45289/59.00%, bp_loss: 2.26292/37.00%, hp_loss: 2.76763/33.00%, j_loss: 1.84356/58.00%, \n",
      "\t\tfr_loss: 0.22659/78.00%, p_loss: 0.00146/100.00%, \n",
      "\t\ttotal weighted loss: 8.55505\n",
      "\tPart 3 - fp_loss: 1.41171/63.00%, bp_loss: 2.13431/40.00%, hp_loss: 2.50886/38.00%, j_loss: 1.69740/62.00%, \n",
      "\t\tfr_loss: 0.20757/79.00%, p_loss: 0.00154/100.00%, \n",
      "\t\ttotal weighted loss: 7.96140\n",
      "\tPart 4 - fp_loss: 1.44142/61.00%, bp_loss: 2.22934/39.00%, hp_loss: 2.68547/33.00%, j_loss: 1.76519/61.00%, \n",
      "\t\tfr_loss: 0.21665/78.00%, p_loss: 0.00166/100.00%, \n",
      "\t\ttotal weighted loss: 8.33972\n",
      "\tTraining time elapsed: 226.68 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.70728/51.00%, bp_loss: 2.58112/28.00%, hp_loss: 3.11900/22.00%, j_loss: 2.12683/50.00%, \n",
      "\t\tfr_loss: 0.23001/78.00%, p_loss: 0.00093/100.00%, \n",
      "\t\ttotal weighted loss: 9.76517\n",
      "\tPart 2 - fp_loss: 1.50233/59.00%, bp_loss: 2.25122/35.00%, hp_loss: 2.85728/29.00%, j_loss: 1.87527/59.00%, \n",
      "\t\tfr_loss: 0.22333/78.00%, p_loss: 0.00123/100.00%, \n",
      "\t\ttotal weighted loss: 8.71065\n",
      "\tPart 3 - fp_loss: 1.35757/61.00%, bp_loss: 2.08433/41.00%, hp_loss: 2.47913/38.00%, j_loss: 1.72062/61.00%, \n",
      "\t\tfr_loss: 0.20617/79.00%, p_loss: 0.00151/100.00%, \n",
      "\t\ttotal weighted loss: 7.84934\n",
      "\tPart 4 - fp_loss: 1.36660/63.00%, bp_loss: 2.31298/37.00%, hp_loss: 2.70551/31.00%, j_loss: 1.72190/63.00%, \n",
      "\t\tfr_loss: 0.19300/81.00%, p_loss: 0.00150/100.00%, \n",
      "\t\ttotal weighted loss: 8.30149\n",
      "\tTraining time elapsed: 264.29 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.71021/50.00%, bp_loss: 2.48537/27.00%, hp_loss: 3.11232/21.00%, j_loss: 2.09968/50.00%, \n",
      "\t\tfr_loss: 0.24426/75.00%, p_loss: 0.00081/100.00%, \n",
      "\t\ttotal weighted loss: 9.65265\n",
      "\tPart 2 - fp_loss: 1.42629/60.00%, bp_loss: 2.29143/36.00%, hp_loss: 2.77091/32.00%, j_loss: 1.77656/60.00%, \n",
      "\t\tfr_loss: 0.25428/74.00%, p_loss: 0.00104/100.00%, \n",
      "\t\ttotal weighted loss: 8.52051\n",
      "\tPart 3 - fp_loss: 1.38431/62.00%, bp_loss: 2.12273/42.00%, hp_loss: 2.38007/41.00%, j_loss: 1.68014/61.00%, \n",
      "\t\tfr_loss: 0.20929/79.00%, p_loss: 0.00116/100.00%, \n",
      "\t\ttotal weighted loss: 7.77771\n",
      "\tPart 4 - fp_loss: 1.37447/61.00%, bp_loss: 2.28835/35.00%, hp_loss: 2.61962/34.00%, j_loss: 1.78558/61.00%, \n",
      "\t\tfr_loss: 0.21086/79.00%, p_loss: 0.00103/100.00%, \n",
      "\t\ttotal weighted loss: 8.27991\n",
      "\tTraining time elapsed: 301.85 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.65691/49.00%, bp_loss: 2.89828/19.00%, hp_loss: 3.16105/21.00%, j_loss: 2.18954/47.00%, \n",
      "\t\tfr_loss: 0.22704/77.00%, p_loss: 0.00092/100.00%, \n",
      "\t\ttotal weighted loss: 10.13375\n",
      "\tPart 2 - fp_loss: 1.24617/60.00%, bp_loss: 2.64067/31.00%, hp_loss: 2.85452/28.00%, j_loss: 1.79254/58.00%, \n",
      "\t\tfr_loss: 0.19587/81.00%, p_loss: 0.00123/100.00%, \n",
      "\t\ttotal weighted loss: 8.73102\n",
      "\tPart 3 - fp_loss: 0.99766/71.00%, bp_loss: 2.30187/38.00%, hp_loss: 2.41918/41.00%, j_loss: 1.44941/69.00%, \n",
      "\t\tfr_loss: 0.20881/79.00%, p_loss: 0.00132/100.00%, \n",
      "\t\ttotal weighted loss: 7.37825\n",
      "\tPart 4 - fp_loss: 1.15211/68.00%, bp_loss: 2.66104/33.00%, hp_loss: 2.58153/37.00%, j_loss: 1.66326/66.00%, \n",
      "\t\tfr_loss: 0.21083/80.00%, p_loss: 0.00182/100.00%, \n",
      "\t\ttotal weighted loss: 8.27059\n",
      "\t`Validation time elapsed: 0.69 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.57161/51.00%, bp_loss: 2.60415/24.00%, hp_loss: 3.12271/23.00%, j_loss: 2.07653/50.00%, \n",
      "\t\tfr_loss: 0.22151/78.00%, p_loss: 0.00084/100.00%, \n",
      "\t\ttotal weighted loss: 9.59735\n",
      "\tPart 2 - fp_loss: 1.36463/57.00%, bp_loss: 2.38758/31.00%, hp_loss: 2.85827/29.00%, j_loss: 1.91379/56.00%, \n",
      "\t\tfr_loss: 0.20947/79.00%, p_loss: 0.00112/100.00%, \n",
      "\t\ttotal weighted loss: 8.73485\n",
      "\tPart 3 - fp_loss: 1.04526/70.00%, bp_loss: 2.04505/45.00%, hp_loss: 2.41960/41.00%, j_loss: 1.44875/69.00%, \n",
      "\t\tfr_loss: 0.20162/80.00%, p_loss: 0.00120/100.00%, \n",
      "\t\ttotal weighted loss: 7.16146\n",
      "\tPart 4 - fp_loss: 1.18270/69.00%, bp_loss: 2.36491/35.00%, hp_loss: 2.59985/37.00%, j_loss: 1.58426/67.00%, \n",
      "\t\tfr_loss: 0.21818/78.00%, p_loss: 0.00190/100.00%, \n",
      "\t\ttotal weighted loss: 7.95179\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 1.\n",
      "\n",
      "EPOCH 2\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.72267/49.00%, bp_loss: 2.91563/22.00%, hp_loss: 3.13554/21.00%, j_loss: 2.21074/48.00%, \n",
      "\t\tfr_loss: 0.23865/76.00%, p_loss: 0.00081/100.00%, \n",
      "\t\ttotal weighted loss: 10.22405\n",
      "\tPart 2 - fp_loss: 1.48287/59.00%, bp_loss: 2.60270/32.00%, hp_loss: 2.79127/32.00%, j_loss: 1.92433/58.00%, \n",
      "\t\tfr_loss: 0.23813/76.00%, p_loss: 0.00103/100.00%, \n",
      "\t\ttotal weighted loss: 9.04032\n",
      "\tPart 3 - fp_loss: 1.50037/56.00%, bp_loss: 2.46938/33.00%, hp_loss: 2.47599/38.00%, j_loss: 1.89569/56.00%, \n",
      "\t\tfr_loss: 0.23836/76.00%, p_loss: 0.00128/100.00%, \n",
      "\t\ttotal weighted loss: 8.58107\n",
      "\tPart 4 - fp_loss: 1.44441/60.00%, bp_loss: 2.69811/28.00%, hp_loss: 2.74765/30.00%, j_loss: 1.84019/59.00%, \n",
      "\t\tfr_loss: 0.21838/78.00%, p_loss: 0.00117/100.00%, \n",
      "\t\ttotal weighted loss: 8.94990\n",
      "\tTraining time elapsed: 0.96 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.65949/53.00%, bp_loss: 2.54731/29.00%, hp_loss: 3.09982/24.00%, j_loss: 2.08747/51.00%, \n",
      "\t\tfr_loss: 0.23935/76.00%, p_loss: 0.00074/100.00%, \n",
      "\t\ttotal weighted loss: 9.63418\n",
      "\tPart 2 - fp_loss: 1.42585/58.00%, bp_loss: 2.27675/38.00%, hp_loss: 2.78746/33.00%, j_loss: 1.78858/58.00%, \n",
      "\t\tfr_loss: 0.24084/77.00%, p_loss: 0.00088/100.00%, \n",
      "\t\ttotal weighted loss: 8.52037\n",
      "\tPart 3 - fp_loss: 1.38372/62.00%, bp_loss: 2.08808/41.00%, hp_loss: 2.38328/40.00%, j_loss: 1.70431/62.00%, \n",
      "\t\tfr_loss: 0.21552/79.00%, p_loss: 0.00121/100.00%, \n",
      "\t\ttotal weighted loss: 7.77613\n",
      "\tPart 4 - fp_loss: 1.31877/64.00%, bp_loss: 2.15217/38.00%, hp_loss: 2.62330/34.00%, j_loss: 1.64240/63.00%, \n",
      "\t\tfr_loss: 0.21662/78.00%, p_loss: 0.00111/100.00%, \n",
      "\t\ttotal weighted loss: 7.95437\n",
      "\tTraining time elapsed: 38.61 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.71865/48.00%, bp_loss: 2.53011/30.00%, hp_loss: 3.11114/22.00%, j_loss: 2.11657/48.00%, \n",
      "\t\tfr_loss: 0.25677/75.00%, p_loss: 0.00057/100.00%, \n",
      "\t\ttotal weighted loss: 9.73381\n",
      "\tPart 2 - fp_loss: 1.42606/60.00%, bp_loss: 2.19378/39.00%, hp_loss: 2.74189/34.00%, j_loss: 1.75895/59.00%, \n",
      "\t\tfr_loss: 0.27060/73.00%, p_loss: 0.00088/100.00%, \n",
      "\t\ttotal weighted loss: 8.39216\n",
      "\tPart 3 - fp_loss: 1.35571/62.00%, bp_loss: 2.10275/42.00%, hp_loss: 2.51644/37.00%, j_loss: 1.69259/62.00%, \n",
      "\t\tfr_loss: 0.20699/79.00%, p_loss: 0.00099/100.00%, \n",
      "\t\ttotal weighted loss: 7.87547\n",
      "\tPart 4 - fp_loss: 1.34600/64.00%, bp_loss: 2.23424/38.00%, hp_loss: 2.68416/34.00%, j_loss: 1.67318/64.00%, \n",
      "\t\tfr_loss: 0.19615/80.00%, p_loss: 0.00097/100.00%, \n",
      "\t\ttotal weighted loss: 8.13470\n",
      "\tTraining time elapsed: 76.20 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.63994/50.00%, bp_loss: 2.51247/27.00%, hp_loss: 3.07158/24.00%, j_loss: 2.09505/50.00%, \n",
      "\t\tfr_loss: 0.23633/76.00%, p_loss: 0.00056/100.00%, \n",
      "\t\ttotal weighted loss: 9.55592\n",
      "\tPart 2 - fp_loss: 1.42241/59.00%, bp_loss: 2.15898/38.00%, hp_loss: 2.73405/34.00%, j_loss: 1.74843/58.00%, \n",
      "\t\tfr_loss: 0.24460/76.00%, p_loss: 0.00071/100.00%, \n",
      "\t\ttotal weighted loss: 8.30918\n",
      "\tPart 3 - fp_loss: 1.29081/63.00%, bp_loss: 2.02796/41.00%, hp_loss: 2.37161/41.00%, j_loss: 1.60601/63.00%, \n",
      "\t\tfr_loss: 0.21414/79.00%, p_loss: 0.00085/100.00%, \n",
      "\t\ttotal weighted loss: 7.51138\n",
      "\tPart 4 - fp_loss: 1.31858/63.00%, bp_loss: 2.21961/38.00%, hp_loss: 2.59732/35.00%, j_loss: 1.69353/63.00%, \n",
      "\t\tfr_loss: 0.18726/82.00%, p_loss: 0.00076/100.00%, \n",
      "\t\ttotal weighted loss: 8.01706\n",
      "\tTraining time elapsed: 113.83 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.63247/53.00%, bp_loss: 2.50529/29.00%, hp_loss: 3.14788/22.00%, j_loss: 2.03893/52.00%, \n",
      "\t\tfr_loss: 0.22477/78.00%, p_loss: 0.00053/100.00%, \n",
      "\t\ttotal weighted loss: 9.54987\n",
      "\tPart 2 - fp_loss: 1.43652/61.00%, bp_loss: 2.24443/37.00%, hp_loss: 2.78942/31.00%, j_loss: 1.79730/60.00%, \n",
      "\t\tfr_loss: 0.23076/77.00%, p_loss: 0.00069/100.00%, \n",
      "\t\ttotal weighted loss: 8.49910\n",
      "\tPart 3 - fp_loss: 1.30238/64.00%, bp_loss: 2.06674/41.00%, hp_loss: 2.46692/38.00%, j_loss: 1.60268/63.00%, \n",
      "\t\tfr_loss: 0.24359/75.00%, p_loss: 0.00091/100.00%, \n",
      "\t\ttotal weighted loss: 7.68321\n",
      "\tPart 4 - fp_loss: 1.33280/64.00%, bp_loss: 2.20934/38.00%, hp_loss: 2.70241/32.00%, j_loss: 1.68751/64.00%, \n",
      "\t\tfr_loss: 0.21266/79.00%, p_loss: 0.00079/100.00%, \n",
      "\t\ttotal weighted loss: 8.14552\n",
      "\tTraining time elapsed: 151.45 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.59584/53.00%, bp_loss: 2.48501/28.00%, hp_loss: 3.17643/20.00%, j_loss: 2.02914/52.00%, \n",
      "\t\tfr_loss: 0.22401/78.00%, p_loss: 0.00046/100.00%, \n",
      "\t\ttotal weighted loss: 9.51089\n",
      "\tPart 2 - fp_loss: 1.39057/60.00%, bp_loss: 2.19283/37.00%, hp_loss: 2.76246/33.00%, j_loss: 1.76916/60.00%, \n",
      "\t\tfr_loss: 0.25613/74.00%, p_loss: 0.00067/100.00%, \n",
      "\t\ttotal weighted loss: 8.37182\n",
      "\tPart 3 - fp_loss: 1.29249/65.00%, bp_loss: 2.03790/42.00%, hp_loss: 2.47489/37.00%, j_loss: 1.56436/65.00%, \n",
      "\t\tfr_loss: 0.20420/79.00%, p_loss: 0.00083/100.00%, \n",
      "\t\ttotal weighted loss: 7.57468\n",
      "\tPart 4 - fp_loss: 1.36629/62.00%, bp_loss: 2.20837/37.00%, hp_loss: 2.73190/32.00%, j_loss: 1.69755/62.00%, \n",
      "\t\tfr_loss: 0.19779/81.00%, p_loss: 0.00083/100.00%, \n",
      "\t\ttotal weighted loss: 8.20273\n",
      "\tTraining time elapsed: 189.03 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.60149/52.00%, bp_loss: 2.52404/29.00%, hp_loss: 3.08472/23.00%, j_loss: 2.05256/52.00%, \n",
      "\t\tfr_loss: 0.24063/76.00%, p_loss: 0.00042/100.00%, \n",
      "\t\ttotal weighted loss: 9.50385\n",
      "\tPart 2 - fp_loss: 1.41686/62.00%, bp_loss: 2.18717/38.00%, hp_loss: 2.78717/32.00%, j_loss: 1.72849/61.00%, \n",
      "\t\tfr_loss: 0.22162/78.00%, p_loss: 0.00063/100.00%, \n",
      "\t\ttotal weighted loss: 8.34194\n",
      "\tPart 3 - fp_loss: 1.29488/65.00%, bp_loss: 2.11310/42.00%, hp_loss: 2.48689/37.00%, j_loss: 1.58248/65.00%, \n",
      "\t\tfr_loss: 0.21568/78.00%, p_loss: 0.00061/100.00%, \n",
      "\t\ttotal weighted loss: 7.69364\n",
      "\tPart 4 - fp_loss: 1.25915/65.00%, bp_loss: 2.18903/38.00%, hp_loss: 2.64841/34.00%, j_loss: 1.57519/65.00%, \n",
      "\t\tfr_loss: 0.20904/79.00%, p_loss: 0.00062/100.00%, \n",
      "\t\ttotal weighted loss: 7.88144\n",
      "\tTraining time elapsed: 226.64 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.62796/53.00%, bp_loss: 2.49712/30.00%, hp_loss: 3.19152/21.00%, j_loss: 1.99325/53.00%, \n",
      "\t\tfr_loss: 0.23310/76.00%, p_loss: 0.00039/100.00%, \n",
      "\t\ttotal weighted loss: 9.54334\n",
      "\tPart 2 - fp_loss: 1.42012/60.00%, bp_loss: 2.23360/37.00%, hp_loss: 2.84457/31.00%, j_loss: 1.77563/60.00%, \n",
      "\t\tfr_loss: 0.25056/75.00%, p_loss: 0.00059/100.00%, \n",
      "\t\ttotal weighted loss: 8.52507\n",
      "\tPart 3 - fp_loss: 1.28227/67.00%, bp_loss: 2.05185/41.00%, hp_loss: 2.46010/38.00%, j_loss: 1.55175/66.00%, \n",
      "\t\tfr_loss: 0.21611/78.00%, p_loss: 0.00065/100.00%, \n",
      "\t\ttotal weighted loss: 7.56273\n",
      "\tPart 4 - fp_loss: 1.23613/66.00%, bp_loss: 2.18825/38.00%, hp_loss: 2.68566/32.00%, j_loss: 1.58397/65.00%, \n",
      "\t\tfr_loss: 0.19726/80.00%, p_loss: 0.00063/100.00%, \n",
      "\t\ttotal weighted loss: 7.89190\n",
      "\tTraining time elapsed: 264.24 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.56268/54.00%, bp_loss: 2.43092/29.00%, hp_loss: 3.08667/23.00%, j_loss: 1.96181/54.00%, \n",
      "\t\tfr_loss: 0.22561/78.00%, p_loss: 0.00033/100.00%, \n",
      "\t\ttotal weighted loss: 9.26803\n",
      "\tPart 2 - fp_loss: 1.41646/58.00%, bp_loss: 2.18566/38.00%, hp_loss: 2.78853/32.00%, j_loss: 1.76862/59.00%, \n",
      "\t\tfr_loss: 0.21826/78.00%, p_loss: 0.00049/100.00%, \n",
      "\t\ttotal weighted loss: 8.37802\n",
      "\tPart 3 - fp_loss: 1.31374/65.00%, bp_loss: 2.06547/42.00%, hp_loss: 2.43194/39.00%, j_loss: 1.61107/65.00%, \n",
      "\t\tfr_loss: 0.21781/78.00%, p_loss: 0.00058/100.00%, \n",
      "\t\ttotal weighted loss: 7.64061\n",
      "\tPart 4 - fp_loss: 1.30576/64.00%, bp_loss: 2.18348/39.00%, hp_loss: 2.61377/33.00%, j_loss: 1.65404/64.00%, \n",
      "\t\tfr_loss: 0.21054/79.00%, p_loss: 0.00056/100.00%, \n",
      "\t\ttotal weighted loss: 7.96814\n",
      "\tTraining time elapsed: 301.87 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.48824/54.00%, bp_loss: 2.84817/22.00%, hp_loss: 3.07995/23.00%, j_loss: 2.04027/53.00%, \n",
      "\t\tfr_loss: 0.19885/80.00%, p_loss: 0.00032/100.00%, \n",
      "\t\ttotal weighted loss: 9.65579\n",
      "\tPart 2 - fp_loss: 1.24498/62.00%, bp_loss: 2.53983/33.00%, hp_loss: 2.74225/31.00%, j_loss: 1.68067/62.00%, \n",
      "\t\tfr_loss: 0.19897/80.00%, p_loss: 0.00051/100.00%, \n",
      "\t\ttotal weighted loss: 8.40720\n",
      "\tPart 3 - fp_loss: 0.92280/72.00%, bp_loss: 2.19364/40.00%, hp_loss: 2.25975/43.00%, j_loss: 1.31919/72.00%, \n",
      "\t\tfr_loss: 0.20041/80.00%, p_loss: 0.00054/100.00%, \n",
      "\t\ttotal weighted loss: 6.89633\n",
      "\tPart 4 - fp_loss: 1.01280/71.00%, bp_loss: 2.62010/31.00%, hp_loss: 2.47532/38.00%, j_loss: 1.52648/70.00%, \n",
      "\t\tfr_loss: 0.19535/80.00%, p_loss: 0.00080/100.00%, \n",
      "\t\ttotal weighted loss: 7.83084\n",
      "\t`Validation time elapsed: 0.67 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.52364/53.00%, bp_loss: 2.42034/28.00%, hp_loss: 3.05220/24.00%, j_loss: 1.99128/53.00%, \n",
      "\t\tfr_loss: 0.21727/78.00%, p_loss: 0.00033/100.00%, \n",
      "\t\ttotal weighted loss: 9.20506\n",
      "\tPart 2 - fp_loss: 1.34143/59.00%, bp_loss: 2.20109/36.00%, hp_loss: 2.74061/31.00%, j_loss: 1.70821/58.00%, \n",
      "\t\tfr_loss: 0.25092/75.00%, p_loss: 0.00054/100.00%, \n",
      "\t\ttotal weighted loss: 8.24280\n",
      "\tPart 3 - fp_loss: 1.05060/70.00%, bp_loss: 1.99819/43.00%, hp_loss: 2.30657/43.00%, j_loss: 1.38338/70.00%, \n",
      "\t\tfr_loss: 0.18466/81.00%, p_loss: 0.00043/100.00%, \n",
      "\t\ttotal weighted loss: 6.92384\n",
      "\tPart 4 - fp_loss: 1.10277/69.00%, bp_loss: 2.26347/37.00%, hp_loss: 2.53529/39.00%, j_loss: 1.50984/69.00%, \n",
      "\t\tfr_loss: 0.18414/82.00%, p_loss: 0.00058/100.00%, \n",
      "\t\ttotal weighted loss: 7.59610\n",
      "\t`Validation time elapsed: 9.42 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 2.\n",
      "\n",
      "EPOCH 3\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.66023/52.00%, bp_loss: 2.87943/22.00%, hp_loss: 3.10153/23.00%, j_loss: 2.10738/51.00%, \n",
      "\t\tfr_loss: 0.22268/78.00%, p_loss: 0.00034/100.00%, \n",
      "\t\ttotal weighted loss: 9.97158\n",
      "\tPart 2 - fp_loss: 1.33146/59.00%, bp_loss: 2.42204/37.00%, hp_loss: 2.73175/34.00%, j_loss: 1.70598/59.00%, \n",
      "\t\tfr_loss: 0.21107/79.00%, p_loss: 0.00051/100.00%, \n",
      "\t\ttotal weighted loss: 8.40280\n",
      "\tPart 3 - fp_loss: 1.31859/65.00%, bp_loss: 2.43591/36.00%, hp_loss: 2.46138/38.00%, j_loss: 1.62870/65.00%, \n",
      "\t\tfr_loss: 0.21022/79.00%, p_loss: 0.00063/100.00%, \n",
      "\t\ttotal weighted loss: 8.05542\n",
      "\tPart 4 - fp_loss: 1.33957/62.00%, bp_loss: 2.65432/30.00%, hp_loss: 2.65998/33.00%, j_loss: 1.79750/61.00%, \n",
      "\t\tfr_loss: 0.19482/80.00%, p_loss: 0.00054/100.00%, \n",
      "\t\ttotal weighted loss: 8.64672\n",
      "\tTraining time elapsed: 0.98 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.62541/54.00%, bp_loss: 2.44915/31.00%, hp_loss: 3.11426/21.00%, j_loss: 1.99232/53.00%, \n",
      "\t\tfr_loss: 0.21040/79.00%, p_loss: 0.00029/100.00%, \n",
      "\t\ttotal weighted loss: 9.39182\n",
      "\tPart 2 - fp_loss: 1.43764/58.00%, bp_loss: 2.20033/37.00%, hp_loss: 2.83062/30.00%, j_loss: 1.81629/58.00%, \n",
      "\t\tfr_loss: 0.22785/77.00%, p_loss: 0.00045/100.00%, \n",
      "\t\ttotal weighted loss: 8.51317\n",
      "\tPart 3 - fp_loss: 1.25322/66.00%, bp_loss: 1.95435/44.00%, hp_loss: 2.42708/39.00%, j_loss: 1.51850/65.00%, \n",
      "\t\tfr_loss: 0.18962/81.00%, p_loss: 0.00048/100.00%, \n",
      "\t\ttotal weighted loss: 7.34325\n",
      "\tPart 4 - fp_loss: 1.32977/64.00%, bp_loss: 2.13956/39.00%, hp_loss: 2.75331/31.00%, j_loss: 1.65312/63.00%, \n",
      "\t\tfr_loss: 0.21521/78.00%, p_loss: 0.00051/100.00%, \n",
      "\t\ttotal weighted loss: 8.09149\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.59877/54.00%, bp_loss: 2.43939/31.00%, hp_loss: 3.08115/23.00%, j_loss: 1.98650/53.00%, \n",
      "\t\tfr_loss: 0.23251/77.00%, p_loss: 0.00026/100.00%, \n",
      "\t\ttotal weighted loss: 9.33857\n",
      "\tPart 2 - fp_loss: 1.42902/59.00%, bp_loss: 2.14506/38.00%, hp_loss: 2.78989/31.00%, j_loss: 1.80048/58.00%, \n",
      "\t\tfr_loss: 0.23965/76.00%, p_loss: 0.00047/100.00%, \n",
      "\t\ttotal weighted loss: 8.40456\n",
      "\tPart 3 - fp_loss: 1.25010/67.00%, bp_loss: 2.05100/43.00%, hp_loss: 2.44257/38.00%, j_loss: 1.48851/67.00%, \n",
      "\t\tfr_loss: 0.22103/78.00%, p_loss: 0.00047/100.00%, \n",
      "\t\ttotal weighted loss: 7.45367\n",
      "\tPart 4 - fp_loss: 1.30035/64.00%, bp_loss: 2.19453/37.00%, hp_loss: 2.68518/32.00%, j_loss: 1.61566/64.00%, \n",
      "\t\tfr_loss: 0.21616/78.00%, p_loss: 0.00067/100.00%, \n",
      "\t\ttotal weighted loss: 8.01254\n",
      "\tTraining time elapsed: 76.27 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.53352/53.00%, bp_loss: 2.45336/30.00%, hp_loss: 3.14957/21.00%, j_loss: 1.99421/52.00%, \n",
      "\t\tfr_loss: 0.23069/77.00%, p_loss: 0.00025/100.00%, \n",
      "\t\ttotal weighted loss: 9.36158\n",
      "\tPart 2 - fp_loss: 1.30889/63.00%, bp_loss: 2.19647/38.00%, hp_loss: 2.78023/32.00%, j_loss: 1.63642/63.00%, \n",
      "\t\tfr_loss: 0.22697/77.00%, p_loss: 0.00040/100.00%, \n",
      "\t\ttotal weighted loss: 8.14937\n",
      "\tPart 3 - fp_loss: 1.31789/62.00%, bp_loss: 2.03018/40.00%, hp_loss: 2.37152/40.00%, j_loss: 1.61733/63.00%, \n",
      "\t\tfr_loss: 0.20047/79.00%, p_loss: 0.00045/100.00%, \n",
      "\t\ttotal weighted loss: 7.53784\n",
      "\tPart 4 - fp_loss: 1.19239/67.00%, bp_loss: 2.14334/39.00%, hp_loss: 2.61282/35.00%, j_loss: 1.51079/67.00%, \n",
      "\t\tfr_loss: 0.19986/80.00%, p_loss: 0.00037/100.00%, \n",
      "\t\ttotal weighted loss: 7.65957\n",
      "\tTraining time elapsed: 113.89 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.49327/55.00%, bp_loss: 2.42043/30.00%, hp_loss: 3.14286/21.00%, j_loss: 1.92390/55.00%, \n",
      "\t\tfr_loss: 0.22896/77.00%, p_loss: 0.00023/100.00%, \n",
      "\t\ttotal weighted loss: 9.20965\n",
      "\tPart 2 - fp_loss: 1.35501/59.00%, bp_loss: 2.18273/37.00%, hp_loss: 2.85397/30.00%, j_loss: 1.78673/59.00%, \n",
      "\t\tfr_loss: 0.23390/77.00%, p_loss: 0.00038/100.00%, \n",
      "\t\ttotal weighted loss: 8.41271\n",
      "\tPart 3 - fp_loss: 1.32769/64.00%, bp_loss: 2.08313/41.00%, hp_loss: 2.48466/37.00%, j_loss: 1.58130/64.00%, \n",
      "\t\tfr_loss: 0.20014/79.00%, p_loss: 0.00045/100.00%, \n",
      "\t\ttotal weighted loss: 7.67737\n",
      "\tPart 4 - fp_loss: 1.24611/66.00%, bp_loss: 2.20406/38.00%, hp_loss: 2.71935/33.00%, j_loss: 1.56778/66.00%, \n",
      "\t\tfr_loss: 0.18417/82.00%, p_loss: 0.00040/100.00%, \n",
      "\t\ttotal weighted loss: 7.92189\n",
      "\tTraining time elapsed: 151.51 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.48806/57.00%, bp_loss: 2.30534/33.00%, hp_loss: 3.02172/25.00%, j_loss: 1.82363/57.00%, \n",
      "\t\tfr_loss: 0.22567/77.00%, p_loss: 0.00018/100.00%, \n",
      "\t\ttotal weighted loss: 8.86460\n",
      "\tPart 2 - fp_loss: 1.42635/59.00%, bp_loss: 2.09391/38.00%, hp_loss: 2.72382/31.00%, j_loss: 1.74593/59.00%, \n",
      "\t\tfr_loss: 0.25090/75.00%, p_loss: 0.00033/100.00%, \n",
      "\t\ttotal weighted loss: 8.24125\n",
      "\tPart 3 - fp_loss: 1.24264/66.00%, bp_loss: 1.96564/42.00%, hp_loss: 2.40816/38.00%, j_loss: 1.54618/65.00%, \n",
      "\t\tfr_loss: 0.20359/79.00%, p_loss: 0.00036/100.00%, \n",
      "\t\ttotal weighted loss: 7.36657\n",
      "\tPart 4 - fp_loss: 1.27433/64.00%, bp_loss: 2.13909/39.00%, hp_loss: 2.63658/33.00%, j_loss: 1.59458/63.00%, \n",
      "\t\tfr_loss: 0.20665/79.00%, p_loss: 0.00035/100.00%, \n",
      "\t\ttotal weighted loss: 7.85158\n",
      "\tTraining time elapsed: 189.13 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.50128/57.00%, bp_loss: 2.39321/31.00%, hp_loss: 3.09169/22.00%, j_loss: 1.87210/57.00%, \n",
      "\t\tfr_loss: 0.23054/77.00%, p_loss: 0.00020/100.00%, \n",
      "\t\ttotal weighted loss: 9.08902\n",
      "\tPart 2 - fp_loss: 1.36570/60.00%, bp_loss: 2.17053/38.00%, hp_loss: 2.80708/31.00%, j_loss: 1.69160/60.00%, \n",
      "\t\tfr_loss: 0.22193/78.00%, p_loss: 0.00033/100.00%, \n",
      "\t\ttotal weighted loss: 8.25717\n",
      "\tPart 3 - fp_loss: 1.32397/65.00%, bp_loss: 2.00122/42.00%, hp_loss: 2.40371/38.00%, j_loss: 1.55685/65.00%, \n",
      "\t\tfr_loss: 0.18749/81.00%, p_loss: 0.00037/100.00%, \n",
      "\t\ttotal weighted loss: 7.47361\n",
      "\tPart 4 - fp_loss: 1.21266/66.00%, bp_loss: 2.07587/40.00%, hp_loss: 2.57194/35.00%, j_loss: 1.52587/66.00%, \n",
      "\t\tfr_loss: 0.20694/79.00%, p_loss: 0.00026/100.00%, \n",
      "\t\ttotal weighted loss: 7.59355\n",
      "\tTraining time elapsed: 226.76 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.50218/56.00%, bp_loss: 2.44470/29.00%, hp_loss: 3.16622/21.00%, j_loss: 1.93707/56.00%, \n",
      "\t\tfr_loss: 0.22988/77.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 9.28021\n",
      "\tPart 2 - fp_loss: 1.36394/62.00%, bp_loss: 2.11080/40.00%, hp_loss: 2.77456/33.00%, j_loss: 1.68685/61.00%, \n",
      "\t\tfr_loss: 0.23728/76.00%, p_loss: 0.00033/100.00%, \n",
      "\t\ttotal weighted loss: 8.17376\n",
      "\tPart 3 - fp_loss: 1.23541/66.00%, bp_loss: 1.98926/44.00%, hp_loss: 2.41463/37.00%, j_loss: 1.47800/66.00%, \n",
      "\t\tfr_loss: 0.19878/80.00%, p_loss: 0.00033/100.00%, \n",
      "\t\ttotal weighted loss: 7.31641\n",
      "\tPart 4 - fp_loss: 1.24137/66.00%, bp_loss: 2.12604/38.00%, hp_loss: 2.65514/33.00%, j_loss: 1.52366/65.00%, \n",
      "\t\tfr_loss: 0.16972/83.00%, p_loss: 0.00029/100.00%, \n",
      "\t\ttotal weighted loss: 7.71621\n",
      "\tTraining time elapsed: 264.35 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.52508/56.00%, bp_loss: 2.51748/27.00%, hp_loss: 3.17498/20.00%, j_loss: 1.93124/55.00%, \n",
      "\t\tfr_loss: 0.22647/78.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 9.37541\n",
      "\tPart 2 - fp_loss: 1.32595/62.00%, bp_loss: 2.07104/40.00%, hp_loss: 2.76058/34.00%, j_loss: 1.64933/62.00%, \n",
      "\t\tfr_loss: 0.22726/77.00%, p_loss: 0.00028/100.00%, \n",
      "\t\ttotal weighted loss: 8.03444\n",
      "\tPart 3 - fp_loss: 1.16197/69.00%, bp_loss: 1.87662/46.00%, hp_loss: 2.33939/42.00%, j_loss: 1.35287/69.00%, \n",
      "\t\tfr_loss: 0.19220/80.00%, p_loss: 0.00028/100.00%, \n",
      "\t\ttotal weighted loss: 6.92333\n",
      "\tPart 4 - fp_loss: 1.21727/65.00%, bp_loss: 2.04616/40.00%, hp_loss: 2.58697/34.00%, j_loss: 1.54517/66.00%, \n",
      "\t\tfr_loss: 0.17736/82.00%, p_loss: 0.00028/100.00%, \n",
      "\t\ttotal weighted loss: 7.57322\n",
      "\tTraining time elapsed: 301.98 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.51014/54.00%, bp_loss: 2.80558/20.00%, hp_loss: 3.10033/21.00%, j_loss: 2.04434/54.00%, \n",
      "\t\tfr_loss: 0.21640/78.00%, p_loss: 0.00017/100.00%, \n",
      "\t\ttotal weighted loss: 9.67697\n",
      "\tPart 2 - fp_loss: 1.25285/61.00%, bp_loss: 2.51836/28.00%, hp_loss: 2.79394/29.00%, j_loss: 1.74992/60.00%, \n",
      "\t\tfr_loss: 0.20287/79.00%, p_loss: 0.00035/100.00%, \n",
      "\t\ttotal weighted loss: 8.51831\n",
      "\tPart 3 - fp_loss: 0.94523/71.00%, bp_loss: 2.35040/37.00%, hp_loss: 2.39858/41.00%, j_loss: 1.42223/70.00%, \n",
      "\t\tfr_loss: 0.18733/81.00%, p_loss: 0.00025/100.00%, \n",
      "\t\ttotal weighted loss: 7.30402\n",
      "\tPart 4 - fp_loss: 1.07705/69.00%, bp_loss: 2.67566/29.00%, hp_loss: 2.46320/38.00%, j_loss: 1.61487/68.00%, \n",
      "\t\tfr_loss: 0.20671/79.00%, p_loss: 0.00051/100.00%, \n",
      "\t\ttotal weighted loss: 8.03800\n",
      "\t`Validation time elapsed: 0.67 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.50533/54.00%, bp_loss: 2.48517/25.00%, hp_loss: 3.13949/20.00%, j_loss: 1.98299/54.00%, \n",
      "\t\tfr_loss: 0.22981/77.00%, p_loss: 0.00017/100.00%, \n",
      "\t\ttotal weighted loss: 9.34296\n",
      "\tPart 2 - fp_loss: 1.27289/60.00%, bp_loss: 2.19665/35.00%, hp_loss: 2.74542/29.00%, j_loss: 1.67828/60.00%, \n",
      "\t\tfr_loss: 0.20894/78.00%, p_loss: 0.00033/100.00%, \n",
      "\t\ttotal weighted loss: 8.10251\n",
      "\tPart 3 - fp_loss: 0.90594/72.00%, bp_loss: 1.92923/46.00%, hp_loss: 2.29710/43.00%, j_loss: 1.29575/72.00%, \n",
      "\t\tfr_loss: 0.18574/81.00%, p_loss: 0.00024/100.00%, \n",
      "\t\ttotal weighted loss: 6.61400\n",
      "\tPart 4 - fp_loss: 1.08625/69.00%, bp_loss: 2.27063/39.00%, hp_loss: 2.54544/37.00%, j_loss: 1.56325/68.00%, \n",
      "\t\tfr_loss: 0.18479/81.00%, p_loss: 0.00039/100.00%, \n",
      "\t\ttotal weighted loss: 7.65074\n",
      "\t`Validation time elapsed: 9.44 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 3.\n",
      "\n",
      "EPOCH 4\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.52925/55.00%, bp_loss: 2.83869/24.00%, hp_loss: 3.10939/22.00%, j_loss: 2.02429/54.00%, \n",
      "\t\tfr_loss: 0.21639/79.00%, p_loss: 0.00018/100.00%, \n",
      "\t\ttotal weighted loss: 9.71819\n",
      "\tPart 2 - fp_loss: 1.33419/62.00%, bp_loss: 2.54106/29.00%, hp_loss: 2.76159/32.00%, j_loss: 1.73689/61.00%, \n",
      "\t\tfr_loss: 0.19608/80.00%, p_loss: 0.00032/100.00%, \n",
      "\t\ttotal weighted loss: 8.57012\n",
      "\tPart 3 - fp_loss: 1.21262/65.00%, bp_loss: 2.34347/36.00%, hp_loss: 2.33986/40.00%, j_loss: 1.57553/65.00%, \n",
      "\t\tfr_loss: 0.18511/82.00%, p_loss: 0.00026/100.00%, \n",
      "\t\ttotal weighted loss: 7.65687\n",
      "\tPart 4 - fp_loss: 1.25987/64.00%, bp_loss: 2.58836/29.00%, hp_loss: 2.57189/34.00%, j_loss: 1.69263/64.00%, \n",
      "\t\tfr_loss: 0.18705/81.00%, p_loss: 0.00023/100.00%, \n",
      "\t\ttotal weighted loss: 8.30004\n",
      "\tTraining time elapsed: 1.00 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.43387/58.00%, bp_loss: 2.37783/29.00%, hp_loss: 3.04437/24.00%, j_loss: 1.82262/58.00%, \n",
      "\t\tfr_loss: 0.21118/79.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 8.89002\n",
      "\tPart 2 - fp_loss: 1.34707/60.00%, bp_loss: 2.11408/38.00%, hp_loss: 2.76205/31.00%, j_loss: 1.67232/60.00%, \n",
      "\t\tfr_loss: 0.22909/77.00%, p_loss: 0.00032/100.00%, \n",
      "\t\ttotal weighted loss: 8.12493\n",
      "\tPart 3 - fp_loss: 1.32903/64.00%, bp_loss: 2.06556/41.00%, hp_loss: 2.44921/38.00%, j_loss: 1.55924/64.00%, \n",
      "\t\tfr_loss: 0.19656/80.00%, p_loss: 0.00029/100.00%, \n",
      "\t\ttotal weighted loss: 7.59989\n",
      "\tPart 4 - fp_loss: 1.25983/65.00%, bp_loss: 2.16609/37.00%, hp_loss: 2.68340/32.00%, j_loss: 1.58616/65.00%, \n",
      "\t\tfr_loss: 0.17686/82.00%, p_loss: 0.00023/100.00%, \n",
      "\t\ttotal weighted loss: 7.87256\n",
      "\tTraining time elapsed: 38.61 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.54995/56.00%, bp_loss: 2.43081/28.00%, hp_loss: 3.17765/20.00%, j_loss: 1.91215/56.00%, \n",
      "\t\tfr_loss: 0.20255/80.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 9.27326\n",
      "\tPart 2 - fp_loss: 1.32417/63.00%, bp_loss: 2.18977/34.00%, hp_loss: 2.87517/28.00%, j_loss: 1.64413/63.00%, \n",
      "\t\tfr_loss: 0.21746/78.00%, p_loss: 0.00029/100.00%, \n",
      "\t\ttotal weighted loss: 8.25098\n",
      "\tPart 3 - fp_loss: 1.19090/68.00%, bp_loss: 1.89577/45.00%, hp_loss: 2.36699/40.00%, j_loss: 1.41593/68.00%, \n",
      "\t\tfr_loss: 0.17402/83.00%, p_loss: 0.00026/100.00%, \n",
      "\t\ttotal weighted loss: 7.04386\n",
      "\tPart 4 - fp_loss: 1.23788/66.00%, bp_loss: 1.99597/42.00%, hp_loss: 2.68121/33.00%, j_loss: 1.53832/66.00%, \n",
      "\t\tfr_loss: 0.18412/81.00%, p_loss: 0.00022/100.00%, \n",
      "\t\ttotal weighted loss: 7.63773\n",
      "\tTraining time elapsed: 76.23 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.52802/55.00%, bp_loss: 2.39041/31.00%, hp_loss: 3.11982/21.00%, j_loss: 1.92230/55.00%, \n",
      "\t\tfr_loss: 0.24173/76.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 9.20240\n",
      "\tPart 2 - fp_loss: 1.37418/62.00%, bp_loss: 2.20641/37.00%, hp_loss: 2.81686/29.00%, j_loss: 1.64132/62.00%, \n",
      "\t\tfr_loss: 0.21733/78.00%, p_loss: 0.00029/100.00%, \n",
      "\t\ttotal weighted loss: 8.25638\n",
      "\tPart 3 - fp_loss: 1.26132/67.00%, bp_loss: 1.97883/41.00%, hp_loss: 2.51443/36.00%, j_loss: 1.50935/66.00%, \n",
      "\t\tfr_loss: 0.19118/81.00%, p_loss: 0.00025/100.00%, \n",
      "\t\ttotal weighted loss: 7.45537\n",
      "\tPart 4 - fp_loss: 1.20304/66.00%, bp_loss: 2.02669/41.00%, hp_loss: 2.70244/32.00%, j_loss: 1.53161/65.00%, \n",
      "\t\tfr_loss: 0.16999/83.00%, p_loss: 0.00028/100.00%, \n",
      "\t\ttotal weighted loss: 7.63407\n",
      "\tTraining time elapsed: 113.81 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.43551/58.00%, bp_loss: 2.32869/32.00%, hp_loss: 3.06698/24.00%, j_loss: 1.85911/58.00%, \n",
      "\t\tfr_loss: 0.20948/79.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 8.89987\n",
      "\tPart 2 - fp_loss: 1.24106/64.00%, bp_loss: 2.10634/41.00%, hp_loss: 2.75177/32.00%, j_loss: 1.57676/64.00%, \n",
      "\t\tfr_loss: 0.21335/79.00%, p_loss: 0.00020/100.00%, \n",
      "\t\ttotal weighted loss: 7.88948\n",
      "\tPart 3 - fp_loss: 1.18602/67.00%, bp_loss: 1.96789/43.00%, hp_loss: 2.41855/38.00%, j_loss: 1.46791/67.00%, \n",
      "\t\tfr_loss: 0.17553/83.00%, p_loss: 0.00017/100.00%, \n",
      "\t\ttotal weighted loss: 7.21607\n",
      "\tPart 4 - fp_loss: 1.15431/66.00%, bp_loss: 2.09041/38.00%, hp_loss: 2.57141/36.00%, j_loss: 1.48614/67.00%, \n",
      "\t\tfr_loss: 0.16635/83.00%, p_loss: 0.00017/100.00%, \n",
      "\t\ttotal weighted loss: 7.46879\n",
      "\tTraining time elapsed: 151.41 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.45738/57.00%, bp_loss: 2.36715/31.00%, hp_loss: 3.10376/22.00%, j_loss: 1.82586/57.00%, \n",
      "\t\tfr_loss: 0.19322/81.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 8.94747\n",
      "\tPart 2 - fp_loss: 1.28324/62.00%, bp_loss: 2.04260/43.00%, hp_loss: 2.72320/33.00%, j_loss: 1.59781/62.00%, \n",
      "\t\tfr_loss: 0.21538/79.00%, p_loss: 0.00024/100.00%, \n",
      "\t\ttotal weighted loss: 7.86247\n",
      "\tPart 3 - fp_loss: 1.18361/66.00%, bp_loss: 1.95950/42.00%, hp_loss: 2.43293/38.00%, j_loss: 1.51333/66.00%, \n",
      "\t\tfr_loss: 0.19833/79.00%, p_loss: 0.00020/100.00%, \n",
      "\t\ttotal weighted loss: 7.28790\n",
      "\tPart 4 - fp_loss: 1.22933/65.00%, bp_loss: 2.08406/40.00%, hp_loss: 2.61549/33.00%, j_loss: 1.54549/65.00%, \n",
      "\t\tfr_loss: 0.19290/80.00%, p_loss: 0.00017/100.00%, \n",
      "\t\ttotal weighted loss: 7.66744\n",
      "\tTraining time elapsed: 189.01 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.52108/56.00%, bp_loss: 2.35957/30.00%, hp_loss: 3.07114/23.00%, j_loss: 1.88986/56.00%, \n",
      "\t\tfr_loss: 0.21696/78.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 9.05871\n",
      "\tPart 2 - fp_loss: 1.29367/61.00%, bp_loss: 2.13768/39.00%, hp_loss: 2.84957/29.00%, j_loss: 1.64889/61.00%, \n",
      "\t\tfr_loss: 0.21251/78.00%, p_loss: 0.00025/100.00%, \n",
      "\t\ttotal weighted loss: 8.14257\n",
      "\tPart 3 - fp_loss: 1.24550/66.00%, bp_loss: 1.99736/42.00%, hp_loss: 2.47550/38.00%, j_loss: 1.49156/66.00%, \n",
      "\t\tfr_loss: 0.19918/80.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.40924\n",
      "\tPart 4 - fp_loss: 1.13789/70.00%, bp_loss: 2.12344/40.00%, hp_loss: 2.62321/32.00%, j_loss: 1.43522/69.00%, \n",
      "\t\tfr_loss: 0.17969/82.00%, p_loss: 0.00026/100.00%, \n",
      "\t\ttotal weighted loss: 7.49971\n",
      "\tTraining time elapsed: 226.56 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.50474/56.00%, bp_loss: 2.44386/30.00%, hp_loss: 3.14640/20.00%, j_loss: 1.88671/55.00%, \n",
      "\t\tfr_loss: 0.21591/79.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 9.19771\n",
      "\tPart 2 - fp_loss: 1.31275/63.00%, bp_loss: 2.03869/40.00%, hp_loss: 2.74698/32.00%, j_loss: 1.58744/63.00%, \n",
      "\t\tfr_loss: 0.21689/78.00%, p_loss: 0.00030/100.00%, \n",
      "\t\ttotal weighted loss: 7.90306\n",
      "\tPart 3 - fp_loss: 1.34401/64.00%, bp_loss: 1.96711/44.00%, hp_loss: 2.45074/37.00%, j_loss: 1.57049/63.00%, \n",
      "\t\tfr_loss: 0.21197/78.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 7.54445\n",
      "\tPart 4 - fp_loss: 1.19923/68.00%, bp_loss: 2.08055/40.00%, hp_loss: 2.68153/32.00%, j_loss: 1.50016/67.00%, \n",
      "\t\tfr_loss: 0.17517/82.00%, p_loss: 0.00025/100.00%, \n",
      "\t\ttotal weighted loss: 7.63689\n",
      "\tTraining time elapsed: 264.10 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.39054/59.00%, bp_loss: 2.33501/34.00%, hp_loss: 3.05006/24.00%, j_loss: 1.77849/59.00%, \n",
      "\t\tfr_loss: 0.22088/78.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 8.77508\n",
      "\tPart 2 - fp_loss: 1.25816/65.00%, bp_loss: 2.05824/40.00%, hp_loss: 2.82102/31.00%, j_loss: 1.50960/65.00%, \n",
      "\t\tfr_loss: 0.22215/78.00%, p_loss: 0.00023/100.00%, \n",
      "\t\ttotal weighted loss: 7.86942\n",
      "\tPart 3 - fp_loss: 1.15746/68.00%, bp_loss: 1.95950/42.00%, hp_loss: 2.46862/36.00%, j_loss: 1.47050/68.00%, \n",
      "\t\tfr_loss: 0.16217/84.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 7.21839\n",
      "\tPart 4 - fp_loss: 1.14792/68.00%, bp_loss: 2.01644/41.00%, hp_loss: 2.62240/34.00%, j_loss: 1.37029/69.00%, \n",
      "\t\tfr_loss: 0.18085/82.00%, p_loss: 0.00019/100.00%, \n",
      "\t\ttotal weighted loss: 7.33810\n",
      "\tTraining time elapsed: 301.70 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.44208/55.00%, bp_loss: 2.73155/21.00%, hp_loss: 3.09622/21.00%, j_loss: 1.97361/54.00%, \n",
      "\t\tfr_loss: 0.19204/80.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 9.43560\n",
      "\tPart 2 - fp_loss: 1.26040/60.00%, bp_loss: 2.64756/28.00%, hp_loss: 2.82150/27.00%, j_loss: 1.80496/59.00%, \n",
      "\t\tfr_loss: 0.16791/83.00%, p_loss: 0.00028/100.00%, \n",
      "\t\ttotal weighted loss: 8.70260\n",
      "\tPart 3 - fp_loss: 0.92683/72.00%, bp_loss: 2.22450/38.00%, hp_loss: 2.36108/40.00%, j_loss: 1.37688/71.00%, \n",
      "\t\tfr_loss: 0.18676/81.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.07620\n",
      "\tPart 4 - fp_loss: 1.08209/69.00%, bp_loss: 2.61210/32.00%, hp_loss: 2.54378/37.00%, j_loss: 1.56947/68.00%, \n",
      "\t\tfr_loss: 0.18490/82.00%, p_loss: 0.00025/100.00%, \n",
      "\t\ttotal weighted loss: 7.99258\n",
      "\t`Validation time elapsed: 0.69 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.43229/55.00%, bp_loss: 2.44618/28.00%, hp_loss: 3.02715/23.00%, j_loss: 1.91463/55.00%, \n",
      "\t\tfr_loss: 0.19470/81.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 9.01504\n",
      "\tPart 2 - fp_loss: 1.11658/64.00%, bp_loss: 2.07187/39.00%, hp_loss: 2.70804/30.00%, j_loss: 1.52951/64.00%, \n",
      "\t\tfr_loss: 0.19792/80.00%, p_loss: 0.00029/100.00%, \n",
      "\t\ttotal weighted loss: 7.62421\n",
      "\tPart 3 - fp_loss: 0.86361/73.00%, bp_loss: 1.92759/44.00%, hp_loss: 2.37096/43.00%, j_loss: 1.26911/73.00%, \n",
      "\t\tfr_loss: 0.19555/80.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 6.62694\n",
      "\tPart 4 - fp_loss: 0.99407/70.00%, bp_loss: 2.19776/41.00%, hp_loss: 2.44703/39.00%, j_loss: 1.50184/69.00%, \n",
      "\t\tfr_loss: 0.19959/80.00%, p_loss: 0.00027/100.00%, \n",
      "\t\ttotal weighted loss: 7.34058\n",
      "\t`Validation time elapsed: 9.44 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 4.\n",
      "\n",
      "EPOCH 5\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.44031/57.00%, bp_loss: 2.70026/25.00%, hp_loss: 3.11473/22.00%, j_loss: 1.91262/57.00%, \n",
      "\t\tfr_loss: 0.21058/79.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 9.37859\n",
      "\tPart 2 - fp_loss: 1.30694/64.00%, bp_loss: 2.51294/32.00%, hp_loss: 2.72262/34.00%, j_loss: 1.63722/64.00%, \n",
      "\t\tfr_loss: 0.20961/79.00%, p_loss: 0.00023/100.00%, \n",
      "\t\ttotal weighted loss: 8.38958\n",
      "\tPart 3 - fp_loss: 1.21707/66.00%, bp_loss: 2.49028/32.00%, hp_loss: 2.42341/37.00%, j_loss: 1.55009/66.00%, \n",
      "\t\tfr_loss: 0.16459/83.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.84558\n",
      "\tPart 4 - fp_loss: 1.18876/67.00%, bp_loss: 2.68564/28.00%, hp_loss: 2.72966/31.00%, j_loss: 1.61289/66.00%, \n",
      "\t\tfr_loss: 0.17067/83.00%, p_loss: 0.00020/100.00%, \n",
      "\t\ttotal weighted loss: 8.38781\n",
      "\tTraining time elapsed: 1.03 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.49285/55.00%, bp_loss: 2.37504/30.00%, hp_loss: 3.13301/21.00%, j_loss: 1.90918/55.00%, \n",
      "\t\tfr_loss: 0.21476/79.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 9.12492\n",
      "\tPart 2 - fp_loss: 1.30728/62.00%, bp_loss: 2.01505/42.00%, hp_loss: 2.73024/33.00%, j_loss: 1.57170/62.00%, \n",
      "\t\tfr_loss: 0.21101/79.00%, p_loss: 0.00023/100.00%, \n",
      "\t\ttotal weighted loss: 7.83552\n",
      "\tPart 3 - fp_loss: 1.21255/68.00%, bp_loss: 1.94001/44.00%, hp_loss: 2.41273/38.00%, j_loss: 1.41297/67.00%, \n",
      "\t\tfr_loss: 0.18257/81.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 7.16097\n",
      "\tPart 4 - fp_loss: 1.12069/69.00%, bp_loss: 2.07753/40.00%, hp_loss: 2.66011/32.00%, j_loss: 1.40381/69.00%, \n",
      "\t\tfr_loss: 0.15915/84.00%, p_loss: 0.00018/100.00%, \n",
      "\t\ttotal weighted loss: 7.42147\n",
      "\tTraining time elapsed: 38.60 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.50659/56.00%, bp_loss: 2.41711/30.00%, hp_loss: 3.15700/21.00%, j_loss: 1.88113/55.00%, \n",
      "\t\tfr_loss: 0.19237/80.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 9.15428\n",
      "\tPart 2 - fp_loss: 1.31490/62.00%, bp_loss: 2.05444/41.00%, hp_loss: 2.80529/30.00%, j_loss: 1.62125/62.00%, \n",
      "\t\tfr_loss: 0.21113/80.00%, p_loss: 0.00021/100.00%, \n",
      "\t\ttotal weighted loss: 8.00723\n",
      "\tPart 3 - fp_loss: 1.23631/65.00%, bp_loss: 1.96886/43.00%, hp_loss: 2.48301/37.00%, j_loss: 1.50039/65.00%, \n",
      "\t\tfr_loss: 0.15597/84.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.34465\n",
      "\tPart 4 - fp_loss: 1.16787/68.00%, bp_loss: 2.06066/41.00%, hp_loss: 2.66057/32.00%, j_loss: 1.39546/68.00%, \n",
      "\t\tfr_loss: 0.17074/83.00%, p_loss: 0.00021/100.00%, \n",
      "\t\ttotal weighted loss: 7.45550\n",
      "\tTraining time elapsed: 76.19 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.51449/55.00%, bp_loss: 2.35107/32.00%, hp_loss: 3.15240/21.00%, j_loss: 1.86278/55.00%, \n",
      "\t\tfr_loss: 0.21063/79.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 9.09145\n",
      "\tPart 2 - fp_loss: 1.19670/64.00%, bp_loss: 2.04972/40.00%, hp_loss: 2.76196/31.00%, j_loss: 1.56366/64.00%, \n",
      "\t\tfr_loss: 0.20029/80.00%, p_loss: 0.00021/100.00%, \n",
      "\t\ttotal weighted loss: 7.77253\n",
      "\tPart 3 - fp_loss: 1.10894/69.00%, bp_loss: 1.98394/43.00%, hp_loss: 2.49364/37.00%, j_loss: 1.42062/68.00%, \n",
      "\t\tfr_loss: 0.15656/84.00%, p_loss: 0.00013/100.00%, \n",
      "\t\ttotal weighted loss: 7.16383\n",
      "\tPart 4 - fp_loss: 1.11495/69.00%, bp_loss: 2.05068/39.00%, hp_loss: 2.71187/32.00%, j_loss: 1.42912/69.00%, \n",
      "\t\tfr_loss: 0.15973/83.00%, p_loss: 0.00019/100.00%, \n",
      "\t\ttotal weighted loss: 7.46654\n",
      "\tTraining time elapsed: 113.73 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.45853/58.00%, bp_loss: 2.37115/32.00%, hp_loss: 3.11389/22.00%, j_loss: 1.80955/58.00%, \n",
      "\t\tfr_loss: 0.21767/78.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 8.97086\n",
      "\tPart 2 - fp_loss: 1.20262/66.00%, bp_loss: 1.98668/42.00%, hp_loss: 2.78244/32.00%, j_loss: 1.48592/66.00%, \n",
      "\t\tfr_loss: 0.20743/79.00%, p_loss: 0.00017/100.00%, \n",
      "\t\ttotal weighted loss: 7.66526\n",
      "\tPart 3 - fp_loss: 1.24797/66.00%, bp_loss: 1.92811/43.00%, hp_loss: 2.49582/36.00%, j_loss: 1.45064/66.00%, \n",
      "\t\tfr_loss: 0.20171/80.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 7.32436\n",
      "\tPart 4 - fp_loss: 1.12307/70.00%, bp_loss: 2.04401/39.00%, hp_loss: 2.68022/32.00%, j_loss: 1.38327/70.00%, \n",
      "\t\tfr_loss: 0.17593/82.00%, p_loss: 0.00013/100.00%, \n",
      "\t\ttotal weighted loss: 7.40662\n",
      "\tTraining time elapsed: 151.31 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.56234/55.00%, bp_loss: 2.30390/32.00%, hp_loss: 3.09600/22.00%, j_loss: 1.87016/55.00%, \n",
      "\t\tfr_loss: 0.21708/78.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 9.04955\n",
      "\tPart 2 - fp_loss: 1.28652/63.00%, bp_loss: 2.01595/41.00%, hp_loss: 2.72150/32.00%, j_loss: 1.58635/63.00%, \n",
      "\t\tfr_loss: 0.21199/79.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 7.82246\n",
      "\tPart 3 - fp_loss: 1.19974/67.00%, bp_loss: 1.86186/45.00%, hp_loss: 2.35908/40.00%, j_loss: 1.39838/67.00%, \n",
      "\t\tfr_loss: 0.20094/80.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.02008\n",
      "\tPart 4 - fp_loss: 1.11100/68.00%, bp_loss: 2.00971/40.00%, hp_loss: 2.58242/35.00%, j_loss: 1.40277/69.00%, \n",
      "\t\tfr_loss: 0.16969/83.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.27570\n",
      "\tTraining time elapsed: 188.88 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.44526/57.00%, bp_loss: 2.27942/33.00%, hp_loss: 3.02704/25.00%, j_loss: 1.82707/57.00%, \n",
      "\t\tfr_loss: 0.21158/79.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 8.79043\n",
      "\tPart 2 - fp_loss: 1.25902/63.00%, bp_loss: 2.12849/37.00%, hp_loss: 2.82557/30.00%, j_loss: 1.60779/63.00%, \n",
      "\t\tfr_loss: 0.20921/79.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 8.03025\n",
      "\tPart 3 - fp_loss: 1.25686/66.00%, bp_loss: 1.93187/45.00%, hp_loss: 2.46352/37.00%, j_loss: 1.44064/67.00%, \n",
      "\t\tfr_loss: 0.19761/80.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.29059\n",
      "\tPart 4 - fp_loss: 1.20564/66.00%, bp_loss: 2.04807/41.00%, hp_loss: 2.69757/30.00%, j_loss: 1.46745/65.00%, \n",
      "\t\tfr_loss: 0.16351/83.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.58240\n",
      "\tTraining time elapsed: 226.45 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.50828/57.00%, bp_loss: 2.38716/32.00%, hp_loss: 3.13886/22.00%, j_loss: 1.84842/57.00%, \n",
      "\t\tfr_loss: 0.19968/80.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 9.08246\n",
      "\tPart 2 - fp_loss: 1.19770/66.00%, bp_loss: 1.99782/43.00%, hp_loss: 2.71642/34.00%, j_loss: 1.44160/66.00%, \n",
      "\t\tfr_loss: 0.19583/80.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 7.54953\n",
      "\tPart 3 - fp_loss: 1.16411/69.00%, bp_loss: 1.93038/44.00%, hp_loss: 2.39411/39.00%, j_loss: 1.34151/69.00%, \n",
      "\t\tfr_loss: 0.18206/82.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.01225\n",
      "\tPart 4 - fp_loss: 1.09089/69.00%, bp_loss: 2.03286/42.00%, hp_loss: 2.54687/37.00%, j_loss: 1.39892/69.00%, \n",
      "\t\tfr_loss: 0.16875/83.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 7.23839\n",
      "\tTraining time elapsed: 264.03 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.45576/56.00%, bp_loss: 2.40074/31.00%, hp_loss: 3.07948/23.00%, j_loss: 1.85770/55.00%, \n",
      "\t\tfr_loss: 0.20196/80.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 8.99571\n",
      "\tPart 2 - fp_loss: 1.18963/66.00%, bp_loss: 1.95893/44.00%, hp_loss: 2.68575/35.00%, j_loss: 1.43519/66.00%, \n",
      "\t\tfr_loss: 0.20445/79.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 7.47409\n",
      "\tPart 3 - fp_loss: 1.28566/65.00%, bp_loss: 1.97917/43.00%, hp_loss: 2.45993/37.00%, j_loss: 1.50919/65.00%, \n",
      "\t\tfr_loss: 0.18365/81.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.41768\n",
      "\tPart 4 - fp_loss: 1.15261/67.00%, bp_loss: 2.05619/41.00%, hp_loss: 2.66739/31.00%, j_loss: 1.38601/68.00%, \n",
      "\t\tfr_loss: 0.15942/84.00%, p_loss: 0.00018/100.00%, \n",
      "\t\ttotal weighted loss: 7.42180\n",
      "\tTraining time elapsed: 301.63 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.46041/54.00%, bp_loss: 2.80614/23.00%, hp_loss: 3.06394/22.00%, j_loss: 2.01102/53.00%, \n",
      "\t\tfr_loss: 0.18219/82.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 9.52376\n",
      "\tPart 2 - fp_loss: 1.10820/64.00%, bp_loss: 2.57503/30.00%, hp_loss: 2.71985/31.00%, j_loss: 1.60990/64.00%, \n",
      "\t\tfr_loss: 0.17644/82.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 8.18957\n",
      "\tPart 3 - fp_loss: 0.82156/75.00%, bp_loss: 2.34088/36.00%, hp_loss: 2.31955/43.00%, j_loss: 1.23283/75.00%, \n",
      "\t\tfr_loss: 0.15112/84.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 6.86601\n",
      "\tPart 4 - fp_loss: 0.90809/72.00%, bp_loss: 2.64505/31.00%, hp_loss: 2.48744/38.00%, j_loss: 1.46666/71.00%, \n",
      "\t\tfr_loss: 0.16863/83.00%, p_loss: 0.00022/100.00%, \n",
      "\t\ttotal weighted loss: 7.67609\n",
      "\t`Validation time elapsed: 0.70 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.49630/53.00%, bp_loss: 2.38692/28.00%, hp_loss: 3.08807/22.00%, j_loss: 1.93312/53.00%, \n",
      "\t\tfr_loss: 0.20942/79.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 9.11390\n",
      "\tPart 2 - fp_loss: 1.28882/60.00%, bp_loss: 2.13858/36.00%, hp_loss: 2.78171/29.00%, j_loss: 1.68637/59.00%, \n",
      "\t\tfr_loss: 0.21475/79.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 8.11038\n",
      "\tPart 3 - fp_loss: 0.93919/72.00%, bp_loss: 1.96936/42.00%, hp_loss: 2.32992/42.00%, j_loss: 1.32343/71.00%, \n",
      "\t\tfr_loss: 0.18779/80.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 6.74975\n",
      "\tPart 4 - fp_loss: 1.02030/69.00%, bp_loss: 2.09062/41.00%, hp_loss: 2.46562/40.00%, j_loss: 1.46981/69.00%, \n",
      "\t\tfr_loss: 0.17094/82.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 7.21744\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 5.\n",
      "\n",
      "EPOCH 6\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.46461/58.00%, bp_loss: 2.78620/24.00%, hp_loss: 3.07891/23.00%, j_loss: 1.89245/58.00%, \n",
      "\t\tfr_loss: 0.20107/80.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 9.42329\n",
      "\tPart 2 - fp_loss: 1.22504/64.00%, bp_loss: 2.64488/31.00%, hp_loss: 2.72345/34.00%, j_loss: 1.64229/64.00%, \n",
      "\t\tfr_loss: 0.21593/78.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 8.45176\n",
      "\tPart 3 - fp_loss: 1.17407/67.00%, bp_loss: 2.34589/35.00%, hp_loss: 2.45176/37.00%, j_loss: 1.50993/66.00%, \n",
      "\t\tfr_loss: 0.18285/81.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.66457\n",
      "\tPart 4 - fp_loss: 1.08776/68.00%, bp_loss: 2.53895/30.00%, hp_loss: 2.62572/33.00%, j_loss: 1.53226/68.00%, \n",
      "\t\tfr_loss: 0.16154/84.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.94634\n",
      "\tTraining time elapsed: 1.01 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.38588/59.00%, bp_loss: 2.30350/33.00%, hp_loss: 3.09961/21.00%, j_loss: 1.75448/59.00%, \n",
      "\t\tfr_loss: 0.19725/80.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 8.74077\n",
      "\tPart 2 - fp_loss: 1.25779/64.00%, bp_loss: 2.02021/40.00%, hp_loss: 2.72599/32.00%, j_loss: 1.55951/64.00%, \n",
      "\t\tfr_loss: 0.21468/78.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.77833\n",
      "\tPart 3 - fp_loss: 1.17423/68.00%, bp_loss: 1.90010/44.00%, hp_loss: 2.40665/37.00%, j_loss: 1.39715/68.00%, \n",
      "\t\tfr_loss: 0.19195/80.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.07016\n",
      "\tPart 4 - fp_loss: 1.18826/67.00%, bp_loss: 2.02289/41.00%, hp_loss: 2.62912/33.00%, j_loss: 1.45299/67.00%, \n",
      "\t\tfr_loss: 0.18631/81.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.47969\n",
      "\tTraining time elapsed: 38.60 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.42096/59.00%, bp_loss: 2.39463/30.00%, hp_loss: 3.13548/20.00%, j_loss: 1.77384/59.00%, \n",
      "\t\tfr_loss: 0.21336/79.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 8.93834\n",
      "\tPart 2 - fp_loss: 1.20078/66.00%, bp_loss: 2.03141/40.00%, hp_loss: 2.73005/33.00%, j_loss: 1.49018/65.00%, \n",
      "\t\tfr_loss: 0.21322/78.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.66579\n",
      "\tPart 3 - fp_loss: 1.13786/69.00%, bp_loss: 1.87027/46.00%, hp_loss: 2.37346/39.00%, j_loss: 1.33794/70.00%, \n",
      "\t\tfr_loss: 0.17527/82.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 6.89487\n",
      "\tPart 4 - fp_loss: 1.11854/69.00%, bp_loss: 2.09440/40.00%, hp_loss: 2.72471/30.00%, j_loss: 1.39048/69.00%, \n",
      "\t\tfr_loss: 0.17906/82.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.50728\n",
      "\tTraining time elapsed: 76.20 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.42908/57.00%, bp_loss: 2.29076/33.00%, hp_loss: 3.05620/23.00%, j_loss: 1.80341/57.00%, \n",
      "\t\tfr_loss: 0.19607/80.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 8.77557\n",
      "\tPart 2 - fp_loss: 1.17691/68.00%, bp_loss: 2.09103/38.00%, hp_loss: 2.73947/32.00%, j_loss: 1.42842/68.00%, \n",
      "\t\tfr_loss: 0.19717/80.00%, p_loss: 0.00013/100.00%, \n",
      "\t\ttotal weighted loss: 7.63314\n",
      "\tPart 3 - fp_loss: 1.13839/69.00%, bp_loss: 1.80880/47.00%, hp_loss: 2.39983/41.00%, j_loss: 1.34340/69.00%, \n",
      "\t\tfr_loss: 0.19721/80.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 6.88769\n",
      "\tPart 4 - fp_loss: 1.05232/71.00%, bp_loss: 2.04930/40.00%, hp_loss: 2.71600/33.00%, j_loss: 1.34929/70.00%, \n",
      "\t\tfr_loss: 0.16248/84.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.32949\n",
      "\tTraining time elapsed: 113.78 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.44629/57.00%, bp_loss: 2.37809/31.00%, hp_loss: 3.10145/21.00%, j_loss: 1.83565/56.00%, \n",
      "\t\tfr_loss: 0.21450/78.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 8.97602\n",
      "\tPart 2 - fp_loss: 1.21304/64.00%, bp_loss: 1.98340/41.00%, hp_loss: 2.68173/34.00%, j_loss: 1.54794/64.00%, \n",
      "\t\tfr_loss: 0.19630/80.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 7.62257\n",
      "\tPart 3 - fp_loss: 1.06081/69.00%, bp_loss: 1.91034/44.00%, hp_loss: 2.41457/39.00%, j_loss: 1.32328/69.00%, \n",
      "\t\tfr_loss: 0.18147/81.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 6.89053\n",
      "\tPart 4 - fp_loss: 1.04705/70.00%, bp_loss: 1.99160/43.00%, hp_loss: 2.62500/33.00%, j_loss: 1.33627/70.00%, \n",
      "\t\tfr_loss: 0.15573/85.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.15575\n",
      "\tTraining time elapsed: 151.34 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.33986/61.00%, bp_loss: 2.38896/30.00%, hp_loss: 3.14305/21.00%, j_loss: 1.71361/61.00%, \n",
      "\t\tfr_loss: 0.17615/83.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 8.76166\n",
      "\tPart 2 - fp_loss: 1.17221/68.00%, bp_loss: 1.98460/42.00%, hp_loss: 2.75154/33.00%, j_loss: 1.42209/68.00%, \n",
      "\t\tfr_loss: 0.18221/81.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 7.51275\n",
      "\tPart 3 - fp_loss: 1.10664/68.00%, bp_loss: 1.86954/45.00%, hp_loss: 2.43637/38.00%, j_loss: 1.38390/68.00%, \n",
      "\t\tfr_loss: 0.17100/83.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 6.96751\n",
      "\tPart 4 - fp_loss: 1.15506/68.00%, bp_loss: 2.03538/41.00%, hp_loss: 2.67135/33.00%, j_loss: 1.44523/68.00%, \n",
      "\t\tfr_loss: 0.16242/83.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.46953\n",
      "\tTraining time elapsed: 188.90 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.43926/57.00%, bp_loss: 2.27104/32.00%, hp_loss: 3.01013/25.00%, j_loss: 1.80761/57.00%, \n",
      "\t\tfr_loss: 0.19255/81.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 8.72064\n",
      "\tPart 2 - fp_loss: 1.25829/64.00%, bp_loss: 2.03278/43.00%, hp_loss: 2.73884/32.00%, j_loss: 1.53129/64.00%, \n",
      "\t\tfr_loss: 0.20394/79.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 7.76527\n",
      "\tPart 3 - fp_loss: 1.18912/67.00%, bp_loss: 1.87773/44.00%, hp_loss: 2.42943/38.00%, j_loss: 1.41181/67.00%, \n",
      "\t\tfr_loss: 0.17555/83.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 7.08370\n",
      "\tPart 4 - fp_loss: 1.14694/67.00%, bp_loss: 2.04750/38.00%, hp_loss: 2.71221/31.00%, j_loss: 1.44677/67.00%, \n",
      "\t\tfr_loss: 0.16268/84.00%, p_loss: 0.00013/100.00%, \n",
      "\t\ttotal weighted loss: 7.51625\n",
      "\tTraining time elapsed: 226.46 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.39583/59.00%, bp_loss: 2.30301/33.00%, hp_loss: 3.08049/21.00%, j_loss: 1.72310/60.00%, \n",
      "\t\tfr_loss: 0.18448/81.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 8.68694\n",
      "\tPart 2 - fp_loss: 1.24365/64.00%, bp_loss: 2.04963/41.00%, hp_loss: 2.77474/31.00%, j_loss: 1.52581/64.00%, \n",
      "\t\tfr_loss: 0.19408/80.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.78803\n",
      "\tPart 3 - fp_loss: 1.21276/65.00%, bp_loss: 1.87085/45.00%, hp_loss: 2.43629/37.00%, j_loss: 1.42086/65.00%, \n",
      "\t\tfr_loss: 0.18849/81.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.12929\n",
      "\tPart 4 - fp_loss: 1.12246/69.00%, bp_loss: 1.98210/43.00%, hp_loss: 2.66189/32.00%, j_loss: 1.38714/69.00%, \n",
      "\t\tfr_loss: 0.16656/83.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 7.32024\n",
      "\tTraining time elapsed: 264.04 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.49838/56.00%, bp_loss: 2.35984/30.00%, hp_loss: 3.16168/20.00%, j_loss: 1.84912/56.00%, \n",
      "\t\tfr_loss: 0.20327/80.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 9.07232\n",
      "\tPart 2 - fp_loss: 1.24319/64.00%, bp_loss: 2.00939/41.00%, hp_loss: 2.79279/30.00%, j_loss: 1.48850/64.00%, \n",
      "\t\tfr_loss: 0.17144/83.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.70542\n",
      "\tPart 3 - fp_loss: 1.04527/72.00%, bp_loss: 1.78262/47.00%, hp_loss: 2.43356/38.00%, j_loss: 1.19051/72.00%, \n",
      "\t\tfr_loss: 0.17929/82.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.63130\n",
      "\tPart 4 - fp_loss: 1.05082/71.00%, bp_loss: 1.96397/41.00%, hp_loss: 2.70166/32.00%, j_loss: 1.33721/70.00%, \n",
      "\t\tfr_loss: 0.14549/85.00%, p_loss: 0.00013/100.00%, \n",
      "\t\ttotal weighted loss: 7.19926\n",
      "\tTraining time elapsed: 301.60 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.55052/52.00%, bp_loss: 2.72550/20.00%, hp_loss: 3.04004/25.00%, j_loss: 2.09034/51.00%, \n",
      "\t\tfr_loss: 0.22241/78.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 9.62883\n",
      "\tPart 2 - fp_loss: 1.22573/61.00%, bp_loss: 2.50719/30.00%, hp_loss: 2.72448/31.00%, j_loss: 1.70763/61.00%, \n",
      "\t\tfr_loss: 0.18943/81.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 8.35455\n",
      "\tPart 3 - fp_loss: 0.89075/73.00%, bp_loss: 2.24033/36.00%, hp_loss: 2.28926/42.00%, j_loss: 1.30693/72.00%, \n",
      "\t\tfr_loss: 0.17804/82.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.90535\n",
      "\tPart 4 - fp_loss: 1.00923/70.00%, bp_loss: 2.49700/32.00%, hp_loss: 2.44257/40.00%, j_loss: 1.51877/70.00%, \n",
      "\t\tfr_loss: 0.16887/83.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.63659\n",
      "\t`Validation time elapsed: 0.68 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.52922/51.00%, bp_loss: 2.43232/27.00%, hp_loss: 3.09754/21.00%, j_loss: 2.00225/51.00%, \n",
      "\t\tfr_loss: 0.19478/80.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 9.25615\n",
      "\tPart 2 - fp_loss: 1.23140/62.00%, bp_loss: 2.02863/40.00%, hp_loss: 2.79880/28.00%, j_loss: 1.60433/62.00%, \n",
      "\t\tfr_loss: 0.18905/81.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 7.85234\n",
      "\tPart 3 - fp_loss: 0.89892/73.00%, bp_loss: 1.83777/47.00%, hp_loss: 2.34788/41.00%, j_loss: 1.20644/73.00%, \n",
      "\t\tfr_loss: 0.17147/82.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.46253\n",
      "\tPart 4 - fp_loss: 0.94546/72.00%, bp_loss: 2.07778/41.00%, hp_loss: 2.46905/39.00%, j_loss: 1.32660/72.00%, \n",
      "\t\tfr_loss: 0.15053/85.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 6.96958\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 6.\n",
      "\n",
      "EPOCH 7\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.44941/56.00%, bp_loss: 2.69154/25.00%, hp_loss: 3.10332/22.00%, j_loss: 1.91278/55.00%, \n",
      "\t\tfr_loss: 0.21845/78.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 9.37553\n",
      "\tPart 2 - fp_loss: 1.18100/66.00%, bp_loss: 2.59958/29.00%, hp_loss: 2.79408/31.00%, j_loss: 1.61734/65.00%, \n",
      "\t\tfr_loss: 0.17740/82.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 8.36950\n",
      "\tPart 3 - fp_loss: 1.13948/69.00%, bp_loss: 2.33175/35.00%, hp_loss: 2.35410/40.00%, j_loss: 1.40766/69.00%, \n",
      "\t\tfr_loss: 0.17626/82.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.40929\n",
      "\tPart 4 - fp_loss: 0.95995/73.00%, bp_loss: 2.55748/31.00%, hp_loss: 2.60275/34.00%, j_loss: 1.34258/72.00%, \n",
      "\t\tfr_loss: 0.15655/84.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.61940\n",
      "\tTraining time elapsed: 1.03 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.45065/59.00%, bp_loss: 2.28986/34.00%, hp_loss: 3.06877/22.00%, j_loss: 1.76665/59.00%, \n",
      "\t\tfr_loss: 0.18984/81.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 8.76580\n",
      "\tPart 2 - fp_loss: 1.15222/66.00%, bp_loss: 1.96107/43.00%, hp_loss: 2.68142/32.00%, j_loss: 1.42924/66.00%, \n",
      "\t\tfr_loss: 0.19410/81.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.41814\n",
      "\tPart 3 - fp_loss: 1.13794/66.00%, bp_loss: 1.78622/45.00%, hp_loss: 2.38733/38.00%, j_loss: 1.37734/66.00%, \n",
      "\t\tfr_loss: 0.14915/85.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.83802\n",
      "\tPart 4 - fp_loss: 1.02996/71.00%, bp_loss: 1.90460/43.00%, hp_loss: 2.65139/32.00%, j_loss: 1.29019/70.00%, \n",
      "\t\tfr_loss: 0.16177/83.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 7.03803\n",
      "\tTraining time elapsed: 38.58 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.30564/61.00%, bp_loss: 2.32607/32.00%, hp_loss: 3.11442/22.00%, j_loss: 1.68381/60.00%, \n",
      "\t\tfr_loss: 0.20696/79.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 8.63695\n",
      "\tPart 2 - fp_loss: 1.19961/65.00%, bp_loss: 2.06555/42.00%, hp_loss: 2.77531/31.00%, j_loss: 1.52501/65.00%, \n",
      "\t\tfr_loss: 0.17299/83.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.73855\n",
      "\tPart 3 - fp_loss: 1.16951/67.00%, bp_loss: 1.92955/44.00%, hp_loss: 2.51424/36.00%, j_loss: 1.38379/67.00%, \n",
      "\t\tfr_loss: 0.17603/82.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.17316\n",
      "\tPart 4 - fp_loss: 1.05654/70.00%, bp_loss: 2.04531/40.00%, hp_loss: 2.68662/31.00%, j_loss: 1.39729/70.00%, \n",
      "\t\tfr_loss: 0.15032/85.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 7.33619\n",
      "\tTraining time elapsed: 76.12 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.38316/59.00%, bp_loss: 2.32452/32.00%, hp_loss: 3.06489/23.00%, j_loss: 1.72339/59.00%, \n",
      "\t\tfr_loss: 0.18476/82.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 8.68075\n",
      "\tPart 2 - fp_loss: 1.14617/66.00%, bp_loss: 1.96136/41.00%, hp_loss: 2.68537/34.00%, j_loss: 1.45314/66.00%, \n",
      "\t\tfr_loss: 0.18762/81.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.43373\n",
      "\tPart 3 - fp_loss: 1.19807/66.00%, bp_loss: 1.89211/45.00%, hp_loss: 2.40533/39.00%, j_loss: 1.40787/67.00%, \n",
      "\t\tfr_loss: 0.18931/81.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.09274\n",
      "\tPart 4 - fp_loss: 1.07068/71.00%, bp_loss: 2.00036/42.00%, hp_loss: 2.66860/32.00%, j_loss: 1.33095/70.00%, \n",
      "\t\tfr_loss: 0.17568/82.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.24634\n",
      "\tTraining time elapsed: 113.70 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.34075/60.00%, bp_loss: 2.29496/34.00%, hp_loss: 3.02867/25.00%, j_loss: 1.66215/60.00%, \n",
      "\t\tfr_loss: 0.22753/77.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 8.55409\n",
      "\tPart 2 - fp_loss: 1.16189/67.00%, bp_loss: 1.97431/43.00%, hp_loss: 2.73525/33.00%, j_loss: 1.43139/67.00%, \n",
      "\t\tfr_loss: 0.19439/80.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.49729\n",
      "\tPart 3 - fp_loss: 1.11624/69.00%, bp_loss: 1.86211/46.00%, hp_loss: 2.43940/36.00%, j_loss: 1.35170/69.00%, \n",
      "\t\tfr_loss: 0.19864/80.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 6.96813\n",
      "\tPart 4 - fp_loss: 1.07338/70.00%, bp_loss: 2.01754/42.00%, hp_loss: 2.65585/34.00%, j_loss: 1.37544/70.00%, \n",
      "\t\tfr_loss: 0.16670/83.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.28900\n",
      "\tTraining time elapsed: 151.27 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.29442/62.00%, bp_loss: 2.28424/33.00%, hp_loss: 3.10674/20.00%, j_loss: 1.68224/62.00%, \n",
      "\t\tfr_loss: 0.17099/83.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 8.53864\n",
      "\tPart 2 - fp_loss: 1.14125/67.00%, bp_loss: 1.95314/40.00%, hp_loss: 2.74897/32.00%, j_loss: 1.45385/67.00%, \n",
      "\t\tfr_loss: 0.18542/81.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.48271\n",
      "\tPart 3 - fp_loss: 1.08768/69.00%, bp_loss: 1.78748/48.00%, hp_loss: 2.39960/39.00%, j_loss: 1.29994/69.00%, \n",
      "\t\tfr_loss: 0.17684/82.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.75158\n",
      "\tPart 4 - fp_loss: 0.96906/73.00%, bp_loss: 1.94676/42.00%, hp_loss: 2.63787/34.00%, j_loss: 1.20343/73.00%, \n",
      "\t\tfr_loss: 0.16453/83.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 6.92170\n",
      "\tTraining time elapsed: 188.83 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.34959/60.00%, bp_loss: 2.27541/33.00%, hp_loss: 3.06033/22.00%, j_loss: 1.72868/60.00%, \n",
      "\t\tfr_loss: 0.19996/80.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 8.61400\n",
      "\tPart 2 - fp_loss: 1.13144/67.00%, bp_loss: 1.98287/40.00%, hp_loss: 2.74265/31.00%, j_loss: 1.45998/67.00%, \n",
      "\t\tfr_loss: 0.20132/80.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.51833\n",
      "\tPart 3 - fp_loss: 1.10062/69.00%, bp_loss: 1.78497/47.00%, hp_loss: 2.45724/38.00%, j_loss: 1.35656/69.00%, \n",
      "\t\tfr_loss: 0.17356/82.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 6.87299\n",
      "\tPart 4 - fp_loss: 1.07656/72.00%, bp_loss: 2.04897/41.00%, hp_loss: 2.61836/33.00%, j_loss: 1.27019/71.00%, \n",
      "\t\tfr_loss: 0.15062/85.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.16479\n",
      "\tTraining time elapsed: 226.38 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.44115/58.00%, bp_loss: 2.26256/33.00%, hp_loss: 3.07178/23.00%, j_loss: 1.80321/58.00%, \n",
      "\t\tfr_loss: 0.19098/80.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.76971\n",
      "\tPart 2 - fp_loss: 1.18321/65.00%, bp_loss: 1.93307/42.00%, hp_loss: 2.74737/33.00%, j_loss: 1.47350/65.00%, \n",
      "\t\tfr_loss: 0.18891/81.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 7.52613\n",
      "\tPart 3 - fp_loss: 1.14473/67.00%, bp_loss: 1.84463/46.00%, hp_loss: 2.50797/33.00%, j_loss: 1.39476/67.00%, \n",
      "\t\tfr_loss: 0.16352/83.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.05565\n",
      "\tPart 4 - fp_loss: 1.04907/70.00%, bp_loss: 1.91062/44.00%, hp_loss: 2.69859/31.00%, j_loss: 1.37001/69.00%, \n",
      "\t\tfr_loss: 0.15059/84.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.17895\n",
      "\tTraining time elapsed: 263.95 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.41070/59.00%, bp_loss: 2.40669/29.00%, hp_loss: 3.15324/21.00%, j_loss: 1.82800/58.00%, \n",
      "\t\tfr_loss: 0.19025/81.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.98890\n",
      "\tPart 2 - fp_loss: 1.21956/64.00%, bp_loss: 1.95907/41.00%, hp_loss: 2.78316/31.00%, j_loss: 1.54109/64.00%, \n",
      "\t\tfr_loss: 0.16498/83.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.66793\n",
      "\tPart 3 - fp_loss: 1.08327/69.00%, bp_loss: 1.78433/45.00%, hp_loss: 2.36295/40.00%, j_loss: 1.36444/70.00%, \n",
      "\t\tfr_loss: 0.15231/84.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.74732\n",
      "\tPart 4 - fp_loss: 1.02748/70.00%, bp_loss: 1.89795/45.00%, hp_loss: 2.56479/36.00%, j_loss: 1.28179/70.00%, \n",
      "\t\tfr_loss: 0.13899/86.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 6.91106\n",
      "\tTraining time elapsed: 301.49 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.52473/52.00%, bp_loss: 2.80040/20.00%, hp_loss: 3.11404/20.00%, j_loss: 2.08147/52.00%, \n",
      "\t\tfr_loss: 0.18537/81.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 9.70604\n",
      "\tPart 2 - fp_loss: 1.20266/62.00%, bp_loss: 2.51461/28.00%, hp_loss: 2.72872/29.00%, j_loss: 1.69405/62.00%, \n",
      "\t\tfr_loss: 0.18996/80.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 8.33006\n",
      "\tPart 3 - fp_loss: 0.89569/73.00%, bp_loss: 2.26029/39.00%, hp_loss: 2.32125/42.00%, j_loss: 1.27315/72.00%, \n",
      "\t\tfr_loss: 0.18341/81.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.93382\n",
      "\tPart 4 - fp_loss: 0.96245/72.00%, bp_loss: 2.53076/32.00%, hp_loss: 2.42912/39.00%, j_loss: 1.42748/72.00%, \n",
      "\t\tfr_loss: 0.18862/81.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.53855\n",
      "\t`Validation time elapsed: 0.70 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.51689/53.00%, bp_loss: 2.34118/29.00%, hp_loss: 3.01593/25.00%, j_loss: 1.92164/53.00%, \n",
      "\t\tfr_loss: 0.21545/78.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 9.01112\n",
      "\tPart 2 - fp_loss: 1.18276/63.00%, bp_loss: 2.04779/38.00%, hp_loss: 2.68295/32.00%, j_loss: 1.54343/63.00%, \n",
      "\t\tfr_loss: 0.20991/79.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 7.66689\n",
      "\tPart 3 - fp_loss: 0.90026/72.00%, bp_loss: 1.73042/49.00%, hp_loss: 2.18124/46.00%, j_loss: 1.19871/72.00%, \n",
      "\t\tfr_loss: 0.18945/81.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.20011\n",
      "\tPart 4 - fp_loss: 1.02278/73.00%, bp_loss: 2.03284/41.00%, hp_loss: 2.35934/42.00%, j_loss: 1.26600/73.00%, \n",
      "\t\tfr_loss: 0.18742/81.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 6.86850\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 7.\n",
      "\n",
      "EPOCH 8\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.31737/62.00%, bp_loss: 2.71297/24.00%, hp_loss: 3.08295/21.00%, j_loss: 1.75661/62.00%, \n",
      "\t\tfr_loss: 0.18852/81.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 9.05844\n",
      "\tPart 2 - fp_loss: 1.15936/66.00%, bp_loss: 2.47684/33.00%, hp_loss: 2.75791/31.00%, j_loss: 1.55621/66.00%, \n",
      "\t\tfr_loss: 0.18731/81.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 8.13770\n",
      "\tPart 3 - fp_loss: 1.13147/68.00%, bp_loss: 2.40719/32.00%, hp_loss: 2.40348/36.00%, j_loss: 1.45232/68.00%, \n",
      "\t\tfr_loss: 0.18245/81.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.57695\n",
      "\tPart 4 - fp_loss: 1.05586/70.00%, bp_loss: 2.57570/28.00%, hp_loss: 2.63295/34.00%, j_loss: 1.49890/69.00%, \n",
      "\t\tfr_loss: 0.14476/85.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.90824\n",
      "\tTraining time elapsed: 1.03 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.36646/60.00%, bp_loss: 2.35119/31.00%, hp_loss: 3.09350/22.00%, j_loss: 1.76559/60.00%, \n",
      "\t\tfr_loss: 0.16972/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.74647\n",
      "\tPart 2 - fp_loss: 1.13922/67.00%, bp_loss: 1.94025/44.00%, hp_loss: 2.75019/31.00%, j_loss: 1.39725/67.00%, \n",
      "\t\tfr_loss: 0.18099/81.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 7.40796\n",
      "\tPart 3 - fp_loss: 1.11094/70.00%, bp_loss: 1.81028/45.00%, hp_loss: 2.37111/38.00%, j_loss: 1.31976/69.00%, \n",
      "\t\tfr_loss: 0.17992/82.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.79204\n",
      "\tPart 4 - fp_loss: 1.03152/72.00%, bp_loss: 1.92040/44.00%, hp_loss: 2.67179/33.00%, j_loss: 1.28317/72.00%, \n",
      "\t\tfr_loss: 0.13407/86.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 7.04101\n",
      "\tTraining time elapsed: 38.55 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.25369/64.00%, bp_loss: 2.25731/33.00%, hp_loss: 3.06546/22.00%, j_loss: 1.60086/64.00%, \n",
      "\t\tfr_loss: 0.19746/80.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.37481\n",
      "\tPart 2 - fp_loss: 1.09513/67.00%, bp_loss: 2.00772/43.00%, hp_loss: 2.74338/33.00%, j_loss: 1.39699/67.00%, \n",
      "\t\tfr_loss: 0.18289/81.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.42616\n",
      "\tPart 3 - fp_loss: 0.98331/72.00%, bp_loss: 1.83177/46.00%, hp_loss: 2.44843/38.00%, j_loss: 1.19997/73.00%, \n",
      "\t\tfr_loss: 0.14146/85.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.60496\n",
      "\tPart 4 - fp_loss: 1.05006/71.00%, bp_loss: 1.98234/42.00%, hp_loss: 2.65834/33.00%, j_loss: 1.28526/71.00%, \n",
      "\t\tfr_loss: 0.13174/87.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.10781\n",
      "\tTraining time elapsed: 76.06 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.38250/61.00%, bp_loss: 2.29090/33.00%, hp_loss: 3.09156/22.00%, j_loss: 1.68463/61.00%, \n",
      "\t\tfr_loss: 0.17388/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.62350\n",
      "\tPart 2 - fp_loss: 1.12729/68.00%, bp_loss: 1.92130/42.00%, hp_loss: 2.68662/33.00%, j_loss: 1.39695/68.00%, \n",
      "\t\tfr_loss: 0.19971/80.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.33190\n",
      "\tPart 3 - fp_loss: 1.10944/68.00%, bp_loss: 1.81087/47.00%, hp_loss: 2.43839/36.00%, j_loss: 1.30454/68.00%, \n",
      "\t\tfr_loss: 0.15940/84.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.82266\n",
      "\tPart 4 - fp_loss: 1.07039/70.00%, bp_loss: 1.96746/43.00%, hp_loss: 2.59643/33.00%, j_loss: 1.35526/70.00%, \n",
      "\t\tfr_loss: 0.15863/84.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 7.14822\n",
      "\tTraining time elapsed: 113.59 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.38016/60.00%, bp_loss: 2.38199/29.00%, hp_loss: 3.11610/20.00%, j_loss: 1.80333/59.00%, \n",
      "\t\tfr_loss: 0.19190/80.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.87350\n",
      "\tPart 2 - fp_loss: 1.08902/71.00%, bp_loss: 1.95258/43.00%, hp_loss: 2.77230/31.00%, j_loss: 1.28325/71.00%, \n",
      "\t\tfr_loss: 0.17083/83.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.26802\n",
      "\tPart 3 - fp_loss: 1.10661/70.00%, bp_loss: 1.82338/45.00%, hp_loss: 2.44589/37.00%, j_loss: 1.26631/70.00%, \n",
      "\t\tfr_loss: 0.18372/81.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.82594\n",
      "\tPart 4 - fp_loss: 1.00344/71.00%, bp_loss: 1.98374/41.00%, hp_loss: 2.74167/29.00%, j_loss: 1.30282/70.00%, \n",
      "\t\tfr_loss: 0.14373/85.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 7.17545\n",
      "\tTraining time elapsed: 151.13 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.29722/61.00%, bp_loss: 2.27364/35.00%, hp_loss: 3.04128/24.00%, j_loss: 1.65622/61.00%, \n",
      "\t\tfr_loss: 0.18428/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.45266\n",
      "\tPart 2 - fp_loss: 1.28874/63.00%, bp_loss: 2.02127/42.00%, hp_loss: 2.73448/31.00%, j_loss: 1.58018/63.00%, \n",
      "\t\tfr_loss: 0.17824/82.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.80294\n",
      "\tPart 3 - fp_loss: 1.13993/68.00%, bp_loss: 1.81133/47.00%, hp_loss: 2.42196/39.00%, j_loss: 1.33338/69.00%, \n",
      "\t\tfr_loss: 0.17013/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.87675\n",
      "\tPart 4 - fp_loss: 1.06529/71.00%, bp_loss: 1.95532/43.00%, hp_loss: 2.63397/34.00%, j_loss: 1.31320/70.00%, \n",
      "\t\tfr_loss: 0.13683/86.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.10466\n",
      "\tTraining time elapsed: 188.64 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.39759/57.00%, bp_loss: 2.27599/34.00%, hp_loss: 3.04820/24.00%, j_loss: 1.79607/57.00%, \n",
      "\t\tfr_loss: 0.19816/80.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.71602\n",
      "\tPart 2 - fp_loss: 1.14395/67.00%, bp_loss: 1.97148/41.00%, hp_loss: 2.70187/33.00%, j_loss: 1.44567/67.00%, \n",
      "\t\tfr_loss: 0.18659/81.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.44961\n",
      "\tPart 3 - fp_loss: 1.11424/69.00%, bp_loss: 1.74427/49.00%, hp_loss: 2.36831/39.00%, j_loss: 1.32430/69.00%, \n",
      "\t\tfr_loss: 0.17186/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.72300\n",
      "\tPart 4 - fp_loss: 0.99866/72.00%, bp_loss: 1.92286/45.00%, hp_loss: 2.59220/36.00%, j_loss: 1.23740/72.00%, \n",
      "\t\tfr_loss: 0.14485/85.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.89602\n",
      "\tTraining time elapsed: 226.19 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.32856/61.00%, bp_loss: 2.24935/33.00%, hp_loss: 3.11165/20.00%, j_loss: 1.68327/61.00%, \n",
      "\t\tfr_loss: 0.18537/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.55821\n",
      "\tPart 2 - fp_loss: 1.13244/67.00%, bp_loss: 1.92740/44.00%, hp_loss: 2.73243/32.00%, j_loss: 1.40585/67.00%, \n",
      "\t\tfr_loss: 0.16516/83.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.36333\n",
      "\tPart 3 - fp_loss: 1.02952/71.00%, bp_loss: 1.80765/49.00%, hp_loss: 2.40516/38.00%, j_loss: 1.23616/71.00%, \n",
      "\t\tfr_loss: 0.13761/86.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.61611\n",
      "\tPart 4 - fp_loss: 1.02880/71.00%, bp_loss: 1.94231/44.00%, hp_loss: 2.59896/33.00%, j_loss: 1.28188/71.00%, \n",
      "\t\tfr_loss: 0.15862/84.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.01063\n",
      "\tTraining time elapsed: 263.73 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.38776/58.00%, bp_loss: 2.25460/33.00%, hp_loss: 3.09423/21.00%, j_loss: 1.74719/58.00%, \n",
      "\t\tfr_loss: 0.17832/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.66212\n",
      "\tPart 2 - fp_loss: 1.17889/66.00%, bp_loss: 2.02691/40.00%, hp_loss: 2.76663/32.00%, j_loss: 1.51485/66.00%, \n",
      "\t\tfr_loss: 0.18647/81.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.67379\n",
      "\tPart 3 - fp_loss: 1.11144/68.00%, bp_loss: 1.70704/48.00%, hp_loss: 2.39238/41.00%, j_loss: 1.23379/69.00%, \n",
      "\t\tfr_loss: 0.16621/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.61088\n",
      "\tPart 4 - fp_loss: 1.01595/72.00%, bp_loss: 1.91353/44.00%, hp_loss: 2.65264/34.00%, j_loss: 1.22437/72.00%, \n",
      "\t\tfr_loss: 0.14790/85.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 6.95447\n",
      "\tTraining time elapsed: 301.24 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.49014/57.00%, bp_loss: 2.68346/23.00%, hp_loss: 3.07650/23.00%, j_loss: 1.93529/56.00%, \n",
      "\t\tfr_loss: 0.19790/79.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 9.38330\n",
      "\tPart 2 - fp_loss: 1.15951/64.00%, bp_loss: 2.36218/33.00%, hp_loss: 2.68212/31.00%, j_loss: 1.54407/64.00%, \n",
      "\t\tfr_loss: 0.19579/80.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.94371\n",
      "\tPart 3 - fp_loss: 0.86229/73.00%, bp_loss: 2.18134/38.00%, hp_loss: 2.27842/43.00%, j_loss: 1.29155/72.00%, \n",
      "\t\tfr_loss: 0.16768/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.78130\n",
      "\tPart 4 - fp_loss: 1.04343/70.00%, bp_loss: 2.48852/33.00%, hp_loss: 2.40788/41.00%, j_loss: 1.54257/70.00%, \n",
      "\t\tfr_loss: 0.17048/83.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 7.65296\n",
      "\t`Validation time elapsed: 0.70 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.50850/54.00%, bp_loss: 2.30165/27.00%, hp_loss: 3.04665/22.00%, j_loss: 1.89202/54.00%, \n",
      "\t\tfr_loss: 0.20202/80.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.95085\n",
      "\tPart 2 - fp_loss: 1.34808/57.00%, bp_loss: 2.11562/37.00%, hp_loss: 2.82778/27.00%, j_loss: 1.73163/57.00%, \n",
      "\t\tfr_loss: 0.19756/80.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 8.22070\n",
      "\tPart 3 - fp_loss: 0.95812/71.00%, bp_loss: 1.77615/48.00%, hp_loss: 2.31462/41.00%, j_loss: 1.23721/71.00%, \n",
      "\t\tfr_loss: 0.17929/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.46542\n",
      "\tPart 4 - fp_loss: 1.05500/70.00%, bp_loss: 2.04955/41.00%, hp_loss: 2.51389/36.00%, j_loss: 1.38707/70.00%, \n",
      "\t\tfr_loss: 0.16552/83.00%, p_loss: 0.00008/100.00%, \n",
      "\t\ttotal weighted loss: 7.17112\n",
      "\t`Validation time elapsed: 9.45 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 8.\n",
      "\n",
      "EPOCH 9\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.29115/61.00%, bp_loss: 2.73029/24.00%, hp_loss: 3.07583/23.00%, j_loss: 1.76106/61.00%, \n",
      "\t\tfr_loss: 0.18605/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 9.04439\n",
      "\tPart 2 - fp_loss: 1.11387/68.00%, bp_loss: 2.46888/32.00%, hp_loss: 2.75108/30.00%, j_loss: 1.52522/68.00%, \n",
      "\t\tfr_loss: 0.17440/82.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 8.03350\n",
      "\tPart 3 - fp_loss: 1.02407/72.00%, bp_loss: 2.23713/38.00%, hp_loss: 2.43433/38.00%, j_loss: 1.31592/71.00%, \n",
      "\t\tfr_loss: 0.15452/84.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.16600\n",
      "\tPart 4 - fp_loss: 0.99197/73.00%, bp_loss: 2.54346/32.00%, hp_loss: 2.60243/34.00%, j_loss: 1.37559/72.00%, \n",
      "\t\tfr_loss: 0.14763/85.00%, p_loss: 0.00007/100.00%, \n",
      "\t\ttotal weighted loss: 7.66114\n",
      "\tTraining time elapsed: 1.03 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.29814/62.00%, bp_loss: 2.26135/34.00%, hp_loss: 3.07056/22.00%, j_loss: 1.64920/62.00%, \n",
      "\t\tfr_loss: 0.17010/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.44937\n",
      "\tPart 2 - fp_loss: 1.11469/69.00%, bp_loss: 1.91392/44.00%, hp_loss: 2.79626/30.00%, j_loss: 1.35853/68.00%, \n",
      "\t\tfr_loss: 0.18840/81.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.37184\n",
      "\tPart 3 - fp_loss: 1.12125/70.00%, bp_loss: 1.77295/47.00%, hp_loss: 2.47713/38.00%, j_loss: 1.27719/70.00%, \n",
      "\t\tfr_loss: 0.16130/84.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.80985\n",
      "\tPart 4 - fp_loss: 1.00568/71.00%, bp_loss: 1.87836/44.00%, hp_loss: 2.60417/34.00%, j_loss: 1.27173/71.00%, \n",
      "\t\tfr_loss: 0.15167/84.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 6.91166\n",
      "\tTraining time elapsed: 38.61 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.29379/63.00%, bp_loss: 2.26511/33.00%, hp_loss: 3.09777/23.00%, j_loss: 1.60550/63.00%, \n",
      "\t\tfr_loss: 0.18581/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.44799\n",
      "\tPart 2 - fp_loss: 1.13734/69.00%, bp_loss: 1.96079/42.00%, hp_loss: 2.76448/32.00%, j_loss: 1.35157/69.00%, \n",
      "\t\tfr_loss: 0.16847/83.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.38271\n",
      "\tPart 3 - fp_loss: 1.05848/70.00%, bp_loss: 1.75341/49.00%, hp_loss: 2.36575/40.00%, j_loss: 1.25852/70.00%, \n",
      "\t\tfr_loss: 0.16801/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.60419\n",
      "\tPart 4 - fp_loss: 1.00468/72.00%, bp_loss: 1.99882/41.00%, hp_loss: 2.61286/32.00%, j_loss: 1.26948/72.00%, \n",
      "\t\tfr_loss: 0.13406/86.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.01995\n",
      "\tTraining time elapsed: 76.19 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.31656/60.00%, bp_loss: 2.24099/32.00%, hp_loss: 3.09181/21.00%, j_loss: 1.71354/60.00%, \n",
      "\t\tfr_loss: 0.16953/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.53244\n",
      "\tPart 2 - fp_loss: 1.01331/69.00%, bp_loss: 1.83975/45.00%, hp_loss: 2.65619/35.00%, j_loss: 1.31410/69.00%, \n",
      "\t\tfr_loss: 0.18233/81.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.00572\n",
      "\tPart 3 - fp_loss: 1.05136/72.00%, bp_loss: 1.73265/50.00%, hp_loss: 2.46828/37.00%, j_loss: 1.18045/72.00%, \n",
      "\t\tfr_loss: 0.15610/84.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.58886\n",
      "\tPart 4 - fp_loss: 1.01465/72.00%, bp_loss: 1.93430/44.00%, hp_loss: 2.60022/34.00%, j_loss: 1.21521/73.00%, \n",
      "\t\tfr_loss: 0.13112/87.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 6.89555\n",
      "\tTraining time elapsed: 113.76 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.37605/59.00%, bp_loss: 2.30676/31.00%, hp_loss: 3.12993/20.00%, j_loss: 1.77921/59.00%, \n",
      "\t\tfr_loss: 0.18811/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.78007\n",
      "\tPart 2 - fp_loss: 1.21721/64.00%, bp_loss: 1.93861/42.00%, hp_loss: 2.77127/30.00%, j_loss: 1.49021/64.00%, \n",
      "\t\tfr_loss: 0.17748/82.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.59481\n",
      "\tPart 3 - fp_loss: 1.00681/72.00%, bp_loss: 1.73044/51.00%, hp_loss: 2.37657/38.00%, j_loss: 1.13855/72.00%, \n",
      "\t\tfr_loss: 0.14670/85.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.39908\n",
      "\tPart 4 - fp_loss: 0.97678/72.00%, bp_loss: 1.95953/42.00%, hp_loss: 2.65440/32.00%, j_loss: 1.23262/72.00%, \n",
      "\t\tfr_loss: 0.13853/86.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.96192\n",
      "\tTraining time elapsed: 151.30 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.41072/59.00%, bp_loss: 2.29058/33.00%, hp_loss: 3.05979/23.00%, j_loss: 1.74418/59.00%, \n",
      "\t\tfr_loss: 0.19575/80.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.70103\n",
      "\tPart 2 - fp_loss: 1.15860/65.00%, bp_loss: 1.93544/43.00%, hp_loss: 2.77274/32.00%, j_loss: 1.49383/65.00%, \n",
      "\t\tfr_loss: 0.15913/85.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.51976\n",
      "\tPart 3 - fp_loss: 1.07719/70.00%, bp_loss: 1.77680/48.00%, hp_loss: 2.43188/36.00%, j_loss: 1.23360/70.00%, \n",
      "\t\tfr_loss: 0.17072/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.69019\n",
      "\tPart 4 - fp_loss: 0.93287/75.00%, bp_loss: 1.96242/42.00%, hp_loss: 2.61623/33.00%, j_loss: 1.17269/74.00%, \n",
      "\t\tfr_loss: 0.13411/87.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.81834\n",
      "\tTraining time elapsed: 188.87 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.22553/64.00%, bp_loss: 2.25665/35.00%, hp_loss: 3.06235/23.00%, j_loss: 1.54728/64.00%, \n",
      "\t\tfr_loss: 0.18780/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.27962\n",
      "\tPart 2 - fp_loss: 1.07230/70.00%, bp_loss: 1.97853/41.00%, hp_loss: 2.69548/32.00%, j_loss: 1.35231/69.00%, \n",
      "\t\tfr_loss: 0.17287/83.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.27151\n",
      "\tPart 3 - fp_loss: 1.12718/67.00%, bp_loss: 1.78010/46.00%, hp_loss: 2.48482/36.00%, j_loss: 1.35766/68.00%, \n",
      "\t\tfr_loss: 0.16103/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.91080\n",
      "\tPart 4 - fp_loss: 1.02054/71.00%, bp_loss: 1.92586/43.00%, hp_loss: 2.57205/36.00%, j_loss: 1.25562/72.00%, \n",
      "\t\tfr_loss: 0.13462/86.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.90873\n",
      "\tTraining time elapsed: 226.43 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.34646/60.00%, bp_loss: 2.33796/30.00%, hp_loss: 3.13818/19.00%, j_loss: 1.73051/60.00%, \n",
      "\t\tfr_loss: 0.17341/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.72653\n",
      "\tPart 2 - fp_loss: 1.15317/65.00%, bp_loss: 1.93864/43.00%, hp_loss: 2.84546/30.00%, j_loss: 1.43222/65.00%, \n",
      "\t\tfr_loss: 0.19461/80.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.56412\n",
      "\tPart 3 - fp_loss: 1.09837/69.00%, bp_loss: 1.75145/48.00%, hp_loss: 2.49785/35.00%, j_loss: 1.30895/69.00%, \n",
      "\t\tfr_loss: 0.15762/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.81425\n",
      "\tPart 4 - fp_loss: 0.99756/72.00%, bp_loss: 1.90441/45.00%, hp_loss: 2.60843/35.00%, j_loss: 1.23174/72.00%, \n",
      "\t\tfr_loss: 0.14604/85.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 6.88822\n",
      "\tTraining time elapsed: 263.98 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.29071/60.00%, bp_loss: 2.30798/32.00%, hp_loss: 3.10322/22.00%, j_loss: 1.67942/60.00%, \n",
      "\t\tfr_loss: 0.16500/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.54634\n",
      "\tPart 2 - fp_loss: 1.04852/69.00%, bp_loss: 1.99994/41.00%, hp_loss: 2.75159/30.00%, j_loss: 1.34384/69.00%, \n",
      "\t\tfr_loss: 0.17681/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.32072\n",
      "\tPart 3 - fp_loss: 1.08427/70.00%, bp_loss: 1.68160/48.00%, hp_loss: 2.47008/36.00%, j_loss: 1.23080/71.00%, \n",
      "\t\tfr_loss: 0.16303/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.62979\n",
      "\tPart 4 - fp_loss: 0.98814/72.00%, bp_loss: 2.02524/39.00%, hp_loss: 2.73478/31.00%, j_loss: 1.29605/71.00%, \n",
      "\t\tfr_loss: 0.14212/85.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.18635\n",
      "\tTraining time elapsed: 301.52 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.51142/54.00%, bp_loss: 2.67427/23.00%, hp_loss: 3.08859/21.00%, j_loss: 1.97545/54.00%, \n",
      "\t\tfr_loss: 0.22742/77.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 9.47716\n",
      "\tPart 2 - fp_loss: 1.28775/62.00%, bp_loss: 2.49418/30.00%, hp_loss: 2.81470/29.00%, j_loss: 1.73757/61.00%, \n",
      "\t\tfr_loss: 0.18088/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.51511\n",
      "\tPart 3 - fp_loss: 0.96677/71.00%, bp_loss: 2.24856/35.00%, hp_loss: 2.32988/44.00%, j_loss: 1.38427/71.00%, \n",
      "\t\tfr_loss: 0.15899/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.08848\n",
      "\tPart 4 - fp_loss: 1.02190/70.00%, bp_loss: 2.58819/30.00%, hp_loss: 2.48467/40.00%, j_loss: 1.49792/70.00%, \n",
      "\t\tfr_loss: 0.18990/81.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.78262\n",
      "\t`Validation time elapsed: 0.69 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.52409/55.00%, bp_loss: 2.31163/30.00%, hp_loss: 3.00923/25.00%, j_loss: 1.89563/55.00%, \n",
      "\t\tfr_loss: 0.21834/78.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.95894\n",
      "\tPart 2 - fp_loss: 1.27590/61.00%, bp_loss: 2.04745/38.00%, hp_loss: 2.72346/30.00%, j_loss: 1.65217/61.00%, \n",
      "\t\tfr_loss: 0.18982/80.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.88882\n",
      "\tPart 3 - fp_loss: 0.86248/75.00%, bp_loss: 1.65817/52.00%, hp_loss: 2.25971/43.00%, j_loss: 1.04952/75.00%, \n",
      "\t\tfr_loss: 0.15798/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 5.98787\n",
      "\tPart 4 - fp_loss: 1.00769/71.00%, bp_loss: 2.01367/41.00%, hp_loss: 2.43259/39.00%, j_loss: 1.36882/71.00%, \n",
      "\t\tfr_loss: 0.15805/84.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 6.98086\n",
      "\t`Validation time elapsed: 9.45 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Completed epoch 9.\n",
      "\n",
      "EPOCH 10\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.24087/63.00%, bp_loss: 2.68628/25.00%, hp_loss: 3.04707/24.00%, j_loss: 1.73751/63.00%, \n",
      "\t\tfr_loss: 0.18744/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.89917\n",
      "\tPart 2 - fp_loss: 1.10439/68.00%, bp_loss: 2.43464/30.00%, hp_loss: 2.80855/30.00%, j_loss: 1.52075/68.00%, \n",
      "\t\tfr_loss: 0.17207/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.04043\n",
      "\tPart 3 - fp_loss: 1.02693/70.00%, bp_loss: 2.41222/33.00%, hp_loss: 2.50314/36.00%, j_loss: 1.36599/70.00%, \n",
      "\t\tfr_loss: 0.15610/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.46439\n",
      "\tPart 4 - fp_loss: 0.90793/75.00%, bp_loss: 2.49326/32.00%, hp_loss: 2.69927/31.00%, j_loss: 1.33623/74.00%, \n",
      "\t\tfr_loss: 0.12913/87.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.56586\n",
      "\tTraining time elapsed: 1.05 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.23377/61.00%, bp_loss: 2.27931/35.00%, hp_loss: 3.09866/21.00%, j_loss: 1.66611/61.00%, \n",
      "\t\tfr_loss: 0.17091/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.44877\n",
      "\tPart 2 - fp_loss: 1.14748/65.00%, bp_loss: 1.92298/42.00%, hp_loss: 2.76181/30.00%, j_loss: 1.44446/65.00%, \n",
      "\t\tfr_loss: 0.16889/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.44563\n",
      "\tPart 3 - fp_loss: 1.03979/70.00%, bp_loss: 1.67247/50.00%, hp_loss: 2.43247/36.00%, j_loss: 1.23867/70.00%, \n",
      "\t\tfr_loss: 0.14103/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.52444\n",
      "\tPart 4 - fp_loss: 1.00684/73.00%, bp_loss: 1.90943/45.00%, hp_loss: 2.58968/35.00%, j_loss: 1.18323/73.00%, \n",
      "\t\tfr_loss: 0.12834/87.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 6.81755\n",
      "\tTraining time elapsed: 38.58 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.28031/62.00%, bp_loss: 2.29304/31.00%, hp_loss: 3.08897/20.00%, j_loss: 1.65391/62.00%, \n",
      "\t\tfr_loss: 0.17898/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.49521\n",
      "\tPart 2 - fp_loss: 1.10379/67.00%, bp_loss: 1.90222/43.00%, hp_loss: 2.77050/31.00%, j_loss: 1.39541/67.00%, \n",
      "\t\tfr_loss: 0.17163/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.34356\n",
      "\tPart 3 - fp_loss: 1.05340/70.00%, bp_loss: 1.63569/52.00%, hp_loss: 2.39008/39.00%, j_loss: 1.23498/70.00%, \n",
      "\t\tfr_loss: 0.15058/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.46474\n",
      "\tPart 4 - fp_loss: 0.97711/74.00%, bp_loss: 1.86453/46.00%, hp_loss: 2.62028/34.00%, j_loss: 1.16383/73.00%, \n",
      "\t\tfr_loss: 0.15088/85.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 6.77668\n",
      "\tTraining time elapsed: 76.13 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.33989/61.00%, bp_loss: 2.28143/32.00%, hp_loss: 3.09305/21.00%, j_loss: 1.64789/60.00%, \n",
      "\t\tfr_loss: 0.17450/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.53677\n",
      "\tPart 2 - fp_loss: 1.13443/70.00%, bp_loss: 1.82503/45.00%, hp_loss: 2.70744/33.00%, j_loss: 1.33478/70.00%, \n",
      "\t\tfr_loss: 0.17336/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.17507\n",
      "\tPart 3 - fp_loss: 0.96362/74.00%, bp_loss: 1.59343/53.00%, hp_loss: 2.35182/40.00%, j_loss: 1.08173/74.00%, \n",
      "\t\tfr_loss: 0.13934/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.12996\n",
      "\tPart 4 - fp_loss: 0.97718/72.00%, bp_loss: 1.94700/43.00%, hp_loss: 2.60908/33.00%, j_loss: 1.27068/72.00%, \n",
      "\t\tfr_loss: 0.13015/87.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.93413\n",
      "\tTraining time elapsed: 113.68 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.24492/61.00%, bp_loss: 2.19271/34.00%, hp_loss: 3.05922/22.00%, j_loss: 1.67481/61.00%, \n",
      "\t\tfr_loss: 0.17180/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.34347\n",
      "\tPart 2 - fp_loss: 1.04828/70.00%, bp_loss: 1.93439/41.00%, hp_loss: 2.75759/31.00%, j_loss: 1.30768/70.00%, \n",
      "\t\tfr_loss: 0.16095/84.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.20890\n",
      "\tPart 3 - fp_loss: 1.02865/70.00%, bp_loss: 1.71628/51.00%, hp_loss: 2.45835/36.00%, j_loss: 1.20416/70.00%, \n",
      "\t\tfr_loss: 0.14693/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.55438\n",
      "\tPart 4 - fp_loss: 0.92778/74.00%, bp_loss: 1.85859/45.00%, hp_loss: 2.64793/32.00%, j_loss: 1.16928/74.00%, \n",
      "\t\tfr_loss: 0.12390/87.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.72750\n",
      "\tTraining time elapsed: 151.23 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.30977/62.00%, bp_loss: 2.22940/35.00%, hp_loss: 3.08663/22.00%, j_loss: 1.62881/62.00%, \n",
      "\t\tfr_loss: 0.18340/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.43802\n",
      "\tPart 2 - fp_loss: 1.18427/66.00%, bp_loss: 1.82790/44.00%, hp_loss: 2.73004/32.00%, j_loss: 1.46131/66.00%, \n",
      "\t\tfr_loss: 0.16151/84.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.36505\n",
      "\tPart 3 - fp_loss: 1.08605/69.00%, bp_loss: 1.74162/52.00%, hp_loss: 2.53112/36.00%, j_loss: 1.20879/70.00%, \n",
      "\t\tfr_loss: 0.15379/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.72138\n",
      "\tPart 4 - fp_loss: 1.00205/72.00%, bp_loss: 1.94692/45.00%, hp_loss: 2.69851/31.00%, j_loss: 1.24074/71.00%, \n",
      "\t\tfr_loss: 0.13756/86.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 7.02582\n",
      "\tTraining time elapsed: 188.78 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.36767/60.00%, bp_loss: 2.27230/32.00%, hp_loss: 3.08457/23.00%, j_loss: 1.75026/60.00%, \n",
      "\t\tfr_loss: 0.19131/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.66613\n",
      "\tPart 2 - fp_loss: 1.05897/70.00%, bp_loss: 1.85258/44.00%, hp_loss: 2.66175/35.00%, j_loss: 1.30034/70.00%, \n",
      "\t\tfr_loss: 0.18068/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.05434\n",
      "\tPart 3 - fp_loss: 1.04037/71.00%, bp_loss: 1.62798/52.00%, hp_loss: 2.38384/40.00%, j_loss: 1.18497/71.00%, \n",
      "\t\tfr_loss: 0.15392/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.39110\n",
      "\tPart 4 - fp_loss: 0.90954/73.00%, bp_loss: 1.91650/43.00%, hp_loss: 2.59270/35.00%, j_loss: 1.18620/74.00%, \n",
      "\t\tfr_loss: 0.13355/86.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.73853\n",
      "\tTraining time elapsed: 226.35 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.24674/63.00%, bp_loss: 2.22905/33.00%, hp_loss: 3.02104/23.00%, j_loss: 1.60343/63.00%, \n",
      "\t\tfr_loss: 0.18860/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.28887\n",
      "\tPart 2 - fp_loss: 1.08908/68.00%, bp_loss: 1.93784/44.00%, hp_loss: 2.74063/31.00%, j_loss: 1.37918/68.00%, \n",
      "\t\tfr_loss: 0.16148/84.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.30822\n",
      "\tPart 3 - fp_loss: 1.01355/71.00%, bp_loss: 1.63543/52.00%, hp_loss: 2.39753/37.00%, j_loss: 1.14329/72.00%, \n",
      "\t\tfr_loss: 0.15324/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.34305\n",
      "\tPart 4 - fp_loss: 0.96229/75.00%, bp_loss: 1.93617/41.00%, hp_loss: 2.64137/32.00%, j_loss: 1.15505/75.00%, \n",
      "\t\tfr_loss: 0.12471/87.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.81961\n",
      "\tTraining time elapsed: 263.90 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.32344/63.00%, bp_loss: 2.25902/34.00%, hp_loss: 3.12680/21.00%, j_loss: 1.65217/63.00%, \n",
      "\t\tfr_loss: 0.16856/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.52999\n",
      "\tPart 2 - fp_loss: 1.09777/68.00%, bp_loss: 1.95765/41.00%, hp_loss: 2.77212/32.00%, j_loss: 1.39360/68.00%, \n",
      "\t\tfr_loss: 0.20352/79.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.42467\n",
      "\tPart 3 - fp_loss: 1.07084/71.00%, bp_loss: 1.77188/49.00%, hp_loss: 2.45749/36.00%, j_loss: 1.21650/71.00%, \n",
      "\t\tfr_loss: 0.15861/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.67534\n",
      "\tPart 4 - fp_loss: 0.96724/74.00%, bp_loss: 1.87680/45.00%, hp_loss: 2.56243/34.00%, j_loss: 1.18009/74.00%, \n",
      "\t\tfr_loss: 0.12961/87.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 6.71620\n",
      "\tTraining time elapsed: 301.45 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.50350/55.00%, bp_loss: 2.69123/22.00%, hp_loss: 3.03837/23.00%, j_loss: 1.94354/54.00%, \n",
      "\t\tfr_loss: 0.19976/79.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 9.37640\n",
      "\tPart 2 - fp_loss: 1.23625/62.00%, bp_loss: 2.38853/34.00%, hp_loss: 2.72268/30.00%, j_loss: 1.64021/62.00%, \n",
      "\t\tfr_loss: 0.18466/81.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 8.17234\n",
      "\tPart 3 - fp_loss: 0.91715/71.00%, bp_loss: 2.15967/38.00%, hp_loss: 2.19537/44.00%, j_loss: 1.35819/72.00%, \n",
      "\t\tfr_loss: 0.18697/80.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.81736\n",
      "\tPart 4 - fp_loss: 0.98445/71.00%, bp_loss: 2.51551/33.00%, hp_loss: 2.40800/40.00%, j_loss: 1.43335/71.00%, \n",
      "\t\tfr_loss: 0.17791/82.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.51925\n",
      "\t`Validation time elapsed: 0.71 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.49483/55.00%, bp_loss: 2.30817/29.00%, hp_loss: 3.01324/24.00%, j_loss: 1.88830/55.00%, \n",
      "\t\tfr_loss: 0.18792/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.89247\n",
      "\tPart 2 - fp_loss: 1.22734/63.00%, bp_loss: 2.07164/38.00%, hp_loss: 2.82464/27.00%, j_loss: 1.51653/63.00%, \n",
      "\t\tfr_loss: 0.17204/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.81220\n",
      "\tPart 3 - fp_loss: 0.91094/73.00%, bp_loss: 1.72156/48.00%, hp_loss: 2.24362/43.00%, j_loss: 1.12918/73.00%, \n",
      "\t\tfr_loss: 0.19287/80.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.19817\n",
      "\tPart 4 - fp_loss: 1.06941/69.00%, bp_loss: 2.08968/39.00%, hp_loss: 2.40472/40.00%, j_loss: 1.41879/69.00%, \n",
      "\t\tfr_loss: 0.18204/81.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.16467\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 10.\n",
      "\n",
      "EPOCH 11\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.23518/64.00%, bp_loss: 2.62524/23.00%, hp_loss: 3.09169/22.00%, j_loss: 1.65485/64.00%, \n",
      "\t\tfr_loss: 0.18970/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.79667\n",
      "\tPart 2 - fp_loss: 1.07105/70.00%, bp_loss: 2.42885/34.00%, hp_loss: 2.72009/33.00%, j_loss: 1.45002/69.00%, \n",
      "\t\tfr_loss: 0.18324/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.85326\n",
      "\tPart 3 - fp_loss: 0.95090/73.00%, bp_loss: 2.24241/40.00%, hp_loss: 2.38577/39.00%, j_loss: 1.24362/73.00%, \n",
      "\t\tfr_loss: 0.13686/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.95957\n",
      "\tPart 4 - fp_loss: 0.89924/74.00%, bp_loss: 2.50711/31.00%, hp_loss: 2.59314/34.00%, j_loss: 1.27290/74.00%, \n",
      "\t\tfr_loss: 0.13282/87.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.40523\n",
      "\tTraining time elapsed: 1.07 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.28401/62.00%, bp_loss: 2.26261/34.00%, hp_loss: 3.05990/21.00%, j_loss: 1.61896/62.00%, \n",
      "\t\tfr_loss: 0.17708/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.40257\n",
      "\tPart 2 - fp_loss: 1.05610/69.00%, bp_loss: 1.93569/42.00%, hp_loss: 2.80161/29.00%, j_loss: 1.31773/69.00%, \n",
      "\t\tfr_loss: 0.16772/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.27887\n",
      "\tPart 3 - fp_loss: 1.02296/71.00%, bp_loss: 1.60273/52.00%, hp_loss: 2.37857/38.00%, j_loss: 1.17014/71.00%, \n",
      "\t\tfr_loss: 0.14946/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.32387\n",
      "\tPart 4 - fp_loss: 0.95229/73.00%, bp_loss: 1.93296/43.00%, hp_loss: 2.68104/29.00%, j_loss: 1.17741/73.00%, \n",
      "\t\tfr_loss: 0.12615/87.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.86988\n",
      "\tTraining time elapsed: 38.64 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.28784/62.00%, bp_loss: 2.24080/34.00%, hp_loss: 3.08651/21.00%, j_loss: 1.65422/62.00%, \n",
      "\t\tfr_loss: 0.17590/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.44527\n",
      "\tPart 2 - fp_loss: 1.02416/69.00%, bp_loss: 1.93317/43.00%, hp_loss: 2.78052/32.00%, j_loss: 1.33663/69.00%, \n",
      "\t\tfr_loss: 0.16599/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.24048\n",
      "\tPart 3 - fp_loss: 1.08723/71.00%, bp_loss: 1.64985/53.00%, hp_loss: 2.48482/37.00%, j_loss: 1.13868/71.00%, \n",
      "\t\tfr_loss: 0.15786/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.51846\n",
      "\tPart 4 - fp_loss: 0.89605/75.00%, bp_loss: 1.81110/45.00%, hp_loss: 2.63850/33.00%, j_loss: 1.14286/75.00%, \n",
      "\t\tfr_loss: 0.12188/88.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.61041\n",
      "\tTraining time elapsed: 76.20 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.30284/62.00%, bp_loss: 2.22690/36.00%, hp_loss: 3.06750/22.00%, j_loss: 1.63105/62.00%, \n",
      "\t\tfr_loss: 0.19841/80.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.42670\n",
      "\tPart 2 - fp_loss: 1.12946/67.00%, bp_loss: 1.85018/45.00%, hp_loss: 2.73352/32.00%, j_loss: 1.34417/67.00%, \n",
      "\t\tfr_loss: 0.17492/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.23227\n",
      "\tPart 3 - fp_loss: 1.03861/71.00%, bp_loss: 1.68934/51.00%, hp_loss: 2.47085/36.00%, j_loss: 1.20221/71.00%, \n",
      "\t\tfr_loss: 0.15373/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.55474\n",
      "\tPart 4 - fp_loss: 0.92575/73.00%, bp_loss: 1.84796/46.00%, hp_loss: 2.62717/32.00%, j_loss: 1.15871/73.00%, \n",
      "\t\tfr_loss: 0.14823/85.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.70784\n",
      "\tTraining time elapsed: 113.76 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.26322/63.00%, bp_loss: 2.15165/37.00%, hp_loss: 3.09292/22.00%, j_loss: 1.58219/63.00%, \n",
      "\t\tfr_loss: 0.16489/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.25488\n",
      "\tPart 2 - fp_loss: 1.11158/68.00%, bp_loss: 1.92268/44.00%, hp_loss: 2.71866/31.00%, j_loss: 1.37145/68.00%, \n",
      "\t\tfr_loss: 0.15620/85.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.28059\n",
      "\tPart 3 - fp_loss: 1.01224/72.00%, bp_loss: 1.61569/52.00%, hp_loss: 2.40061/38.00%, j_loss: 1.09636/72.00%, \n",
      "\t\tfr_loss: 0.15181/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.27672\n",
      "\tPart 4 - fp_loss: 0.86285/75.00%, bp_loss: 1.86911/47.00%, hp_loss: 2.61336/34.00%, j_loss: 1.07310/75.00%, \n",
      "\t\tfr_loss: 0.13807/86.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.55651\n",
      "\tTraining time elapsed: 151.33 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.29833/61.00%, bp_loss: 2.27831/33.00%, hp_loss: 3.15644/21.00%, j_loss: 1.72925/61.00%, \n",
      "\t\tfr_loss: 0.18151/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.64384\n",
      "\tPart 2 - fp_loss: 1.07385/69.00%, bp_loss: 1.94539/44.00%, hp_loss: 2.75635/31.00%, j_loss: 1.31435/69.00%, \n",
      "\t\tfr_loss: 0.17530/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.26526\n",
      "\tPart 3 - fp_loss: 1.01514/73.00%, bp_loss: 1.58904/53.00%, hp_loss: 2.42243/38.00%, j_loss: 1.13463/73.00%, \n",
      "\t\tfr_loss: 0.13901/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.30025\n",
      "\tPart 4 - fp_loss: 0.93707/73.00%, bp_loss: 1.85012/45.00%, hp_loss: 2.61182/33.00%, j_loss: 1.17032/73.00%, \n",
      "\t\tfr_loss: 0.13424/86.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.70359\n",
      "\tTraining time elapsed: 188.86 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.20086/63.00%, bp_loss: 2.23318/34.00%, hp_loss: 3.07111/22.00%, j_loss: 1.60664/63.00%, \n",
      "\t\tfr_loss: 0.15491/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.26671\n",
      "\tPart 2 - fp_loss: 1.07061/69.00%, bp_loss: 1.91223/42.00%, hp_loss: 2.78312/30.00%, j_loss: 1.33033/69.00%, \n",
      "\t\tfr_loss: 0.19243/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.28872\n",
      "\tPart 3 - fp_loss: 1.03115/73.00%, bp_loss: 1.58111/52.00%, hp_loss: 2.37884/36.00%, j_loss: 1.13949/73.00%, \n",
      "\t\tfr_loss: 0.15427/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.28486\n",
      "\tPart 4 - fp_loss: 0.92542/75.00%, bp_loss: 1.75451/49.00%, hp_loss: 2.58299/33.00%, j_loss: 1.09688/75.00%, \n",
      "\t\tfr_loss: 0.12579/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.48560\n",
      "\tTraining time elapsed: 226.39 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.28290/65.00%, bp_loss: 2.13649/38.00%, hp_loss: 3.07270/22.00%, j_loss: 1.49838/65.00%, \n",
      "\t\tfr_loss: 0.18002/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.17050\n",
      "\tPart 2 - fp_loss: 1.10909/69.00%, bp_loss: 1.84551/43.00%, hp_loss: 2.80021/29.00%, j_loss: 1.34434/69.00%, \n",
      "\t\tfr_loss: 0.16082/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.25998\n",
      "\tPart 3 - fp_loss: 1.06124/70.00%, bp_loss: 1.65691/52.00%, hp_loss: 2.45084/36.00%, j_loss: 1.17152/70.00%, \n",
      "\t\tfr_loss: 0.16221/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.50272\n",
      "\tPart 4 - fp_loss: 0.95954/72.00%, bp_loss: 1.84142/46.00%, hp_loss: 2.59523/35.00%, j_loss: 1.25937/72.00%, \n",
      "\t\tfr_loss: 0.12269/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.77826\n",
      "\tTraining time elapsed: 263.91 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.27069/61.00%, bp_loss: 2.25982/32.00%, hp_loss: 3.07240/23.00%, j_loss: 1.65164/61.00%, \n",
      "\t\tfr_loss: 0.17883/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.43338\n",
      "\tPart 2 - fp_loss: 1.11235/66.00%, bp_loss: 1.88324/43.00%, hp_loss: 2.72120/32.00%, j_loss: 1.36477/66.00%, \n",
      "\t\tfr_loss: 0.16028/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.24185\n",
      "\tPart 3 - fp_loss: 1.01588/71.00%, bp_loss: 1.66516/50.00%, hp_loss: 2.41114/38.00%, j_loss: 1.19154/72.00%, \n",
      "\t\tfr_loss: 0.14060/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.42432\n",
      "\tPart 4 - fp_loss: 0.91102/74.00%, bp_loss: 1.85486/45.00%, hp_loss: 2.66035/33.00%, j_loss: 1.15938/75.00%, \n",
      "\t\tfr_loss: 0.12354/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.70916\n",
      "\tTraining time elapsed: 301.43 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.52593/55.00%, bp_loss: 2.61990/23.00%, hp_loss: 2.99249/24.00%, j_loss: 1.93922/55.00%, \n",
      "\t\tfr_loss: 0.22066/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.29821\n",
      "\tPart 2 - fp_loss: 1.20332/62.00%, bp_loss: 2.45806/30.00%, hp_loss: 2.67936/30.00%, j_loss: 1.66114/62.00%, \n",
      "\t\tfr_loss: 0.21357/78.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.21547\n",
      "\tPart 3 - fp_loss: 0.97232/72.00%, bp_loss: 2.17023/39.00%, hp_loss: 2.29809/42.00%, j_loss: 1.30853/72.00%, \n",
      "\t\tfr_loss: 0.19589/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.94506\n",
      "\tPart 4 - fp_loss: 1.07385/70.00%, bp_loss: 2.50297/29.00%, hp_loss: 2.41432/39.00%, j_loss: 1.53276/70.00%, \n",
      "\t\tfr_loss: 0.19876/80.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.72269\n",
      "\t`Validation time elapsed: 0.70 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.60656/51.00%, bp_loss: 2.33401/27.00%, hp_loss: 3.09956/21.00%, j_loss: 2.01498/51.00%, \n",
      "\t\tfr_loss: 0.20015/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.25526\n",
      "\tPart 2 - fp_loss: 1.18313/63.00%, bp_loss: 1.96522/40.00%, hp_loss: 2.73731/29.00%, j_loss: 1.46892/63.00%, \n",
      "\t\tfr_loss: 0.18517/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.53976\n",
      "\tPart 3 - fp_loss: 0.94973/71.00%, bp_loss: 1.74109/51.00%, hp_loss: 2.25703/45.00%, j_loss: 1.23821/71.00%, \n",
      "\t\tfr_loss: 0.16425/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.35032\n",
      "\tPart 4 - fp_loss: 1.05492/72.00%, bp_loss: 1.90037/44.00%, hp_loss: 2.39693/40.00%, j_loss: 1.28296/72.00%, \n",
      "\t\tfr_loss: 0.17014/83.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.80536\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 11.\n",
      "\n",
      "EPOCH 12\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.20645/65.00%, bp_loss: 2.69232/23.00%, hp_loss: 3.11492/21.00%, j_loss: 1.66288/65.00%, \n",
      "\t\tfr_loss: 0.18204/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.85861\n",
      "\tPart 2 - fp_loss: 1.01113/70.00%, bp_loss: 2.44260/32.00%, hp_loss: 2.70309/31.00%, j_loss: 1.39623/69.00%, \n",
      "\t\tfr_loss: 0.17259/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.72564\n",
      "\tPart 3 - fp_loss: 0.99231/72.00%, bp_loss: 2.25800/39.00%, hp_loss: 2.43017/37.00%, j_loss: 1.32590/72.00%, \n",
      "\t\tfr_loss: 0.14574/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.15212\n",
      "\tPart 4 - fp_loss: 0.96884/74.00%, bp_loss: 2.52797/30.00%, hp_loss: 2.64811/32.00%, j_loss: 1.32689/74.00%, \n",
      "\t\tfr_loss: 0.13580/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.60763\n",
      "\tTraining time elapsed: 1.04 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.29090/63.00%, bp_loss: 2.11308/37.00%, hp_loss: 2.97579/26.00%, j_loss: 1.58238/62.00%, \n",
      "\t\tfr_loss: 0.20625/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.16840\n",
      "\tPart 2 - fp_loss: 1.05367/70.00%, bp_loss: 1.82307/45.00%, hp_loss: 2.70061/32.00%, j_loss: 1.31016/70.00%, \n",
      "\t\tfr_loss: 0.17032/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.05784\n",
      "\tPart 3 - fp_loss: 0.97037/72.00%, bp_loss: 1.72712/51.00%, hp_loss: 2.43296/37.00%, j_loss: 1.08399/73.00%, \n",
      "\t\tfr_loss: 0.14968/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.36413\n",
      "\tPart 4 - fp_loss: 0.85081/76.00%, bp_loss: 1.83042/46.00%, hp_loss: 2.65979/32.00%, j_loss: 1.03591/76.00%, \n",
      "\t\tfr_loss: 0.12746/87.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.50440\n",
      "\tTraining time elapsed: 38.58 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.26350/62.00%, bp_loss: 2.21726/35.00%, hp_loss: 3.10845/21.00%, j_loss: 1.64545/62.00%, \n",
      "\t\tfr_loss: 0.16210/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.39677\n",
      "\tPart 2 - fp_loss: 1.01659/69.00%, bp_loss: 1.86592/45.00%, hp_loss: 2.72659/31.00%, j_loss: 1.30919/69.00%, \n",
      "\t\tfr_loss: 0.17096/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.08926\n",
      "\tPart 3 - fp_loss: 0.95986/73.00%, bp_loss: 1.61146/51.00%, hp_loss: 2.32993/39.00%, j_loss: 1.07267/73.00%, \n",
      "\t\tfr_loss: 0.14451/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11844\n",
      "\tPart 4 - fp_loss: 0.92540/75.00%, bp_loss: 1.75730/50.00%, hp_loss: 2.55873/34.00%, j_loss: 1.03349/75.00%, \n",
      "\t\tfr_loss: 0.13190/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.40683\n",
      "\tTraining time elapsed: 76.13 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.15326/66.00%, bp_loss: 2.21127/36.00%, hp_loss: 3.12244/22.00%, j_loss: 1.47999/66.00%, \n",
      "\t\tfr_loss: 0.17103/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.13800\n",
      "\tPart 2 - fp_loss: 1.08555/70.00%, bp_loss: 1.85433/46.00%, hp_loss: 2.76087/31.00%, j_loss: 1.32374/70.00%, \n",
      "\t\tfr_loss: 0.17004/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.19455\n",
      "\tPart 3 - fp_loss: 0.98213/71.00%, bp_loss: 1.57264/55.00%, hp_loss: 2.40882/37.00%, j_loss: 1.11109/72.00%, \n",
      "\t\tfr_loss: 0.14727/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.22195\n",
      "\tPart 4 - fp_loss: 1.00628/71.00%, bp_loss: 1.80697/47.00%, hp_loss: 2.70015/32.00%, j_loss: 1.27355/71.00%, \n",
      "\t\tfr_loss: 0.13830/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.92527\n",
      "\tTraining time elapsed: 113.69 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.19950/63.00%, bp_loss: 2.20832/33.00%, hp_loss: 3.12650/21.00%, j_loss: 1.60050/62.00%, \n",
      "\t\tfr_loss: 0.17589/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.31072\n",
      "\tPart 2 - fp_loss: 1.12351/67.00%, bp_loss: 1.89699/45.00%, hp_loss: 2.80811/29.00%, j_loss: 1.36380/67.00%, \n",
      "\t\tfr_loss: 0.15070/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.34312\n",
      "\tPart 3 - fp_loss: 0.98250/72.00%, bp_loss: 1.68989/51.00%, hp_loss: 2.38042/39.00%, j_loss: 1.12324/72.00%, \n",
      "\t\tfr_loss: 0.14071/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31677\n",
      "\tPart 4 - fp_loss: 0.90657/74.00%, bp_loss: 1.90876/45.00%, hp_loss: 2.64662/32.00%, j_loss: 1.13834/74.00%, \n",
      "\t\tfr_loss: 0.12429/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.72459\n",
      "\tTraining time elapsed: 151.25 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.20935/66.00%, bp_loss: 2.17114/36.00%, hp_loss: 3.12471/20.00%, j_loss: 1.49851/66.00%, \n",
      "\t\tfr_loss: 0.17240/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.17610\n",
      "\tPart 2 - fp_loss: 0.97050/73.00%, bp_loss: 1.85598/45.00%, hp_loss: 2.76379/33.00%, j_loss: 1.22894/72.00%, \n",
      "\t\tfr_loss: 0.15016/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.96939\n",
      "\tPart 3 - fp_loss: 1.02147/71.00%, bp_loss: 1.62244/53.00%, hp_loss: 2.48025/36.00%, j_loss: 1.11975/70.00%, \n",
      "\t\tfr_loss: 0.16098/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.40490\n",
      "\tPart 4 - fp_loss: 0.91087/75.00%, bp_loss: 1.77899/47.00%, hp_loss: 2.59601/32.00%, j_loss: 1.06890/75.00%, \n",
      "\t\tfr_loss: 0.13889/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.49367\n",
      "\tTraining time elapsed: 188.79 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.25098/62.00%, bp_loss: 2.20838/36.00%, hp_loss: 3.10113/21.00%, j_loss: 1.60473/62.00%, \n",
      "\t\tfr_loss: 0.16421/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.32944\n",
      "\tPart 2 - fp_loss: 0.97741/72.00%, bp_loss: 1.88786/42.00%, hp_loss: 2.78233/29.00%, j_loss: 1.21007/72.00%, \n",
      "\t\tfr_loss: 0.14511/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.00279\n",
      "\tPart 3 - fp_loss: 0.97990/72.00%, bp_loss: 1.61743/53.00%, hp_loss: 2.47048/39.00%, j_loss: 1.10200/73.00%, \n",
      "\t\tfr_loss: 0.15314/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.32295\n",
      "\tPart 4 - fp_loss: 0.93761/74.00%, bp_loss: 1.81875/47.00%, hp_loss: 2.64607/32.00%, j_loss: 1.13605/75.00%, \n",
      "\t\tfr_loss: 0.14624/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.68474\n",
      "\tTraining time elapsed: 226.33 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.16230/64.00%, bp_loss: 2.13112/37.00%, hp_loss: 3.01477/25.00%, j_loss: 1.52227/64.00%, \n",
      "\t\tfr_loss: 0.16342/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.99387\n",
      "\tPart 2 - fp_loss: 1.08169/70.00%, bp_loss: 1.82433/45.00%, hp_loss: 2.76669/33.00%, j_loss: 1.28495/70.00%, \n",
      "\t\tfr_loss: 0.19233/80.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.14999\n",
      "\tPart 3 - fp_loss: 0.96305/72.00%, bp_loss: 1.57482/53.00%, hp_loss: 2.39379/39.00%, j_loss: 1.08893/72.00%, \n",
      "\t\tfr_loss: 0.15348/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17407\n",
      "\tPart 4 - fp_loss: 0.93278/73.00%, bp_loss: 1.73677/49.00%, hp_loss: 2.60556/33.00%, j_loss: 1.10305/74.00%, \n",
      "\t\tfr_loss: 0.12963/87.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.50782\n",
      "\tTraining time elapsed: 263.87 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.21923/63.00%, bp_loss: 2.23297/34.00%, hp_loss: 3.06106/22.00%, j_loss: 1.60425/63.00%, \n",
      "\t\tfr_loss: 0.17303/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.29054\n",
      "\tPart 2 - fp_loss: 1.00970/70.00%, bp_loss: 1.81165/46.00%, hp_loss: 2.74249/32.00%, j_loss: 1.24537/70.00%, \n",
      "\t\tfr_loss: 0.16549/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.97472\n",
      "\tPart 3 - fp_loss: 1.04445/70.00%, bp_loss: 1.61409/52.00%, hp_loss: 2.42382/37.00%, j_loss: 1.22799/70.00%, \n",
      "\t\tfr_loss: 0.16829/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47865\n",
      "\tPart 4 - fp_loss: 0.88740/74.00%, bp_loss: 1.70795/50.00%, hp_loss: 2.59634/35.00%, j_loss: 1.06732/74.00%, \n",
      "\t\tfr_loss: 0.14282/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.40182\n",
      "\tTraining time elapsed: 301.42 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.61031/52.00%, bp_loss: 2.66275/22.00%, hp_loss: 3.05299/23.00%, j_loss: 2.02398/52.00%, \n",
      "\t\tfr_loss: 0.21393/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.56396\n",
      "\tPart 2 - fp_loss: 1.26685/61.00%, bp_loss: 2.45276/32.00%, hp_loss: 2.76038/30.00%, j_loss: 1.71125/61.00%, \n",
      "\t\tfr_loss: 0.17930/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.37055\n",
      "\tPart 3 - fp_loss: 0.93457/72.00%, bp_loss: 2.14798/41.00%, hp_loss: 2.22060/44.00%, j_loss: 1.24713/73.00%, \n",
      "\t\tfr_loss: 0.16542/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.71571\n",
      "\tPart 4 - fp_loss: 1.08486/69.00%, bp_loss: 2.62192/29.00%, hp_loss: 2.37345/39.00%, j_loss: 1.58614/69.00%, \n",
      "\t\tfr_loss: 0.18030/82.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 7.84668\n",
      "\t`Validation time elapsed: 0.72 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.59732/54.00%, bp_loss: 2.26608/30.00%, hp_loss: 3.08723/24.00%, j_loss: 1.89942/54.00%, \n",
      "\t\tfr_loss: 0.19989/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.04995\n",
      "\tPart 2 - fp_loss: 1.24772/63.00%, bp_loss: 1.98474/40.00%, hp_loss: 2.69317/32.00%, j_loss: 1.53934/63.00%, \n",
      "\t\tfr_loss: 0.18849/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.65346\n",
      "\tPart 3 - fp_loss: 0.97042/72.00%, bp_loss: 1.51620/57.00%, hp_loss: 2.16642/48.00%, j_loss: 1.08930/72.00%, \n",
      "\t\tfr_loss: 0.18080/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92314\n",
      "\tPart 4 - fp_loss: 1.11746/70.00%, bp_loss: 1.94562/43.00%, hp_loss: 2.40665/41.00%, j_loss: 1.34341/69.00%, \n",
      "\t\tfr_loss: 0.16858/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.98173\n",
      "\t`Validation time elapsed: 9.50 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 12.\n",
      "\n",
      "EPOCH 13\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.19511/66.00%, bp_loss: 2.60265/23.00%, hp_loss: 3.11771/21.00%, j_loss: 1.63427/66.00%, \n",
      "\t\tfr_loss: 0.15899/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.70875\n",
      "\tPart 2 - fp_loss: 0.93909/73.00%, bp_loss: 2.29764/39.00%, hp_loss: 2.71293/32.00%, j_loss: 1.23708/73.00%, \n",
      "\t\tfr_loss: 0.16445/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.35119\n",
      "\tPart 3 - fp_loss: 1.00880/71.00%, bp_loss: 2.19403/42.00%, hp_loss: 2.49773/36.00%, j_loss: 1.28478/71.00%, \n",
      "\t\tfr_loss: 0.15059/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.13593\n",
      "\tPart 4 - fp_loss: 0.89366/74.00%, bp_loss: 2.53585/31.00%, hp_loss: 2.69158/31.00%, j_loss: 1.36957/73.00%, \n",
      "\t\tfr_loss: 0.12320/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.61387\n",
      "\tTraining time elapsed: 1.05 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.25300/63.00%, bp_loss: 2.15803/35.00%, hp_loss: 3.13437/21.00%, j_loss: 1.57796/63.00%, \n",
      "\t\tfr_loss: 0.18775/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.31111\n",
      "\tPart 2 - fp_loss: 0.96459/72.00%, bp_loss: 1.80950/46.00%, hp_loss: 2.65253/34.00%, j_loss: 1.18919/72.00%, \n",
      "\t\tfr_loss: 0.17207/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.78788\n",
      "\tPart 3 - fp_loss: 0.99605/72.00%, bp_loss: 1.62032/52.00%, hp_loss: 2.41702/37.00%, j_loss: 1.13782/72.00%, \n",
      "\t\tfr_loss: 0.14034/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31155\n",
      "\tPart 4 - fp_loss: 0.84991/75.00%, bp_loss: 1.75091/47.00%, hp_loss: 2.56876/34.00%, j_loss: 1.06330/75.00%, \n",
      "\t\tfr_loss: 0.13694/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.36982\n",
      "\tTraining time elapsed: 38.57 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.21723/62.00%, bp_loss: 2.13711/35.00%, hp_loss: 3.15180/21.00%, j_loss: 1.59483/62.00%, \n",
      "\t\tfr_loss: 0.17579/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.27676\n",
      "\tPart 2 - fp_loss: 0.99966/72.00%, bp_loss: 1.76152/46.00%, hp_loss: 2.74509/32.00%, j_loss: 1.21168/72.00%, \n",
      "\t\tfr_loss: 0.14384/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.86180\n",
      "\tPart 3 - fp_loss: 1.00594/72.00%, bp_loss: 1.52682/56.00%, hp_loss: 2.40064/39.00%, j_loss: 1.07469/72.00%, \n",
      "\t\tfr_loss: 0.15579/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16388\n",
      "\tPart 4 - fp_loss: 0.89884/74.00%, bp_loss: 1.79138/48.00%, hp_loss: 2.69561/33.00%, j_loss: 1.09426/74.00%, \n",
      "\t\tfr_loss: 0.12490/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.60499\n",
      "\tTraining time elapsed: 76.12 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.12819/65.00%, bp_loss: 2.14736/36.00%, hp_loss: 3.01020/24.00%, j_loss: 1.51866/65.00%, \n",
      "\t\tfr_loss: 0.16594/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.97035\n",
      "\tPart 2 - fp_loss: 1.06048/69.00%, bp_loss: 1.82254/46.00%, hp_loss: 2.73685/31.00%, j_loss: 1.32459/69.00%, \n",
      "\t\tfr_loss: 0.14984/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.09431\n",
      "\tPart 3 - fp_loss: 0.96768/72.00%, bp_loss: 1.57400/54.00%, hp_loss: 2.38516/38.00%, j_loss: 1.09959/73.00%, \n",
      "\t\tfr_loss: 0.14695/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17338\n",
      "\tPart 4 - fp_loss: 0.95118/74.00%, bp_loss: 1.74898/49.00%, hp_loss: 2.62358/32.00%, j_loss: 1.10763/73.00%, \n",
      "\t\tfr_loss: 0.12517/88.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.55655\n",
      "\tTraining time elapsed: 113.70 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.19039/63.00%, bp_loss: 2.24684/34.00%, hp_loss: 3.05286/23.00%, j_loss: 1.61140/63.00%, \n",
      "\t\tfr_loss: 0.17647/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.27796\n",
      "\tPart 2 - fp_loss: 1.01417/71.00%, bp_loss: 1.76005/48.00%, hp_loss: 2.72416/33.00%, j_loss: 1.21974/70.00%, \n",
      "\t\tfr_loss: 0.14139/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.85952\n",
      "\tPart 3 - fp_loss: 1.01504/71.00%, bp_loss: 1.54394/54.00%, hp_loss: 2.34901/38.00%, j_loss: 1.11261/71.00%, \n",
      "\t\tfr_loss: 0.15320/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17381\n",
      "\tPart 4 - fp_loss: 0.90669/75.00%, bp_loss: 1.75863/49.00%, hp_loss: 2.60587/31.00%, j_loss: 1.08468/75.00%, \n",
      "\t\tfr_loss: 0.13018/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.48605\n",
      "\tTraining time elapsed: 151.24 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.23939/63.00%, bp_loss: 2.18097/36.00%, hp_loss: 3.05193/22.00%, j_loss: 1.54549/63.00%, \n",
      "\t\tfr_loss: 0.17535/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.19313\n",
      "\tPart 2 - fp_loss: 0.99086/70.00%, bp_loss: 1.88547/46.00%, hp_loss: 2.76788/30.00%, j_loss: 1.23406/70.00%, \n",
      "\t\tfr_loss: 0.15593/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.03420\n",
      "\tPart 3 - fp_loss: 1.01409/71.00%, bp_loss: 1.61806/52.00%, hp_loss: 2.46626/35.00%, j_loss: 1.11798/72.00%, \n",
      "\t\tfr_loss: 0.14877/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36516\n",
      "\tPart 4 - fp_loss: 0.91066/75.00%, bp_loss: 1.78654/46.00%, hp_loss: 2.66220/32.00%, j_loss: 1.07603/75.00%, \n",
      "\t\tfr_loss: 0.14350/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.57894\n",
      "\tTraining time elapsed: 188.76 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.22616/64.00%, bp_loss: 2.22597/35.00%, hp_loss: 3.13072/20.00%, j_loss: 1.56364/64.00%, \n",
      "\t\tfr_loss: 0.15914/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.30563\n",
      "\tPart 2 - fp_loss: 0.91145/73.00%, bp_loss: 1.69356/49.00%, hp_loss: 2.71508/34.00%, j_loss: 1.13129/73.00%, \n",
      "\t\tfr_loss: 0.15074/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.60213\n",
      "\tPart 3 - fp_loss: 0.89763/74.00%, bp_loss: 1.46010/58.00%, hp_loss: 2.38872/38.00%, j_loss: 1.01092/74.00%, \n",
      "\t\tfr_loss: 0.14057/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.89794\n",
      "\tPart 4 - fp_loss: 0.97768/72.00%, bp_loss: 1.74242/49.00%, hp_loss: 2.66201/31.00%, j_loss: 1.13863/72.00%, \n",
      "\t\tfr_loss: 0.13010/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.65084\n",
      "\tTraining time elapsed: 226.27 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.18591/62.00%, bp_loss: 2.25938/32.00%, hp_loss: 3.03719/23.00%, j_loss: 1.60164/62.00%, \n",
      "\t\tfr_loss: 0.18568/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.26980\n",
      "\tPart 2 - fp_loss: 0.97281/72.00%, bp_loss: 1.81049/47.00%, hp_loss: 2.68197/32.00%, j_loss: 1.18599/72.00%, \n",
      "\t\tfr_loss: 0.16462/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.81589\n",
      "\tPart 3 - fp_loss: 0.98375/72.00%, bp_loss: 1.53956/56.00%, hp_loss: 2.41399/38.00%, j_loss: 1.05149/73.00%, \n",
      "\t\tfr_loss: 0.12613/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11492\n",
      "\tPart 4 - fp_loss: 0.88123/74.00%, bp_loss: 1.79046/48.00%, hp_loss: 2.69379/31.00%, j_loss: 1.13269/74.00%, \n",
      "\t\tfr_loss: 0.14339/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.64156\n",
      "\tTraining time elapsed: 263.79 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.16067/66.00%, bp_loss: 2.17805/35.00%, hp_loss: 3.03128/23.00%, j_loss: 1.48900/65.00%, \n",
      "\t\tfr_loss: 0.15822/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.01723\n",
      "\tPart 2 - fp_loss: 1.04008/70.00%, bp_loss: 1.84392/45.00%, hp_loss: 2.80715/29.00%, j_loss: 1.25525/70.00%, \n",
      "\t\tfr_loss: 0.17348/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.11988\n",
      "\tPart 3 - fp_loss: 0.93631/73.00%, bp_loss: 1.58029/53.00%, hp_loss: 2.36826/40.00%, j_loss: 1.06377/74.00%, \n",
      "\t\tfr_loss: 0.14923/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09786\n",
      "\tPart 4 - fp_loss: 0.86744/77.00%, bp_loss: 1.77990/48.00%, hp_loss: 2.64814/33.00%, j_loss: 1.00906/77.00%, \n",
      "\t\tfr_loss: 0.11685/88.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.42140\n",
      "\tTraining time elapsed: 301.31 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.56237/54.00%, bp_loss: 2.50368/25.00%, hp_loss: 3.05385/22.00%, j_loss: 2.01251/54.00%, \n",
      "\t\tfr_loss: 0.20666/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.33908\n",
      "\tPart 2 - fp_loss: 1.25878/61.00%, bp_loss: 2.38803/32.00%, hp_loss: 2.72747/30.00%, j_loss: 1.63800/61.00%, \n",
      "\t\tfr_loss: 0.19022/81.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 8.20250\n",
      "\tPart 3 - fp_loss: 0.93854/72.00%, bp_loss: 2.07379/45.00%, hp_loss: 2.31748/43.00%, j_loss: 1.27643/72.00%, \n",
      "\t\tfr_loss: 0.15441/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.76066\n",
      "\tPart 4 - fp_loss: 1.15552/70.00%, bp_loss: 2.42171/31.00%, hp_loss: 2.45060/39.00%, j_loss: 1.51490/69.00%, \n",
      "\t\tfr_loss: 0.16902/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.71176\n",
      "\t`Validation time elapsed: 0.73 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.64667/53.00%, bp_loss: 2.31300/30.00%, hp_loss: 2.99659/24.00%, j_loss: 2.01296/52.00%, \n",
      "\t\tfr_loss: 0.21000/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.17923\n",
      "\tPart 2 - fp_loss: 1.37009/60.00%, bp_loss: 1.96122/42.00%, hp_loss: 2.76083/29.00%, j_loss: 1.55498/60.00%, \n",
      "\t\tfr_loss: 0.18486/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.83198\n",
      "\tPart 3 - fp_loss: 0.97660/72.00%, bp_loss: 1.59987/54.00%, hp_loss: 2.27834/44.00%, j_loss: 1.12577/72.00%, \n",
      "\t\tfr_loss: 0.16697/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14755\n",
      "\tPart 4 - fp_loss: 1.06550/72.00%, bp_loss: 1.93503/44.00%, hp_loss: 2.42624/40.00%, j_loss: 1.28368/72.00%, \n",
      "\t\tfr_loss: 0.17252/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.88298\n",
      "\t`Validation time elapsed: 9.49 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 13.\n",
      "\n",
      "EPOCH 14\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.16294/65.00%, bp_loss: 2.49766/28.00%, hp_loss: 3.16008/20.00%, j_loss: 1.63586/65.00%, \n",
      "\t\tfr_loss: 0.18170/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.63824\n",
      "\tPart 2 - fp_loss: 1.02908/70.00%, bp_loss: 2.37215/36.00%, hp_loss: 2.72176/32.00%, j_loss: 1.40006/70.00%, \n",
      "\t\tfr_loss: 0.15438/84.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.67745\n",
      "\tPart 3 - fp_loss: 0.97755/72.00%, bp_loss: 2.12966/43.00%, hp_loss: 2.45119/38.00%, j_loss: 1.26839/72.00%, \n",
      "\t\tfr_loss: 0.12723/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.95401\n",
      "\tPart 4 - fp_loss: 0.85842/77.00%, bp_loss: 2.43238/30.00%, hp_loss: 2.57300/34.00%, j_loss: 1.17596/77.00%, \n",
      "\t\tfr_loss: 0.11829/88.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.15806\n",
      "\tTraining time elapsed: 1.05 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.20325/63.00%, bp_loss: 2.13484/37.00%, hp_loss: 3.04272/23.00%, j_loss: 1.56127/63.00%, \n",
      "\t\tfr_loss: 0.17181/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.11389\n",
      "\tPart 2 - fp_loss: 0.97598/71.00%, bp_loss: 1.81146/47.00%, hp_loss: 2.74859/32.00%, j_loss: 1.20537/71.00%, \n",
      "\t\tfr_loss: 0.17739/82.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.91879\n",
      "\tPart 3 - fp_loss: 0.97705/73.00%, bp_loss: 1.53077/54.00%, hp_loss: 2.40023/37.00%, j_loss: 1.10448/73.00%, \n",
      "\t\tfr_loss: 0.14803/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16056\n",
      "\tPart 4 - fp_loss: 0.87340/76.00%, bp_loss: 1.74510/50.00%, hp_loss: 2.65869/31.00%, j_loss: 1.03175/75.00%, \n",
      "\t\tfr_loss: 0.14096/86.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.44991\n",
      "\tTraining time elapsed: 38.60 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.16550/65.00%, bp_loss: 2.21681/35.00%, hp_loss: 3.08682/22.00%, j_loss: 1.49651/65.00%, \n",
      "\t\tfr_loss: 0.17369/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.13933\n",
      "\tPart 2 - fp_loss: 1.05621/70.00%, bp_loss: 1.78868/46.00%, hp_loss: 2.72375/32.00%, j_loss: 1.31084/70.00%, \n",
      "\t\tfr_loss: 0.16965/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.04914\n",
      "\tPart 3 - fp_loss: 0.92446/73.00%, bp_loss: 1.54945/53.00%, hp_loss: 2.40706/39.00%, j_loss: 1.05849/73.00%, \n",
      "\t\tfr_loss: 0.14387/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08334\n",
      "\tPart 4 - fp_loss: 0.82656/75.00%, bp_loss: 1.69430/50.00%, hp_loss: 2.59818/33.00%, j_loss: 1.03835/76.00%, \n",
      "\t\tfr_loss: 0.13073/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.28812\n",
      "\tTraining time elapsed: 76.10 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.18996/65.00%, bp_loss: 2.16590/35.00%, hp_loss: 3.11026/21.00%, j_loss: 1.56262/65.00%, \n",
      "\t\tfr_loss: 0.16435/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.19309\n",
      "\tPart 2 - fp_loss: 1.01310/71.00%, bp_loss: 1.80042/46.00%, hp_loss: 2.77169/32.00%, j_loss: 1.22608/71.00%, \n",
      "\t\tfr_loss: 0.16838/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.97969\n",
      "\tPart 3 - fp_loss: 0.90256/75.00%, bp_loss: 1.54187/54.00%, hp_loss: 2.31666/41.00%, j_loss: 1.01458/75.00%, \n",
      "\t\tfr_loss: 0.11981/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.89549\n",
      "\tPart 4 - fp_loss: 0.86907/76.00%, bp_loss: 1.69770/50.00%, hp_loss: 2.61555/33.00%, j_loss: 1.00516/76.00%, \n",
      "\t\tfr_loss: 0.11802/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30551\n",
      "\tTraining time elapsed: 113.61 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.17008/65.00%, bp_loss: 2.20766/33.00%, hp_loss: 3.07369/21.00%, j_loss: 1.52421/65.00%, \n",
      "\t\tfr_loss: 0.17158/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.14722\n",
      "\tPart 2 - fp_loss: 1.01347/71.00%, bp_loss: 1.72654/49.00%, hp_loss: 2.73383/31.00%, j_loss: 1.17886/71.00%, \n",
      "\t\tfr_loss: 0.17046/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.82318\n",
      "\tPart 3 - fp_loss: 0.92393/73.00%, bp_loss: 1.52191/57.00%, hp_loss: 2.42483/37.00%, j_loss: 0.98309/74.00%, \n",
      "\t\tfr_loss: 0.13669/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.99044\n",
      "\tPart 4 - fp_loss: 0.86964/76.00%, bp_loss: 1.69758/50.00%, hp_loss: 2.59830/33.00%, j_loss: 1.03662/76.00%, \n",
      "\t\tfr_loss: 0.11003/89.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.31218\n",
      "\tTraining time elapsed: 151.11 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.15785/66.00%, bp_loss: 2.22161/35.00%, hp_loss: 3.09647/21.00%, j_loss: 1.47638/66.00%, \n",
      "\t\tfr_loss: 0.15887/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.11118\n",
      "\tPart 2 - fp_loss: 1.00221/71.00%, bp_loss: 1.70878/49.00%, hp_loss: 2.68926/33.00%, j_loss: 1.18385/71.00%, \n",
      "\t\tfr_loss: 0.15922/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.74333\n",
      "\tPart 3 - fp_loss: 1.00272/71.00%, bp_loss: 1.56320/54.00%, hp_loss: 2.37386/38.00%, j_loss: 1.08396/71.00%, \n",
      "\t\tfr_loss: 0.14761/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17135\n",
      "\tPart 4 - fp_loss: 0.83769/77.00%, bp_loss: 1.64231/53.00%, hp_loss: 2.56667/34.00%, j_loss: 0.97202/77.00%, \n",
      "\t\tfr_loss: 0.12646/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.14515\n",
      "\tTraining time elapsed: 188.63 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.19866/64.00%, bp_loss: 2.14704/35.00%, hp_loss: 3.12985/21.00%, j_loss: 1.57917/64.00%, \n",
      "\t\tfr_loss: 0.14359/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.19831\n",
      "\tPart 2 - fp_loss: 0.99738/71.00%, bp_loss: 1.72871/48.00%, hp_loss: 2.71517/33.00%, j_loss: 1.15259/71.00%, \n",
      "\t\tfr_loss: 0.15399/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.74785\n",
      "\tPart 3 - fp_loss: 0.97273/73.00%, bp_loss: 1.60213/54.00%, hp_loss: 2.35592/40.00%, j_loss: 1.04520/73.00%, \n",
      "\t\tfr_loss: 0.13996/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11595\n",
      "\tPart 4 - fp_loss: 0.84135/78.00%, bp_loss: 1.64168/52.00%, hp_loss: 2.51993/35.00%, j_loss: 0.97741/78.00%, \n",
      "\t\tfr_loss: 0.12328/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.10366\n",
      "\tTraining time elapsed: 226.15 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.17709/64.00%, bp_loss: 2.11469/37.00%, hp_loss: 3.06487/23.00%, j_loss: 1.53511/64.00%, \n",
      "\t\tfr_loss: 0.16202/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.05378\n",
      "\tPart 2 - fp_loss: 0.99246/72.00%, bp_loss: 1.69953/49.00%, hp_loss: 2.71849/32.00%, j_loss: 1.21278/72.00%, \n",
      "\t\tfr_loss: 0.16312/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.78639\n",
      "\tPart 3 - fp_loss: 0.94781/73.00%, bp_loss: 1.53475/55.00%, hp_loss: 2.44189/36.00%, j_loss: 0.99214/74.00%, \n",
      "\t\tfr_loss: 0.13803/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05463\n",
      "\tPart 4 - fp_loss: 0.88062/74.00%, bp_loss: 1.71198/50.00%, hp_loss: 2.64777/32.00%, j_loss: 1.09586/75.00%, \n",
      "\t\tfr_loss: 0.12752/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.46376\n",
      "\tTraining time elapsed: 263.66 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.22005/65.00%, bp_loss: 2.24951/34.00%, hp_loss: 3.10411/22.00%, j_loss: 1.54155/65.00%, \n",
      "\t\tfr_loss: 0.18284/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.29806\n",
      "\tPart 2 - fp_loss: 1.01587/72.00%, bp_loss: 1.76425/48.00%, hp_loss: 2.74133/32.00%, j_loss: 1.20959/72.00%, \n",
      "\t\tfr_loss: 0.15007/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.88112\n",
      "\tPart 3 - fp_loss: 0.97375/73.00%, bp_loss: 1.58150/54.00%, hp_loss: 2.37668/38.00%, j_loss: 1.02274/73.00%, \n",
      "\t\tfr_loss: 0.13633/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09100\n",
      "\tPart 4 - fp_loss: 0.84066/77.00%, bp_loss: 1.67693/51.00%, hp_loss: 2.59539/34.00%, j_loss: 0.95114/77.00%, \n",
      "\t\tfr_loss: 0.10741/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17153\n",
      "\tTraining time elapsed: 301.17 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.62822/53.00%, bp_loss: 2.61519/21.00%, hp_loss: 3.00962/23.00%, j_loss: 2.02646/53.00%, \n",
      "\t\tfr_loss: 0.21314/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.49263\n",
      "\tPart 2 - fp_loss: 1.30872/61.00%, bp_loss: 2.32943/33.00%, hp_loss: 2.70839/30.00%, j_loss: 1.65224/61.00%, \n",
      "\t\tfr_loss: 0.21730/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.21608\n",
      "\tPart 3 - fp_loss: 0.95210/73.00%, bp_loss: 1.95045/45.00%, hp_loss: 2.27121/42.00%, j_loss: 1.17951/73.00%, \n",
      "\t\tfr_loss: 0.16074/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51399\n",
      "\tPart 4 - fp_loss: 1.02945/73.00%, bp_loss: 2.52685/27.00%, hp_loss: 2.45526/39.00%, j_loss: 1.46431/72.00%, \n",
      "\t\tfr_loss: 0.16450/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.64038\n",
      "\t`Validation time elapsed: 0.72 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.65126/53.00%, bp_loss: 2.22959/32.00%, hp_loss: 3.05025/22.00%, j_loss: 1.92184/53.00%, \n",
      "\t\tfr_loss: 0.21761/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.07055\n",
      "\tPart 2 - fp_loss: 1.32827/61.00%, bp_loss: 1.87689/43.00%, hp_loss: 2.73975/29.00%, j_loss: 1.48261/61.00%, \n",
      "\t\tfr_loss: 0.18746/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.61497\n",
      "\tPart 3 - fp_loss: 0.97952/72.00%, bp_loss: 1.54273/56.00%, hp_loss: 2.28116/43.00%, j_loss: 1.06857/72.00%, \n",
      "\t\tfr_loss: 0.18709/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05908\n",
      "\tPart 4 - fp_loss: 1.11367/70.00%, bp_loss: 1.98678/43.00%, hp_loss: 2.41851/39.00%, j_loss: 1.30770/70.00%, \n",
      "\t\tfr_loss: 0.16848/83.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.99515\n",
      "\t`Validation time elapsed: 9.48 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 14.\n",
      "\n",
      "EPOCH 15\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.15814/64.00%, bp_loss: 2.49723/26.00%, hp_loss: 3.01674/24.00%, j_loss: 1.65450/63.00%, \n",
      "\t\tfr_loss: 0.15609/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.48271\n",
      "\tPart 2 - fp_loss: 0.98165/71.00%, bp_loss: 2.26649/37.00%, hp_loss: 2.68992/33.00%, j_loss: 1.32761/71.00%, \n",
      "\t\tfr_loss: 0.16458/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.43025\n",
      "\tPart 3 - fp_loss: 0.95366/72.00%, bp_loss: 2.05645/43.00%, hp_loss: 2.41775/37.00%, j_loss: 1.23862/72.00%, \n",
      "\t\tfr_loss: 0.14113/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.80760\n",
      "\tPart 4 - fp_loss: 0.83497/77.00%, bp_loss: 2.41472/31.00%, hp_loss: 2.61636/33.00%, j_loss: 1.17362/76.00%, \n",
      "\t\tfr_loss: 0.11763/88.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 7.15731\n",
      "\tTraining time elapsed: 1.07 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.24637/62.00%, bp_loss: 2.09918/37.00%, hp_loss: 3.08443/21.00%, j_loss: 1.59757/62.00%, \n",
      "\t\tfr_loss: 0.17305/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.20060\n",
      "\tPart 2 - fp_loss: 1.00223/70.00%, bp_loss: 1.62814/50.00%, hp_loss: 2.73124/30.00%, j_loss: 1.17417/70.00%, \n",
      "\t\tfr_loss: 0.17581/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.71159\n",
      "\tPart 3 - fp_loss: 0.96571/72.00%, bp_loss: 1.53029/54.00%, hp_loss: 2.42663/37.00%, j_loss: 1.01954/73.00%, \n",
      "\t\tfr_loss: 0.12865/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.07081\n",
      "\tPart 4 - fp_loss: 0.82806/77.00%, bp_loss: 1.63742/51.00%, hp_loss: 2.62712/31.00%, j_loss: 0.96544/77.00%, \n",
      "\t\tfr_loss: 0.11728/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17532\n",
      "\tTraining time elapsed: 38.60 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.18997/63.00%, bp_loss: 2.19973/35.00%, hp_loss: 3.11878/20.00%, j_loss: 1.58260/63.00%, \n",
      "\t\tfr_loss: 0.17902/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.27011\n",
      "\tPart 2 - fp_loss: 0.95865/72.00%, bp_loss: 1.71650/50.00%, hp_loss: 2.74933/31.00%, j_loss: 1.13815/72.00%, \n",
      "\t\tfr_loss: 0.14771/85.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.71035\n",
      "\tPart 3 - fp_loss: 0.91726/74.00%, bp_loss: 1.52086/54.00%, hp_loss: 2.42019/38.00%, j_loss: 1.01414/74.00%, \n",
      "\t\tfr_loss: 0.13349/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.00594\n",
      "\tPart 4 - fp_loss: 0.83600/77.00%, bp_loss: 1.62550/52.00%, hp_loss: 2.64450/32.00%, j_loss: 0.96843/77.00%, \n",
      "\t\tfr_loss: 0.12599/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.20042\n",
      "\tTraining time elapsed: 76.16 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.17732/66.00%, bp_loss: 2.13935/36.00%, hp_loss: 3.06050/22.00%, j_loss: 1.56255/66.00%, \n",
      "\t\tfr_loss: 0.18051/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.12023\n",
      "\tPart 2 - fp_loss: 0.99821/71.00%, bp_loss: 1.76073/47.00%, hp_loss: 2.71573/33.00%, j_loss: 1.19462/71.00%, \n",
      "\t\tfr_loss: 0.17329/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.84259\n",
      "\tPart 3 - fp_loss: 0.96199/73.00%, bp_loss: 1.47470/56.00%, hp_loss: 2.40715/39.00%, j_loss: 1.03200/73.00%, \n",
      "\t\tfr_loss: 0.14159/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01742\n",
      "\tPart 4 - fp_loss: 0.88830/75.00%, bp_loss: 1.67266/49.00%, hp_loss: 2.64088/31.00%, j_loss: 1.06704/75.00%, \n",
      "\t\tfr_loss: 0.14434/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41322\n",
      "\tTraining time elapsed: 113.71 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.24108/64.00%, bp_loss: 2.12650/38.00%, hp_loss: 3.09678/21.00%, j_loss: 1.50039/64.00%, \n",
      "\t\tfr_loss: 0.15695/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.12171\n",
      "\tPart 2 - fp_loss: 1.02782/70.00%, bp_loss: 1.77598/48.00%, hp_loss: 2.73304/33.00%, j_loss: 1.27497/70.00%, \n",
      "\t\tfr_loss: 0.14999/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.96179\n",
      "\tPart 3 - fp_loss: 0.83881/77.00%, bp_loss: 1.47984/57.00%, hp_loss: 2.38759/39.00%, j_loss: 0.90699/77.00%, \n",
      "\t\tfr_loss: 0.14277/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75600\n",
      "\tPart 4 - fp_loss: 0.85170/74.00%, bp_loss: 1.61646/52.00%, hp_loss: 2.63975/32.00%, j_loss: 1.03623/75.00%, \n",
      "\t\tfr_loss: 0.12190/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.26604\n",
      "\tTraining time elapsed: 151.22 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.20554/64.00%, bp_loss: 2.19235/34.00%, hp_loss: 3.07825/23.00%, j_loss: 1.55067/64.00%, \n",
      "\t\tfr_loss: 0.14195/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.16877\n",
      "\tPart 2 - fp_loss: 0.92441/74.00%, bp_loss: 1.70841/49.00%, hp_loss: 2.74762/31.00%, j_loss: 1.08286/74.00%, \n",
      "\t\tfr_loss: 0.15342/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.61674\n",
      "\tPart 3 - fp_loss: 0.90181/74.00%, bp_loss: 1.49492/55.00%, hp_loss: 2.30980/39.00%, j_loss: 0.99051/75.00%, \n",
      "\t\tfr_loss: 0.13142/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.82847\n",
      "\tPart 4 - fp_loss: 0.92177/75.00%, bp_loss: 1.70139/50.00%, hp_loss: 2.63010/32.00%, j_loss: 1.03044/75.00%, \n",
      "\t\tfr_loss: 0.11856/88.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.40227\n",
      "\tTraining time elapsed: 188.76 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.16090/67.00%, bp_loss: 2.11899/37.00%, hp_loss: 3.07353/22.00%, j_loss: 1.42548/67.00%, \n",
      "\t\tfr_loss: 0.16213/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.94103\n",
      "\tPart 2 - fp_loss: 1.00363/70.00%, bp_loss: 1.74577/46.00%, hp_loss: 2.75028/30.00%, j_loss: 1.24988/70.00%, \n",
      "\t\tfr_loss: 0.15578/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.90536\n",
      "\tPart 3 - fp_loss: 1.00839/72.00%, bp_loss: 1.53120/56.00%, hp_loss: 2.43941/37.00%, j_loss: 1.09839/73.00%, \n",
      "\t\tfr_loss: 0.13018/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.20757\n",
      "\tPart 4 - fp_loss: 0.85818/76.00%, bp_loss: 1.60620/52.00%, hp_loss: 2.64948/33.00%, j_loss: 0.97493/76.00%, \n",
      "\t\tfr_loss: 0.13459/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22339\n",
      "\tTraining time elapsed: 226.29 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.10857/67.00%, bp_loss: 2.15945/35.00%, hp_loss: 3.11231/20.00%, j_loss: 1.46317/67.00%, \n",
      "\t\tfr_loss: 0.13449/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.97800\n",
      "\tPart 2 - fp_loss: 0.95107/72.00%, bp_loss: 1.62966/51.00%, hp_loss: 2.69985/32.00%, j_loss: 1.12419/72.00%, \n",
      "\t\tfr_loss: 0.17238/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.57715\n",
      "\tPart 3 - fp_loss: 0.96955/73.00%, bp_loss: 1.40146/60.00%, hp_loss: 2.36604/39.00%, j_loss: 0.98365/73.00%, \n",
      "\t\tfr_loss: 0.14508/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.86578\n",
      "\tPart 4 - fp_loss: 0.84327/76.00%, bp_loss: 1.55084/53.00%, hp_loss: 2.58818/34.00%, j_loss: 0.98293/76.00%, \n",
      "\t\tfr_loss: 0.13251/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09774\n",
      "\tTraining time elapsed: 263.81 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.19754/65.00%, bp_loss: 2.22135/35.00%, hp_loss: 3.08641/22.00%, j_loss: 1.53967/65.00%, \n",
      "\t\tfr_loss: 0.14963/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.19460\n",
      "\tPart 2 - fp_loss: 0.95563/73.00%, bp_loss: 1.77247/48.00%, hp_loss: 2.72727/33.00%, j_loss: 1.17377/73.00%, \n",
      "\t\tfr_loss: 0.15208/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.78123\n",
      "\tPart 3 - fp_loss: 0.92244/74.00%, bp_loss: 1.53115/55.00%, hp_loss: 2.38328/38.00%, j_loss: 1.07765/74.00%, \n",
      "\t\tfr_loss: 0.14059/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05510\n",
      "\tPart 4 - fp_loss: 0.92396/74.00%, bp_loss: 1.51714/55.00%, hp_loss: 2.56724/34.00%, j_loss: 1.01053/75.00%, \n",
      "\t\tfr_loss: 0.12597/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14484\n",
      "\tTraining time elapsed: 301.35 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.55264/55.00%, bp_loss: 2.49592/24.00%, hp_loss: 3.03100/24.00%, j_loss: 1.94432/55.00%, \n",
      "\t\tfr_loss: 0.19421/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.21809\n",
      "\tPart 2 - fp_loss: 1.37762/61.00%, bp_loss: 2.46824/33.00%, hp_loss: 2.79897/29.00%, j_loss: 1.71054/61.00%, \n",
      "\t\tfr_loss: 0.18761/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.54299\n",
      "\tPart 3 - fp_loss: 0.98232/72.00%, bp_loss: 2.18503/44.00%, hp_loss: 2.31040/42.00%, j_loss: 1.26106/71.00%, \n",
      "\t\tfr_loss: 0.15693/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.89575\n",
      "\tPart 4 - fp_loss: 1.08882/73.00%, bp_loss: 2.25321/39.00%, hp_loss: 2.45001/39.00%, j_loss: 1.36230/72.00%, \n",
      "\t\tfr_loss: 0.15274/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.30709\n",
      "\t`Validation time elapsed: 0.72 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.55441/56.00%, bp_loss: 2.18933/33.00%, hp_loss: 3.02558/23.00%, j_loss: 1.81455/56.00%, \n",
      "\t\tfr_loss: 0.21467/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.79855\n",
      "\tPart 2 - fp_loss: 1.26171/63.00%, bp_loss: 1.82557/44.00%, hp_loss: 2.71178/30.00%, j_loss: 1.43925/62.00%, \n",
      "\t\tfr_loss: 0.19271/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.43102\n",
      "\tPart 3 - fp_loss: 1.05017/72.00%, bp_loss: 1.58689/55.00%, hp_loss: 2.29665/43.00%, j_loss: 1.05500/72.00%, \n",
      "\t\tfr_loss: 0.16887/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15759\n",
      "\tPart 4 - fp_loss: 1.18517/70.00%, bp_loss: 1.85967/47.00%, hp_loss: 2.44664/39.00%, j_loss: 1.25389/70.00%, \n",
      "\t\tfr_loss: 0.17002/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.91539\n",
      "\t`Validation time elapsed: 9.48 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 15.\n",
      "\n",
      "EPOCH 16\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.11963/67.00%, bp_loss: 2.51453/28.00%, hp_loss: 3.06534/24.00%, j_loss: 1.54614/66.00%, \n",
      "\t\tfr_loss: 0.17311/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.41875\n",
      "\tPart 2 - fp_loss: 0.91838/73.00%, bp_loss: 2.26676/40.00%, hp_loss: 2.68885/33.00%, j_loss: 1.23467/73.00%, \n",
      "\t\tfr_loss: 0.13989/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.24854\n",
      "\tPart 3 - fp_loss: 0.88806/75.00%, bp_loss: 2.07098/46.00%, hp_loss: 2.41154/39.00%, j_loss: 1.13410/75.00%, \n",
      "\t\tfr_loss: 0.12806/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.63274\n",
      "\tPart 4 - fp_loss: 0.74706/79.00%, bp_loss: 2.14746/38.00%, hp_loss: 2.53500/36.00%, j_loss: 1.08489/79.00%, \n",
      "\t\tfr_loss: 0.12472/87.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.63914\n",
      "\tTraining time elapsed: 1.07 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.16720/65.00%, bp_loss: 2.14327/36.00%, hp_loss: 3.04892/22.00%, j_loss: 1.50783/65.00%, \n",
      "\t\tfr_loss: 0.18497/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.05220\n",
      "\tPart 2 - fp_loss: 0.86731/75.00%, bp_loss: 1.70591/49.00%, hp_loss: 2.68285/33.00%, j_loss: 1.05845/75.00%, \n",
      "\t\tfr_loss: 0.17403/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.48855\n",
      "\tPart 3 - fp_loss: 0.93137/73.00%, bp_loss: 1.54133/56.00%, hp_loss: 2.41345/37.00%, j_loss: 1.07628/73.00%, \n",
      "\t\tfr_loss: 0.12291/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08533\n",
      "\tPart 4 - fp_loss: 0.77686/78.00%, bp_loss: 1.64717/50.00%, hp_loss: 2.65928/32.00%, j_loss: 0.94336/78.00%, \n",
      "\t\tfr_loss: 0.11760/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14428\n",
      "\tTraining time elapsed: 38.57 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.13788/66.00%, bp_loss: 2.10679/36.00%, hp_loss: 3.06900/23.00%, j_loss: 1.49143/66.00%, \n",
      "\t\tfr_loss: 0.19106/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.99616\n",
      "\tPart 2 - fp_loss: 0.94634/74.00%, bp_loss: 1.68910/50.00%, hp_loss: 2.74082/32.00%, j_loss: 1.12041/74.00%, \n",
      "\t\tfr_loss: 0.13237/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.62904\n",
      "\tPart 3 - fp_loss: 0.84447/76.00%, bp_loss: 1.43999/58.00%, hp_loss: 2.43444/37.00%, j_loss: 0.90551/77.00%, \n",
      "\t\tfr_loss: 0.11131/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.73572\n",
      "\tPart 4 - fp_loss: 0.80436/77.00%, bp_loss: 1.60377/54.00%, hp_loss: 2.64166/33.00%, j_loss: 0.99101/76.00%, \n",
      "\t\tfr_loss: 0.11784/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15864\n",
      "\tTraining time elapsed: 76.08 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.14318/65.00%, bp_loss: 2.06765/39.00%, hp_loss: 3.02275/23.00%, j_loss: 1.48372/65.00%, \n",
      "\t\tfr_loss: 0.16753/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.88483\n",
      "\tPart 2 - fp_loss: 1.03617/71.00%, bp_loss: 1.80499/47.00%, hp_loss: 2.77072/30.00%, j_loss: 1.21237/71.00%, \n",
      "\t\tfr_loss: 0.16008/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.98433\n",
      "\tPart 3 - fp_loss: 0.91283/73.00%, bp_loss: 1.52943/56.00%, hp_loss: 2.45118/35.00%, j_loss: 1.02240/73.00%, \n",
      "\t\tfr_loss: 0.13225/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.04809\n",
      "\tPart 4 - fp_loss: 0.80374/76.00%, bp_loss: 1.61826/50.00%, hp_loss: 2.56183/33.00%, j_loss: 1.00342/77.00%, \n",
      "\t\tfr_loss: 0.10979/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09704\n",
      "\tTraining time elapsed: 113.55 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.18365/63.00%, bp_loss: 2.17171/37.00%, hp_loss: 3.11964/21.00%, j_loss: 1.51665/63.00%, \n",
      "\t\tfr_loss: 0.18541/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.17707\n",
      "\tPart 2 - fp_loss: 0.92547/74.00%, bp_loss: 1.76423/46.00%, hp_loss: 2.79908/30.00%, j_loss: 1.12753/74.00%, \n",
      "\t\tfr_loss: 0.15270/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.76901\n",
      "\tPart 3 - fp_loss: 0.97849/72.00%, bp_loss: 1.44971/57.00%, hp_loss: 2.45239/37.00%, j_loss: 1.02170/73.00%, \n",
      "\t\tfr_loss: 0.14142/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.04372\n",
      "\tPart 4 - fp_loss: 0.88847/75.00%, bp_loss: 1.56446/53.00%, hp_loss: 2.66343/32.00%, j_loss: 1.00771/76.00%, \n",
      "\t\tfr_loss: 0.14014/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26422\n",
      "\tTraining time elapsed: 151.02 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.13250/66.00%, bp_loss: 2.15649/35.00%, hp_loss: 3.10560/21.00%, j_loss: 1.46456/66.00%, \n",
      "\t\tfr_loss: 0.15744/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.01660\n",
      "\tPart 2 - fp_loss: 0.96660/72.00%, bp_loss: 1.73158/48.00%, hp_loss: 2.75215/30.00%, j_loss: 1.15816/72.00%, \n",
      "\t\tfr_loss: 0.16259/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.77107\n",
      "\tPart 3 - fp_loss: 0.95960/73.00%, bp_loss: 1.43913/59.00%, hp_loss: 2.43332/38.00%, j_loss: 0.99460/74.00%, \n",
      "\t\tfr_loss: 0.13697/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.96362\n",
      "\tPart 4 - fp_loss: 0.84656/77.00%, bp_loss: 1.55656/52.00%, hp_loss: 2.63516/32.00%, j_loss: 0.96590/77.00%, \n",
      "\t\tfr_loss: 0.12109/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.12528\n",
      "\tTraining time elapsed: 188.53 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.19042/63.00%, bp_loss: 2.17991/35.00%, hp_loss: 3.09410/21.00%, j_loss: 1.54483/63.00%, \n",
      "\t\tfr_loss: 0.15529/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.16455\n",
      "\tPart 2 - fp_loss: 0.98845/72.00%, bp_loss: 1.74324/49.00%, hp_loss: 2.82965/30.00%, j_loss: 1.17087/72.00%, \n",
      "\t\tfr_loss: 0.16506/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.89728\n",
      "\tPart 3 - fp_loss: 0.97151/74.00%, bp_loss: 1.43793/59.00%, hp_loss: 2.35453/40.00%, j_loss: 0.97711/74.00%, \n",
      "\t\tfr_loss: 0.13711/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.87819\n",
      "\tPart 4 - fp_loss: 0.87168/76.00%, bp_loss: 1.58515/52.00%, hp_loss: 2.58491/34.00%, j_loss: 0.98386/76.00%, \n",
      "\t\tfr_loss: 0.10617/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13178\n",
      "\tTraining time elapsed: 226.02 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.19642/63.00%, bp_loss: 2.26750/33.00%, hp_loss: 3.12150/21.00%, j_loss: 1.59686/62.00%, \n",
      "\t\tfr_loss: 0.16386/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.34614\n",
      "\tPart 2 - fp_loss: 0.96569/72.00%, bp_loss: 1.67877/49.00%, hp_loss: 2.65361/34.00%, j_loss: 1.15563/72.00%, \n",
      "\t\tfr_loss: 0.16120/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.61491\n",
      "\tPart 3 - fp_loss: 0.89846/75.00%, bp_loss: 1.47167/56.00%, hp_loss: 2.44140/39.00%, j_loss: 1.00637/75.00%, \n",
      "\t\tfr_loss: 0.11661/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.93451\n",
      "\tPart 4 - fp_loss: 0.90650/75.00%, bp_loss: 1.64721/52.00%, hp_loss: 2.71953/30.00%, j_loss: 1.01849/76.00%, \n",
      "\t\tfr_loss: 0.11658/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.40830\n",
      "\tTraining time elapsed: 263.52 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.17243/65.00%, bp_loss: 2.23997/34.00%, hp_loss: 3.06752/22.00%, j_loss: 1.54790/65.00%, \n",
      "\t\tfr_loss: 0.17142/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.19924\n",
      "\tPart 2 - fp_loss: 0.90281/74.00%, bp_loss: 1.67302/50.00%, hp_loss: 2.72661/31.00%, j_loss: 1.04608/74.00%, \n",
      "\t\tfr_loss: 0.16211/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51063\n",
      "\tPart 3 - fp_loss: 0.90944/73.00%, bp_loss: 1.43616/58.00%, hp_loss: 2.47639/33.00%, j_loss: 1.04531/73.00%, \n",
      "\t\tfr_loss: 0.13492/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.00223\n",
      "\tPart 4 - fp_loss: 0.84521/76.00%, bp_loss: 1.58900/54.00%, hp_loss: 2.62386/31.00%, j_loss: 0.97878/76.00%, \n",
      "\t\tfr_loss: 0.11383/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15067\n",
      "\tTraining time elapsed: 300.99 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.53420/53.00%, bp_loss: 2.51908/22.00%, hp_loss: 3.03892/22.00%, j_loss: 1.96047/53.00%, \n",
      "\t\tfr_loss: 0.21771/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.27038\n",
      "\tPart 2 - fp_loss: 1.43214/59.00%, bp_loss: 2.37268/32.00%, hp_loss: 2.80556/27.00%, j_loss: 1.75072/59.00%, \n",
      "\t\tfr_loss: 0.20662/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.56772\n",
      "\tPart 3 - fp_loss: 1.01023/72.00%, bp_loss: 2.09359/43.00%, hp_loss: 2.34823/41.00%, j_loss: 1.24186/72.00%, \n",
      "\t\tfr_loss: 0.16235/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.85626\n",
      "\tPart 4 - fp_loss: 1.20562/69.00%, bp_loss: 2.33466/33.00%, hp_loss: 2.43392/36.00%, j_loss: 1.53985/68.00%, \n",
      "\t\tfr_loss: 0.17207/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.68611\n",
      "\t`Validation time elapsed: 0.70 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.60507/51.00%, bp_loss: 2.28696/31.00%, hp_loss: 3.06529/22.00%, j_loss: 1.98377/51.00%, \n",
      "\t\tfr_loss: 0.21194/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.15303\n",
      "\tPart 2 - fp_loss: 1.39070/59.00%, bp_loss: 1.88370/44.00%, hp_loss: 2.80654/27.00%, j_loss: 1.60188/59.00%, \n",
      "\t\tfr_loss: 0.16427/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.84709\n",
      "\tPart 3 - fp_loss: 1.08907/69.00%, bp_loss: 1.62288/52.00%, hp_loss: 2.26533/44.00%, j_loss: 1.22640/70.00%, \n",
      "\t\tfr_loss: 0.16607/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36976\n",
      "\tPart 4 - fp_loss: 1.29207/65.00%, bp_loss: 1.98178/44.00%, hp_loss: 2.48864/39.00%, j_loss: 1.45003/66.00%, \n",
      "\t\tfr_loss: 0.18251/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.39503\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 16.\n",
      "\n",
      "EPOCH 17\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.04628/69.00%, bp_loss: 2.50696/27.00%, hp_loss: 3.07845/20.00%, j_loss: 1.44206/69.00%, \n",
      "\t\tfr_loss: 0.16338/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.23713\n",
      "\tPart 2 - fp_loss: 0.92675/72.00%, bp_loss: 2.23746/41.00%, hp_loss: 2.70307/32.00%, j_loss: 1.29282/72.00%, \n",
      "\t\tfr_loss: 0.14207/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.30217\n",
      "\tPart 3 - fp_loss: 0.84869/76.00%, bp_loss: 1.95884/45.00%, hp_loss: 2.45336/38.00%, j_loss: 1.08387/75.00%, \n",
      "\t\tfr_loss: 0.13177/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47653\n",
      "\tPart 4 - fp_loss: 0.75180/77.00%, bp_loss: 2.08523/42.00%, hp_loss: 2.62730/32.00%, j_loss: 1.05484/78.00%, \n",
      "\t\tfr_loss: 0.11853/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.63770\n",
      "\tTraining time elapsed: 1.05 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.09226/69.00%, bp_loss: 2.04982/40.00%, hp_loss: 3.04586/23.00%, j_loss: 1.37595/69.00%, \n",
      "\t\tfr_loss: 0.17648/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.74037\n",
      "\tPart 2 - fp_loss: 1.01301/70.00%, bp_loss: 1.62823/51.00%, hp_loss: 2.73148/33.00%, j_loss: 1.18070/70.00%, \n",
      "\t\tfr_loss: 0.15657/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.70999\n",
      "\tPart 3 - fp_loss: 0.92885/73.00%, bp_loss: 1.49139/55.00%, hp_loss: 2.51022/37.00%, j_loss: 1.04127/73.00%, \n",
      "\t\tfr_loss: 0.12616/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09789\n",
      "\tPart 4 - fp_loss: 0.78677/78.00%, bp_loss: 1.58976/54.00%, hp_loss: 2.68608/31.00%, j_loss: 0.87172/78.00%, \n",
      "\t\tfr_loss: 0.11872/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05306\n",
      "\tTraining time elapsed: 38.54 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.11480/67.00%, bp_loss: 2.19363/37.00%, hp_loss: 3.04539/22.00%, j_loss: 1.43755/67.00%, \n",
      "\t\tfr_loss: 0.15816/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.94953\n",
      "\tPart 2 - fp_loss: 0.97864/72.00%, bp_loss: 1.67890/50.00%, hp_loss: 2.74441/31.00%, j_loss: 1.11366/72.00%, \n",
      "\t\tfr_loss: 0.15158/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.66718\n",
      "\tPart 3 - fp_loss: 1.01874/71.00%, bp_loss: 1.39789/58.00%, hp_loss: 2.38772/40.00%, j_loss: 1.04753/71.00%, \n",
      "\t\tfr_loss: 0.14229/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.99415\n",
      "\tPart 4 - fp_loss: 0.84839/75.00%, bp_loss: 1.55428/54.00%, hp_loss: 2.64915/32.00%, j_loss: 0.99673/75.00%, \n",
      "\t\tfr_loss: 0.11925/88.00%, p_loss: 0.00001/100.00%, \n",
      "\t\ttotal weighted loss: 6.16781\n",
      "\tTraining time elapsed: 76.07 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.15673/65.00%, bp_loss: 2.11177/37.00%, hp_loss: 3.05234/22.00%, j_loss: 1.50458/65.00%, \n",
      "\t\tfr_loss: 0.16564/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.99106\n",
      "\tPart 2 - fp_loss: 0.88184/74.00%, bp_loss: 1.67179/49.00%, hp_loss: 2.70145/33.00%, j_loss: 1.07838/74.00%, \n",
      "\t\tfr_loss: 0.16360/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.49707\n",
      "\tPart 3 - fp_loss: 0.94107/74.00%, bp_loss: 1.42181/58.00%, hp_loss: 2.41863/38.00%, j_loss: 0.99494/75.00%, \n",
      "\t\tfr_loss: 0.15282/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92927\n",
      "\tPart 4 - fp_loss: 0.77260/77.00%, bp_loss: 1.56668/52.00%, hp_loss: 2.64064/31.00%, j_loss: 0.90161/76.00%, \n",
      "\t\tfr_loss: 0.12340/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.00494\n",
      "\tTraining time elapsed: 113.58 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.04898/68.00%, bp_loss: 2.15931/36.00%, hp_loss: 3.04668/24.00%, j_loss: 1.43913/68.00%, \n",
      "\t\tfr_loss: 0.17675/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.87086\n",
      "\tPart 2 - fp_loss: 0.94402/72.00%, bp_loss: 1.71467/50.00%, hp_loss: 2.76747/31.00%, j_loss: 1.15872/72.00%, \n",
      "\t\tfr_loss: 0.14588/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.73077\n",
      "\tPart 3 - fp_loss: 0.96000/72.00%, bp_loss: 1.49110/56.00%, hp_loss: 2.49059/35.00%, j_loss: 1.00336/73.00%, \n",
      "\t\tfr_loss: 0.13907/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08412\n",
      "\tPart 4 - fp_loss: 0.81651/77.00%, bp_loss: 1.63535/53.00%, hp_loss: 2.69236/30.00%, j_loss: 0.97819/77.00%, \n",
      "\t\tfr_loss: 0.11030/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23271\n",
      "\tTraining time elapsed: 151.06 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.14403/66.00%, bp_loss: 2.10494/41.00%, hp_loss: 3.09241/22.00%, j_loss: 1.40290/66.00%, \n",
      "\t\tfr_loss: 0.15078/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.89506\n",
      "\tPart 2 - fp_loss: 0.88760/74.00%, bp_loss: 1.60647/53.00%, hp_loss: 2.71144/33.00%, j_loss: 1.06250/74.00%, \n",
      "\t\tfr_loss: 0.12291/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.39091\n",
      "\tPart 3 - fp_loss: 0.91557/74.00%, bp_loss: 1.43810/57.00%, hp_loss: 2.38111/38.00%, j_loss: 0.98561/75.00%, \n",
      "\t\tfr_loss: 0.11779/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.83817\n",
      "\tPart 4 - fp_loss: 0.83222/75.00%, bp_loss: 1.51606/54.00%, hp_loss: 2.61605/33.00%, j_loss: 0.99578/75.00%, \n",
      "\t\tfr_loss: 0.12084/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08095\n",
      "\tTraining time elapsed: 188.57 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.11987/67.00%, bp_loss: 2.12624/38.00%, hp_loss: 3.09422/21.00%, j_loss: 1.42114/67.00%, \n",
      "\t\tfr_loss: 0.16155/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.92301\n",
      "\tPart 2 - fp_loss: 0.98733/71.00%, bp_loss: 1.69772/48.00%, hp_loss: 2.73194/32.00%, j_loss: 1.20847/71.00%, \n",
      "\t\tfr_loss: 0.15612/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.78159\n",
      "\tPart 3 - fp_loss: 0.87934/74.00%, bp_loss: 1.38056/60.00%, hp_loss: 2.40536/38.00%, j_loss: 0.94184/74.00%, \n",
      "\t\tfr_loss: 0.13110/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.73821\n",
      "\tPart 4 - fp_loss: 0.80086/78.00%, bp_loss: 1.61817/52.00%, hp_loss: 2.72365/29.00%, j_loss: 0.93109/79.00%, \n",
      "\t\tfr_loss: 0.11381/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.18758\n",
      "\tTraining time elapsed: 226.10 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.12420/67.00%, bp_loss: 2.21090/36.00%, hp_loss: 3.09697/22.00%, j_loss: 1.45435/67.00%, \n",
      "\t\tfr_loss: 0.18612/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.07254\n",
      "\tPart 2 - fp_loss: 1.01959/70.00%, bp_loss: 1.70582/49.00%, hp_loss: 2.75753/31.00%, j_loss: 1.20125/70.00%, \n",
      "\t\tfr_loss: 0.18621/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.87041\n",
      "\tPart 3 - fp_loss: 0.82214/76.00%, bp_loss: 1.45210/58.00%, hp_loss: 2.32082/42.00%, j_loss: 0.92355/77.00%, \n",
      "\t\tfr_loss: 0.13196/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.65058\n",
      "\tPart 4 - fp_loss: 0.76118/78.00%, bp_loss: 1.46049/57.00%, hp_loss: 2.57117/34.00%, j_loss: 0.86546/78.00%, \n",
      "\t\tfr_loss: 0.10285/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.76115\n",
      "\tTraining time elapsed: 263.64 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.22749/65.00%, bp_loss: 2.21274/35.00%, hp_loss: 3.11451/21.00%, j_loss: 1.52891/65.00%, \n",
      "\t\tfr_loss: 0.18029/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.26393\n",
      "\tPart 2 - fp_loss: 0.93027/73.00%, bp_loss: 1.64501/52.00%, hp_loss: 2.75423/31.00%, j_loss: 1.09131/73.00%, \n",
      "\t\tfr_loss: 0.15436/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.57519\n",
      "\tPart 3 - fp_loss: 0.87148/75.00%, bp_loss: 1.39976/59.00%, hp_loss: 2.42800/38.00%, j_loss: 0.91219/76.00%, \n",
      "\t\tfr_loss: 0.14834/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75977\n",
      "\tPart 4 - fp_loss: 0.78799/78.00%, bp_loss: 1.64670/55.00%, hp_loss: 2.56178/34.00%, j_loss: 0.94607/77.00%, \n",
      "\t\tfr_loss: 0.11401/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05655\n",
      "\tTraining time elapsed: 301.15 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.63358/52.00%, bp_loss: 2.50436/26.00%, hp_loss: 2.96889/25.00%, j_loss: 1.99077/52.00%, \n",
      "\t\tfr_loss: 0.23802/75.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.33562\n",
      "\tPart 2 - fp_loss: 1.29671/60.00%, bp_loss: 2.29185/37.00%, hp_loss: 2.68013/30.00%, j_loss: 1.66556/60.00%, \n",
      "\t\tfr_loss: 0.17393/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.10820\n",
      "\tPart 3 - fp_loss: 0.97756/74.00%, bp_loss: 1.99425/48.00%, hp_loss: 2.27875/42.00%, j_loss: 1.14632/74.00%, \n",
      "\t\tfr_loss: 0.13785/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.53472\n",
      "\tPart 4 - fp_loss: 1.16045/71.00%, bp_loss: 2.25864/39.00%, hp_loss: 2.51637/36.00%, j_loss: 1.33633/71.00%, \n",
      "\t\tfr_loss: 0.16115/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.43294\n",
      "\t`Validation time elapsed: 0.73 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.71608/51.00%, bp_loss: 2.23496/31.00%, hp_loss: 3.06603/20.00%, j_loss: 1.98112/51.00%, \n",
      "\t\tfr_loss: 0.21629/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.21448\n",
      "\tPart 2 - fp_loss: 1.30178/62.00%, bp_loss: 1.80156/47.00%, hp_loss: 2.69333/31.00%, j_loss: 1.45082/62.00%, \n",
      "\t\tfr_loss: 0.18165/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.42915\n",
      "\tPart 3 - fp_loss: 1.03485/72.00%, bp_loss: 1.48175/57.00%, hp_loss: 2.27301/42.00%, j_loss: 1.06523/73.00%, \n",
      "\t\tfr_loss: 0.16507/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01990\n",
      "\tPart 4 - fp_loss: 1.19778/69.00%, bp_loss: 1.74178/50.00%, hp_loss: 2.51440/37.00%, j_loss: 1.24544/70.00%, \n",
      "\t\tfr_loss: 0.17987/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.87926\n",
      "\t`Validation time elapsed: 9.46 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 17.\n",
      "\n",
      "EPOCH 18\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.09715/66.00%, bp_loss: 2.41703/32.00%, hp_loss: 3.04204/23.00%, j_loss: 1.51855/66.00%, \n",
      "\t\tfr_loss: 0.17078/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.24556\n",
      "\tPart 2 - fp_loss: 0.95277/73.00%, bp_loss: 2.33381/39.00%, hp_loss: 2.74485/31.00%, j_loss: 1.26126/73.00%, \n",
      "\t\tfr_loss: 0.15002/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.44271\n",
      "\tPart 3 - fp_loss: 0.85436/76.00%, bp_loss: 1.92174/47.00%, hp_loss: 2.35651/39.00%, j_loss: 1.07426/75.00%, \n",
      "\t\tfr_loss: 0.11666/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.32353\n",
      "\tPart 4 - fp_loss: 0.79487/77.00%, bp_loss: 1.98893/43.00%, hp_loss: 2.57911/33.00%, j_loss: 1.10997/76.00%, \n",
      "\t\tfr_loss: 0.11970/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.59258\n",
      "\tTraining time elapsed: 1.05 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.11675/66.00%, bp_loss: 2.19295/37.00%, hp_loss: 3.12848/21.00%, j_loss: 1.47401/66.00%, \n",
      "\t\tfr_loss: 0.14936/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.06154\n",
      "\tPart 2 - fp_loss: 0.97071/73.00%, bp_loss: 1.72254/50.00%, hp_loss: 2.78787/30.00%, j_loss: 1.11736/73.00%, \n",
      "\t\tfr_loss: 0.13280/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.73129\n",
      "\tPart 3 - fp_loss: 0.87847/75.00%, bp_loss: 1.47077/59.00%, hp_loss: 2.35108/40.00%, j_loss: 0.91101/76.00%, \n",
      "\t\tfr_loss: 0.13549/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.74682\n",
      "\tPart 4 - fp_loss: 0.80599/77.00%, bp_loss: 1.48814/56.00%, hp_loss: 2.52717/34.00%, j_loss: 0.90620/78.00%, \n",
      "\t\tfr_loss: 0.11712/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.84463\n",
      "\tTraining time elapsed: 38.59 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.15091/65.00%, bp_loss: 2.18395/36.00%, hp_loss: 3.14837/21.00%, j_loss: 1.53421/65.00%, \n",
      "\t\tfr_loss: 0.15668/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.17411\n",
      "\tPart 2 - fp_loss: 0.95215/72.00%, bp_loss: 1.77063/47.00%, hp_loss: 2.78457/30.00%, j_loss: 1.18647/72.00%, \n",
      "\t\tfr_loss: 0.14476/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.83858\n",
      "\tPart 3 - fp_loss: 0.87654/75.00%, bp_loss: 1.47087/58.00%, hp_loss: 2.44804/37.00%, j_loss: 0.93119/75.00%, \n",
      "\t\tfr_loss: 0.11177/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.83842\n",
      "\tPart 4 - fp_loss: 0.78749/77.00%, bp_loss: 1.57465/54.00%, hp_loss: 2.58903/33.00%, j_loss: 0.91118/77.00%, \n",
      "\t\tfr_loss: 0.11428/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.97663\n",
      "\tTraining time elapsed: 76.11 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.14722/67.00%, bp_loss: 2.09733/38.00%, hp_loss: 3.03855/24.00%, j_loss: 1.44142/67.00%, \n",
      "\t\tfr_loss: 0.15963/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.88415\n",
      "\tPart 2 - fp_loss: 0.93254/74.00%, bp_loss: 1.65769/51.00%, hp_loss: 2.74738/33.00%, j_loss: 1.05472/74.00%, \n",
      "\t\tfr_loss: 0.13542/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.52775\n",
      "\tPart 3 - fp_loss: 0.89424/75.00%, bp_loss: 1.45768/56.00%, hp_loss: 2.40491/37.00%, j_loss: 0.92592/75.00%, \n",
      "\t\tfr_loss: 0.11994/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.80270\n",
      "\tPart 4 - fp_loss: 0.88146/75.00%, bp_loss: 1.56127/54.00%, hp_loss: 2.61514/32.00%, j_loss: 0.96437/75.00%, \n",
      "\t\tfr_loss: 0.11683/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13907\n",
      "\tTraining time elapsed: 113.60 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.16544/68.00%, bp_loss: 2.23791/34.00%, hp_loss: 3.12966/20.00%, j_loss: 1.46010/68.00%, \n",
      "\t\tfr_loss: 0.17157/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.16468\n",
      "\tPart 2 - fp_loss: 0.91551/73.00%, bp_loss: 1.69837/49.00%, hp_loss: 2.67694/34.00%, j_loss: 1.12051/73.00%, \n",
      "\t\tfr_loss: 0.15895/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.57029\n",
      "\tPart 3 - fp_loss: 0.86488/75.00%, bp_loss: 1.38190/61.00%, hp_loss: 2.40518/38.00%, j_loss: 0.91370/76.00%, \n",
      "\t\tfr_loss: 0.12052/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.68618\n",
      "\tPart 4 - fp_loss: 0.84627/76.00%, bp_loss: 1.57428/55.00%, hp_loss: 2.65376/31.00%, j_loss: 0.96182/76.00%, \n",
      "\t\tfr_loss: 0.11473/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15086\n",
      "\tTraining time elapsed: 151.11 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.06825/69.00%, bp_loss: 2.13219/38.00%, hp_loss: 3.10865/22.00%, j_loss: 1.40027/69.00%, \n",
      "\t\tfr_loss: 0.15786/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.86721\n",
      "\tPart 2 - fp_loss: 0.95140/71.00%, bp_loss: 1.65345/51.00%, hp_loss: 2.75093/30.00%, j_loss: 1.11083/71.00%, \n",
      "\t\tfr_loss: 0.15112/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.61773\n",
      "\tPart 3 - fp_loss: 0.89385/75.00%, bp_loss: 1.37207/62.00%, hp_loss: 2.33943/40.00%, j_loss: 0.88230/76.00%, \n",
      "\t\tfr_loss: 0.13507/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.62272\n",
      "\tPart 4 - fp_loss: 0.87435/75.00%, bp_loss: 1.53197/54.00%, hp_loss: 2.60765/32.00%, j_loss: 0.97146/75.00%, \n",
      "\t\tfr_loss: 0.11269/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09813\n",
      "\tTraining time elapsed: 188.63 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.08119/67.00%, bp_loss: 2.16919/35.00%, hp_loss: 3.13943/21.00%, j_loss: 1.47914/67.00%, \n",
      "\t\tfr_loss: 0.16183/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.03079\n",
      "\tPart 2 - fp_loss: 0.88252/75.00%, bp_loss: 1.64830/53.00%, hp_loss: 2.72572/33.00%, j_loss: 1.05634/75.00%, \n",
      "\t\tfr_loss: 0.14384/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.45671\n",
      "\tPart 3 - fp_loss: 0.93270/75.00%, bp_loss: 1.29088/64.00%, hp_loss: 2.36524/39.00%, j_loss: 0.86551/76.00%, \n",
      "\t\tfr_loss: 0.14701/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60135\n",
      "\tPart 4 - fp_loss: 0.79290/77.00%, bp_loss: 1.46562/56.00%, hp_loss: 2.55903/34.00%, j_loss: 0.88042/78.00%, \n",
      "\t\tfr_loss: 0.11936/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.81735\n",
      "\tTraining time elapsed: 226.14 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.11494/67.00%, bp_loss: 2.21123/35.00%, hp_loss: 3.11161/23.00%, j_loss: 1.47960/67.00%, \n",
      "\t\tfr_loss: 0.15296/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.07033\n",
      "\tPart 2 - fp_loss: 0.94993/74.00%, bp_loss: 1.67492/52.00%, hp_loss: 2.78660/30.00%, j_loss: 1.09556/74.00%, \n",
      "\t\tfr_loss: 0.14257/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.64959\n",
      "\tPart 3 - fp_loss: 0.89225/74.00%, bp_loss: 1.34555/60.00%, hp_loss: 2.42588/37.00%, j_loss: 0.93146/75.00%, \n",
      "\t\tfr_loss: 0.12466/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.71980\n",
      "\tPart 4 - fp_loss: 0.82596/77.00%, bp_loss: 1.57784/55.00%, hp_loss: 2.65017/31.00%, j_loss: 0.90135/77.00%, \n",
      "\t\tfr_loss: 0.11802/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.07336\n",
      "\tTraining time elapsed: 263.64 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.19763/63.00%, bp_loss: 2.20781/35.00%, hp_loss: 3.11590/20.00%, j_loss: 1.61232/63.00%, \n",
      "\t\tfr_loss: 0.15845/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.29210\n",
      "\tPart 2 - fp_loss: 0.98313/70.00%, bp_loss: 1.59741/52.00%, hp_loss: 2.64379/34.00%, j_loss: 1.18001/70.00%, \n",
      "\t\tfr_loss: 0.13975/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.54410\n",
      "\tPart 3 - fp_loss: 0.87082/75.00%, bp_loss: 1.29366/62.00%, hp_loss: 2.30410/39.00%, j_loss: 0.91988/75.00%, \n",
      "\t\tfr_loss: 0.12052/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.50899\n",
      "\tPart 4 - fp_loss: 0.77813/78.00%, bp_loss: 1.42474/59.00%, hp_loss: 2.47724/36.00%, j_loss: 0.87702/78.00%, \n",
      "\t\tfr_loss: 0.10310/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66022\n",
      "\tTraining time elapsed: 301.14 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.71973/53.00%, bp_loss: 2.43736/25.00%, hp_loss: 3.02325/23.00%, j_loss: 2.01330/52.00%, \n",
      "\t\tfr_loss: 0.21536/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.40900\n",
      "\tPart 2 - fp_loss: 1.34743/61.00%, bp_loss: 2.40814/35.00%, hp_loss: 2.73411/29.00%, j_loss: 1.65830/61.00%, \n",
      "\t\tfr_loss: 0.19058/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.33857\n",
      "\tPart 3 - fp_loss: 1.05298/71.00%, bp_loss: 1.88309/50.00%, hp_loss: 2.20820/45.00%, j_loss: 1.24882/70.00%, \n",
      "\t\tfr_loss: 0.20198/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.59508\n",
      "\tPart 4 - fp_loss: 1.14589/71.00%, bp_loss: 2.09448/41.00%, hp_loss: 2.42056/40.00%, j_loss: 1.37238/70.00%, \n",
      "\t\tfr_loss: 0.18300/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.21630\n",
      "\t`Validation time elapsed: 0.74 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.61697/52.00%, bp_loss: 2.19302/35.00%, hp_loss: 3.08103/21.00%, j_loss: 1.94531/52.00%, \n",
      "\t\tfr_loss: 0.22214/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.05847\n",
      "\tPart 2 - fp_loss: 1.39645/61.00%, bp_loss: 1.77914/46.00%, hp_loss: 2.70440/30.00%, j_loss: 1.48111/60.00%, \n",
      "\t\tfr_loss: 0.20677/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.56787\n",
      "\tPart 3 - fp_loss: 0.96490/72.00%, bp_loss: 1.39011/59.00%, hp_loss: 2.24904/44.00%, j_loss: 1.02172/73.00%, \n",
      "\t\tfr_loss: 0.16805/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.79381\n",
      "\tPart 4 - fp_loss: 1.15919/69.00%, bp_loss: 1.75082/51.00%, hp_loss: 2.44474/38.00%, j_loss: 1.25803/69.00%, \n",
      "\t\tfr_loss: 0.18257/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.79535\n",
      "\t`Validation time elapsed: 9.49 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 18.\n",
      "\n",
      "EPOCH 19\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.02132/70.00%, bp_loss: 2.35831/33.00%, hp_loss: 3.05252/22.00%, j_loss: 1.39882/70.00%, \n",
      "\t\tfr_loss: 0.13935/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.97032\n",
      "\tPart 2 - fp_loss: 0.84847/74.00%, bp_loss: 2.41847/37.00%, hp_loss: 2.74897/30.00%, j_loss: 1.26942/73.00%, \n",
      "\t\tfr_loss: 0.13174/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.41707\n",
      "\tPart 3 - fp_loss: 0.90228/74.00%, bp_loss: 1.95378/49.00%, hp_loss: 2.44625/38.00%, j_loss: 1.15229/74.00%, \n",
      "\t\tfr_loss: 0.10985/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.56444\n",
      "\tPart 4 - fp_loss: 0.73482/79.00%, bp_loss: 1.99801/44.00%, hp_loss: 2.62161/31.00%, j_loss: 0.99812/78.00%, \n",
      "\t\tfr_loss: 0.12129/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47386\n",
      "\tTraining time elapsed: 1.05 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.11660/67.00%, bp_loss: 2.12979/38.00%, hp_loss: 3.10536/21.00%, j_loss: 1.40630/67.00%, \n",
      "\t\tfr_loss: 0.16309/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.92115\n",
      "\tPart 2 - fp_loss: 0.92570/74.00%, bp_loss: 1.62424/52.00%, hp_loss: 2.75948/31.00%, j_loss: 1.06833/74.00%, \n",
      "\t\tfr_loss: 0.15167/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.52942\n",
      "\tPart 3 - fp_loss: 0.88271/76.00%, bp_loss: 1.33561/61.00%, hp_loss: 2.43244/38.00%, j_loss: 0.86366/77.00%, \n",
      "\t\tfr_loss: 0.11635/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.63076\n",
      "\tPart 4 - fp_loss: 0.78554/78.00%, bp_loss: 1.43722/58.00%, hp_loss: 2.50573/36.00%, j_loss: 0.86009/78.00%, \n",
      "\t\tfr_loss: 0.11197/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.70054\n",
      "\tTraining time elapsed: 38.59 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.07303/69.00%, bp_loss: 2.12764/38.00%, hp_loss: 3.09544/22.00%, j_loss: 1.33521/69.00%, \n",
      "\t\tfr_loss: 0.15211/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.78342\n",
      "\tPart 2 - fp_loss: 0.86441/75.00%, bp_loss: 1.54624/55.00%, hp_loss: 2.69996/33.00%, j_loss: 0.98411/75.00%, \n",
      "\t\tfr_loss: 0.14983/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24455\n",
      "\tPart 3 - fp_loss: 0.83864/77.00%, bp_loss: 1.34285/61.00%, hp_loss: 2.41339/38.00%, j_loss: 0.86511/78.00%, \n",
      "\t\tfr_loss: 0.13378/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.59378\n",
      "\tPart 4 - fp_loss: 0.76163/78.00%, bp_loss: 1.43271/56.00%, hp_loss: 2.63308/32.00%, j_loss: 0.90168/78.00%, \n",
      "\t\tfr_loss: 0.12571/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.85481\n",
      "\tTraining time elapsed: 76.08 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.03282/67.00%, bp_loss: 2.10573/37.00%, hp_loss: 3.07093/22.00%, j_loss: 1.43200/67.00%, \n",
      "\t\tfr_loss: 0.16172/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.80319\n",
      "\tPart 2 - fp_loss: 0.86144/75.00%, bp_loss: 1.60864/54.00%, hp_loss: 2.74286/32.00%, j_loss: 1.00532/75.00%, \n",
      "\t\tfr_loss: 0.14276/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36102\n",
      "\tPart 3 - fp_loss: 0.87265/76.00%, bp_loss: 1.39476/58.00%, hp_loss: 2.45909/37.00%, j_loss: 0.90026/77.00%, \n",
      "\t\tfr_loss: 0.14530/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77205\n",
      "\tPart 4 - fp_loss: 0.75727/80.00%, bp_loss: 1.40302/60.00%, hp_loss: 2.61682/34.00%, j_loss: 0.77834/80.00%, \n",
      "\t\tfr_loss: 0.11382/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66926\n",
      "\tTraining time elapsed: 113.56 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.13300/66.00%, bp_loss: 2.14852/37.00%, hp_loss: 3.04802/22.00%, j_loss: 1.45704/66.00%, \n",
      "\t\tfr_loss: 0.16219/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.94878\n",
      "\tPart 2 - fp_loss: 0.86464/75.00%, bp_loss: 1.58999/55.00%, hp_loss: 2.70686/33.00%, j_loss: 0.99205/75.00%, \n",
      "\t\tfr_loss: 0.15143/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30497\n",
      "\tPart 3 - fp_loss: 0.91463/74.00%, bp_loss: 1.40756/59.00%, hp_loss: 2.43147/37.00%, j_loss: 0.99035/75.00%, \n",
      "\t\tfr_loss: 0.11665/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.86067\n",
      "\tPart 4 - fp_loss: 0.85399/77.00%, bp_loss: 1.51713/56.00%, hp_loss: 2.67531/31.00%, j_loss: 0.93664/77.00%, \n",
      "\t\tfr_loss: 0.11027/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09334\n",
      "\tTraining time elapsed: 151.03 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.12200/67.00%, bp_loss: 2.15215/38.00%, hp_loss: 3.07910/22.00%, j_loss: 1.49812/67.00%, \n",
      "\t\tfr_loss: 0.16403/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.01540\n",
      "\tPart 2 - fp_loss: 0.83720/76.00%, bp_loss: 1.59802/52.00%, hp_loss: 2.70947/33.00%, j_loss: 1.02419/76.00%, \n",
      "\t\tfr_loss: 0.14570/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31457\n",
      "\tPart 3 - fp_loss: 0.87599/76.00%, bp_loss: 1.37219/61.00%, hp_loss: 2.40854/38.00%, j_loss: 0.87720/77.00%, \n",
      "\t\tfr_loss: 0.13036/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66428\n",
      "\tPart 4 - fp_loss: 0.78227/78.00%, bp_loss: 1.43547/58.00%, hp_loss: 2.65478/33.00%, j_loss: 0.86479/78.00%, \n",
      "\t\tfr_loss: 0.10261/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.83991\n",
      "\tTraining time elapsed: 188.51 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.12690/66.00%, bp_loss: 2.08772/38.00%, hp_loss: 3.04787/24.00%, j_loss: 1.46642/66.00%, \n",
      "\t\tfr_loss: 0.16170/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.89061\n",
      "\tPart 2 - fp_loss: 0.92997/74.00%, bp_loss: 1.61292/53.00%, hp_loss: 2.68641/34.00%, j_loss: 1.09953/74.00%, \n",
      "\t\tfr_loss: 0.14332/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47215\n",
      "\tPart 3 - fp_loss: 0.91906/74.00%, bp_loss: 1.29195/62.00%, hp_loss: 2.41747/37.00%, j_loss: 0.92403/74.00%, \n",
      "\t\tfr_loss: 0.12792/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.68044\n",
      "\tPart 4 - fp_loss: 0.71491/79.00%, bp_loss: 1.41643/59.00%, hp_loss: 2.58471/35.00%, j_loss: 0.84227/80.00%, \n",
      "\t\tfr_loss: 0.10964/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66795\n",
      "\tTraining time elapsed: 226.00 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.16232/67.00%, bp_loss: 2.17754/36.00%, hp_loss: 3.11837/21.00%, j_loss: 1.45304/66.00%, \n",
      "\t\tfr_loss: 0.15339/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.06465\n",
      "\tPart 2 - fp_loss: 0.93879/72.00%, bp_loss: 1.59162/52.00%, hp_loss: 2.76898/31.00%, j_loss: 1.11091/72.00%, \n",
      "\t\tfr_loss: 0.14613/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.55643\n",
      "\tPart 3 - fp_loss: 0.89756/73.00%, bp_loss: 1.34767/62.00%, hp_loss: 2.37455/38.00%, j_loss: 0.90985/74.00%, \n",
      "\t\tfr_loss: 0.14097/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.67060\n",
      "\tPart 4 - fp_loss: 0.80719/77.00%, bp_loss: 1.34266/61.00%, hp_loss: 2.59283/34.00%, j_loss: 0.83336/78.00%, \n",
      "\t\tfr_loss: 0.11473/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.69078\n",
      "\tTraining time elapsed: 263.54 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.11530/65.00%, bp_loss: 2.14023/38.00%, hp_loss: 3.10114/23.00%, j_loss: 1.48351/65.00%, \n",
      "\t\tfr_loss: 0.16445/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.00463\n",
      "\tPart 2 - fp_loss: 0.94796/72.00%, bp_loss: 1.57086/52.00%, hp_loss: 2.74334/32.00%, j_loss: 1.09009/72.00%, \n",
      "\t\tfr_loss: 0.14057/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.49282\n",
      "\tPart 3 - fp_loss: 0.86887/76.00%, bp_loss: 1.28743/63.00%, hp_loss: 2.37380/39.00%, j_loss: 0.88560/77.00%, \n",
      "\t\tfr_loss: 0.13382/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.54952\n",
      "\tPart 4 - fp_loss: 0.77637/78.00%, bp_loss: 1.42044/60.00%, hp_loss: 2.64364/32.00%, j_loss: 0.82344/79.00%, \n",
      "\t\tfr_loss: 0.10646/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77035\n",
      "\tTraining time elapsed: 301.04 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.68207/52.00%, bp_loss: 2.41712/26.00%, hp_loss: 3.04678/22.00%, j_loss: 2.07182/52.00%, \n",
      "\t\tfr_loss: 0.20602/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.42381\n",
      "\tPart 2 - fp_loss: 1.41500/59.00%, bp_loss: 2.51036/30.00%, hp_loss: 2.83453/25.00%, j_loss: 1.75240/59.00%, \n",
      "\t\tfr_loss: 0.20347/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.71577\n",
      "\tPart 3 - fp_loss: 1.05771/72.00%, bp_loss: 1.81035/48.00%, hp_loss: 2.25505/42.00%, j_loss: 1.21297/72.00%, \n",
      "\t\tfr_loss: 0.17670/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51277\n",
      "\tPart 4 - fp_loss: 1.33115/69.00%, bp_loss: 2.19424/40.00%, hp_loss: 2.46784/38.00%, j_loss: 1.44181/69.00%, \n",
      "\t\tfr_loss: 0.17578/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.61082\n",
      "\t`Validation time elapsed: 0.71 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.67440/53.00%, bp_loss: 2.26372/30.00%, hp_loss: 3.07310/21.00%, j_loss: 1.98235/53.00%, \n",
      "\t\tfr_loss: 0.21292/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.20650\n",
      "\tPart 2 - fp_loss: 1.31800/62.00%, bp_loss: 1.84994/44.00%, hp_loss: 2.74460/30.00%, j_loss: 1.44012/62.00%, \n",
      "\t\tfr_loss: 0.18792/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.54057\n",
      "\tPart 3 - fp_loss: 1.08023/70.00%, bp_loss: 1.39820/60.00%, hp_loss: 2.29427/42.00%, j_loss: 1.07543/72.00%, \n",
      "\t\tfr_loss: 0.17596/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.02409\n",
      "\tPart 4 - fp_loss: 1.15454/71.00%, bp_loss: 1.70139/54.00%, hp_loss: 2.43747/39.00%, j_loss: 1.17727/72.00%, \n",
      "\t\tfr_loss: 0.15512/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.62579\n",
      "\t`Validation time elapsed: 9.45 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Completed epoch 19.\n",
      "\n",
      "EPOCH 20\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.04436/70.00%, bp_loss: 2.41397/32.00%, hp_loss: 3.05280/24.00%, j_loss: 1.39524/70.00%, \n",
      "\t\tfr_loss: 0.13741/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.04378\n",
      "\tPart 2 - fp_loss: 0.95313/74.00%, bp_loss: 2.31843/39.00%, hp_loss: 2.74377/32.00%, j_loss: 1.22220/74.00%, \n",
      "\t\tfr_loss: 0.15360/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.39113\n",
      "\tPart 3 - fp_loss: 0.91011/74.00%, bp_loss: 1.83358/49.00%, hp_loss: 2.46387/35.00%, j_loss: 1.10266/74.00%, \n",
      "\t\tfr_loss: 0.12183/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.43205\n",
      "\tPart 4 - fp_loss: 0.76685/78.00%, bp_loss: 1.83634/46.00%, hp_loss: 2.64157/32.00%, j_loss: 0.98227/77.00%, \n",
      "\t\tfr_loss: 0.10134/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.32838\n",
      "\tTraining time elapsed: 1.09 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.12278/67.00%, bp_loss: 2.17519/37.00%, hp_loss: 3.10548/22.00%, j_loss: 1.46414/67.00%, \n",
      "\t\tfr_loss: 0.15788/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.02548\n",
      "\tPart 2 - fp_loss: 0.82887/76.00%, bp_loss: 1.64322/50.00%, hp_loss: 2.73571/31.00%, j_loss: 0.99418/76.00%, \n",
      "\t\tfr_loss: 0.13660/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33858\n",
      "\tPart 3 - fp_loss: 0.80997/76.00%, bp_loss: 1.38015/61.00%, hp_loss: 2.43596/35.00%, j_loss: 0.86102/77.00%, \n",
      "\t\tfr_loss: 0.11436/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60146\n",
      "\tPart 4 - fp_loss: 0.78940/79.00%, bp_loss: 1.47139/59.00%, hp_loss: 2.65201/32.00%, j_loss: 0.78675/78.00%, \n",
      "\t\tfr_loss: 0.09839/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.79794\n",
      "\tTraining time elapsed: 38.59 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.18264/66.00%, bp_loss: 2.15970/36.00%, hp_loss: 3.11788/21.00%, j_loss: 1.50945/66.00%, \n",
      "\t\tfr_loss: 0.14657/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.11623\n",
      "\tPart 2 - fp_loss: 0.92348/73.00%, bp_loss: 1.58365/52.00%, hp_loss: 2.71687/34.00%, j_loss: 1.12028/73.00%, \n",
      "\t\tfr_loss: 0.15345/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.49773\n",
      "\tPart 3 - fp_loss: 0.84584/76.00%, bp_loss: 1.41697/58.00%, hp_loss: 2.44409/36.00%, j_loss: 0.87777/77.00%, \n",
      "\t\tfr_loss: 0.11812/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.70279\n",
      "\tPart 4 - fp_loss: 0.70394/80.00%, bp_loss: 1.44140/58.00%, hp_loss: 2.68269/31.00%, j_loss: 0.83196/79.00%, \n",
      "\t\tfr_loss: 0.11740/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77739\n",
      "\tTraining time elapsed: 76.07 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.15428/66.00%, bp_loss: 2.12277/38.00%, hp_loss: 3.09277/21.00%, j_loss: 1.45935/66.00%, \n",
      "\t\tfr_loss: 0.14434/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.97351\n",
      "\tPart 2 - fp_loss: 0.85208/75.00%, bp_loss: 1.59275/52.00%, hp_loss: 2.65841/34.00%, j_loss: 1.06077/74.00%, \n",
      "\t\tfr_loss: 0.13841/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30242\n",
      "\tPart 3 - fp_loss: 0.71630/80.00%, bp_loss: 1.27321/63.00%, hp_loss: 2.34325/41.00%, j_loss: 0.74557/80.00%, \n",
      "\t\tfr_loss: 0.08964/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16797\n",
      "\tPart 4 - fp_loss: 0.69319/80.00%, bp_loss: 1.35966/62.00%, hp_loss: 2.54731/37.00%, j_loss: 0.76815/80.00%, \n",
      "\t\tfr_loss: 0.10668/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47500\n",
      "\tTraining time elapsed: 113.56 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.02831/69.00%, bp_loss: 2.07787/38.00%, hp_loss: 3.10104/21.00%, j_loss: 1.38503/69.00%, \n",
      "\t\tfr_loss: 0.14903/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.74127\n",
      "\tPart 2 - fp_loss: 0.89776/73.00%, bp_loss: 1.54901/55.00%, hp_loss: 2.66581/34.00%, j_loss: 1.03592/73.00%, \n",
      "\t\tfr_loss: 0.15425/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30276\n",
      "\tPart 3 - fp_loss: 0.84385/76.00%, bp_loss: 1.37716/61.00%, hp_loss: 2.41675/36.00%, j_loss: 0.88626/76.00%, \n",
      "\t\tfr_loss: 0.12038/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.64440\n",
      "\tPart 4 - fp_loss: 0.81345/78.00%, bp_loss: 1.42913/58.00%, hp_loss: 2.66676/30.00%, j_loss: 0.84490/78.00%, \n",
      "\t\tfr_loss: 0.11582/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.87007\n",
      "\tTraining time elapsed: 151.05 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.13599/65.00%, bp_loss: 2.14426/36.00%, hp_loss: 3.16622/19.00%, j_loss: 1.48380/65.00%, \n",
      "\t\tfr_loss: 0.17366/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.10393\n",
      "\tPart 2 - fp_loss: 0.95720/72.00%, bp_loss: 1.60232/52.00%, hp_loss: 2.78970/30.00%, j_loss: 1.07369/73.00%, \n",
      "\t\tfr_loss: 0.15502/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.57793\n",
      "\tPart 3 - fp_loss: 0.88303/75.00%, bp_loss: 1.29001/64.00%, hp_loss: 2.41067/38.00%, j_loss: 0.86167/76.00%, \n",
      "\t\tfr_loss: 0.12970/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57507\n",
      "\tPart 4 - fp_loss: 0.71231/79.00%, bp_loss: 1.30508/62.00%, hp_loss: 2.56486/35.00%, j_loss: 0.74225/80.00%, \n",
      "\t\tfr_loss: 0.12011/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44462\n",
      "\tTraining time elapsed: 188.57 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.04549/68.00%, bp_loss: 2.13120/37.00%, hp_loss: 3.08466/21.00%, j_loss: 1.40291/68.00%, \n",
      "\t\tfr_loss: 0.15820/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.82246\n",
      "\tPart 2 - fp_loss: 0.91784/74.00%, bp_loss: 1.53329/54.00%, hp_loss: 2.65343/33.00%, j_loss: 1.02590/74.00%, \n",
      "\t\tfr_loss: 0.16258/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29304\n",
      "\tPart 3 - fp_loss: 0.88546/76.00%, bp_loss: 1.34532/62.00%, hp_loss: 2.32718/39.00%, j_loss: 0.81757/76.00%, \n",
      "\t\tfr_loss: 0.12471/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.50023\n",
      "\tPart 4 - fp_loss: 0.76986/78.00%, bp_loss: 1.34777/62.00%, hp_loss: 2.63537/32.00%, j_loss: 0.77636/78.00%, \n",
      "\t\tfr_loss: 0.09572/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.62508\n",
      "\tTraining time elapsed: 226.06 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.03211/69.00%, bp_loss: 2.09971/39.00%, hp_loss: 3.02216/25.00%, j_loss: 1.34463/69.00%, \n",
      "\t\tfr_loss: 0.15416/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.65275\n",
      "\tPart 2 - fp_loss: 0.81693/76.00%, bp_loss: 1.56497/52.00%, hp_loss: 2.68853/33.00%, j_loss: 0.99297/76.00%, \n",
      "\t\tfr_loss: 0.13678/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.20017\n",
      "\tPart 3 - fp_loss: 0.85016/76.00%, bp_loss: 1.35143/61.00%, hp_loss: 2.35864/36.00%, j_loss: 0.86475/77.00%, \n",
      "\t\tfr_loss: 0.12509/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55006\n",
      "\tPart 4 - fp_loss: 0.75590/78.00%, bp_loss: 1.33451/62.00%, hp_loss: 2.53958/35.00%, j_loss: 0.78375/79.00%, \n",
      "\t\tfr_loss: 0.13265/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.54638\n",
      "\tTraining time elapsed: 263.59 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.14395/67.00%, bp_loss: 2.14151/37.00%, hp_loss: 3.04502/23.00%, j_loss: 1.37172/67.00%, \n",
      "\t\tfr_loss: 0.17116/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.87335\n",
      "\tPart 2 - fp_loss: 0.97184/72.00%, bp_loss: 1.59789/51.00%, hp_loss: 2.75768/31.00%, j_loss: 1.13432/72.00%, \n",
      "\t\tfr_loss: 0.15588/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.61761\n",
      "\tPart 3 - fp_loss: 0.89901/76.00%, bp_loss: 1.33015/62.00%, hp_loss: 2.39429/38.00%, j_loss: 0.83662/78.00%, \n",
      "\t\tfr_loss: 0.11186/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57192\n",
      "\tPart 4 - fp_loss: 0.78325/78.00%, bp_loss: 1.37464/60.00%, hp_loss: 2.64968/31.00%, j_loss: 0.76102/79.00%, \n",
      "\t\tfr_loss: 0.11287/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.68147\n",
      "\tTraining time elapsed: 301.12 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.67868/53.00%, bp_loss: 2.34477/28.00%, hp_loss: 3.06611/22.00%, j_loss: 2.01561/53.00%, \n",
      "\t\tfr_loss: 0.22197/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.32714\n",
      "\tPart 2 - fp_loss: 1.43348/58.00%, bp_loss: 2.27898/36.00%, hp_loss: 2.76574/28.00%, j_loss: 1.71242/59.00%, \n",
      "\t\tfr_loss: 0.19709/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.38771\n",
      "\tPart 3 - fp_loss: 1.00873/71.00%, bp_loss: 1.96013/44.00%, hp_loss: 2.42094/39.00%, j_loss: 1.21827/71.00%, \n",
      "\t\tfr_loss: 0.16986/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.77792\n",
      "\tPart 4 - fp_loss: 1.21116/69.00%, bp_loss: 1.98697/46.00%, hp_loss: 2.43544/39.00%, j_loss: 1.26958/68.00%, \n",
      "\t\tfr_loss: 0.16676/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.06990\n",
      "\t`Validation time elapsed: 0.71 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.68451/53.00%, bp_loss: 2.17406/34.00%, hp_loss: 3.02547/24.00%, j_loss: 1.93673/53.00%, \n",
      "\t\tfr_loss: 0.20242/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.02318\n",
      "\tPart 2 - fp_loss: 1.32241/62.00%, bp_loss: 1.86325/45.00%, hp_loss: 2.74427/29.00%, j_loss: 1.50792/62.00%, \n",
      "\t\tfr_loss: 0.17143/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.60927\n",
      "\tPart 3 - fp_loss: 1.00299/73.00%, bp_loss: 1.49148/56.00%, hp_loss: 2.31977/41.00%, j_loss: 1.04365/73.00%, \n",
      "\t\tfr_loss: 0.17411/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03201\n",
      "\tPart 4 - fp_loss: 1.16813/73.00%, bp_loss: 1.69574/55.00%, hp_loss: 2.43582/39.00%, j_loss: 1.14807/74.00%, \n",
      "\t\tfr_loss: 0.13829/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58606\n",
      "\t`Validation time elapsed: 9.47 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 20.\n",
      "\n",
      "EPOCH 21\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.99417/71.00%, bp_loss: 2.26722/32.00%, hp_loss: 3.11540/21.00%, j_loss: 1.34561/71.00%, \n",
      "\t\tfr_loss: 0.14704/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.86944\n",
      "\tPart 2 - fp_loss: 0.83404/76.00%, bp_loss: 2.25572/41.00%, hp_loss: 2.79591/31.00%, j_loss: 1.15470/76.00%, \n",
      "\t\tfr_loss: 0.13353/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.17389\n",
      "\tPart 3 - fp_loss: 0.79612/77.00%, bp_loss: 1.76237/50.00%, hp_loss: 2.44076/37.00%, j_loss: 0.99057/77.00%, \n",
      "\t\tfr_loss: 0.12056/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11037\n",
      "\tPart 4 - fp_loss: 0.71605/80.00%, bp_loss: 1.66171/54.00%, hp_loss: 2.72321/32.00%, j_loss: 0.83900/79.00%, \n",
      "\t\tfr_loss: 0.10816/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.04812\n",
      "\tTraining time elapsed: 1.08 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.06707/67.00%, bp_loss: 2.08988/40.00%, hp_loss: 3.08360/23.00%, j_loss: 1.39349/67.00%, \n",
      "\t\tfr_loss: 0.15302/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.78705\n",
      "\tPart 2 - fp_loss: 0.88878/75.00%, bp_loss: 1.54610/55.00%, hp_loss: 2.68261/33.00%, j_loss: 1.01648/75.00%, \n",
      "\t\tfr_loss: 0.16479/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29876\n",
      "\tPart 3 - fp_loss: 0.80910/77.00%, bp_loss: 1.34618/62.00%, hp_loss: 2.35012/39.00%, j_loss: 0.87357/77.00%, \n",
      "\t\tfr_loss: 0.11908/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.49805\n",
      "\tPart 4 - fp_loss: 0.70234/80.00%, bp_loss: 1.31632/62.00%, hp_loss: 2.59102/35.00%, j_loss: 0.70568/80.00%, \n",
      "\t\tfr_loss: 0.10088/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.41624\n",
      "\tTraining time elapsed: 38.65 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.13052/66.00%, bp_loss: 2.06301/38.00%, hp_loss: 3.04249/24.00%, j_loss: 1.47376/66.00%, \n",
      "\t\tfr_loss: 0.15524/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.86503\n",
      "\tPart 2 - fp_loss: 0.81512/76.00%, bp_loss: 1.56604/54.00%, hp_loss: 2.72827/33.00%, j_loss: 1.00262/76.00%, \n",
      "\t\tfr_loss: 0.13362/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24568\n",
      "\tPart 3 - fp_loss: 0.80863/77.00%, bp_loss: 1.33119/60.00%, hp_loss: 2.39637/39.00%, j_loss: 0.88489/78.00%, \n",
      "\t\tfr_loss: 0.12902/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55009\n",
      "\tPart 4 - fp_loss: 0.82627/78.00%, bp_loss: 1.32377/61.00%, hp_loss: 2.62905/33.00%, j_loss: 0.84107/78.00%, \n",
      "\t\tfr_loss: 0.12159/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.74174\n",
      "\tTraining time elapsed: 76.21 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.06953/68.00%, bp_loss: 2.10598/39.00%, hp_loss: 3.08319/21.00%, j_loss: 1.35185/68.00%, \n",
      "\t\tfr_loss: 0.14204/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.75259\n",
      "\tPart 2 - fp_loss: 0.85859/75.00%, bp_loss: 1.60584/54.00%, hp_loss: 2.73057/32.00%, j_loss: 0.98658/75.00%, \n",
      "\t\tfr_loss: 0.14319/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.32476\n",
      "\tPart 3 - fp_loss: 0.81761/75.00%, bp_loss: 1.30898/63.00%, hp_loss: 2.41655/38.00%, j_loss: 0.85809/75.00%, \n",
      "\t\tfr_loss: 0.11315/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.51439\n",
      "\tPart 4 - fp_loss: 0.75166/78.00%, bp_loss: 1.34430/62.00%, hp_loss: 2.58148/34.00%, j_loss: 0.82401/79.00%, \n",
      "\t\tfr_loss: 0.10883/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.61028\n",
      "\tTraining time elapsed: 113.77 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.06716/68.00%, bp_loss: 2.05686/39.00%, hp_loss: 3.13842/20.00%, j_loss: 1.34989/68.00%, \n",
      "\t\tfr_loss: 0.15607/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.76841\n",
      "\tPart 2 - fp_loss: 0.92649/73.00%, bp_loss: 1.58512/54.00%, hp_loss: 2.77015/30.00%, j_loss: 1.04011/73.00%, \n",
      "\t\tfr_loss: 0.15986/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.48174\n",
      "\tPart 3 - fp_loss: 0.78534/78.00%, bp_loss: 1.28144/63.00%, hp_loss: 2.47707/36.00%, j_loss: 0.75207/79.00%, \n",
      "\t\tfr_loss: 0.11999/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.41590\n",
      "\tPart 4 - fp_loss: 0.76444/79.00%, bp_loss: 1.25733/64.00%, hp_loss: 2.69015/31.00%, j_loss: 0.72827/81.00%, \n",
      "\t\tfr_loss: 0.11067/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55087\n",
      "\tTraining time elapsed: 151.28 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.03859/69.00%, bp_loss: 2.08031/39.00%, hp_loss: 3.08455/23.00%, j_loss: 1.38938/69.00%, \n",
      "\t\tfr_loss: 0.15579/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.74862\n",
      "\tPart 2 - fp_loss: 0.91858/75.00%, bp_loss: 1.59003/52.00%, hp_loss: 2.76316/32.00%, j_loss: 1.02890/75.00%, \n",
      "\t\tfr_loss: 0.15825/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.45892\n",
      "\tPart 3 - fp_loss: 0.86867/74.00%, bp_loss: 1.29594/62.00%, hp_loss: 2.43418/38.00%, j_loss: 0.87726/75.00%, \n",
      "\t\tfr_loss: 0.12684/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60288\n",
      "\tPart 4 - fp_loss: 0.73120/81.00%, bp_loss: 1.24554/65.00%, hp_loss: 2.61111/34.00%, j_loss: 0.69526/81.00%, \n",
      "\t\tfr_loss: 0.11816/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40126\n",
      "\tTraining time elapsed: 188.81 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.01280/70.00%, bp_loss: 2.15008/37.00%, hp_loss: 3.16267/18.00%, j_loss: 1.35711/70.00%, \n",
      "\t\tfr_loss: 0.16336/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.84602\n",
      "\tPart 2 - fp_loss: 0.89796/74.00%, bp_loss: 1.54778/52.00%, hp_loss: 2.72914/33.00%, j_loss: 1.04637/74.00%, \n",
      "\t\tfr_loss: 0.14277/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36402\n",
      "\tPart 3 - fp_loss: 0.82411/77.00%, bp_loss: 1.24740/64.00%, hp_loss: 2.43521/38.00%, j_loss: 0.77574/78.00%, \n",
      "\t\tfr_loss: 0.12386/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40632\n",
      "\tPart 4 - fp_loss: 0.80482/77.00%, bp_loss: 1.18203/65.00%, hp_loss: 2.65645/33.00%, j_loss: 0.73901/79.00%, \n",
      "\t\tfr_loss: 0.12333/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.50564\n",
      "\tTraining time elapsed: 226.33 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.06992/67.00%, bp_loss: 2.10780/40.00%, hp_loss: 3.05605/22.00%, j_loss: 1.41892/67.00%, \n",
      "\t\tfr_loss: 0.15588/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.80857\n",
      "\tPart 2 - fp_loss: 0.86139/73.00%, bp_loss: 1.58023/54.00%, hp_loss: 2.65731/34.00%, j_loss: 1.00996/73.00%, \n",
      "\t\tfr_loss: 0.14312/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25200\n",
      "\tPart 3 - fp_loss: 0.86038/74.00%, bp_loss: 1.25008/64.00%, hp_loss: 2.33743/40.00%, j_loss: 0.90569/74.00%, \n",
      "\t\tfr_loss: 0.12329/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47687\n",
      "\tPart 4 - fp_loss: 0.72989/78.00%, bp_loss: 1.23312/65.00%, hp_loss: 2.64047/33.00%, j_loss: 0.73981/80.00%, \n",
      "\t\tfr_loss: 0.10366/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44696\n",
      "\tTraining time elapsed: 263.88 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.07006/69.00%, bp_loss: 2.08328/39.00%, hp_loss: 3.02790/22.00%, j_loss: 1.35999/69.00%, \n",
      "\t\tfr_loss: 0.13970/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.68093\n",
      "\tPart 2 - fp_loss: 0.92564/74.00%, bp_loss: 1.56868/52.00%, hp_loss: 2.72388/32.00%, j_loss: 1.03205/74.00%, \n",
      "\t\tfr_loss: 0.16679/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41704\n",
      "\tPart 3 - fp_loss: 0.84745/76.00%, bp_loss: 1.23488/64.00%, hp_loss: 2.37874/39.00%, j_loss: 0.81586/78.00%, \n",
      "\t\tfr_loss: 0.14236/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.41929\n",
      "\tPart 4 - fp_loss: 0.76041/79.00%, bp_loss: 1.19254/65.00%, hp_loss: 2.55928/34.00%, j_loss: 0.71698/80.00%, \n",
      "\t\tfr_loss: 0.11316/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.34237\n",
      "\tTraining time elapsed: 301.39 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.58397/56.00%, bp_loss: 2.44085/28.00%, hp_loss: 3.01238/22.00%, j_loss: 1.87490/56.00%, \n",
      "\t\tfr_loss: 0.20462/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.11671\n",
      "\tPart 2 - fp_loss: 1.41495/61.00%, bp_loss: 2.20011/40.00%, hp_loss: 2.72324/29.00%, j_loss: 1.60862/61.00%, \n",
      "\t\tfr_loss: 0.18723/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.13415\n",
      "\tPart 3 - fp_loss: 1.01720/73.00%, bp_loss: 1.84440/51.00%, hp_loss: 2.25370/43.00%, j_loss: 1.07782/72.00%, \n",
      "\t\tfr_loss: 0.16489/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.35800\n",
      "\tPart 4 - fp_loss: 1.16728/71.00%, bp_loss: 1.75427/51.00%, hp_loss: 2.43556/37.00%, j_loss: 1.16672/70.00%, \n",
      "\t\tfr_loss: 0.15636/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.68019\n",
      "\t`Validation time elapsed: 0.74 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.71897/52.00%, bp_loss: 2.19200/34.00%, hp_loss: 3.06027/22.00%, j_loss: 1.90261/52.00%, \n",
      "\t\tfr_loss: 0.22460/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.09844\n",
      "\tPart 2 - fp_loss: 1.38159/61.00%, bp_loss: 1.84296/43.00%, hp_loss: 2.73596/30.00%, j_loss: 1.50348/61.00%, \n",
      "\t\tfr_loss: 0.18745/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.65144\n",
      "\tPart 3 - fp_loss: 1.05123/70.00%, bp_loss: 1.39507/60.00%, hp_loss: 2.31236/42.00%, j_loss: 1.08867/71.00%, \n",
      "\t\tfr_loss: 0.16716/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01449\n",
      "\tPart 4 - fp_loss: 1.21210/70.00%, bp_loss: 1.65710/55.00%, hp_loss: 2.52581/37.00%, j_loss: 1.16085/73.00%, \n",
      "\t\tfr_loss: 0.15576/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.71161\n",
      "\t`Validation time elapsed: 9.50 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 21.\n",
      "\n",
      "EPOCH 22\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.98265/69.00%, bp_loss: 2.40754/34.00%, hp_loss: 3.14096/20.00%, j_loss: 1.39167/69.00%, \n",
      "\t\tfr_loss: 0.13748/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.06031\n",
      "\tPart 2 - fp_loss: 0.87466/74.00%, bp_loss: 2.05252/42.00%, hp_loss: 2.75182/30.00%, j_loss: 1.17532/74.00%, \n",
      "\t\tfr_loss: 0.15485/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.00917\n",
      "\tPart 3 - fp_loss: 0.90905/74.00%, bp_loss: 1.78943/52.00%, hp_loss: 2.47446/37.00%, j_loss: 1.06157/74.00%, \n",
      "\t\tfr_loss: 0.12575/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36026\n",
      "\tPart 4 - fp_loss: 0.67467/80.00%, bp_loss: 1.45425/60.00%, hp_loss: 2.54880/33.00%, j_loss: 0.76707/79.00%, \n",
      "\t\tfr_loss: 0.10075/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.54555\n",
      "\tTraining time elapsed: 1.07 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.04294/71.00%, bp_loss: 2.04725/40.00%, hp_loss: 3.07732/21.00%, j_loss: 1.28596/71.00%, \n",
      "\t\tfr_loss: 0.14927/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.60273\n",
      "\tPart 2 - fp_loss: 0.79650/78.00%, bp_loss: 1.60907/53.00%, hp_loss: 2.79360/29.00%, j_loss: 0.91167/78.00%, \n",
      "\t\tfr_loss: 0.13607/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24692\n",
      "\tPart 3 - fp_loss: 0.86629/76.00%, bp_loss: 1.25352/64.00%, hp_loss: 2.50543/36.00%, j_loss: 0.81353/77.00%, \n",
      "\t\tfr_loss: 0.12690/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.56567\n",
      "\tPart 4 - fp_loss: 0.81422/77.00%, bp_loss: 1.27448/63.00%, hp_loss: 2.64800/31.00%, j_loss: 0.84666/79.00%, \n",
      "\t\tfr_loss: 0.11777/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.70113\n",
      "\tTraining time elapsed: 38.59 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.08404/68.00%, bp_loss: 2.14013/38.00%, hp_loss: 3.10093/22.00%, j_loss: 1.37260/68.00%, \n",
      "\t\tfr_loss: 0.16777/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.86547\n",
      "\tPart 2 - fp_loss: 0.81045/77.00%, bp_loss: 1.58051/53.00%, hp_loss: 2.73554/33.00%, j_loss: 0.96362/77.00%, \n",
      "\t\tfr_loss: 0.14179/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23190\n",
      "\tPart 3 - fp_loss: 0.83614/77.00%, bp_loss: 1.30794/62.00%, hp_loss: 2.42817/37.00%, j_loss: 0.83180/78.00%, \n",
      "\t\tfr_loss: 0.11813/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.52219\n",
      "\tPart 4 - fp_loss: 0.73430/79.00%, bp_loss: 1.32421/63.00%, hp_loss: 2.70414/30.00%, j_loss: 0.71000/80.00%, \n",
      "\t\tfr_loss: 0.11623/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.58887\n",
      "\tTraining time elapsed: 76.13 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.11334/67.00%, bp_loss: 2.13206/39.00%, hp_loss: 3.10347/23.00%, j_loss: 1.41010/67.00%, \n",
      "\t\tfr_loss: 0.16041/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.91938\n",
      "\tPart 2 - fp_loss: 0.86445/75.00%, bp_loss: 1.53811/55.00%, hp_loss: 2.69571/32.00%, j_loss: 0.98615/75.00%, \n",
      "\t\tfr_loss: 0.15307/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23749\n",
      "\tPart 3 - fp_loss: 0.83147/76.00%, bp_loss: 1.20594/66.00%, hp_loss: 2.36782/39.00%, j_loss: 0.74748/77.00%, \n",
      "\t\tfr_loss: 0.11456/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.26726\n",
      "\tPart 4 - fp_loss: 0.84018/75.00%, bp_loss: 1.21604/66.00%, hp_loss: 2.67826/31.00%, j_loss: 0.80138/77.00%, \n",
      "\t\tfr_loss: 0.12773/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66360\n",
      "\tTraining time elapsed: 113.67 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.04481/71.00%, bp_loss: 2.09396/38.00%, hp_loss: 3.08850/23.00%, j_loss: 1.34225/70.00%, \n",
      "\t\tfr_loss: 0.14224/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.71176\n",
      "\tPart 2 - fp_loss: 0.87954/74.00%, bp_loss: 1.57242/54.00%, hp_loss: 2.77967/32.00%, j_loss: 0.99959/74.00%, \n",
      "\t\tfr_loss: 0.15260/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.38382\n",
      "\tPart 3 - fp_loss: 0.83751/76.00%, bp_loss: 1.32885/62.00%, hp_loss: 2.48186/37.00%, j_loss: 0.80372/78.00%, \n",
      "\t\tfr_loss: 0.12137/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57332\n",
      "\tPart 4 - fp_loss: 0.81114/78.00%, bp_loss: 1.29192/62.00%, hp_loss: 2.65010/34.00%, j_loss: 0.79393/79.00%, \n",
      "\t\tfr_loss: 0.11531/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66241\n",
      "\tTraining time elapsed: 151.22 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.06455/68.00%, bp_loss: 2.04489/40.00%, hp_loss: 3.10296/21.00%, j_loss: 1.37771/68.00%, \n",
      "\t\tfr_loss: 0.16640/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.75651\n",
      "\tPart 2 - fp_loss: 0.82567/75.00%, bp_loss: 1.64091/52.00%, hp_loss: 2.71456/33.00%, j_loss: 1.04158/75.00%, \n",
      "\t\tfr_loss: 0.14668/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36940\n",
      "\tPart 3 - fp_loss: 0.88143/76.00%, bp_loss: 1.19868/65.00%, hp_loss: 2.46189/36.00%, j_loss: 0.81073/78.00%, \n",
      "\t\tfr_loss: 0.12263/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47535\n",
      "\tPart 4 - fp_loss: 0.73264/79.00%, bp_loss: 1.18247/67.00%, hp_loss: 2.60953/33.00%, j_loss: 0.64347/81.00%, \n",
      "\t\tfr_loss: 0.10067/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.26878\n",
      "\tTraining time elapsed: 188.76 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.15625/65.00%, bp_loss: 2.06309/40.00%, hp_loss: 3.12148/22.00%, j_loss: 1.45994/65.00%, \n",
      "\t\tfr_loss: 0.14154/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.94230\n",
      "\tPart 2 - fp_loss: 0.87909/74.00%, bp_loss: 1.60576/53.00%, hp_loss: 2.65354/35.00%, j_loss: 1.06274/73.00%, \n",
      "\t\tfr_loss: 0.13990/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.34104\n",
      "\tPart 3 - fp_loss: 0.84747/76.00%, bp_loss: 1.21863/66.00%, hp_loss: 2.42829/37.00%, j_loss: 0.81340/78.00%, \n",
      "\t\tfr_loss: 0.11720/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.42500\n",
      "\tPart 4 - fp_loss: 0.78179/78.00%, bp_loss: 1.13006/67.00%, hp_loss: 2.59730/34.00%, j_loss: 0.78105/79.00%, \n",
      "\t\tfr_loss: 0.09986/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.39006\n",
      "\tTraining time elapsed: 226.27 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.10536/67.00%, bp_loss: 1.96154/41.00%, hp_loss: 3.03930/24.00%, j_loss: 1.38732/66.00%, \n",
      "\t\tfr_loss: 0.18377/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.67729\n",
      "\tPart 2 - fp_loss: 0.91032/74.00%, bp_loss: 1.52431/54.00%, hp_loss: 2.70545/33.00%, j_loss: 1.02493/74.00%, \n",
      "\t\tfr_loss: 0.15363/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31864\n",
      "\tPart 3 - fp_loss: 0.84578/77.00%, bp_loss: 1.16368/67.00%, hp_loss: 2.40277/39.00%, j_loss: 0.72212/80.00%, \n",
      "\t\tfr_loss: 0.11927/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.25361\n",
      "\tPart 4 - fp_loss: 0.70995/79.00%, bp_loss: 1.09212/68.00%, hp_loss: 2.61171/33.00%, j_loss: 0.67279/80.00%, \n",
      "\t\tfr_loss: 0.10613/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.19270\n",
      "\tTraining time elapsed: 263.79 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.06413/67.00%, bp_loss: 2.00116/40.00%, hp_loss: 3.03943/23.00%, j_loss: 1.41119/67.00%, \n",
      "\t\tfr_loss: 0.14747/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.66338\n",
      "\tPart 2 - fp_loss: 0.94998/72.00%, bp_loss: 1.51444/55.00%, hp_loss: 2.76740/32.00%, j_loss: 1.05899/72.00%, \n",
      "\t\tfr_loss: 0.15321/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.44402\n",
      "\tPart 3 - fp_loss: 0.90985/73.00%, bp_loss: 1.28228/62.00%, hp_loss: 2.43732/36.00%, j_loss: 0.91453/76.00%, \n",
      "\t\tfr_loss: 0.12880/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.67279\n",
      "\tPart 4 - fp_loss: 0.80131/77.00%, bp_loss: 1.18192/66.00%, hp_loss: 2.65436/33.00%, j_loss: 0.72774/78.00%, \n",
      "\t\tfr_loss: 0.11466/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47998\n",
      "\tTraining time elapsed: 301.31 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.57227/55.00%, bp_loss: 2.41871/33.00%, hp_loss: 3.08272/22.00%, j_loss: 1.84039/55.00%, \n",
      "\t\tfr_loss: 0.21544/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.12954\n",
      "\tPart 2 - fp_loss: 1.50273/59.00%, bp_loss: 2.20921/37.00%, hp_loss: 2.74635/29.00%, j_loss: 1.68454/59.00%, \n",
      "\t\tfr_loss: 0.19256/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.33539\n",
      "\tPart 3 - fp_loss: 1.03865/72.00%, bp_loss: 1.75188/51.00%, hp_loss: 2.32044/43.00%, j_loss: 1.16658/72.00%, \n",
      "\t\tfr_loss: 0.15641/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.43396\n",
      "\tPart 4 - fp_loss: 1.29869/68.00%, bp_loss: 1.81208/50.00%, hp_loss: 2.44103/38.00%, j_loss: 1.25222/66.00%, \n",
      "\t\tfr_loss: 0.17035/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.97436\n",
      "\t`Validation time elapsed: 0.71 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.77037/50.00%, bp_loss: 2.12339/37.00%, hp_loss: 3.06749/23.00%, j_loss: 1.95766/50.00%, \n",
      "\t\tfr_loss: 0.20913/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.12804\n",
      "\tPart 2 - fp_loss: 1.39563/63.00%, bp_loss: 1.71637/48.00%, hp_loss: 2.77540/29.00%, j_loss: 1.42019/63.00%, \n",
      "\t\tfr_loss: 0.17973/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.48731\n",
      "\tPart 3 - fp_loss: 1.03217/71.00%, bp_loss: 1.30669/63.00%, hp_loss: 2.32094/43.00%, j_loss: 0.99476/74.00%, \n",
      "\t\tfr_loss: 0.14957/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.80413\n",
      "\tPart 4 - fp_loss: 1.26953/69.00%, bp_loss: 1.40871/63.00%, hp_loss: 2.47751/38.00%, j_loss: 1.04290/72.00%, \n",
      "\t\tfr_loss: 0.17684/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.37548\n",
      "\t`Validation time elapsed: 9.45 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 22.\n",
      "\n",
      "EPOCH 23\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.03126/68.00%, bp_loss: 2.25560/37.00%, hp_loss: 3.10138/22.00%, j_loss: 1.41101/68.00%, \n",
      "\t\tfr_loss: 0.14183/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.94108\n",
      "\tPart 2 - fp_loss: 0.91848/73.00%, bp_loss: 2.13108/42.00%, hp_loss: 2.76837/30.00%, j_loss: 1.22152/73.00%, \n",
      "\t\tfr_loss: 0.13368/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.17313\n",
      "\tPart 3 - fp_loss: 0.84016/77.00%, bp_loss: 1.58936/57.00%, hp_loss: 2.42645/38.00%, j_loss: 0.89272/78.00%, \n",
      "\t\tfr_loss: 0.12138/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.87007\n",
      "\tPart 4 - fp_loss: 0.69158/81.00%, bp_loss: 1.53654/56.00%, hp_loss: 2.63559/32.00%, j_loss: 0.73061/78.00%, \n",
      "\t\tfr_loss: 0.09916/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.69349\n",
      "\tTraining time elapsed: 1.09 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.12286/68.00%, bp_loss: 1.94815/43.00%, hp_loss: 3.08991/22.00%, j_loss: 1.37718/68.00%, \n",
      "\t\tfr_loss: 0.15944/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.69755\n",
      "\tPart 2 - fp_loss: 0.87373/74.00%, bp_loss: 1.55967/55.00%, hp_loss: 2.73501/33.00%, j_loss: 1.04830/74.00%, \n",
      "\t\tfr_loss: 0.14161/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.35832\n",
      "\tPart 3 - fp_loss: 0.81229/76.00%, bp_loss: 1.23530/65.00%, hp_loss: 2.35397/40.00%, j_loss: 0.82160/77.00%, \n",
      "\t\tfr_loss: 0.11795/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.34111\n",
      "\tPart 4 - fp_loss: 0.71339/79.00%, bp_loss: 1.22699/64.00%, hp_loss: 2.58825/33.00%, j_loss: 0.74018/78.00%, \n",
      "\t\tfr_loss: 0.10881/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.37761\n",
      "\tTraining time elapsed: 38.62 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.07113/69.00%, bp_loss: 1.99781/42.00%, hp_loss: 3.07454/23.00%, j_loss: 1.36403/69.00%, \n",
      "\t\tfr_loss: 0.15093/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.65844\n",
      "\tPart 2 - fp_loss: 0.80445/75.00%, bp_loss: 1.58517/52.00%, hp_loss: 2.68218/33.00%, j_loss: 1.02761/75.00%, \n",
      "\t\tfr_loss: 0.14575/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24517\n",
      "\tPart 3 - fp_loss: 0.84455/76.00%, bp_loss: 1.20807/64.00%, hp_loss: 2.40617/38.00%, j_loss: 0.83359/77.00%, \n",
      "\t\tfr_loss: 0.11631/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40869\n",
      "\tPart 4 - fp_loss: 0.64267/83.00%, bp_loss: 1.13565/67.00%, hp_loss: 2.58350/35.00%, j_loss: 0.57103/83.00%, \n",
      "\t\tfr_loss: 0.09638/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02922\n",
      "\tTraining time elapsed: 76.16 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.06555/68.00%, bp_loss: 2.03081/40.00%, hp_loss: 3.09215/19.00%, j_loss: 1.38588/67.00%, \n",
      "\t\tfr_loss: 0.14047/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.71487\n",
      "\tPart 2 - fp_loss: 0.84053/76.00%, bp_loss: 1.49373/55.00%, hp_loss: 2.65566/33.00%, j_loss: 0.94075/76.00%, \n",
      "\t\tfr_loss: 0.15669/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08735\n",
      "\tPart 3 - fp_loss: 0.83472/77.00%, bp_loss: 1.12450/68.00%, hp_loss: 2.36768/39.00%, j_loss: 0.73518/78.00%, \n",
      "\t\tfr_loss: 0.13714/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.19922\n",
      "\tPart 4 - fp_loss: 0.70986/79.00%, bp_loss: 1.18296/67.00%, hp_loss: 2.59980/34.00%, j_loss: 0.66864/80.00%, \n",
      "\t\tfr_loss: 0.11467/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.27593\n",
      "\tTraining time elapsed: 113.65 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.10718/68.00%, bp_loss: 2.09488/39.00%, hp_loss: 3.17878/20.00%, j_loss: 1.41501/68.00%, \n",
      "\t\tfr_loss: 0.15428/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.95012\n",
      "\tPart 2 - fp_loss: 0.91915/75.00%, bp_loss: 1.63344/53.00%, hp_loss: 2.76627/30.00%, j_loss: 1.03063/74.00%, \n",
      "\t\tfr_loss: 0.13394/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.48342\n",
      "\tPart 3 - fp_loss: 0.81811/76.00%, bp_loss: 1.11678/68.00%, hp_loss: 2.40776/37.00%, j_loss: 0.71691/78.00%, \n",
      "\t\tfr_loss: 0.11982/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.17939\n",
      "\tPart 4 - fp_loss: 0.78388/78.00%, bp_loss: 1.04308/70.00%, hp_loss: 2.54636/33.00%, j_loss: 0.64402/80.00%, \n",
      "\t\tfr_loss: 0.11208/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.12941\n",
      "\tTraining time elapsed: 151.16 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.04182/69.00%, bp_loss: 2.05156/39.00%, hp_loss: 3.09808/22.00%, j_loss: 1.38904/68.00%, \n",
      "\t\tfr_loss: 0.15998/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.74048\n",
      "\tPart 2 - fp_loss: 0.86558/73.00%, bp_loss: 1.50057/56.00%, hp_loss: 2.72439/33.00%, j_loss: 1.01469/73.00%, \n",
      "\t\tfr_loss: 0.11943/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22466\n",
      "\tPart 3 - fp_loss: 0.88141/74.00%, bp_loss: 1.15016/68.00%, hp_loss: 2.36155/39.00%, j_loss: 0.78055/77.00%, \n",
      "\t\tfr_loss: 0.11694/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.29060\n",
      "\tPart 4 - fp_loss: 0.74740/77.00%, bp_loss: 1.14781/66.00%, hp_loss: 2.65128/31.00%, j_loss: 0.72706/78.00%, \n",
      "\t\tfr_loss: 0.10480/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.37835\n",
      "\tTraining time elapsed: 188.67 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.04038/69.00%, bp_loss: 1.92012/43.00%, hp_loss: 3.00913/23.00%, j_loss: 1.31769/69.00%, \n",
      "\t\tfr_loss: 0.15082/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.43814\n",
      "\tPart 2 - fp_loss: 0.85618/76.00%, bp_loss: 1.59053/51.00%, hp_loss: 2.77529/29.00%, j_loss: 0.97302/76.00%, \n",
      "\t\tfr_loss: 0.14127/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33629\n",
      "\tPart 3 - fp_loss: 0.87675/76.00%, bp_loss: 1.16603/67.00%, hp_loss: 2.41291/38.00%, j_loss: 0.80100/77.00%, \n",
      "\t\tfr_loss: 0.12415/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.38083\n",
      "\tPart 4 - fp_loss: 0.69211/79.00%, bp_loss: 1.20203/66.00%, hp_loss: 2.62493/31.00%, j_loss: 0.68841/80.00%, \n",
      "\t\tfr_loss: 0.10337/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.31085\n",
      "\tTraining time elapsed: 226.17 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.10763/68.00%, bp_loss: 2.08198/37.00%, hp_loss: 3.11337/20.00%, j_loss: 1.38707/68.00%, \n",
      "\t\tfr_loss: 0.15821/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.84826\n",
      "\tPart 2 - fp_loss: 0.86450/75.00%, bp_loss: 1.50572/55.00%, hp_loss: 2.72868/32.00%, j_loss: 0.93449/75.00%, \n",
      "\t\tfr_loss: 0.16951/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.20289\n",
      "\tPart 3 - fp_loss: 0.85889/76.00%, bp_loss: 1.04271/69.00%, hp_loss: 2.28749/40.00%, j_loss: 0.73797/77.00%, \n",
      "\t\tfr_loss: 0.12991/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05697\n",
      "\tPart 4 - fp_loss: 0.75877/78.00%, bp_loss: 1.11364/69.00%, hp_loss: 2.57785/33.00%, j_loss: 0.69833/79.00%, \n",
      "\t\tfr_loss: 0.10910/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.25769\n",
      "\tTraining time elapsed: 263.71 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.06426/70.00%, bp_loss: 1.86854/44.00%, hp_loss: 3.03436/24.00%, j_loss: 1.29817/70.00%, \n",
      "\t\tfr_loss: 0.14389/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.40922\n",
      "\tPart 2 - fp_loss: 0.84991/77.00%, bp_loss: 1.56121/54.00%, hp_loss: 2.71401/31.00%, j_loss: 0.97509/77.00%, \n",
      "\t\tfr_loss: 0.16367/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26390\n",
      "\tPart 3 - fp_loss: 0.85009/77.00%, bp_loss: 1.14313/66.00%, hp_loss: 2.42195/37.00%, j_loss: 0.75574/78.00%, \n",
      "\t\tfr_loss: 0.12003/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.29094\n",
      "\tPart 4 - fp_loss: 0.73377/80.00%, bp_loss: 1.05000/69.00%, hp_loss: 2.63371/31.00%, j_loss: 0.63103/82.00%, \n",
      "\t\tfr_loss: 0.11418/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16269\n",
      "\tTraining time elapsed: 301.21 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.79966/49.00%, bp_loss: 2.31280/33.00%, hp_loss: 3.09152/22.00%, j_loss: 2.00959/49.00%, \n",
      "\t\tfr_loss: 0.20507/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.41864\n",
      "\tPart 2 - fp_loss: 1.39755/62.00%, bp_loss: 2.01675/42.00%, hp_loss: 2.62713/33.00%, j_loss: 1.54386/61.00%, \n",
      "\t\tfr_loss: 0.18223/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.76752\n",
      "\tPart 3 - fp_loss: 1.08661/71.00%, bp_loss: 1.43048/59.00%, hp_loss: 2.23550/44.00%, j_loss: 1.08720/70.00%, \n",
      "\t\tfr_loss: 0.17902/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01881\n",
      "\tPart 4 - fp_loss: 1.25203/70.00%, bp_loss: 1.53957/61.00%, hp_loss: 2.41531/38.00%, j_loss: 1.01517/72.00%, \n",
      "\t\tfr_loss: 0.16625/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.38833\n",
      "\t`Validation time elapsed: 0.75 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.75318/52.00%, bp_loss: 2.03199/39.00%, hp_loss: 3.06197/22.00%, j_loss: 1.84018/52.00%, \n",
      "\t\tfr_loss: 0.19534/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.88267\n",
      "\tPart 2 - fp_loss: 1.44506/59.00%, bp_loss: 1.64438/51.00%, hp_loss: 2.69848/30.00%, j_loss: 1.48350/59.00%, \n",
      "\t\tfr_loss: 0.18485/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.45626\n",
      "\tPart 3 - fp_loss: 1.05841/70.00%, bp_loss: 1.33626/62.00%, hp_loss: 2.26664/42.00%, j_loss: 1.08215/72.00%, \n",
      "\t\tfr_loss: 0.15822/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.90167\n",
      "\tPart 4 - fp_loss: 1.34836/71.00%, bp_loss: 1.25921/66.00%, hp_loss: 2.43157/39.00%, j_loss: 0.93055/75.00%, \n",
      "\t\tfr_loss: 0.16639/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13608\n",
      "\t`Validation time elapsed: 9.52 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 23.\n",
      "\n",
      "EPOCH 24\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.94829/72.00%, bp_loss: 2.25369/38.00%, hp_loss: 3.09520/22.00%, j_loss: 1.28999/72.00%, \n",
      "\t\tfr_loss: 0.15663/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.74380\n",
      "\tPart 2 - fp_loss: 0.77331/77.00%, bp_loss: 1.94982/45.00%, hp_loss: 2.69703/32.00%, j_loss: 1.05694/76.00%, \n",
      "\t\tfr_loss: 0.15509/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.63219\n",
      "\tPart 3 - fp_loss: 0.88920/76.00%, bp_loss: 1.41970/61.00%, hp_loss: 2.39793/37.00%, j_loss: 0.87440/77.00%, \n",
      "\t\tfr_loss: 0.12794/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.70917\n",
      "\tPart 4 - fp_loss: 0.75955/78.00%, bp_loss: 1.40991/62.00%, hp_loss: 2.57477/34.00%, j_loss: 0.74830/78.00%, \n",
      "\t\tfr_loss: 0.11720/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60973\n",
      "\tTraining time elapsed: 1.09 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.04774/70.00%, bp_loss: 1.98392/41.00%, hp_loss: 3.07900/22.00%, j_loss: 1.28287/70.00%, \n",
      "\t\tfr_loss: 0.12874/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.52228\n",
      "\tPart 2 - fp_loss: 0.90636/74.00%, bp_loss: 1.47640/58.00%, hp_loss: 2.75772/31.00%, j_loss: 0.97413/74.00%, \n",
      "\t\tfr_loss: 0.14180/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25641\n",
      "\tPart 3 - fp_loss: 0.79029/77.00%, bp_loss: 1.05019/68.00%, hp_loss: 2.41180/39.00%, j_loss: 0.71068/79.00%, \n",
      "\t\tfr_loss: 0.13449/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09746\n",
      "\tPart 4 - fp_loss: 0.63820/81.00%, bp_loss: 0.99624/70.00%, hp_loss: 2.54911/34.00%, j_loss: 0.56434/82.00%, \n",
      "\t\tfr_loss: 0.09413/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.84203\n",
      "\tTraining time elapsed: 38.61 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.06462/69.00%, bp_loss: 1.94973/42.00%, hp_loss: 3.11524/21.00%, j_loss: 1.29382/69.00%, \n",
      "\t\tfr_loss: 0.13918/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.56259\n",
      "\tPart 2 - fp_loss: 0.84752/76.00%, bp_loss: 1.45817/57.00%, hp_loss: 2.72803/31.00%, j_loss: 0.97348/76.00%, \n",
      "\t\tfr_loss: 0.13213/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13934\n",
      "\tPart 3 - fp_loss: 0.75050/79.00%, bp_loss: 1.11619/68.00%, hp_loss: 2.36718/40.00%, j_loss: 0.69132/81.00%, \n",
      "\t\tfr_loss: 0.10800/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.03318\n",
      "\tPart 4 - fp_loss: 0.70965/80.00%, bp_loss: 1.05643/69.00%, hp_loss: 2.64076/35.00%, j_loss: 0.62487/80.00%, \n",
      "\t\tfr_loss: 0.12765/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.15936\n",
      "\tTraining time elapsed: 76.10 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.03400/68.00%, bp_loss: 1.99989/40.00%, hp_loss: 3.04082/23.00%, j_loss: 1.40597/68.00%, \n",
      "\t\tfr_loss: 0.14018/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.62086\n",
      "\tPart 2 - fp_loss: 0.92085/75.00%, bp_loss: 1.53426/54.00%, hp_loss: 2.70211/33.00%, j_loss: 0.99680/75.00%, \n",
      "\t\tfr_loss: 0.15540/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30943\n",
      "\tPart 3 - fp_loss: 0.82486/77.00%, bp_loss: 1.05891/69.00%, hp_loss: 2.43022/37.00%, j_loss: 0.74207/79.00%, \n",
      "\t\tfr_loss: 0.11692/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.17298\n",
      "\tPart 4 - fp_loss: 0.76459/78.00%, bp_loss: 1.06423/70.00%, hp_loss: 2.66655/31.00%, j_loss: 0.63635/80.00%, \n",
      "\t\tfr_loss: 0.09705/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.22877\n",
      "\tTraining time elapsed: 113.62 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.05585/69.00%, bp_loss: 1.94046/43.00%, hp_loss: 3.08686/22.00%, j_loss: 1.34162/69.00%, \n",
      "\t\tfr_loss: 0.14575/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.57053\n",
      "\tPart 2 - fp_loss: 0.86647/75.00%, bp_loss: 1.45119/57.00%, hp_loss: 2.76485/32.00%, j_loss: 0.91941/75.00%, \n",
      "\t\tfr_loss: 0.15359/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15551\n",
      "\tPart 3 - fp_loss: 0.83635/74.00%, bp_loss: 1.07691/69.00%, hp_loss: 2.38539/38.00%, j_loss: 0.73229/76.00%, \n",
      "\t\tfr_loss: 0.11904/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.14999\n",
      "\tPart 4 - fp_loss: 0.77276/77.00%, bp_loss: 1.02239/70.00%, hp_loss: 2.58988/33.00%, j_loss: 0.69061/80.00%, \n",
      "\t\tfr_loss: 0.11818/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.19382\n",
      "\tTraining time elapsed: 151.13 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.93877/72.00%, bp_loss: 1.90265/43.00%, hp_loss: 3.00329/24.00%, j_loss: 1.24635/72.00%, \n",
      "\t\tfr_loss: 0.14146/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.23251\n",
      "\tPart 2 - fp_loss: 0.86299/74.00%, bp_loss: 1.49156/56.00%, hp_loss: 2.71116/32.00%, j_loss: 0.99602/74.00%, \n",
      "\t\tfr_loss: 0.13825/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19998\n",
      "\tPart 3 - fp_loss: 0.88707/75.00%, bp_loss: 1.07447/70.00%, hp_loss: 2.36272/39.00%, j_loss: 0.77258/77.00%, \n",
      "\t\tfr_loss: 0.13285/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.22970\n",
      "\tPart 4 - fp_loss: 0.75099/78.00%, bp_loss: 1.04392/71.00%, hp_loss: 2.56854/33.00%, j_loss: 0.62403/79.00%, \n",
      "\t\tfr_loss: 0.10280/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09028\n",
      "\tTraining time elapsed: 188.65 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.05146/68.00%, bp_loss: 1.96046/42.00%, hp_loss: 3.08323/23.00%, j_loss: 1.31960/68.00%, \n",
      "\t\tfr_loss: 0.13907/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.55381\n",
      "\tPart 2 - fp_loss: 0.92021/73.00%, bp_loss: 1.44359/57.00%, hp_loss: 2.71113/33.00%, j_loss: 1.02118/72.00%, \n",
      "\t\tfr_loss: 0.16041/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25653\n",
      "\tPart 3 - fp_loss: 0.82603/77.00%, bp_loss: 1.04548/69.00%, hp_loss: 2.40899/39.00%, j_loss: 0.72721/78.00%, \n",
      "\t\tfr_loss: 0.11589/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.12360\n",
      "\tPart 4 - fp_loss: 0.74370/79.00%, bp_loss: 1.00871/70.00%, hp_loss: 2.58613/33.00%, j_loss: 0.66129/81.00%, \n",
      "\t\tfr_loss: 0.10982/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10964\n",
      "\tTraining time elapsed: 226.20 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.02930/70.00%, bp_loss: 1.81109/46.00%, hp_loss: 3.04062/24.00%, j_loss: 1.23154/70.00%, \n",
      "\t\tfr_loss: 0.14686/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.25941\n",
      "\tPart 2 - fp_loss: 0.89091/74.00%, bp_loss: 1.57261/54.00%, hp_loss: 2.77255/31.00%, j_loss: 1.00918/74.00%, \n",
      "\t\tfr_loss: 0.13976/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.38502\n",
      "\tPart 3 - fp_loss: 0.74703/78.00%, bp_loss: 1.00726/71.00%, hp_loss: 2.40077/38.00%, j_loss: 0.64330/80.00%, \n",
      "\t\tfr_loss: 0.12080/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.91915\n",
      "\tPart 4 - fp_loss: 0.73158/79.00%, bp_loss: 1.06450/68.00%, hp_loss: 2.65880/32.00%, j_loss: 0.61923/79.00%, \n",
      "\t\tfr_loss: 0.10379/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.17790\n",
      "\tTraining time elapsed: 263.75 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.15841/66.00%, bp_loss: 1.92249/45.00%, hp_loss: 3.06656/24.00%, j_loss: 1.38004/66.00%, \n",
      "\t\tfr_loss: 0.17447/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.70196\n",
      "\tPart 2 - fp_loss: 0.83311/77.00%, bp_loss: 1.45584/59.00%, hp_loss: 2.70891/33.00%, j_loss: 0.92067/76.00%, \n",
      "\t\tfr_loss: 0.13393/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05246\n",
      "\tPart 3 - fp_loss: 0.81949/77.00%, bp_loss: 1.08513/67.00%, hp_loss: 2.42262/38.00%, j_loss: 0.72905/80.00%, \n",
      "\t\tfr_loss: 0.12283/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.17913\n",
      "\tPart 4 - fp_loss: 0.73856/79.00%, bp_loss: 1.09580/69.00%, hp_loss: 2.68940/30.00%, j_loss: 0.64262/82.00%, \n",
      "\t\tfr_loss: 0.09657/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.26294\n",
      "\tTraining time elapsed: 301.28 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.72115/52.00%, bp_loss: 2.42447/33.00%, hp_loss: 3.02185/23.00%, j_loss: 1.93257/51.00%, \n",
      "\t\tfr_loss: 0.21521/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.31524\n",
      "\tPart 2 - fp_loss: 1.54538/60.00%, bp_loss: 2.04866/43.00%, hp_loss: 2.70421/30.00%, j_loss: 1.57658/59.00%, \n",
      "\t\tfr_loss: 0.22001/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.09485\n",
      "\tPart 3 - fp_loss: 1.09550/72.00%, bp_loss: 1.52656/56.00%, hp_loss: 2.24409/44.00%, j_loss: 1.06475/70.00%, \n",
      "\t\tfr_loss: 0.15262/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08353\n",
      "\tPart 4 - fp_loss: 1.25687/69.00%, bp_loss: 1.55872/58.00%, hp_loss: 2.42305/41.00%, j_loss: 1.09385/72.00%, \n",
      "\t\tfr_loss: 0.17859/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51108\n",
      "\t`Validation time elapsed: 0.78 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.73657/52.00%, bp_loss: 1.97524/39.00%, hp_loss: 3.02330/23.00%, j_loss: 1.83805/53.00%, \n",
      "\t\tfr_loss: 0.23357/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.80674\n",
      "\tPart 2 - fp_loss: 1.47105/61.00%, bp_loss: 1.64342/52.00%, hp_loss: 2.76090/29.00%, j_loss: 1.40998/61.00%, \n",
      "\t\tfr_loss: 0.18710/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.47244\n",
      "\tPart 3 - fp_loss: 1.12644/71.00%, bp_loss: 1.21870/67.00%, hp_loss: 2.30717/41.00%, j_loss: 0.88437/76.00%, \n",
      "\t\tfr_loss: 0.16375/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.70042\n",
      "\tPart 4 - fp_loss: 1.30729/68.00%, bp_loss: 1.27618/67.00%, hp_loss: 2.51652/37.00%, j_loss: 1.03750/74.00%, \n",
      "\t\tfr_loss: 0.17414/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31163\n",
      "\t`Validation time elapsed: 9.54 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 24.\n",
      "\n",
      "EPOCH 25\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.90598/72.00%, bp_loss: 2.23265/39.00%, hp_loss: 3.09457/20.00%, j_loss: 1.27112/71.00%, \n",
      "\t\tfr_loss: 0.13753/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.64185\n",
      "\tPart 2 - fp_loss: 0.82457/77.00%, bp_loss: 1.85758/47.00%, hp_loss: 2.68400/32.00%, j_loss: 1.06029/76.00%, \n",
      "\t\tfr_loss: 0.12159/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.54804\n",
      "\tPart 3 - fp_loss: 0.83068/77.00%, bp_loss: 1.36209/63.00%, hp_loss: 2.39058/38.00%, j_loss: 0.85155/75.00%, \n",
      "\t\tfr_loss: 0.12333/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55822\n",
      "\tPart 4 - fp_loss: 0.70308/79.00%, bp_loss: 1.29606/64.00%, hp_loss: 2.62770/34.00%, j_loss: 0.69805/80.00%, \n",
      "\t\tfr_loss: 0.12323/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44812\n",
      "\tTraining time elapsed: 1.06 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.03668/69.00%, bp_loss: 1.98425/41.00%, hp_loss: 3.08411/22.00%, j_loss: 1.34866/69.00%, \n",
      "\t\tfr_loss: 0.17370/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.62741\n",
      "\tPart 2 - fp_loss: 0.82309/76.00%, bp_loss: 1.38761/61.00%, hp_loss: 2.66784/34.00%, j_loss: 0.85638/77.00%, \n",
      "\t\tfr_loss: 0.12895/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.86387\n",
      "\tPart 3 - fp_loss: 0.80095/76.00%, bp_loss: 0.98491/71.00%, hp_loss: 2.32750/39.00%, j_loss: 0.68865/79.00%, \n",
      "\t\tfr_loss: 0.12159/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92360\n",
      "\tPart 4 - fp_loss: 0.64693/82.00%, bp_loss: 0.98742/72.00%, hp_loss: 2.53404/35.00%, j_loss: 0.50807/85.00%, \n",
      "\t\tfr_loss: 0.10010/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.77656\n",
      "\tTraining time elapsed: 38.59 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.93003/73.00%, bp_loss: 1.94140/44.00%, hp_loss: 3.09590/22.00%, j_loss: 1.20922/73.00%, \n",
      "\t\tfr_loss: 0.16147/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.33802\n",
      "\tPart 2 - fp_loss: 0.84314/76.00%, bp_loss: 1.45241/60.00%, hp_loss: 2.71933/32.00%, j_loss: 0.92603/76.00%, \n",
      "\t\tfr_loss: 0.15170/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09260\n",
      "\tPart 3 - fp_loss: 0.79192/76.00%, bp_loss: 1.04049/70.00%, hp_loss: 2.36057/37.00%, j_loss: 0.71718/79.00%, \n",
      "\t\tfr_loss: 0.11936/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02952\n",
      "\tPart 4 - fp_loss: 0.68016/80.00%, bp_loss: 0.93057/73.00%, hp_loss: 2.63740/33.00%, j_loss: 0.58431/81.00%, \n",
      "\t\tfr_loss: 0.09681/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92924\n",
      "\tTraining time elapsed: 76.08 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.04761/68.00%, bp_loss: 1.93936/44.00%, hp_loss: 3.05744/23.00%, j_loss: 1.35101/68.00%, \n",
      "\t\tfr_loss: 0.15886/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.55428\n",
      "\tPart 2 - fp_loss: 0.80512/76.00%, bp_loss: 1.41131/59.00%, hp_loss: 2.60233/37.00%, j_loss: 0.92476/76.00%, \n",
      "\t\tfr_loss: 0.16144/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.90497\n",
      "\tPart 3 - fp_loss: 0.84974/75.00%, bp_loss: 0.93551/71.00%, hp_loss: 2.42057/38.00%, j_loss: 0.69142/79.00%, \n",
      "\t\tfr_loss: 0.11292/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01016\n",
      "\tPart 4 - fp_loss: 0.68510/79.00%, bp_loss: 0.90799/74.00%, hp_loss: 2.61631/34.00%, j_loss: 0.55757/81.00%, \n",
      "\t\tfr_loss: 0.09545/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.86242\n",
      "\tTraining time elapsed: 113.59 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.04038/69.00%, bp_loss: 1.85025/46.00%, hp_loss: 3.05001/23.00%, j_loss: 1.26733/68.00%, \n",
      "\t\tfr_loss: 0.15595/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.36392\n",
      "\tPart 2 - fp_loss: 0.85950/76.00%, bp_loss: 1.45532/59.00%, hp_loss: 2.72763/33.00%, j_loss: 0.88937/76.00%, \n",
      "\t\tfr_loss: 0.14480/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.07662\n",
      "\tPart 3 - fp_loss: 0.80482/77.00%, bp_loss: 1.05051/69.00%, hp_loss: 2.39058/39.00%, j_loss: 0.71660/79.00%, \n",
      "\t\tfr_loss: 0.11478/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.07728\n",
      "\tPart 4 - fp_loss: 0.73408/80.00%, bp_loss: 0.99597/71.00%, hp_loss: 2.60473/32.00%, j_loss: 0.58776/81.00%, \n",
      "\t\tfr_loss: 0.10219/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02472\n",
      "\tTraining time elapsed: 151.10 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.04493/69.00%, bp_loss: 1.84653/46.00%, hp_loss: 3.12246/21.00%, j_loss: 1.24651/69.00%, \n",
      "\t\tfr_loss: 0.14616/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.40659\n",
      "\tPart 2 - fp_loss: 0.85735/76.00%, bp_loss: 1.52305/56.00%, hp_loss: 2.79631/30.00%, j_loss: 0.91817/76.00%, \n",
      "\t\tfr_loss: 0.13525/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23013\n",
      "\tPart 3 - fp_loss: 0.72794/79.00%, bp_loss: 0.94553/72.00%, hp_loss: 2.41390/39.00%, j_loss: 0.64728/81.00%, \n",
      "\t\tfr_loss: 0.11529/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.84994\n",
      "\tPart 4 - fp_loss: 0.70019/81.00%, bp_loss: 0.90842/74.00%, hp_loss: 2.58508/37.00%, j_loss: 0.55257/83.00%, \n",
      "\t\tfr_loss: 0.11941/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.86568\n",
      "\tTraining time elapsed: 188.60 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.00367/69.00%, bp_loss: 1.88349/45.00%, hp_loss: 3.04248/23.00%, j_loss: 1.25030/69.00%, \n",
      "\t\tfr_loss: 0.14656/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.32649\n",
      "\tPart 2 - fp_loss: 0.88565/74.00%, bp_loss: 1.47118/57.00%, hp_loss: 2.63810/34.00%, j_loss: 1.04265/74.00%, \n",
      "\t\tfr_loss: 0.14131/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17889\n",
      "\tPart 3 - fp_loss: 0.78755/78.00%, bp_loss: 0.92027/73.00%, hp_loss: 2.32354/40.00%, j_loss: 0.61770/81.00%, \n",
      "\t\tfr_loss: 0.10375/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.75282\n",
      "\tPart 4 - fp_loss: 0.79760/77.00%, bp_loss: 0.86163/75.00%, hp_loss: 2.54169/35.00%, j_loss: 0.59250/81.00%, \n",
      "\t\tfr_loss: 0.12990/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92332\n",
      "\tTraining time elapsed: 226.11 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.05772/69.00%, bp_loss: 1.81092/47.00%, hp_loss: 3.03393/24.00%, j_loss: 1.29583/69.00%, \n",
      "\t\tfr_loss: 0.15183/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.35023\n",
      "\tPart 2 - fp_loss: 0.84256/75.00%, bp_loss: 1.43697/58.00%, hp_loss: 2.68902/34.00%, j_loss: 0.95451/75.00%, \n",
      "\t\tfr_loss: 0.14816/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.07121\n",
      "\tPart 3 - fp_loss: 0.82474/76.00%, bp_loss: 0.97758/71.00%, hp_loss: 2.38270/38.00%, j_loss: 0.71989/76.00%, \n",
      "\t\tfr_loss: 0.10502/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.00992\n",
      "\tPart 4 - fp_loss: 0.64416/83.00%, bp_loss: 0.90989/73.00%, hp_loss: 2.53325/34.00%, j_loss: 0.50044/84.00%, \n",
      "\t\tfr_loss: 0.10526/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69299\n",
      "\tTraining time elapsed: 263.63 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.00478/71.00%, bp_loss: 1.85866/43.00%, hp_loss: 3.09908/24.00%, j_loss: 1.23736/71.00%, \n",
      "\t\tfr_loss: 0.15613/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.35600\n",
      "\tPart 2 - fp_loss: 0.88075/74.00%, bp_loss: 1.46065/57.00%, hp_loss: 2.70638/33.00%, j_loss: 0.99254/73.00%, \n",
      "\t\tfr_loss: 0.14501/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.18532\n",
      "\tPart 3 - fp_loss: 0.85476/76.00%, bp_loss: 0.93559/72.00%, hp_loss: 2.42029/37.00%, j_loss: 0.71789/78.00%, \n",
      "\t\tfr_loss: 0.12642/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05495\n",
      "\tPart 4 - fp_loss: 0.66865/81.00%, bp_loss: 0.93637/72.00%, hp_loss: 2.68445/30.00%, j_loss: 0.55499/83.00%, \n",
      "\t\tfr_loss: 0.10235/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94680\n",
      "\tTraining time elapsed: 301.14 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.70659/53.00%, bp_loss: 2.28670/35.00%, hp_loss: 3.00620/24.00%, j_loss: 1.90395/53.00%, \n",
      "\t\tfr_loss: 0.21072/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.11415\n",
      "\tPart 2 - fp_loss: 1.45552/61.00%, bp_loss: 2.18064/42.00%, hp_loss: 2.74018/31.00%, j_loss: 1.56140/59.00%, \n",
      "\t\tfr_loss: 0.19473/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.13246\n",
      "\tPart 3 - fp_loss: 1.16639/69.00%, bp_loss: 1.58806/58.00%, hp_loss: 2.25782/44.00%, j_loss: 1.11563/69.00%, \n",
      "\t\tfr_loss: 0.17949/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30738\n",
      "\tPart 4 - fp_loss: 1.34235/68.00%, bp_loss: 1.49048/62.00%, hp_loss: 2.41896/40.00%, j_loss: 1.13802/72.00%, \n",
      "\t\tfr_loss: 0.18012/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.56993\n",
      "\t`Validation time elapsed: 0.69 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.78064/51.00%, bp_loss: 1.99700/38.00%, hp_loss: 2.99889/23.00%, j_loss: 1.95163/51.00%, \n",
      "\t\tfr_loss: 0.20718/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.93533\n",
      "\tPart 2 - fp_loss: 1.58397/58.00%, bp_loss: 1.73585/49.00%, hp_loss: 2.70112/29.00%, j_loss: 1.54946/58.00%, \n",
      "\t\tfr_loss: 0.18522/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.75563\n",
      "\tPart 3 - fp_loss: 1.03909/71.00%, bp_loss: 1.14210/68.00%, hp_loss: 2.27595/41.00%, j_loss: 0.88033/78.00%, \n",
      "\t\tfr_loss: 0.17757/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.51504\n",
      "\tPart 4 - fp_loss: 1.19819/71.00%, bp_loss: 1.23030/67.00%, hp_loss: 2.42770/38.00%, j_loss: 0.91574/77.00%, \n",
      "\t\tfr_loss: 0.17636/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.94830\n",
      "\t`Validation time elapsed: 9.45 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 25.\n",
      "\n",
      "EPOCH 26\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.98439/70.00%, bp_loss: 2.18154/38.00%, hp_loss: 3.12836/22.00%, j_loss: 1.35674/70.00%, \n",
      "\t\tfr_loss: 0.14124/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.79226\n",
      "\tPart 2 - fp_loss: 0.79474/77.00%, bp_loss: 1.90446/50.00%, hp_loss: 2.67377/34.00%, j_loss: 1.01292/75.00%, \n",
      "\t\tfr_loss: 0.15761/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.54351\n",
      "\tPart 3 - fp_loss: 0.75907/78.00%, bp_loss: 1.51257/59.00%, hp_loss: 2.38330/39.00%, j_loss: 0.84099/77.00%, \n",
      "\t\tfr_loss: 0.13341/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.62933\n",
      "\tPart 4 - fp_loss: 0.60352/83.00%, bp_loss: 1.11641/68.00%, hp_loss: 2.55452/34.00%, j_loss: 0.56886/83.00%, \n",
      "\t\tfr_loss: 0.09439/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.93769\n",
      "\tTraining time elapsed: 1.11 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.06044/68.00%, bp_loss: 1.90191/44.00%, hp_loss: 3.09650/22.00%, j_loss: 1.31875/68.00%, \n",
      "\t\tfr_loss: 0.16527/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.54287\n",
      "\tPart 2 - fp_loss: 0.87498/74.00%, bp_loss: 1.46471/59.00%, hp_loss: 2.73362/32.00%, j_loss: 0.91634/75.00%, \n",
      "\t\tfr_loss: 0.15182/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14146\n",
      "\tPart 3 - fp_loss: 0.73389/78.00%, bp_loss: 1.00933/70.00%, hp_loss: 2.39434/39.00%, j_loss: 0.72272/78.00%, \n",
      "\t\tfr_loss: 0.12011/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.98039\n",
      "\tPart 4 - fp_loss: 0.66419/80.00%, bp_loss: 0.94729/72.00%, hp_loss: 2.60472/34.00%, j_loss: 0.59054/81.00%, \n",
      "\t\tfr_loss: 0.10293/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.90967\n",
      "\tTraining time elapsed: 38.59 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.99901/70.00%, bp_loss: 1.89771/44.00%, hp_loss: 3.12573/22.00%, j_loss: 1.23072/70.00%, \n",
      "\t\tfr_loss: 0.14778/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.40094\n",
      "\tPart 2 - fp_loss: 0.86007/75.00%, bp_loss: 1.36074/60.00%, hp_loss: 2.69998/33.00%, j_loss: 0.93813/75.00%, \n",
      "\t\tfr_loss: 0.13849/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.99741\n",
      "\tPart 3 - fp_loss: 0.79026/77.00%, bp_loss: 1.00135/73.00%, hp_loss: 2.33010/39.00%, j_loss: 0.66950/80.00%, \n",
      "\t\tfr_loss: 0.13863/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92984\n",
      "\tPart 4 - fp_loss: 0.70427/79.00%, bp_loss: 0.79342/77.00%, hp_loss: 2.57722/35.00%, j_loss: 0.48929/83.00%, \n",
      "\t\tfr_loss: 0.11313/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.67733\n",
      "\tTraining time elapsed: 76.07 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.02086/70.00%, bp_loss: 1.88949/44.00%, hp_loss: 3.08278/22.00%, j_loss: 1.24899/70.00%, \n",
      "\t\tfr_loss: 0.15821/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.40033\n",
      "\tPart 2 - fp_loss: 0.85742/74.00%, bp_loss: 1.43747/59.00%, hp_loss: 2.72359/32.00%, j_loss: 0.98792/74.00%, \n",
      "\t\tfr_loss: 0.14566/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15206\n",
      "\tPart 3 - fp_loss: 0.82399/76.00%, bp_loss: 0.95340/73.00%, hp_loss: 2.47484/36.00%, j_loss: 0.68259/80.00%, \n",
      "\t\tfr_loss: 0.11486/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.04968\n",
      "\tPart 4 - fp_loss: 0.74648/79.00%, bp_loss: 0.95226/74.00%, hp_loss: 2.69914/33.00%, j_loss: 0.53804/83.00%, \n",
      "\t\tfr_loss: 0.11128/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.04720\n",
      "\tTraining time elapsed: 113.58 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.00126/70.00%, bp_loss: 1.90439/43.00%, hp_loss: 3.08307/22.00%, j_loss: 1.22515/71.00%, \n",
      "\t\tfr_loss: 0.15338/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.36726\n",
      "\tPart 2 - fp_loss: 0.84856/74.00%, bp_loss: 1.40444/59.00%, hp_loss: 2.77612/31.00%, j_loss: 0.96930/74.00%, \n",
      "\t\tfr_loss: 0.14097/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13938\n",
      "\tPart 3 - fp_loss: 0.77879/77.00%, bp_loss: 0.98879/71.00%, hp_loss: 2.46516/37.00%, j_loss: 0.66119/81.00%, \n",
      "\t\tfr_loss: 0.11206/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.00598\n",
      "\tPart 4 - fp_loss: 0.63615/82.00%, bp_loss: 0.84078/76.00%, hp_loss: 2.52267/35.00%, j_loss: 0.50950/85.00%, \n",
      "\t\tfr_loss: 0.09683/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60594\n",
      "\tTraining time elapsed: 151.08 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.02701/70.00%, bp_loss: 1.89043/46.00%, hp_loss: 3.07461/21.00%, j_loss: 1.23425/70.00%, \n",
      "\t\tfr_loss: 0.14675/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.37306\n",
      "\tPart 2 - fp_loss: 0.79243/78.00%, bp_loss: 1.45757/57.00%, hp_loss: 2.71158/32.00%, j_loss: 0.90645/78.00%, \n",
      "\t\tfr_loss: 0.15144/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01946\n",
      "\tPart 3 - fp_loss: 0.87406/74.00%, bp_loss: 0.92498/73.00%, hp_loss: 2.45746/35.00%, j_loss: 0.69936/78.00%, \n",
      "\t\tfr_loss: 0.13886/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09471\n",
      "\tPart 4 - fp_loss: 0.74816/80.00%, bp_loss: 0.86869/75.00%, hp_loss: 2.62790/32.00%, j_loss: 0.54108/81.00%, \n",
      "\t\tfr_loss: 0.12431/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.91015\n",
      "\tTraining time elapsed: 188.65 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.10972/69.00%, bp_loss: 1.85671/43.00%, hp_loss: 3.03629/23.00%, j_loss: 1.31519/69.00%, \n",
      "\t\tfr_loss: 0.15631/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.47422\n",
      "\tPart 2 - fp_loss: 0.82687/76.00%, bp_loss: 1.36982/60.00%, hp_loss: 2.65050/35.00%, j_loss: 0.89130/75.00%, \n",
      "\t\tfr_loss: 0.15854/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.89702\n",
      "\tPart 3 - fp_loss: 0.78783/77.00%, bp_loss: 1.00390/71.00%, hp_loss: 2.40632/37.00%, j_loss: 0.66175/79.00%, \n",
      "\t\tfr_loss: 0.11049/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97030\n",
      "\tPart 4 - fp_loss: 0.62597/82.00%, bp_loss: 0.88919/75.00%, hp_loss: 2.53315/34.00%, j_loss: 0.51928/82.00%, \n",
      "\t\tfr_loss: 0.10189/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.66948\n",
      "\tTraining time elapsed: 226.17 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.95106/73.00%, bp_loss: 1.88120/45.00%, hp_loss: 3.08216/22.00%, j_loss: 1.17380/73.00%, \n",
      "\t\tfr_loss: 0.13253/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.22075\n",
      "\tPart 2 - fp_loss: 0.78273/77.00%, bp_loss: 1.33962/61.00%, hp_loss: 2.67865/34.00%, j_loss: 0.87040/77.00%, \n",
      "\t\tfr_loss: 0.15643/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.82784\n",
      "\tPart 3 - fp_loss: 0.77467/78.00%, bp_loss: 0.95215/72.00%, hp_loss: 2.38093/39.00%, j_loss: 0.66763/79.00%, \n",
      "\t\tfr_loss: 0.11446/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88984\n",
      "\tPart 4 - fp_loss: 0.66652/81.00%, bp_loss: 0.88990/75.00%, hp_loss: 2.52439/37.00%, j_loss: 0.50847/82.00%, \n",
      "\t\tfr_loss: 0.11100/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.70028\n",
      "\tTraining time elapsed: 263.66 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.05896/68.00%, bp_loss: 1.76638/48.00%, hp_loss: 3.06346/23.00%, j_loss: 1.26153/68.00%, \n",
      "\t\tfr_loss: 0.16428/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.31461\n",
      "\tPart 2 - fp_loss: 0.86078/76.00%, bp_loss: 1.37094/59.00%, hp_loss: 2.72055/33.00%, j_loss: 0.92339/76.00%, \n",
      "\t\tfr_loss: 0.14102/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01668\n",
      "\tPart 3 - fp_loss: 0.87385/76.00%, bp_loss: 0.99427/71.00%, hp_loss: 2.42717/38.00%, j_loss: 0.76113/78.00%, \n",
      "\t\tfr_loss: 0.10662/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16303\n",
      "\tPart 4 - fp_loss: 0.71515/79.00%, bp_loss: 0.90676/74.00%, hp_loss: 2.59345/34.00%, j_loss: 0.58358/82.00%, \n",
      "\t\tfr_loss: 0.10696/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.90589\n",
      "\tTraining time elapsed: 301.16 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.80670/51.00%, bp_loss: 2.24819/34.00%, hp_loss: 3.08997/20.00%, j_loss: 1.98015/51.00%, \n",
      "\t\tfr_loss: 0.20844/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.33345\n",
      "\tPart 2 - fp_loss: 1.44226/61.00%, bp_loss: 2.00616/43.00%, hp_loss: 2.73274/28.00%, j_loss: 1.52715/60.00%, \n",
      "\t\tfr_loss: 0.19575/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.90406\n",
      "\tPart 3 - fp_loss: 1.14912/71.00%, bp_loss: 1.59231/58.00%, hp_loss: 2.25416/42.00%, j_loss: 1.01619/71.00%, \n",
      "\t\tfr_loss: 0.17167/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.18346\n",
      "\tPart 4 - fp_loss: 1.42157/67.00%, bp_loss: 1.31317/62.00%, hp_loss: 2.45987/38.00%, j_loss: 1.08566/69.00%, \n",
      "\t\tfr_loss: 0.18097/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.46124\n",
      "\t`Validation time elapsed: 0.74 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.73616/54.00%, bp_loss: 1.96068/40.00%, hp_loss: 3.07714/21.00%, j_loss: 1.83887/55.00%, \n",
      "\t\tfr_loss: 0.19298/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.80583\n",
      "\tPart 2 - fp_loss: 1.37793/62.00%, bp_loss: 1.65837/50.00%, hp_loss: 2.66790/31.00%, j_loss: 1.46129/62.00%, \n",
      "\t\tfr_loss: 0.20090/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.36640\n",
      "\tPart 3 - fp_loss: 1.03008/74.00%, bp_loss: 1.01725/71.00%, hp_loss: 2.20362/44.00%, j_loss: 0.80276/76.00%, \n",
      "\t\tfr_loss: 0.15486/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.20858\n",
      "\tPart 4 - fp_loss: 1.24117/73.00%, bp_loss: 1.18079/70.00%, hp_loss: 2.36365/43.00%, j_loss: 0.83515/79.00%, \n",
      "\t\tfr_loss: 0.15088/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77164\n",
      "\t`Validation time elapsed: 9.49 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 26.\n",
      "\n",
      "EPOCH 27\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.08153/68.00%, bp_loss: 2.21045/38.00%, hp_loss: 3.09569/21.00%, j_loss: 1.41579/68.00%, \n",
      "\t\tfr_loss: 0.15818/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.96164\n",
      "\tPart 2 - fp_loss: 0.84291/75.00%, bp_loss: 1.82594/50.00%, hp_loss: 2.68835/34.00%, j_loss: 1.05678/75.00%, \n",
      "\t\tfr_loss: 0.13891/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.55289\n",
      "\tPart 3 - fp_loss: 0.71967/80.00%, bp_loss: 1.48363/62.00%, hp_loss: 2.34653/39.00%, j_loss: 0.73760/79.00%, \n",
      "\t\tfr_loss: 0.10260/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.39002\n",
      "\tPart 4 - fp_loss: 0.68136/81.00%, bp_loss: 1.10866/69.00%, hp_loss: 2.62653/33.00%, j_loss: 0.57074/81.00%, \n",
      "\t\tfr_loss: 0.10705/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09434\n",
      "\tTraining time elapsed: 1.10 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.97978/72.00%, bp_loss: 1.89166/44.00%, hp_loss: 3.10291/21.00%, j_loss: 1.20590/71.00%, \n",
      "\t\tfr_loss: 0.15300/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.33325\n",
      "\tPart 2 - fp_loss: 0.86318/75.00%, bp_loss: 1.35456/61.00%, hp_loss: 2.69503/33.00%, j_loss: 0.95704/75.00%, \n",
      "\t\tfr_loss: 0.16311/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03293\n",
      "\tPart 3 - fp_loss: 0.83161/77.00%, bp_loss: 0.84863/75.00%, hp_loss: 2.40868/38.00%, j_loss: 0.61173/79.00%, \n",
      "\t\tfr_loss: 0.13321/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.83386\n",
      "\tPart 4 - fp_loss: 0.73160/78.00%, bp_loss: 0.86128/75.00%, hp_loss: 2.66516/31.00%, j_loss: 0.54860/83.00%, \n",
      "\t\tfr_loss: 0.10107/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.90771\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.96064/72.00%, bp_loss: 1.76137/48.00%, hp_loss: 3.07612/22.00%, j_loss: 1.12107/72.00%, \n",
      "\t\tfr_loss: 0.14972/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.06892\n",
      "\tPart 2 - fp_loss: 0.83095/76.00%, bp_loss: 1.38093/61.00%, hp_loss: 2.77544/30.00%, j_loss: 0.85106/76.00%, \n",
      "\t\tfr_loss: 0.12784/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.96623\n",
      "\tPart 3 - fp_loss: 0.73328/79.00%, bp_loss: 0.91094/74.00%, hp_loss: 2.32749/40.00%, j_loss: 0.63789/80.00%, \n",
      "\t\tfr_loss: 0.11441/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.72401\n",
      "\tPart 4 - fp_loss: 0.67517/81.00%, bp_loss: 0.82259/75.00%, hp_loss: 2.57710/33.00%, j_loss: 0.53132/84.00%, \n",
      "\t\tfr_loss: 0.10347/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.70964\n",
      "\tTraining time elapsed: 76.15 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 1.01608/70.00%, bp_loss: 1.82357/48.00%, hp_loss: 3.06887/24.00%, j_loss: 1.23773/70.00%, \n",
      "\t\tfr_loss: 0.15235/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.29860\n",
      "\tPart 2 - fp_loss: 0.84568/75.00%, bp_loss: 1.31823/61.00%, hp_loss: 2.71807/32.00%, j_loss: 0.90547/75.00%, \n",
      "\t\tfr_loss: 0.14989/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.93733\n",
      "\tPart 3 - fp_loss: 0.76704/79.00%, bp_loss: 0.87137/76.00%, hp_loss: 2.41913/38.00%, j_loss: 0.52718/84.00%, \n",
      "\t\tfr_loss: 0.11211/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69683\n",
      "\tPart 4 - fp_loss: 0.65783/81.00%, bp_loss: 0.87450/74.00%, hp_loss: 2.55585/35.00%, j_loss: 0.53067/83.00%, \n",
      "\t\tfr_loss: 0.11421/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73305\n",
      "\tTraining time elapsed: 113.64 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.05840/69.00%, bp_loss: 1.81441/47.00%, hp_loss: 3.09705/21.00%, j_loss: 1.30205/69.00%, \n",
      "\t\tfr_loss: 0.14913/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.42104\n",
      "\tPart 2 - fp_loss: 0.81675/76.00%, bp_loss: 1.40153/59.00%, hp_loss: 2.76838/30.00%, j_loss: 0.89871/77.00%, \n",
      "\t\tfr_loss: 0.14253/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.02790\n",
      "\tPart 3 - fp_loss: 0.76963/78.00%, bp_loss: 0.87895/75.00%, hp_loss: 2.41645/38.00%, j_loss: 0.60297/82.00%, \n",
      "\t\tfr_loss: 0.12190/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.78990\n",
      "\tPart 4 - fp_loss: 0.65371/81.00%, bp_loss: 0.82913/76.00%, hp_loss: 2.56627/34.00%, j_loss: 0.50175/83.00%, \n",
      "\t\tfr_loss: 0.09721/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64808\n",
      "\tTraining time elapsed: 151.14 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.04433/69.00%, bp_loss: 1.71215/49.00%, hp_loss: 3.04006/23.00%, j_loss: 1.19162/70.00%, \n",
      "\t\tfr_loss: 0.14783/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.13599\n",
      "\tPart 2 - fp_loss: 0.88419/74.00%, bp_loss: 1.36301/62.00%, hp_loss: 2.70711/33.00%, j_loss: 0.92495/73.00%, \n",
      "\t\tfr_loss: 0.15406/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03332\n",
      "\tPart 3 - fp_loss: 0.68965/81.00%, bp_loss: 0.87135/75.00%, hp_loss: 2.44905/37.00%, j_loss: 0.52990/83.00%, \n",
      "\t\tfr_loss: 0.11162/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65157\n",
      "\tPart 4 - fp_loss: 0.69484/81.00%, bp_loss: 0.95225/71.00%, hp_loss: 2.65247/31.00%, j_loss: 0.52539/84.00%, \n",
      "\t\tfr_loss: 0.10357/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92850\n",
      "\tTraining time elapsed: 188.68 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.03868/69.00%, bp_loss: 1.85627/46.00%, hp_loss: 3.09276/22.00%, j_loss: 1.29413/69.00%, \n",
      "\t\tfr_loss: 0.13978/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.42162\n",
      "\tPart 2 - fp_loss: 0.86454/76.00%, bp_loss: 1.39514/60.00%, hp_loss: 2.76782/30.00%, j_loss: 0.90842/76.00%, \n",
      "\t\tfr_loss: 0.15239/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08830\n",
      "\tPart 3 - fp_loss: 0.77162/78.00%, bp_loss: 0.97078/72.00%, hp_loss: 2.42850/37.00%, j_loss: 0.66396/80.00%, \n",
      "\t\tfr_loss: 0.11767/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.95253\n",
      "\tPart 4 - fp_loss: 0.73652/80.00%, bp_loss: 0.85940/76.00%, hp_loss: 2.60156/34.00%, j_loss: 0.52213/83.00%, \n",
      "\t\tfr_loss: 0.11165/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.83126\n",
      "\tTraining time elapsed: 226.21 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.02723/71.00%, bp_loss: 1.81049/47.00%, hp_loss: 3.07456/23.00%, j_loss: 1.17712/71.00%, \n",
      "\t\tfr_loss: 0.13718/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.22658\n",
      "\tPart 2 - fp_loss: 0.82613/76.00%, bp_loss: 1.36991/61.00%, hp_loss: 2.73855/31.00%, j_loss: 0.86384/76.00%, \n",
      "\t\tfr_loss: 0.15594/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.95437\n",
      "\tPart 3 - fp_loss: 0.76791/78.00%, bp_loss: 0.90378/74.00%, hp_loss: 2.40736/39.00%, j_loss: 0.59255/81.00%, \n",
      "\t\tfr_loss: 0.11288/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.78447\n",
      "\tPart 4 - fp_loss: 0.67227/81.00%, bp_loss: 0.89146/73.00%, hp_loss: 2.70357/31.00%, j_loss: 0.55796/82.00%, \n",
      "\t\tfr_loss: 0.10531/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.93057\n",
      "\tTraining time elapsed: 263.71 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.00046/70.00%, bp_loss: 1.75437/48.00%, hp_loss: 3.05635/23.00%, j_loss: 1.23575/70.00%, \n",
      "\t\tfr_loss: 0.12780/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.17474\n",
      "\tPart 2 - fp_loss: 0.87116/73.00%, bp_loss: 1.31959/61.00%, hp_loss: 2.67722/34.00%, j_loss: 0.96956/73.00%, \n",
      "\t\tfr_loss: 0.13491/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.97244\n",
      "\tPart 3 - fp_loss: 0.82777/75.00%, bp_loss: 0.82910/76.00%, hp_loss: 2.49445/37.00%, j_loss: 0.60644/80.00%, \n",
      "\t\tfr_loss: 0.13015/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88791\n",
      "\tPart 4 - fp_loss: 0.70025/80.00%, bp_loss: 0.84240/76.00%, hp_loss: 2.63778/32.00%, j_loss: 0.49838/86.00%, \n",
      "\t\tfr_loss: 0.12166/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.80048\n",
      "\tTraining time elapsed: 301.26 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.84007/50.00%, bp_loss: 2.14026/39.00%, hp_loss: 3.08998/22.00%, j_loss: 1.89465/51.00%, \n",
      "\t\tfr_loss: 0.20986/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 9.17482\n",
      "\tPart 2 - fp_loss: 1.47121/59.00%, bp_loss: 1.98316/48.00%, hp_loss: 2.68629/32.00%, j_loss: 1.53543/58.00%, \n",
      "\t\tfr_loss: 0.19344/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.86952\n",
      "\tPart 3 - fp_loss: 1.17951/68.00%, bp_loss: 1.44417/60.00%, hp_loss: 2.28240/41.00%, j_loss: 1.13302/70.00%, \n",
      "\t\tfr_loss: 0.15542/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19452\n",
      "\tPart 4 - fp_loss: 1.44158/66.00%, bp_loss: 1.45968/62.00%, hp_loss: 2.41189/38.00%, j_loss: 1.09979/69.00%, \n",
      "\t\tfr_loss: 0.17522/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58815\n",
      "\t`Validation time elapsed: 0.76 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.78275/51.00%, bp_loss: 1.79121/46.00%, hp_loss: 2.98899/25.00%, j_loss: 1.81041/51.00%, \n",
      "\t\tfr_loss: 0.21538/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.58874\n",
      "\tPart 2 - fp_loss: 1.43775/60.00%, bp_loss: 1.63101/51.00%, hp_loss: 2.74661/30.00%, j_loss: 1.49729/61.00%, \n",
      "\t\tfr_loss: 0.18520/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.49785\n",
      "\tPart 3 - fp_loss: 1.03333/73.00%, bp_loss: 0.98647/73.00%, hp_loss: 2.22608/44.00%, j_loss: 0.75313/80.00%, \n",
      "\t\tfr_loss: 0.16379/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16280\n",
      "\tPart 4 - fp_loss: 1.23709/71.00%, bp_loss: 1.01632/73.00%, hp_loss: 2.42667/39.00%, j_loss: 0.84899/77.00%, \n",
      "\t\tfr_loss: 0.16593/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.69500\n",
      "\t`Validation time elapsed: 9.52 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 27.\n",
      "\n",
      "EPOCH 28\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.97822/72.00%, bp_loss: 2.08903/43.00%, hp_loss: 3.15272/21.00%, j_loss: 1.23486/72.00%, \n",
      "\t\tfr_loss: 0.14201/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.59683\n",
      "\tPart 2 - fp_loss: 0.79045/78.00%, bp_loss: 1.83366/52.00%, hp_loss: 2.76716/31.00%, j_loss: 0.93485/76.00%, \n",
      "\t\tfr_loss: 0.14765/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47377\n",
      "\tPart 3 - fp_loss: 0.71165/80.00%, bp_loss: 1.35717/63.00%, hp_loss: 2.34709/39.00%, j_loss: 0.77775/78.00%, \n",
      "\t\tfr_loss: 0.12273/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.31639\n",
      "\tPart 4 - fp_loss: 0.60837/82.00%, bp_loss: 1.05597/69.00%, hp_loss: 2.54119/35.00%, j_loss: 0.53375/84.00%, \n",
      "\t\tfr_loss: 0.09840/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.83768\n",
      "\tTraining time elapsed: 1.08 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.02751/70.00%, bp_loss: 1.83376/46.00%, hp_loss: 3.07908/21.00%, j_loss: 1.23542/70.00%, \n",
      "\t\tfr_loss: 0.13063/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.30640\n",
      "\tPart 2 - fp_loss: 0.80400/77.00%, bp_loss: 1.41666/59.00%, hp_loss: 2.72428/32.00%, j_loss: 0.81551/78.00%, \n",
      "\t\tfr_loss: 0.12826/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.88872\n",
      "\tPart 3 - fp_loss: 0.81780/77.00%, bp_loss: 0.92138/74.00%, hp_loss: 2.47504/35.00%, j_loss: 0.56277/83.00%, \n",
      "\t\tfr_loss: 0.12376/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.90075\n",
      "\tPart 4 - fp_loss: 0.71101/80.00%, bp_loss: 0.83684/77.00%, hp_loss: 2.63309/32.00%, j_loss: 0.49275/85.00%, \n",
      "\t\tfr_loss: 0.11265/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.78634\n",
      "\tTraining time elapsed: 38.65 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.97087/71.00%, bp_loss: 1.73699/49.00%, hp_loss: 3.06746/22.00%, j_loss: 1.14819/71.00%, \n",
      "\t\tfr_loss: 0.13511/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.05863\n",
      "\tPart 2 - fp_loss: 0.87119/73.00%, bp_loss: 1.45577/59.00%, hp_loss: 2.75980/30.00%, j_loss: 0.92568/74.00%, \n",
      "\t\tfr_loss: 0.14921/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16165\n",
      "\tPart 3 - fp_loss: 0.74082/80.00%, bp_loss: 0.86151/74.00%, hp_loss: 2.36325/39.00%, j_loss: 0.55161/82.00%, \n",
      "\t\tfr_loss: 0.12317/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64036\n",
      "\tPart 4 - fp_loss: 0.63811/82.00%, bp_loss: 0.79184/77.00%, hp_loss: 2.51373/37.00%, j_loss: 0.46962/86.00%, \n",
      "\t\tfr_loss: 0.12029/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53358\n",
      "\tTraining time elapsed: 76.17 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.94288/71.00%, bp_loss: 1.71481/50.00%, hp_loss: 3.07847/23.00%, j_loss: 1.19400/72.00%, \n",
      "\t\tfr_loss: 0.14577/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.07593\n",
      "\tPart 2 - fp_loss: 0.76541/78.00%, bp_loss: 1.29782/63.00%, hp_loss: 2.74304/32.00%, j_loss: 0.77831/78.00%, \n",
      "\t\tfr_loss: 0.13036/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.71493\n",
      "\tPart 3 - fp_loss: 0.82299/77.00%, bp_loss: 0.87830/75.00%, hp_loss: 2.44454/39.00%, j_loss: 0.57564/81.00%, \n",
      "\t\tfr_loss: 0.14398/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.86544\n",
      "\tPart 4 - fp_loss: 0.67281/82.00%, bp_loss: 0.78005/77.00%, hp_loss: 2.61026/32.00%, j_loss: 0.47980/84.00%, \n",
      "\t\tfr_loss: 0.10204/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64495\n",
      "\tTraining time elapsed: 113.73 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.98715/71.00%, bp_loss: 1.61995/52.00%, hp_loss: 3.05553/23.00%, j_loss: 1.15290/71.00%, \n",
      "\t\tfr_loss: 0.14952/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.96505\n",
      "\tPart 2 - fp_loss: 0.84966/76.00%, bp_loss: 1.33002/62.00%, hp_loss: 2.71681/32.00%, j_loss: 0.86756/77.00%, \n",
      "\t\tfr_loss: 0.15450/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.91854\n",
      "\tPart 3 - fp_loss: 0.79057/79.00%, bp_loss: 0.79139/77.00%, hp_loss: 2.38797/38.00%, j_loss: 0.51688/83.00%, \n",
      "\t\tfr_loss: 0.11381/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60062\n",
      "\tPart 4 - fp_loss: 0.74968/80.00%, bp_loss: 0.84484/75.00%, hp_loss: 2.65121/32.00%, j_loss: 0.52237/84.00%, \n",
      "\t\tfr_loss: 0.11629/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88438\n",
      "\tTraining time elapsed: 151.25 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.03172/71.00%, bp_loss: 1.71588/49.00%, hp_loss: 3.08929/21.00%, j_loss: 1.20263/71.00%, \n",
      "\t\tfr_loss: 0.14599/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.18550\n",
      "\tPart 2 - fp_loss: 0.88685/75.00%, bp_loss: 1.28597/63.00%, hp_loss: 2.78818/31.00%, j_loss: 0.93075/75.00%, \n",
      "\t\tfr_loss: 0.13861/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03035\n",
      "\tPart 3 - fp_loss: 0.80483/77.00%, bp_loss: 0.87499/74.00%, hp_loss: 2.40076/38.00%, j_loss: 0.62085/81.00%, \n",
      "\t\tfr_loss: 0.11538/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.81681\n",
      "\tPart 4 - fp_loss: 0.73316/78.00%, bp_loss: 0.82976/76.00%, hp_loss: 2.55367/35.00%, j_loss: 0.55547/83.00%, \n",
      "\t\tfr_loss: 0.09491/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.76697\n",
      "\tTraining time elapsed: 188.78 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.04984/70.00%, bp_loss: 1.74580/50.00%, hp_loss: 3.11656/20.00%, j_loss: 1.20628/70.00%, \n",
      "\t\tfr_loss: 0.13941/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.25789\n",
      "\tPart 2 - fp_loss: 0.80351/77.00%, bp_loss: 1.24194/65.00%, hp_loss: 2.74242/31.00%, j_loss: 0.83877/76.00%, \n",
      "\t\tfr_loss: 0.14127/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.76791\n",
      "\tPart 3 - fp_loss: 0.81786/77.00%, bp_loss: 0.78466/77.00%, hp_loss: 2.30869/41.00%, j_loss: 0.61772/82.00%, \n",
      "\t\tfr_loss: 0.12326/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65218\n",
      "\tPart 4 - fp_loss: 0.68219/81.00%, bp_loss: 0.82656/75.00%, hp_loss: 2.52080/36.00%, j_loss: 0.52427/82.00%, \n",
      "\t\tfr_loss: 0.11086/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.66467\n",
      "\tTraining time elapsed: 226.32 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.05992/68.00%, bp_loss: 1.66877/49.00%, hp_loss: 3.05420/24.00%, j_loss: 1.30426/68.00%, \n",
      "\t\tfr_loss: 0.14821/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.23537\n",
      "\tPart 2 - fp_loss: 0.80315/77.00%, bp_loss: 1.32910/61.00%, hp_loss: 2.77426/32.00%, j_loss: 0.90570/76.00%, \n",
      "\t\tfr_loss: 0.12852/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.94073\n",
      "\tPart 3 - fp_loss: 0.79739/77.00%, bp_loss: 0.89339/74.00%, hp_loss: 2.37684/39.00%, j_loss: 0.65125/81.00%, \n",
      "\t\tfr_loss: 0.12773/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.84660\n",
      "\tPart 4 - fp_loss: 0.71505/79.00%, bp_loss: 0.90359/74.00%, hp_loss: 2.65270/31.00%, j_loss: 0.53585/84.00%, \n",
      "\t\tfr_loss: 0.11329/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92049\n",
      "\tTraining time elapsed: 263.89 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.03241/69.00%, bp_loss: 1.64251/52.00%, hp_loss: 3.08326/22.00%, j_loss: 1.19317/69.00%, \n",
      "\t\tfr_loss: 0.14293/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.09428\n",
      "\tPart 2 - fp_loss: 0.85570/75.00%, bp_loss: 1.36943/61.00%, hp_loss: 2.69815/33.00%, j_loss: 0.91985/75.00%, \n",
      "\t\tfr_loss: 0.15094/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.99408\n",
      "\tPart 3 - fp_loss: 0.76551/77.00%, bp_loss: 0.84288/76.00%, hp_loss: 2.34309/40.00%, j_loss: 0.57560/81.00%, \n",
      "\t\tfr_loss: 0.10395/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63103\n",
      "\tPart 4 - fp_loss: 0.65524/81.00%, bp_loss: 0.84930/74.00%, hp_loss: 2.53085/35.00%, j_loss: 0.56366/81.00%, \n",
      "\t\tfr_loss: 0.11593/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71498\n",
      "\tTraining time elapsed: 301.46 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.80867/52.00%, bp_loss: 2.11537/40.00%, hp_loss: 3.00941/23.00%, j_loss: 1.78010/52.00%, \n",
      "\t\tfr_loss: 0.19887/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.91242\n",
      "\tPart 2 - fp_loss: 1.52922/62.00%, bp_loss: 1.86286/52.00%, hp_loss: 2.68724/31.00%, j_loss: 1.37440/61.00%, \n",
      "\t\tfr_loss: 0.19763/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.65134\n",
      "\tPart 3 - fp_loss: 1.14636/70.00%, bp_loss: 1.28487/63.00%, hp_loss: 2.26530/41.00%, j_loss: 0.93132/72.00%, \n",
      "\t\tfr_loss: 0.18201/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.80986\n",
      "\tPart 4 - fp_loss: 1.32422/68.00%, bp_loss: 1.17548/67.00%, hp_loss: 2.39370/39.00%, j_loss: 0.88826/71.00%, \n",
      "\t\tfr_loss: 0.18197/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.96363\n",
      "\t`Validation time elapsed: 0.76 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.87575/50.00%, bp_loss: 1.86859/44.00%, hp_loss: 3.05236/23.00%, j_loss: 1.85446/50.00%, \n",
      "\t\tfr_loss: 0.20389/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.85504\n",
      "\tPart 2 - fp_loss: 1.59509/59.00%, bp_loss: 1.53824/57.00%, hp_loss: 2.69350/31.00%, j_loss: 1.40684/60.00%, \n",
      "\t\tfr_loss: 0.19530/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.42897\n",
      "\tPart 3 - fp_loss: 1.26166/69.00%, bp_loss: 0.99650/73.00%, hp_loss: 2.30476/43.00%, j_loss: 0.83155/76.00%, \n",
      "\t\tfr_loss: 0.16899/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.56345\n",
      "\tPart 4 - fp_loss: 1.36288/67.00%, bp_loss: 1.03944/73.00%, hp_loss: 2.38720/40.00%, j_loss: 0.90389/76.00%, \n",
      "\t\tfr_loss: 0.17268/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.86609\n",
      "\t`Validation time elapsed: 9.50 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 28.\n",
      "\n",
      "EPOCH 29\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 1.00883/70.00%, bp_loss: 2.12802/43.00%, hp_loss: 3.13059/19.00%, j_loss: 1.27929/69.00%, \n",
      "\t\tfr_loss: 0.13052/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.67726\n",
      "\tPart 2 - fp_loss: 0.82263/76.00%, bp_loss: 1.78583/53.00%, hp_loss: 2.78904/30.00%, j_loss: 1.01308/72.00%, \n",
      "\t\tfr_loss: 0.14479/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.55538\n",
      "\tPart 3 - fp_loss: 0.77013/77.00%, bp_loss: 1.15561/69.00%, hp_loss: 2.44429/37.00%, j_loss: 0.71764/79.00%, \n",
      "\t\tfr_loss: 0.12851/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21619\n",
      "\tPart 4 - fp_loss: 0.62428/83.00%, bp_loss: 0.86812/74.00%, hp_loss: 2.56322/33.00%, j_loss: 0.56555/83.00%, \n",
      "\t\tfr_loss: 0.10679/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.72797\n",
      "\tTraining time elapsed: 1.09 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.96592/71.00%, bp_loss: 1.68177/53.00%, hp_loss: 3.13698/21.00%, j_loss: 1.13266/72.00%, \n",
      "\t\tfr_loss: 0.16018/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.07752\n",
      "\tPart 2 - fp_loss: 0.84353/76.00%, bp_loss: 1.22993/66.00%, hp_loss: 2.61620/35.00%, j_loss: 0.82141/77.00%, \n",
      "\t\tfr_loss: 0.15383/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66491\n",
      "\tPart 3 - fp_loss: 0.82209/76.00%, bp_loss: 0.88414/76.00%, hp_loss: 2.42285/37.00%, j_loss: 0.58058/82.00%, \n",
      "\t\tfr_loss: 0.12554/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.83520\n",
      "\tPart 4 - fp_loss: 0.65989/82.00%, bp_loss: 0.85693/74.00%, hp_loss: 2.58569/33.00%, j_loss: 0.48661/85.00%, \n",
      "\t\tfr_loss: 0.10314/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69225\n",
      "\tTraining time elapsed: 38.64 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.95772/72.00%, bp_loss: 1.63402/53.00%, hp_loss: 3.07375/23.00%, j_loss: 1.10313/72.00%, \n",
      "\t\tfr_loss: 0.15199/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.92062\n",
      "\tPart 2 - fp_loss: 0.82413/77.00%, bp_loss: 1.28999/63.00%, hp_loss: 2.71529/32.00%, j_loss: 0.83307/77.00%, \n",
      "\t\tfr_loss: 0.14816/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.81064\n",
      "\tPart 3 - fp_loss: 0.79491/78.00%, bp_loss: 0.73772/79.00%, hp_loss: 2.36165/39.00%, j_loss: 0.52412/82.00%, \n",
      "\t\tfr_loss: 0.11001/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52841\n",
      "\tPart 4 - fp_loss: 0.62575/82.00%, bp_loss: 0.78547/77.00%, hp_loss: 2.60317/33.00%, j_loss: 0.45090/85.00%, \n",
      "\t\tfr_loss: 0.10744/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57273\n",
      "\tTraining time elapsed: 76.17 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.99903/70.00%, bp_loss: 1.68091/51.00%, hp_loss: 3.11752/21.00%, j_loss: 1.13628/71.00%, \n",
      "\t\tfr_loss: 0.16599/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.09972\n",
      "\tPart 2 - fp_loss: 0.79421/77.00%, bp_loss: 1.26564/62.00%, hp_loss: 2.73614/32.00%, j_loss: 0.81552/77.00%, \n",
      "\t\tfr_loss: 0.14621/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75773\n",
      "\tPart 3 - fp_loss: 0.76176/79.00%, bp_loss: 0.81408/76.00%, hp_loss: 2.37772/36.00%, j_loss: 0.57599/82.00%, \n",
      "\t\tfr_loss: 0.11717/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64673\n",
      "\tPart 4 - fp_loss: 0.75270/79.00%, bp_loss: 0.87159/75.00%, hp_loss: 2.64409/32.00%, j_loss: 0.56451/82.00%, \n",
      "\t\tfr_loss: 0.11239/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94529\n",
      "\tTraining time elapsed: 113.72 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.98916/71.00%, bp_loss: 1.61940/53.00%, hp_loss: 3.05556/22.00%, j_loss: 1.13036/71.00%, \n",
      "\t\tfr_loss: 0.16824/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.96271\n",
      "\tPart 2 - fp_loss: 0.83674/76.00%, bp_loss: 1.29210/64.00%, hp_loss: 2.69069/33.00%, j_loss: 0.83006/76.00%, \n",
      "\t\tfr_loss: 0.12573/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77532\n",
      "\tPart 3 - fp_loss: 0.79404/78.00%, bp_loss: 0.81781/76.00%, hp_loss: 2.41451/38.00%, j_loss: 0.56689/83.00%, \n",
      "\t\tfr_loss: 0.10193/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69519\n",
      "\tPart 4 - fp_loss: 0.70114/79.00%, bp_loss: 0.84282/75.00%, hp_loss: 2.54407/35.00%, j_loss: 0.51696/83.00%, \n",
      "\t\tfr_loss: 0.10936/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71435\n",
      "\tTraining time elapsed: 151.25 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.05055/68.00%, bp_loss: 1.66766/51.00%, hp_loss: 3.09218/21.00%, j_loss: 1.21169/67.00%, \n",
      "\t\tfr_loss: 0.15217/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.17426\n",
      "\tPart 2 - fp_loss: 0.91934/73.00%, bp_loss: 1.30548/62.00%, hp_loss: 2.71008/31.00%, j_loss: 0.93746/74.00%, \n",
      "\t\tfr_loss: 0.14206/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01441\n",
      "\tPart 3 - fp_loss: 0.75161/78.00%, bp_loss: 0.79432/77.00%, hp_loss: 2.36436/38.00%, j_loss: 0.57307/83.00%, \n",
      "\t\tfr_loss: 0.11875/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60211\n",
      "\tPart 4 - fp_loss: 0.66092/81.00%, bp_loss: 0.81654/76.00%, hp_loss: 2.66485/32.00%, j_loss: 0.48570/84.00%, \n",
      "\t\tfr_loss: 0.10673/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73473\n",
      "\tTraining time elapsed: 188.82 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.01696/70.00%, bp_loss: 1.62726/53.00%, hp_loss: 3.05579/24.00%, j_loss: 1.10921/71.00%, \n",
      "\t\tfr_loss: 0.16154/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.97076\n",
      "\tPart 2 - fp_loss: 0.75423/77.00%, bp_loss: 1.19066/65.00%, hp_loss: 2.67441/35.00%, j_loss: 0.80964/76.00%, \n",
      "\t\tfr_loss: 0.14190/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57084\n",
      "\tPart 3 - fp_loss: 0.69604/80.00%, bp_loss: 0.70012/80.00%, hp_loss: 2.36669/38.00%, j_loss: 0.46282/85.00%, \n",
      "\t\tfr_loss: 0.11180/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33747\n",
      "\tPart 4 - fp_loss: 0.65387/81.00%, bp_loss: 0.75155/78.00%, hp_loss: 2.63895/32.00%, j_loss: 0.48511/83.00%, \n",
      "\t\tfr_loss: 0.11893/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64841\n",
      "\tTraining time elapsed: 226.33 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.99346/71.00%, bp_loss: 1.66748/50.00%, hp_loss: 3.04412/23.00%, j_loss: 1.13481/72.00%, \n",
      "\t\tfr_loss: 0.15158/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.99145\n",
      "\tPart 2 - fp_loss: 0.80194/76.00%, bp_loss: 1.25936/66.00%, hp_loss: 2.66772/34.00%, j_loss: 0.83457/76.00%, \n",
      "\t\tfr_loss: 0.13620/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.69978\n",
      "\tPart 3 - fp_loss: 0.82497/77.00%, bp_loss: 0.74680/77.00%, hp_loss: 2.41202/37.00%, j_loss: 0.54835/81.00%, \n",
      "\t\tfr_loss: 0.11545/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64759\n",
      "\tPart 4 - fp_loss: 0.64335/82.00%, bp_loss: 0.74625/77.00%, hp_loss: 2.65873/31.00%, j_loss: 0.44459/86.00%, \n",
      "\t\tfr_loss: 0.09591/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58884\n",
      "\tTraining time elapsed: 263.86 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.89399/72.00%, bp_loss: 1.69379/52.00%, hp_loss: 3.08921/21.00%, j_loss: 1.11556/72.00%, \n",
      "\t\tfr_loss: 0.13925/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.93181\n",
      "\tPart 2 - fp_loss: 0.82215/76.00%, bp_loss: 1.24120/64.00%, hp_loss: 2.68936/32.00%, j_loss: 0.85760/77.00%, \n",
      "\t\tfr_loss: 0.14788/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75818\n",
      "\tPart 3 - fp_loss: 0.73550/80.00%, bp_loss: 0.82039/77.00%, hp_loss: 2.34752/40.00%, j_loss: 0.50294/83.00%, \n",
      "\t\tfr_loss: 0.11027/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51662\n",
      "\tPart 4 - fp_loss: 0.70754/80.00%, bp_loss: 0.79036/76.00%, hp_loss: 2.55950/34.00%, j_loss: 0.54494/83.00%, \n",
      "\t\tfr_loss: 0.09381/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69614\n",
      "\tTraining time elapsed: 301.41 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.77450/52.00%, bp_loss: 2.02926/40.00%, hp_loss: 3.07284/22.00%, j_loss: 1.83059/52.00%, \n",
      "\t\tfr_loss: 0.20872/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.91592\n",
      "\tPart 2 - fp_loss: 1.59242/58.00%, bp_loss: 1.97485/50.00%, hp_loss: 2.72091/29.00%, j_loss: 1.51581/57.00%, \n",
      "\t\tfr_loss: 0.19720/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.00118\n",
      "\tPart 3 - fp_loss: 1.25308/70.00%, bp_loss: 1.27842/64.00%, hp_loss: 2.29983/41.00%, j_loss: 0.95995/70.00%, \n",
      "\t\tfr_loss: 0.18456/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.97583\n",
      "\tPart 4 - fp_loss: 1.34799/67.00%, bp_loss: 1.09996/69.00%, hp_loss: 2.49909/36.00%, j_loss: 0.88050/72.00%, \n",
      "\t\tfr_loss: 0.16927/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.99681\n",
      "\t`Validation time elapsed: 0.75 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.93350/49.00%, bp_loss: 1.75520/47.00%, hp_loss: 3.06129/22.00%, j_loss: 1.86846/50.00%, \n",
      "\t\tfr_loss: 0.23246/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.85091\n",
      "\tPart 2 - fp_loss: 1.64558/56.00%, bp_loss: 1.50812/57.00%, hp_loss: 2.73385/29.00%, j_loss: 1.47858/59.00%, \n",
      "\t\tfr_loss: 0.20906/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.57520\n",
      "\tPart 3 - fp_loss: 1.18549/70.00%, bp_loss: 0.98404/75.00%, hp_loss: 2.43643/38.00%, j_loss: 0.79508/78.00%, \n",
      "\t\tfr_loss: 0.17616/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57720\n",
      "\tPart 4 - fp_loss: 1.37896/68.00%, bp_loss: 0.99262/74.00%, hp_loss: 2.50509/36.00%, j_loss: 0.84857/77.00%, \n",
      "\t\tfr_loss: 0.16508/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.89032\n",
      "\t`Validation time elapsed: 9.50 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Completed epoch 29.\n",
      "\n",
      "EPOCH 30\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.94559/72.00%, bp_loss: 1.85061/48.00%, hp_loss: 3.11523/21.00%, j_loss: 1.18702/71.00%, \n",
      "\t\tfr_loss: 0.13508/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.23353\n",
      "\tPart 2 - fp_loss: 0.78422/78.00%, bp_loss: 1.77529/57.00%, hp_loss: 2.72729/32.00%, j_loss: 0.89518/76.00%, \n",
      "\t\tfr_loss: 0.13987/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.32186\n",
      "\tPart 3 - fp_loss: 0.71148/78.00%, bp_loss: 1.08931/68.00%, hp_loss: 2.45211/37.00%, j_loss: 0.71243/77.00%, \n",
      "\t\tfr_loss: 0.10396/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06928\n",
      "\tPart 4 - fp_loss: 0.68606/79.00%, bp_loss: 0.84614/76.00%, hp_loss: 2.69110/32.00%, j_loss: 0.56862/81.00%, \n",
      "\t\tfr_loss: 0.09513/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88704\n",
      "\tTraining time elapsed: 1.08 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.97047/72.00%, bp_loss: 1.59940/53.00%, hp_loss: 3.04908/22.00%, j_loss: 1.06428/72.00%, \n",
      "\t\tfr_loss: 0.13498/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.81821\n",
      "\tPart 2 - fp_loss: 0.79918/76.00%, bp_loss: 1.30158/63.00%, hp_loss: 2.70877/32.00%, j_loss: 0.82528/76.00%, \n",
      "\t\tfr_loss: 0.14435/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77916\n",
      "\tPart 3 - fp_loss: 0.81661/77.00%, bp_loss: 0.77305/79.00%, hp_loss: 2.38208/38.00%, j_loss: 0.53136/84.00%, \n",
      "\t\tfr_loss: 0.12220/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62531\n",
      "\tPart 4 - fp_loss: 0.68962/82.00%, bp_loss: 0.69844/80.00%, hp_loss: 2.53928/35.00%, j_loss: 0.39788/85.00%, \n",
      "\t\tfr_loss: 0.09014/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41535\n",
      "\tTraining time elapsed: 38.62 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.97140/71.00%, bp_loss: 1.57937/53.00%, hp_loss: 3.03440/24.00%, j_loss: 1.09740/71.00%, \n",
      "\t\tfr_loss: 0.14429/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.82687\n",
      "\tPart 2 - fp_loss: 0.78047/79.00%, bp_loss: 1.25967/65.00%, hp_loss: 2.69424/33.00%, j_loss: 0.76175/79.00%, \n",
      "\t\tfr_loss: 0.13412/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.63025\n",
      "\tPart 3 - fp_loss: 0.76362/79.00%, bp_loss: 0.83259/77.00%, hp_loss: 2.42931/40.00%, j_loss: 0.56054/82.00%, \n",
      "\t\tfr_loss: 0.10847/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69453\n",
      "\tPart 4 - fp_loss: 0.61498/82.00%, bp_loss: 0.78540/76.00%, hp_loss: 2.60026/34.00%, j_loss: 0.45423/85.00%, \n",
      "\t\tfr_loss: 0.10930/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56416\n",
      "\tTraining time elapsed: 76.14 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.95304/70.00%, bp_loss: 1.59735/54.00%, hp_loss: 3.10485/22.00%, j_loss: 1.09389/70.00%, \n",
      "\t\tfr_loss: 0.14435/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.89348\n",
      "\tPart 2 - fp_loss: 0.72510/79.00%, bp_loss: 1.31348/62.00%, hp_loss: 2.83379/29.00%, j_loss: 0.76423/79.00%, \n",
      "\t\tfr_loss: 0.13844/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77505\n",
      "\tPart 3 - fp_loss: 0.78089/77.00%, bp_loss: 0.73586/79.00%, hp_loss: 2.39155/39.00%, j_loss: 0.55589/83.00%, \n",
      "\t\tfr_loss: 0.11106/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57526\n",
      "\tPart 4 - fp_loss: 0.65563/82.00%, bp_loss: 0.75994/77.00%, hp_loss: 2.59795/35.00%, j_loss: 0.45451/85.00%, \n",
      "\t\tfr_loss: 0.08933/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55737\n",
      "\tTraining time elapsed: 113.70 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.90062/73.00%, bp_loss: 1.56929/54.00%, hp_loss: 3.02829/21.00%, j_loss: 1.00813/74.00%, \n",
      "\t\tfr_loss: 0.13649/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.64281\n",
      "\tPart 2 - fp_loss: 0.82404/77.00%, bp_loss: 1.24778/66.00%, hp_loss: 2.67076/34.00%, j_loss: 0.78008/78.00%, \n",
      "\t\tfr_loss: 0.13319/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.65585\n",
      "\tPart 3 - fp_loss: 0.78363/78.00%, bp_loss: 0.83264/76.00%, hp_loss: 2.41613/37.00%, j_loss: 0.55626/81.00%, \n",
      "\t\tfr_loss: 0.14922/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73788\n",
      "\tPart 4 - fp_loss: 0.72471/79.00%, bp_loss: 0.79276/76.00%, hp_loss: 2.62636/32.00%, j_loss: 0.56068/82.00%, \n",
      "\t\tfr_loss: 0.11047/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.81498\n",
      "\tTraining time elapsed: 151.26 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 1.01591/70.00%, bp_loss: 1.56306/54.00%, hp_loss: 3.07578/21.00%, j_loss: 1.14072/69.00%, \n",
      "\t\tfr_loss: 0.15822/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.95368\n",
      "\tPart 2 - fp_loss: 0.79583/77.00%, bp_loss: 1.29191/62.00%, hp_loss: 2.69775/33.00%, j_loss: 0.85179/76.00%, \n",
      "\t\tfr_loss: 0.14730/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.78458\n",
      "\tPart 3 - fp_loss: 0.75440/80.00%, bp_loss: 0.82936/77.00%, hp_loss: 2.42269/38.00%, j_loss: 0.51060/83.00%, \n",
      "\t\tfr_loss: 0.10952/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62657\n",
      "\tPart 4 - fp_loss: 0.71405/79.00%, bp_loss: 0.81726/76.00%, hp_loss: 2.64228/33.00%, j_loss: 0.52555/82.00%, \n",
      "\t\tfr_loss: 0.09685/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.79599\n",
      "\tTraining time elapsed: 188.79 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.00135/70.00%, bp_loss: 1.57825/53.00%, hp_loss: 3.06196/23.00%, j_loss: 1.11409/71.00%, \n",
      "\t\tfr_loss: 0.15952/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.91516\n",
      "\tPart 2 - fp_loss: 0.82385/76.00%, bp_loss: 1.14836/66.00%, hp_loss: 2.72995/33.00%, j_loss: 0.79586/78.00%, \n",
      "\t\tfr_loss: 0.16339/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.66141\n",
      "\tPart 3 - fp_loss: 0.76109/77.00%, bp_loss: 0.74322/79.00%, hp_loss: 2.33697/40.00%, j_loss: 0.50842/82.00%, \n",
      "\t\tfr_loss: 0.12148/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47118\n",
      "\tPart 4 - fp_loss: 0.63788/82.00%, bp_loss: 0.71706/78.00%, hp_loss: 2.51707/36.00%, j_loss: 0.44666/83.00%, \n",
      "\t\tfr_loss: 0.11556/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43423\n",
      "\tTraining time elapsed: 226.32 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.98825/72.00%, bp_loss: 1.61397/52.00%, hp_loss: 3.11787/21.00%, j_loss: 1.13448/72.00%, \n",
      "\t\tfr_loss: 0.14781/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.00238\n",
      "\tPart 2 - fp_loss: 0.80563/76.00%, bp_loss: 1.26673/64.00%, hp_loss: 2.66866/34.00%, j_loss: 0.84211/74.00%, \n",
      "\t\tfr_loss: 0.14935/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.73248\n",
      "\tPart 3 - fp_loss: 0.76833/78.00%, bp_loss: 0.82492/77.00%, hp_loss: 2.37620/37.00%, j_loss: 0.53922/83.00%, \n",
      "\t\tfr_loss: 0.12043/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62910\n",
      "\tPart 4 - fp_loss: 0.66053/81.00%, bp_loss: 0.87019/75.00%, hp_loss: 2.55644/33.00%, j_loss: 0.54192/80.00%, \n",
      "\t\tfr_loss: 0.08990/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71898\n",
      "\tTraining time elapsed: 263.86 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.06693/70.00%, bp_loss: 1.51826/55.00%, hp_loss: 3.13108/21.00%, j_loss: 1.09717/71.00%, \n",
      "\t\tfr_loss: 0.14954/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.96299\n",
      "\tPart 2 - fp_loss: 0.78516/76.00%, bp_loss: 1.21244/66.00%, hp_loss: 2.72520/32.00%, j_loss: 0.81519/77.00%, \n",
      "\t\tfr_loss: 0.14531/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.68330\n",
      "\tPart 3 - fp_loss: 0.75009/80.00%, bp_loss: 0.70987/79.00%, hp_loss: 2.37495/40.00%, j_loss: 0.49526/83.00%, \n",
      "\t\tfr_loss: 0.11234/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44250\n",
      "\tPart 4 - fp_loss: 0.70180/79.00%, bp_loss: 0.80868/76.00%, hp_loss: 2.59537/34.00%, j_loss: 0.57208/83.00%, \n",
      "\t\tfr_loss: 0.10845/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.78638\n",
      "\tTraining time elapsed: 301.40 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.76078/50.00%, bp_loss: 2.02538/41.00%, hp_loss: 2.99921/25.00%, j_loss: 1.88091/49.00%, \n",
      "\t\tfr_loss: 0.20674/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.87304\n",
      "\tPart 2 - fp_loss: 1.49099/61.00%, bp_loss: 1.67424/56.00%, hp_loss: 2.64849/31.00%, j_loss: 1.34380/61.00%, \n",
      "\t\tfr_loss: 0.19369/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.35121\n",
      "\tPart 3 - fp_loss: 1.13391/72.00%, bp_loss: 1.15956/68.00%, hp_loss: 2.29265/42.00%, j_loss: 0.78515/73.00%, \n",
      "\t\tfr_loss: 0.18169/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55296\n",
      "\tPart 4 - fp_loss: 1.41554/67.00%, bp_loss: 1.07917/70.00%, hp_loss: 2.43138/39.00%, j_loss: 0.85757/70.00%, \n",
      "\t\tfr_loss: 0.16998/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.95365\n",
      "\t`Validation time elapsed: 0.78 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.89692/51.00%, bp_loss: 1.75258/49.00%, hp_loss: 3.08271/21.00%, j_loss: 1.77133/51.00%, \n",
      "\t\tfr_loss: 0.20259/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.70614\n",
      "\tPart 2 - fp_loss: 1.53083/60.00%, bp_loss: 1.57778/56.00%, hp_loss: 2.77224/28.00%, j_loss: 1.39720/61.00%, \n",
      "\t\tfr_loss: 0.19571/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.47377\n",
      "\tPart 3 - fp_loss: 1.11769/72.00%, bp_loss: 0.88461/76.00%, hp_loss: 2.28726/43.00%, j_loss: 0.73753/80.00%, \n",
      "\t\tfr_loss: 0.15854/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18562\n",
      "\tPart 4 - fp_loss: 1.32973/69.00%, bp_loss: 0.95114/74.00%, hp_loss: 2.49499/37.00%, j_loss: 0.91347/77.00%, \n",
      "\t\tfr_loss: 0.16204/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.85136\n",
      "\t`Validation time elapsed: 9.52 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 30.\n",
      "\n",
      "EPOCH 31\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.95126/71.00%, bp_loss: 1.83697/48.00%, hp_loss: 3.06223/24.00%, j_loss: 1.23029/69.00%, \n",
      "\t\tfr_loss: 0.13323/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.21398\n",
      "\tPart 2 - fp_loss: 0.74917/78.00%, bp_loss: 1.67987/57.00%, hp_loss: 2.72944/31.00%, j_loss: 0.87004/76.00%, \n",
      "\t\tfr_loss: 0.13330/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16183\n",
      "\tPart 3 - fp_loss: 0.69887/79.00%, bp_loss: 1.11904/71.00%, hp_loss: 2.40844/37.00%, j_loss: 0.64310/79.00%, \n",
      "\t\tfr_loss: 0.12131/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.99077\n",
      "\tPart 4 - fp_loss: 0.66868/81.00%, bp_loss: 0.81484/76.00%, hp_loss: 2.57928/33.00%, j_loss: 0.53676/84.00%, \n",
      "\t\tfr_loss: 0.10389/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.70345\n",
      "\tTraining time elapsed: 1.08 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.96128/70.00%, bp_loss: 1.51083/57.00%, hp_loss: 3.03075/23.00%, j_loss: 1.07514/72.00%, \n",
      "\t\tfr_loss: 0.16527/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.74328\n",
      "\tPart 2 - fp_loss: 0.72660/77.00%, bp_loss: 1.20296/64.00%, hp_loss: 2.67843/33.00%, j_loss: 0.79915/77.00%, \n",
      "\t\tfr_loss: 0.13129/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.53843\n",
      "\tPart 3 - fp_loss: 0.70177/80.00%, bp_loss: 0.85740/75.00%, hp_loss: 2.40836/37.00%, j_loss: 0.52746/83.00%, \n",
      "\t\tfr_loss: 0.11927/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61425\n",
      "\tPart 4 - fp_loss: 0.55787/84.00%, bp_loss: 0.76771/78.00%, hp_loss: 2.55554/35.00%, j_loss: 0.42256/86.00%, \n",
      "\t\tfr_loss: 0.09790/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40159\n",
      "\tTraining time elapsed: 38.62 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.98635/69.00%, bp_loss: 1.61343/53.00%, hp_loss: 3.14630/19.00%, j_loss: 1.13057/69.00%, \n",
      "\t\tfr_loss: 0.14791/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.02456\n",
      "\tPart 2 - fp_loss: 0.84868/75.00%, bp_loss: 1.15224/67.00%, hp_loss: 2.79406/29.00%, j_loss: 0.81645/75.00%, \n",
      "\t\tfr_loss: 0.14377/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75521\n",
      "\tPart 3 - fp_loss: 0.75596/78.00%, bp_loss: 0.67560/81.00%, hp_loss: 2.38404/37.00%, j_loss: 0.50491/85.00%, \n",
      "\t\tfr_loss: 0.10609/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42660\n",
      "\tPart 4 - fp_loss: 0.70707/80.00%, bp_loss: 0.66886/79.00%, hp_loss: 2.62612/31.00%, j_loss: 0.44525/84.00%, \n",
      "\t\tfr_loss: 0.11407/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56137\n",
      "\tTraining time elapsed: 76.14 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.97546/71.00%, bp_loss: 1.43625/57.00%, hp_loss: 3.06294/23.00%, j_loss: 1.07399/71.00%, \n",
      "\t\tfr_loss: 0.14308/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.69172\n",
      "\tPart 2 - fp_loss: 0.78429/77.00%, bp_loss: 1.11081/67.00%, hp_loss: 2.69733/30.00%, j_loss: 0.72569/78.00%, \n",
      "\t\tfr_loss: 0.14370/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.46183\n",
      "\tPart 3 - fp_loss: 0.74779/78.00%, bp_loss: 0.70240/79.00%, hp_loss: 2.42312/37.00%, j_loss: 0.54024/83.00%, \n",
      "\t\tfr_loss: 0.10716/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52071\n",
      "\tPart 4 - fp_loss: 0.64389/81.00%, bp_loss: 0.77450/76.00%, hp_loss: 2.69359/31.00%, j_loss: 0.47862/85.00%, \n",
      "\t\tfr_loss: 0.10253/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69313\n",
      "\tTraining time elapsed: 113.65 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.96519/71.00%, bp_loss: 1.58964/55.00%, hp_loss: 3.13999/21.00%, j_loss: 1.07002/71.00%, \n",
      "\t\tfr_loss: 0.14442/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.90926\n",
      "\tPart 2 - fp_loss: 0.83341/75.00%, bp_loss: 1.16567/66.00%, hp_loss: 2.73556/32.00%, j_loss: 0.79848/76.00%, \n",
      "\t\tfr_loss: 0.15647/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.68960\n",
      "\tPart 3 - fp_loss: 0.79568/78.00%, bp_loss: 0.82040/76.00%, hp_loss: 2.44998/36.00%, j_loss: 0.54236/83.00%, \n",
      "\t\tfr_loss: 0.11416/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.72258\n",
      "\tPart 4 - fp_loss: 0.68126/81.00%, bp_loss: 0.79267/77.00%, hp_loss: 2.52078/35.00%, j_loss: 0.47058/84.00%, \n",
      "\t\tfr_loss: 0.12156/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58685\n",
      "\tTraining time elapsed: 151.19 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.98779/71.00%, bp_loss: 1.49908/56.00%, hp_loss: 3.07841/23.00%, j_loss: 1.11830/71.00%, \n",
      "\t\tfr_loss: 0.14861/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.83218\n",
      "\tPart 2 - fp_loss: 0.76183/78.00%, bp_loss: 1.19062/66.00%, hp_loss: 2.68442/32.00%, j_loss: 0.73617/78.00%, \n",
      "\t\tfr_loss: 0.13313/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.50617\n",
      "\tPart 3 - fp_loss: 0.84306/76.00%, bp_loss: 0.74354/79.00%, hp_loss: 2.39352/39.00%, j_loss: 0.55647/82.00%, \n",
      "\t\tfr_loss: 0.13421/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.67080\n",
      "\tPart 4 - fp_loss: 0.64731/81.00%, bp_loss: 0.79848/76.00%, hp_loss: 2.64517/33.00%, j_loss: 0.52113/84.00%, \n",
      "\t\tfr_loss: 0.09263/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.70473\n",
      "\tTraining time elapsed: 188.73 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.97998/72.00%, bp_loss: 1.54350/55.00%, hp_loss: 3.07657/21.00%, j_loss: 1.05181/72.00%, \n",
      "\t\tfr_loss: 0.14359/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.79545\n",
      "\tPart 2 - fp_loss: 0.78557/76.00%, bp_loss: 1.12227/68.00%, hp_loss: 2.67990/30.00%, j_loss: 0.76157/76.00%, \n",
      "\t\tfr_loss: 0.12188/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47118\n",
      "\tPart 3 - fp_loss: 0.83819/77.00%, bp_loss: 0.72128/80.00%, hp_loss: 2.36581/41.00%, j_loss: 0.53126/83.00%, \n",
      "\t\tfr_loss: 0.11763/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57417\n",
      "\tPart 4 - fp_loss: 0.66337/79.00%, bp_loss: 0.78856/77.00%, hp_loss: 2.53086/34.00%, j_loss: 0.54361/84.00%, \n",
      "\t\tfr_loss: 0.09857/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62497\n",
      "\tTraining time elapsed: 226.23 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.03007/70.00%, bp_loss: 1.49434/55.00%, hp_loss: 3.09294/21.00%, j_loss: 1.12286/71.00%, \n",
      "\t\tfr_loss: 0.14323/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.88344\n",
      "\tPart 2 - fp_loss: 0.83851/77.00%, bp_loss: 1.09952/68.00%, hp_loss: 2.76923/29.00%, j_loss: 0.75767/78.00%, \n",
      "\t\tfr_loss: 0.13293/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.59786\n",
      "\tPart 3 - fp_loss: 0.75613/79.00%, bp_loss: 0.70787/79.00%, hp_loss: 2.43861/35.00%, j_loss: 0.52183/84.00%, \n",
      "\t\tfr_loss: 0.11976/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54420\n",
      "\tPart 4 - fp_loss: 0.69885/81.00%, bp_loss: 0.77042/78.00%, hp_loss: 2.56656/34.00%, j_loss: 0.44499/85.00%, \n",
      "\t\tfr_loss: 0.10953/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.59033\n",
      "\tTraining time elapsed: 263.76 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.00582/71.00%, bp_loss: 1.44047/59.00%, hp_loss: 3.08483/22.00%, j_loss: 0.99201/73.00%, \n",
      "\t\tfr_loss: 0.13478/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.65791\n",
      "\tPart 2 - fp_loss: 0.72118/80.00%, bp_loss: 1.10289/68.00%, hp_loss: 2.73205/32.00%, j_loss: 0.68970/82.00%, \n",
      "\t\tfr_loss: 0.12868/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.37450\n",
      "\tPart 3 - fp_loss: 0.75583/78.00%, bp_loss: 0.74217/80.00%, hp_loss: 2.49412/35.00%, j_loss: 0.50026/85.00%, \n",
      "\t\tfr_loss: 0.11883/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61121\n",
      "\tPart 4 - fp_loss: 0.69290/81.00%, bp_loss: 0.74988/78.00%, hp_loss: 2.61654/31.00%, j_loss: 0.45883/84.00%, \n",
      "\t\tfr_loss: 0.11048/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62863\n",
      "\tTraining time elapsed: 301.30 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.83301/51.00%, bp_loss: 1.93082/45.00%, hp_loss: 3.08682/21.00%, j_loss: 1.83066/51.00%, \n",
      "\t\tfr_loss: 0.21387/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.89519\n",
      "\tPart 2 - fp_loss: 1.66470/57.00%, bp_loss: 1.73663/53.00%, hp_loss: 2.73510/29.00%, j_loss: 1.53197/56.00%, \n",
      "\t\tfr_loss: 0.18892/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.85733\n",
      "\tPart 3 - fp_loss: 1.17169/69.00%, bp_loss: 1.19690/66.00%, hp_loss: 2.37534/41.00%, j_loss: 0.97161/72.00%, \n",
      "\t\tfr_loss: 0.17377/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.88931\n",
      "\tPart 4 - fp_loss: 1.41132/68.00%, bp_loss: 1.20319/65.00%, hp_loss: 2.46588/37.00%, j_loss: 0.99585/70.00%, \n",
      "\t\tfr_loss: 0.18587/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26212\n",
      "\t`Validation time elapsed: 0.75 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.89386/51.00%, bp_loss: 1.53748/54.00%, hp_loss: 3.09078/22.00%, j_loss: 1.64511/54.00%, \n",
      "\t\tfr_loss: 0.20266/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.36988\n",
      "\tPart 2 - fp_loss: 1.62567/58.00%, bp_loss: 1.38215/61.00%, hp_loss: 2.72823/29.00%, j_loss: 1.29717/62.00%, \n",
      "\t\tfr_loss: 0.20405/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.23727\n",
      "\tPart 3 - fp_loss: 1.23560/71.00%, bp_loss: 0.84263/78.00%, hp_loss: 2.29865/42.00%, j_loss: 0.70519/79.00%, \n",
      "\t\tfr_loss: 0.17002/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.25209\n",
      "\tPart 4 - fp_loss: 1.30414/69.00%, bp_loss: 0.97296/74.00%, hp_loss: 2.39597/40.00%, j_loss: 0.80447/77.00%, \n",
      "\t\tfr_loss: 0.17125/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.64879\n",
      "\t`Validation time elapsed: 9.49 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 31.\n",
      "\n",
      "EPOCH 32\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.95101/73.00%, bp_loss: 1.72619/53.00%, hp_loss: 3.07527/22.00%, j_loss: 1.04358/72.00%, \n",
      "\t\tfr_loss: 0.15266/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.94871\n",
      "\tPart 2 - fp_loss: 0.75590/77.00%, bp_loss: 1.64967/57.00%, hp_loss: 2.71388/32.00%, j_loss: 0.91750/73.00%, \n",
      "\t\tfr_loss: 0.13837/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17533\n",
      "\tPart 3 - fp_loss: 0.76204/78.00%, bp_loss: 0.96119/71.00%, hp_loss: 2.37851/38.00%, j_loss: 0.66574/79.00%, \n",
      "\t\tfr_loss: 0.12302/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.89050\n",
      "\tPart 4 - fp_loss: 0.57895/83.00%, bp_loss: 0.79074/76.00%, hp_loss: 2.60505/33.00%, j_loss: 0.51065/83.00%, \n",
      "\t\tfr_loss: 0.09777/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58317\n",
      "\tTraining time elapsed: 1.08 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.90370/71.00%, bp_loss: 1.41815/59.00%, hp_loss: 3.05738/23.00%, j_loss: 1.08029/72.00%, \n",
      "\t\tfr_loss: 0.13080/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.59033\n",
      "\tPart 2 - fp_loss: 0.79871/77.00%, bp_loss: 1.15315/66.00%, hp_loss: 2.73084/31.00%, j_loss: 0.76798/78.00%, \n",
      "\t\tfr_loss: 0.14021/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.59090\n",
      "\tPart 3 - fp_loss: 0.73055/79.00%, bp_loss: 0.82363/77.00%, hp_loss: 2.42622/37.00%, j_loss: 0.51139/84.00%, \n",
      "\t\tfr_loss: 0.11145/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60324\n",
      "\tPart 4 - fp_loss: 0.68452/79.00%, bp_loss: 0.84049/76.00%, hp_loss: 2.58147/33.00%, j_loss: 0.51964/82.00%, \n",
      "\t\tfr_loss: 0.10980/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73592\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.95616/71.00%, bp_loss: 1.43829/58.00%, hp_loss: 3.09899/21.00%, j_loss: 1.02006/71.00%, \n",
      "\t\tfr_loss: 0.14447/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.65798\n",
      "\tPart 2 - fp_loss: 0.77418/77.00%, bp_loss: 1.08535/69.00%, hp_loss: 2.65406/33.00%, j_loss: 0.75370/78.00%, \n",
      "\t\tfr_loss: 0.14952/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.41681\n",
      "\tPart 3 - fp_loss: 0.75881/78.00%, bp_loss: 0.65418/81.00%, hp_loss: 2.32183/41.00%, j_loss: 0.48887/83.00%, \n",
      "\t\tfr_loss: 0.11901/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34270\n",
      "\tPart 4 - fp_loss: 0.63845/80.00%, bp_loss: 0.74600/78.00%, hp_loss: 2.56378/34.00%, j_loss: 0.47091/84.00%, \n",
      "\t\tfr_loss: 0.09378/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51293\n",
      "\tTraining time elapsed: 76.17 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.97115/71.00%, bp_loss: 1.48212/57.00%, hp_loss: 3.02811/24.00%, j_loss: 1.06196/72.00%, \n",
      "\t\tfr_loss: 0.14725/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.69059\n",
      "\tPart 2 - fp_loss: 0.73730/79.00%, bp_loss: 1.17643/66.00%, hp_loss: 2.69512/32.00%, j_loss: 0.72801/77.00%, \n",
      "\t\tfr_loss: 0.14139/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47825\n",
      "\tPart 3 - fp_loss: 0.75089/79.00%, bp_loss: 0.75874/77.00%, hp_loss: 2.38272/38.00%, j_loss: 0.55868/81.00%, \n",
      "\t\tfr_loss: 0.12033/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57137\n",
      "\tPart 4 - fp_loss: 0.65079/81.00%, bp_loss: 0.89252/73.00%, hp_loss: 2.59006/33.00%, j_loss: 0.53646/84.00%, \n",
      "\t\tfr_loss: 0.10858/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.77840\n",
      "\tTraining time elapsed: 113.71 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.98378/71.00%, bp_loss: 1.35728/62.00%, hp_loss: 3.01113/25.00%, j_loss: 0.99996/71.00%, \n",
      "\t\tfr_loss: 0.16447/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51661\n",
      "\tPart 2 - fp_loss: 0.76570/79.00%, bp_loss: 0.98435/73.00%, hp_loss: 2.68487/33.00%, j_loss: 0.60044/81.00%, \n",
      "\t\tfr_loss: 0.13128/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16663\n",
      "\tPart 3 - fp_loss: 0.74460/80.00%, bp_loss: 0.70626/79.00%, hp_loss: 2.43737/39.00%, j_loss: 0.50915/85.00%, \n",
      "\t\tfr_loss: 0.11792/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51532\n",
      "\tPart 4 - fp_loss: 0.67514/80.00%, bp_loss: 0.84086/75.00%, hp_loss: 2.71015/31.00%, j_loss: 0.52255/82.00%, \n",
      "\t\tfr_loss: 0.10111/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.84982\n",
      "\tTraining time elapsed: 151.26 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.91434/73.00%, bp_loss: 1.37040/61.00%, hp_loss: 3.02884/23.00%, j_loss: 0.97351/74.00%, \n",
      "\t\tfr_loss: 0.13777/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.42485\n",
      "\tPart 2 - fp_loss: 0.77582/78.00%, bp_loss: 1.07881/69.00%, hp_loss: 2.66781/33.00%, j_loss: 0.69923/79.00%, \n",
      "\t\tfr_loss: 0.15649/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.37816\n",
      "\tPart 3 - fp_loss: 0.70735/79.00%, bp_loss: 0.80999/78.00%, hp_loss: 2.34788/40.00%, j_loss: 0.49026/84.00%, \n",
      "\t\tfr_loss: 0.09879/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45428\n",
      "\tPart 4 - fp_loss: 0.65082/82.00%, bp_loss: 0.87106/75.00%, hp_loss: 2.56495/34.00%, j_loss: 0.50265/83.00%, \n",
      "\t\tfr_loss: 0.09825/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68773\n",
      "\tTraining time elapsed: 188.81 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.97621/70.00%, bp_loss: 1.42197/58.00%, hp_loss: 3.07964/22.00%, j_loss: 1.09717/71.00%, \n",
      "\t\tfr_loss: 0.15116/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.72614\n",
      "\tPart 2 - fp_loss: 0.78669/76.00%, bp_loss: 1.13342/67.00%, hp_loss: 2.77353/31.00%, j_loss: 0.77403/76.00%, \n",
      "\t\tfr_loss: 0.13830/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60598\n",
      "\tPart 3 - fp_loss: 0.74367/78.00%, bp_loss: 0.78513/78.00%, hp_loss: 2.46173/37.00%, j_loss: 0.52099/84.00%, \n",
      "\t\tfr_loss: 0.11718/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62870\n",
      "\tPart 4 - fp_loss: 0.64299/81.00%, bp_loss: 0.86715/74.00%, hp_loss: 2.60421/33.00%, j_loss: 0.51134/82.00%, \n",
      "\t\tfr_loss: 0.11363/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73932\n",
      "\tTraining time elapsed: 226.36 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.96763/71.00%, bp_loss: 1.42171/59.00%, hp_loss: 3.09073/21.00%, j_loss: 0.99057/73.00%, \n",
      "\t\tfr_loss: 0.15680/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.62743\n",
      "\tPart 2 - fp_loss: 0.81549/76.00%, bp_loss: 1.05847/69.00%, hp_loss: 2.74306/30.00%, j_loss: 0.70089/77.00%, \n",
      "\t\tfr_loss: 0.12726/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44517\n",
      "\tPart 3 - fp_loss: 0.76338/79.00%, bp_loss: 0.71635/80.00%, hp_loss: 2.42240/37.00%, j_loss: 0.47287/84.00%, \n",
      "\t\tfr_loss: 0.11187/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48687\n",
      "\tPart 4 - fp_loss: 0.70467/79.00%, bp_loss: 0.79789/76.00%, hp_loss: 2.59576/34.00%, j_loss: 0.55242/82.00%, \n",
      "\t\tfr_loss: 0.11938/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.77012\n",
      "\tTraining time elapsed: 263.90 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.97237/70.00%, bp_loss: 1.32508/62.00%, hp_loss: 3.05644/23.00%, j_loss: 1.01424/71.00%, \n",
      "\t\tfr_loss: 0.13622/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.50435\n",
      "\tPart 2 - fp_loss: 0.80589/76.00%, bp_loss: 1.06617/70.00%, hp_loss: 2.71284/34.00%, j_loss: 0.71464/78.00%, \n",
      "\t\tfr_loss: 0.13890/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.43844\n",
      "\tPart 3 - fp_loss: 0.78541/78.00%, bp_loss: 0.75181/80.00%, hp_loss: 2.41276/38.00%, j_loss: 0.52746/84.00%, \n",
      "\t\tfr_loss: 0.10913/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58658\n",
      "\tPart 4 - fp_loss: 0.62380/81.00%, bp_loss: 0.83112/76.00%, hp_loss: 2.56263/34.00%, j_loss: 0.54000/83.00%, \n",
      "\t\tfr_loss: 0.09418/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65174\n",
      "\tTraining time elapsed: 301.40 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.94132/48.00%, bp_loss: 1.73966/50.00%, hp_loss: 3.03629/23.00%, j_loss: 1.79002/51.00%, \n",
      "\t\tfr_loss: 0.20958/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.71688\n",
      "\tPart 2 - fp_loss: 1.51171/58.00%, bp_loss: 1.68017/55.00%, hp_loss: 2.70829/31.00%, j_loss: 1.43150/57.00%, \n",
      "\t\tfr_loss: 0.20028/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.53195\n",
      "\tPart 3 - fp_loss: 1.22717/68.00%, bp_loss: 1.05219/69.00%, hp_loss: 2.25656/43.00%, j_loss: 0.89551/75.00%, \n",
      "\t\tfr_loss: 0.17616/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60759\n",
      "\tPart 4 - fp_loss: 1.42396/69.00%, bp_loss: 1.13078/69.00%, hp_loss: 2.42317/38.00%, j_loss: 0.88619/73.00%, \n",
      "\t\tfr_loss: 0.17028/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03438\n",
      "\t`Validation time elapsed: 0.76 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.85745/49.00%, bp_loss: 1.50812/56.00%, hp_loss: 3.07399/22.00%, j_loss: 1.62537/53.00%, \n",
      "\t\tfr_loss: 0.20871/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.27363\n",
      "\tPart 2 - fp_loss: 1.58911/58.00%, bp_loss: 1.43390/58.00%, hp_loss: 2.76732/27.00%, j_loss: 1.40512/61.00%, \n",
      "\t\tfr_loss: 0.18201/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.37746\n",
      "\tPart 3 - fp_loss: 1.20403/69.00%, bp_loss: 1.01697/73.00%, hp_loss: 2.24076/43.00%, j_loss: 0.80690/80.00%, \n",
      "\t\tfr_loss: 0.17530/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44396\n",
      "\tPart 4 - fp_loss: 1.40021/69.00%, bp_loss: 1.01810/72.00%, hp_loss: 2.47181/37.00%, j_loss: 0.85404/76.00%, \n",
      "\t\tfr_loss: 0.17664/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92080\n",
      "\t`Validation time elapsed: 9.52 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 32.\n",
      "\n",
      "EPOCH 33\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.94675/74.00%, bp_loss: 1.67246/53.00%, hp_loss: 3.09469/22.00%, j_loss: 1.10468/70.00%, \n",
      "\t\tfr_loss: 0.14740/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.96599\n",
      "\tPart 2 - fp_loss: 0.78691/76.00%, bp_loss: 1.50933/60.00%, hp_loss: 2.70072/32.00%, j_loss: 0.92019/73.00%, \n",
      "\t\tfr_loss: 0.12741/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.04457\n",
      "\tPart 3 - fp_loss: 0.77502/79.00%, bp_loss: 0.83366/76.00%, hp_loss: 2.47235/35.00%, j_loss: 0.56508/81.00%, \n",
      "\t\tfr_loss: 0.11841/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.76452\n",
      "\tPart 4 - fp_loss: 0.59688/82.00%, bp_loss: 0.80813/75.00%, hp_loss: 2.67470/33.00%, j_loss: 0.49073/83.00%, \n",
      "\t\tfr_loss: 0.11067/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68112\n",
      "\tTraining time elapsed: 1.10 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.96416/73.00%, bp_loss: 1.35425/59.00%, hp_loss: 3.12485/20.00%, j_loss: 1.00722/72.00%, \n",
      "\t\tfr_loss: 0.14338/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.59387\n",
      "\tPart 2 - fp_loss: 0.77308/77.00%, bp_loss: 1.04605/70.00%, hp_loss: 2.72616/32.00%, j_loss: 0.72349/78.00%, \n",
      "\t\tfr_loss: 0.12391/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.39269\n",
      "\tPart 3 - fp_loss: 0.75023/78.00%, bp_loss: 0.70422/81.00%, hp_loss: 2.42292/39.00%, j_loss: 0.48658/84.00%, \n",
      "\t\tfr_loss: 0.10386/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46781\n",
      "\tPart 4 - fp_loss: 0.59561/83.00%, bp_loss: 0.74598/79.00%, hp_loss: 2.53890/35.00%, j_loss: 0.43707/85.00%, \n",
      "\t\tfr_loss: 0.10432/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42186\n",
      "\tTraining time elapsed: 38.66 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.02940/69.00%, bp_loss: 1.35685/60.00%, hp_loss: 3.12879/21.00%, j_loss: 1.07678/71.00%, \n",
      "\t\tfr_loss: 0.15610/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.74792\n",
      "\tPart 2 - fp_loss: 0.82436/77.00%, bp_loss: 1.14549/67.00%, hp_loss: 2.74162/31.00%, j_loss: 0.75283/77.00%, \n",
      "\t\tfr_loss: 0.14058/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60487\n",
      "\tPart 3 - fp_loss: 0.70034/80.00%, bp_loss: 0.74457/79.00%, hp_loss: 2.37687/40.00%, j_loss: 0.49682/83.00%, \n",
      "\t\tfr_loss: 0.11449/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43308\n",
      "\tPart 4 - fp_loss: 0.67358/80.00%, bp_loss: 0.88926/75.00%, hp_loss: 2.53022/35.00%, j_loss: 0.52557/84.00%, \n",
      "\t\tfr_loss: 0.09641/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71505\n",
      "\tTraining time elapsed: 76.21 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.94999/70.00%, bp_loss: 1.29868/61.00%, hp_loss: 3.05109/22.00%, j_loss: 1.00981/71.00%, \n",
      "\t\tfr_loss: 0.15362/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.46318\n",
      "\tPart 2 - fp_loss: 0.82197/78.00%, bp_loss: 1.08254/69.00%, hp_loss: 2.73692/31.00%, j_loss: 0.75143/79.00%, \n",
      "\t\tfr_loss: 0.12608/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.51894\n",
      "\tPart 3 - fp_loss: 0.74084/78.00%, bp_loss: 0.85167/77.00%, hp_loss: 2.44361/38.00%, j_loss: 0.56329/83.00%, \n",
      "\t\tfr_loss: 0.12056/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71997\n",
      "\tPart 4 - fp_loss: 0.65218/82.00%, bp_loss: 0.87147/76.00%, hp_loss: 2.62021/33.00%, j_loss: 0.50062/85.00%, \n",
      "\t\tfr_loss: 0.09661/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.74108\n",
      "\tTraining time elapsed: 113.78 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.05007/68.00%, bp_loss: 1.30647/62.00%, hp_loss: 3.11407/21.00%, j_loss: 0.98582/70.00%, \n",
      "\t\tfr_loss: 0.16389/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.62032\n",
      "\tPart 2 - fp_loss: 0.73988/78.00%, bp_loss: 1.01354/73.00%, hp_loss: 2.64567/36.00%, j_loss: 0.68636/79.00%, \n",
      "\t\tfr_loss: 0.12819/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21364\n",
      "\tPart 3 - fp_loss: 0.78305/78.00%, bp_loss: 0.71636/81.00%, hp_loss: 2.42971/37.00%, j_loss: 0.46562/83.00%, \n",
      "\t\tfr_loss: 0.11643/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51117\n",
      "\tPart 4 - fp_loss: 0.62250/81.00%, bp_loss: 0.81968/76.00%, hp_loss: 2.54911/33.00%, j_loss: 0.51619/83.00%, \n",
      "\t\tfr_loss: 0.10305/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61054\n",
      "\tTraining time elapsed: 151.31 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.97967/72.00%, bp_loss: 1.40620/59.00%, hp_loss: 3.05860/24.00%, j_loss: 1.01033/73.00%, \n",
      "\t\tfr_loss: 0.14973/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.60454\n",
      "\tPart 2 - fp_loss: 0.72689/78.00%, bp_loss: 1.05124/71.00%, hp_loss: 2.69476/33.00%, j_loss: 0.65522/79.00%, \n",
      "\t\tfr_loss: 0.14506/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.27317\n",
      "\tPart 3 - fp_loss: 0.75859/78.00%, bp_loss: 0.74292/79.00%, hp_loss: 2.40620/38.00%, j_loss: 0.51189/83.00%, \n",
      "\t\tfr_loss: 0.10803/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52763\n",
      "\tPart 4 - fp_loss: 0.62974/82.00%, bp_loss: 0.83358/76.00%, hp_loss: 2.60632/34.00%, j_loss: 0.47688/86.00%, \n",
      "\t\tfr_loss: 0.09830/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64482\n",
      "\tTraining time elapsed: 188.85 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 1.05518/69.00%, bp_loss: 1.40794/58.00%, hp_loss: 3.11346/20.00%, j_loss: 1.08712/72.00%, \n",
      "\t\tfr_loss: 0.18384/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.84754\n",
      "\tPart 2 - fp_loss: 0.84004/78.00%, bp_loss: 1.15841/68.00%, hp_loss: 2.75098/31.00%, j_loss: 0.73355/76.00%, \n",
      "\t\tfr_loss: 0.14864/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.63161\n",
      "\tPart 3 - fp_loss: 0.61393/82.00%, bp_loss: 0.82395/77.00%, hp_loss: 2.42321/38.00%, j_loss: 0.45142/85.00%, \n",
      "\t\tfr_loss: 0.10145/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41395\n",
      "\tPart 4 - fp_loss: 0.61393/81.00%, bp_loss: 0.96669/72.00%, hp_loss: 2.68342/30.00%, j_loss: 0.51393/83.00%, \n",
      "\t\tfr_loss: 0.10246/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88043\n",
      "\tTraining time elapsed: 226.43 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.96322/72.00%, bp_loss: 1.33741/59.00%, hp_loss: 3.03862/23.00%, j_loss: 0.99588/72.00%, \n",
      "\t\tfr_loss: 0.14637/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.48150\n",
      "\tPart 2 - fp_loss: 0.87561/75.00%, bp_loss: 1.10932/68.00%, hp_loss: 2.75404/30.00%, j_loss: 0.78581/77.00%, \n",
      "\t\tfr_loss: 0.13480/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.65958\n",
      "\tPart 3 - fp_loss: 0.82761/77.00%, bp_loss: 0.68304/80.00%, hp_loss: 2.41793/38.00%, j_loss: 0.49893/84.00%, \n",
      "\t\tfr_loss: 0.12098/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54849\n",
      "\tPart 4 - fp_loss: 0.66981/80.00%, bp_loss: 0.85989/75.00%, hp_loss: 2.60041/34.00%, j_loss: 0.50844/84.00%, \n",
      "\t\tfr_loss: 0.11668/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.75523\n",
      "\tTraining time elapsed: 264.00 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.00395/71.00%, bp_loss: 1.38504/60.00%, hp_loss: 3.02246/24.00%, j_loss: 0.97155/73.00%, \n",
      "\t\tfr_loss: 0.15300/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.53600\n",
      "\tPart 2 - fp_loss: 0.83556/77.00%, bp_loss: 1.13546/68.00%, hp_loss: 2.78936/30.00%, j_loss: 0.71699/77.00%, \n",
      "\t\tfr_loss: 0.13396/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.61134\n",
      "\tPart 3 - fp_loss: 0.74622/79.00%, bp_loss: 0.69969/81.00%, hp_loss: 2.39806/36.00%, j_loss: 0.45663/85.00%, \n",
      "\t\tfr_loss: 0.12384/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42444\n",
      "\tPart 4 - fp_loss: 0.67555/80.00%, bp_loss: 0.78904/77.00%, hp_loss: 2.61549/34.00%, j_loss: 0.48697/82.00%, \n",
      "\t\tfr_loss: 0.10777/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.67482\n",
      "\tTraining time elapsed: 301.57 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.88310/50.00%, bp_loss: 1.57150/54.00%, hp_loss: 3.00191/25.00%, j_loss: 1.67508/54.00%, \n",
      "\t\tfr_loss: 0.21436/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.34595\n",
      "\tPart 2 - fp_loss: 1.43499/60.00%, bp_loss: 1.64294/56.00%, hp_loss: 2.60599/33.00%, j_loss: 1.38960/57.00%, \n",
      "\t\tfr_loss: 0.19937/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.27289\n",
      "\tPart 3 - fp_loss: 1.23336/70.00%, bp_loss: 1.03030/70.00%, hp_loss: 2.19272/45.00%, j_loss: 0.81776/74.00%, \n",
      "\t\tfr_loss: 0.19342/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.46757\n",
      "\tPart 4 - fp_loss: 1.45511/68.00%, bp_loss: 1.05695/71.00%, hp_loss: 2.36735/42.00%, j_loss: 0.82951/74.00%, \n",
      "\t\tfr_loss: 0.17531/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.88423\n",
      "\t`Validation time elapsed: 0.77 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.85830/51.00%, bp_loss: 1.58162/52.00%, hp_loss: 3.11731/20.00%, j_loss: 1.64671/55.00%, \n",
      "\t\tfr_loss: 0.21312/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.41705\n",
      "\tPart 2 - fp_loss: 1.57852/60.00%, bp_loss: 1.37294/62.00%, hp_loss: 2.76345/29.00%, j_loss: 1.28748/64.00%, \n",
      "\t\tfr_loss: 0.17301/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.17540\n",
      "\tPart 3 - fp_loss: 1.19113/70.00%, bp_loss: 0.85523/77.00%, hp_loss: 2.27107/43.00%, j_loss: 0.73828/80.00%, \n",
      "\t\tfr_loss: 0.19202/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.24773\n",
      "\tPart 4 - fp_loss: 1.41376/67.00%, bp_loss: 0.91880/76.00%, hp_loss: 2.43299/38.00%, j_loss: 0.86124/78.00%, \n",
      "\t\tfr_loss: 0.17484/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.80163\n",
      "\t`Validation time elapsed: 9.51 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 33.\n",
      "\n",
      "EPOCH 34\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.97480/73.00%, bp_loss: 1.53844/55.00%, hp_loss: 3.11468/21.00%, j_loss: 1.06088/69.00%, \n",
      "\t\tfr_loss: 0.16484/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.85364\n",
      "\tPart 2 - fp_loss: 0.70729/80.00%, bp_loss: 1.44811/61.00%, hp_loss: 2.73805/31.00%, j_loss: 0.78277/76.00%, \n",
      "\t\tfr_loss: 0.10967/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.78589\n",
      "\tPart 3 - fp_loss: 0.70134/80.00%, bp_loss: 0.82271/76.00%, hp_loss: 2.33979/39.00%, j_loss: 0.57838/80.00%, \n",
      "\t\tfr_loss: 0.09758/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53980\n",
      "\tPart 4 - fp_loss: 0.55266/84.00%, bp_loss: 0.72348/79.00%, hp_loss: 2.64731/33.00%, j_loss: 0.41861/86.00%, \n",
      "\t\tfr_loss: 0.10270/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44477\n",
      "\tTraining time elapsed: 1.07 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.94489/72.00%, bp_loss: 1.33505/61.00%, hp_loss: 3.03746/22.00%, j_loss: 0.95347/73.00%, \n",
      "\t\tfr_loss: 0.14587/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41674\n",
      "\tPart 2 - fp_loss: 0.75685/78.00%, bp_loss: 0.99600/72.00%, hp_loss: 2.68676/32.00%, j_loss: 0.68873/80.00%, \n",
      "\t\tfr_loss: 0.13289/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.26123\n",
      "\tPart 3 - fp_loss: 0.71317/78.00%, bp_loss: 0.71731/79.00%, hp_loss: 2.34140/39.00%, j_loss: 0.53813/83.00%, \n",
      "\t\tfr_loss: 0.11149/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42151\n",
      "\tPart 4 - fp_loss: 0.67115/80.00%, bp_loss: 0.82596/77.00%, hp_loss: 2.58339/33.00%, j_loss: 0.49139/84.00%, \n",
      "\t\tfr_loss: 0.10919/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68108\n",
      "\tTraining time elapsed: 38.59 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.95473/73.00%, bp_loss: 1.37250/60.00%, hp_loss: 3.15998/21.00%, j_loss: 0.94916/72.00%, \n",
      "\t\tfr_loss: 0.13760/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.57396\n",
      "\tPart 2 - fp_loss: 0.85355/77.00%, bp_loss: 1.05685/69.00%, hp_loss: 2.79427/30.00%, j_loss: 0.73410/78.00%, \n",
      "\t\tfr_loss: 0.13582/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57458\n",
      "\tPart 3 - fp_loss: 0.70706/79.00%, bp_loss: 0.70439/79.00%, hp_loss: 2.40083/37.00%, j_loss: 0.53123/83.00%, \n",
      "\t\tfr_loss: 0.11370/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45721\n",
      "\tPart 4 - fp_loss: 0.63036/81.00%, bp_loss: 0.73437/79.00%, hp_loss: 2.52658/34.00%, j_loss: 0.39419/86.00%, \n",
      "\t\tfr_loss: 0.11318/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39867\n",
      "\tTraining time elapsed: 76.13 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.93462/72.00%, bp_loss: 1.36654/60.00%, hp_loss: 3.05360/21.00%, j_loss: 0.92203/73.00%, \n",
      "\t\tfr_loss: 0.14706/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.42386\n",
      "\tPart 2 - fp_loss: 0.73083/79.00%, bp_loss: 0.97918/72.00%, hp_loss: 2.63342/36.00%, j_loss: 0.62225/79.00%, \n",
      "\t\tfr_loss: 0.13828/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10395\n",
      "\tPart 3 - fp_loss: 0.68495/80.00%, bp_loss: 0.76106/79.00%, hp_loss: 2.37511/39.00%, j_loss: 0.47219/85.00%, \n",
      "\t\tfr_loss: 0.10430/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39760\n",
      "\tPart 4 - fp_loss: 0.65083/83.00%, bp_loss: 0.80523/78.00%, hp_loss: 2.54525/35.00%, j_loss: 0.43166/85.00%, \n",
      "\t\tfr_loss: 0.10760/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54057\n",
      "\tTraining time elapsed: 113.67 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.02761/70.00%, bp_loss: 1.35587/59.00%, hp_loss: 3.05778/22.00%, j_loss: 1.09015/69.00%, \n",
      "\t\tfr_loss: 0.14282/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.67423\n",
      "\tPart 2 - fp_loss: 0.83953/76.00%, bp_loss: 1.04354/69.00%, hp_loss: 2.68834/33.00%, j_loss: 0.77625/79.00%, \n",
      "\t\tfr_loss: 0.13163/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47928\n",
      "\tPart 3 - fp_loss: 0.74307/77.00%, bp_loss: 0.70441/80.00%, hp_loss: 2.35607/39.00%, j_loss: 0.53840/82.00%, \n",
      "\t\tfr_loss: 0.09999/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44195\n",
      "\tPart 4 - fp_loss: 0.65325/82.00%, bp_loss: 0.84026/77.00%, hp_loss: 2.55718/34.00%, j_loss: 0.48420/83.00%, \n",
      "\t\tfr_loss: 0.08754/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62243\n",
      "\tTraining time elapsed: 151.20 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.94227/73.00%, bp_loss: 1.42298/60.00%, hp_loss: 3.10076/21.00%, j_loss: 0.96503/74.00%, \n",
      "\t\tfr_loss: 0.13017/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.56120\n",
      "\tPart 2 - fp_loss: 0.75311/77.00%, bp_loss: 1.09781/68.00%, hp_loss: 2.77273/32.00%, j_loss: 0.78256/79.00%, \n",
      "\t\tfr_loss: 0.15873/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.56496\n",
      "\tPart 3 - fp_loss: 0.77881/77.00%, bp_loss: 0.73310/79.00%, hp_loss: 2.48607/35.00%, j_loss: 0.53707/82.00%, \n",
      "\t\tfr_loss: 0.11831/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65337\n",
      "\tPart 4 - fp_loss: 0.74975/78.00%, bp_loss: 0.79991/77.00%, hp_loss: 2.71292/31.00%, j_loss: 0.50993/83.00%, \n",
      "\t\tfr_loss: 0.11406/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88656\n",
      "\tTraining time elapsed: 188.72 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.95017/71.00%, bp_loss: 1.31358/60.00%, hp_loss: 3.05340/23.00%, j_loss: 0.99801/71.00%, \n",
      "\t\tfr_loss: 0.15262/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.46778\n",
      "\tPart 2 - fp_loss: 0.72658/79.00%, bp_loss: 1.06682/68.00%, hp_loss: 2.70445/33.00%, j_loss: 0.70397/78.00%, \n",
      "\t\tfr_loss: 0.13418/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.33599\n",
      "\tPart 3 - fp_loss: 0.71934/79.00%, bp_loss: 0.69899/80.00%, hp_loss: 2.31128/41.00%, j_loss: 0.51525/83.00%, \n",
      "\t\tfr_loss: 0.11072/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35558\n",
      "\tPart 4 - fp_loss: 0.62683/82.00%, bp_loss: 0.83643/77.00%, hp_loss: 2.64026/31.00%, j_loss: 0.44854/86.00%, \n",
      "\t\tfr_loss: 0.10325/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65530\n",
      "\tTraining time elapsed: 226.23 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.06404/68.00%, bp_loss: 1.41716/59.00%, hp_loss: 3.11186/22.00%, j_loss: 1.08693/71.00%, \n",
      "\t\tfr_loss: 0.12954/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.80953\n",
      "\tPart 2 - fp_loss: 0.82228/76.00%, bp_loss: 0.94677/74.00%, hp_loss: 2.69292/33.00%, j_loss: 0.68380/79.00%, \n",
      "\t\tfr_loss: 0.12895/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.27471\n",
      "\tPart 3 - fp_loss: 0.75442/78.00%, bp_loss: 0.82014/77.00%, hp_loss: 2.32942/40.00%, j_loss: 0.56665/83.00%, \n",
      "\t\tfr_loss: 0.12610/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.59673\n",
      "\tPart 4 - fp_loss: 0.60760/82.00%, bp_loss: 0.82198/77.00%, hp_loss: 2.62279/33.00%, j_loss: 0.43376/86.00%, \n",
      "\t\tfr_loss: 0.10128/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58740\n",
      "\tTraining time elapsed: 263.73 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.96945/71.00%, bp_loss: 1.32956/62.00%, hp_loss: 3.07162/22.00%, j_loss: 0.97488/73.00%, \n",
      "\t\tfr_loss: 0.14253/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.48804\n",
      "\tPart 2 - fp_loss: 0.80722/77.00%, bp_loss: 1.05485/70.00%, hp_loss: 2.72603/32.00%, j_loss: 0.75036/79.00%, \n",
      "\t\tfr_loss: 0.12846/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.46691\n",
      "\tPart 3 - fp_loss: 0.69545/80.00%, bp_loss: 0.74047/79.00%, hp_loss: 2.35127/38.00%, j_loss: 0.49773/82.00%, \n",
      "\t\tfr_loss: 0.10555/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39046\n",
      "\tPart 4 - fp_loss: 0.66286/81.00%, bp_loss: 0.80741/77.00%, hp_loss: 2.59290/33.00%, j_loss: 0.47111/86.00%, \n",
      "\t\tfr_loss: 0.09984/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63411\n",
      "\tTraining time elapsed: 301.24 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.82981/52.00%, bp_loss: 1.59427/54.00%, hp_loss: 3.02327/24.00%, j_loss: 1.57375/55.00%, \n",
      "\t\tfr_loss: 0.19344/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.21453\n",
      "\tPart 2 - fp_loss: 1.54974/59.00%, bp_loss: 1.48577/60.00%, hp_loss: 2.63037/33.00%, j_loss: 1.34352/59.00%, \n",
      "\t\tfr_loss: 0.18481/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.19422\n",
      "\tPart 3 - fp_loss: 1.18954/70.00%, bp_loss: 0.94865/73.00%, hp_loss: 2.29052/40.00%, j_loss: 0.78722/77.00%, \n",
      "\t\tfr_loss: 0.17204/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.38796\n",
      "\tPart 4 - fp_loss: 1.30605/69.00%, bp_loss: 1.05218/71.00%, hp_loss: 2.40514/38.00%, j_loss: 0.83223/73.00%, \n",
      "\t\tfr_loss: 0.17608/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77169\n",
      "\t`Validation time elapsed: 0.76 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.82025/52.00%, bp_loss: 1.48444/55.00%, hp_loss: 3.03357/24.00%, j_loss: 1.63109/55.00%, \n",
      "\t\tfr_loss: 0.19275/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.16211\n",
      "\tPart 2 - fp_loss: 1.54761/61.00%, bp_loss: 1.40888/60.00%, hp_loss: 2.78060/28.00%, j_loss: 1.32172/65.00%, \n",
      "\t\tfr_loss: 0.21131/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.27011\n",
      "\tPart 3 - fp_loss: 1.13439/72.00%, bp_loss: 0.93477/75.00%, hp_loss: 2.29674/43.00%, j_loss: 0.73283/79.00%, \n",
      "\t\tfr_loss: 0.16638/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.26511\n",
      "\tPart 4 - fp_loss: 1.36237/68.00%, bp_loss: 0.99703/73.00%, hp_loss: 2.47979/38.00%, j_loss: 0.89511/77.00%, \n",
      "\t\tfr_loss: 0.18576/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92006\n",
      "\t`Validation time elapsed: 9.52 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 34.\n",
      "\n",
      "EPOCH 35\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.96279/70.00%, bp_loss: 1.47201/57.00%, hp_loss: 3.11189/21.00%, j_loss: 1.09446/70.00%, \n",
      "\t\tfr_loss: 0.15201/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.79316\n",
      "\tPart 2 - fp_loss: 0.75539/78.00%, bp_loss: 1.35690/63.00%, hp_loss: 2.68389/34.00%, j_loss: 0.80560/75.00%, \n",
      "\t\tfr_loss: 0.14121/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.74300\n",
      "\tPart 3 - fp_loss: 0.70788/79.00%, bp_loss: 0.76368/78.00%, hp_loss: 2.34662/39.00%, j_loss: 0.59512/83.00%, \n",
      "\t\tfr_loss: 0.11224/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52555\n",
      "\tPart 4 - fp_loss: 0.62312/82.00%, bp_loss: 0.76269/77.00%, hp_loss: 2.54921/34.00%, j_loss: 0.45949/85.00%, \n",
      "\t\tfr_loss: 0.11965/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51416\n",
      "\tTraining time elapsed: 1.09 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 1.01210/70.00%, bp_loss: 1.27446/62.00%, hp_loss: 3.04129/25.00%, j_loss: 0.99211/72.00%, \n",
      "\t\tfr_loss: 0.14293/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.46289\n",
      "\tPart 2 - fp_loss: 0.82340/77.00%, bp_loss: 1.05228/70.00%, hp_loss: 2.71270/33.00%, j_loss: 0.72473/80.00%, \n",
      "\t\tfr_loss: 0.13948/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.45259\n",
      "\tPart 3 - fp_loss: 0.73210/80.00%, bp_loss: 0.67266/80.00%, hp_loss: 2.37478/39.00%, j_loss: 0.45641/83.00%, \n",
      "\t\tfr_loss: 0.10026/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33621\n",
      "\tPart 4 - fp_loss: 0.57338/84.00%, bp_loss: 0.80272/78.00%, hp_loss: 2.62407/34.00%, j_loss: 0.44320/85.00%, \n",
      "\t\tfr_loss: 0.10333/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54670\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.97110/71.00%, bp_loss: 1.30834/62.00%, hp_loss: 3.06684/21.00%, j_loss: 0.99961/72.00%, \n",
      "\t\tfr_loss: 0.14823/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.49413\n",
      "\tPart 2 - fp_loss: 0.71007/80.00%, bp_loss: 0.93923/72.00%, hp_loss: 2.70306/32.00%, j_loss: 0.61994/80.00%, \n",
      "\t\tfr_loss: 0.13542/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10773\n",
      "\tPart 3 - fp_loss: 0.68146/79.00%, bp_loss: 0.69756/81.00%, hp_loss: 2.36722/39.00%, j_loss: 0.47338/83.00%, \n",
      "\t\tfr_loss: 0.09493/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.31455\n",
      "\tPart 4 - fp_loss: 0.61772/82.00%, bp_loss: 0.74982/78.00%, hp_loss: 2.63278/34.00%, j_loss: 0.43804/83.00%, \n",
      "\t\tfr_loss: 0.09264/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53100\n",
      "\tTraining time elapsed: 76.18 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.92148/74.00%, bp_loss: 1.30365/61.00%, hp_loss: 3.02311/23.00%, j_loss: 0.88150/77.00%, \n",
      "\t\tfr_loss: 0.14908/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.27883\n",
      "\tPart 2 - fp_loss: 0.77411/78.00%, bp_loss: 0.92961/73.00%, hp_loss: 2.68094/33.00%, j_loss: 0.64307/79.00%, \n",
      "\t\tfr_loss: 0.13303/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16075\n",
      "\tPart 3 - fp_loss: 0.76364/77.00%, bp_loss: 0.76572/77.00%, hp_loss: 2.46547/35.00%, j_loss: 0.58211/81.00%, \n",
      "\t\tfr_loss: 0.10957/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68651\n",
      "\tPart 4 - fp_loss: 0.67525/82.00%, bp_loss: 0.86693/76.00%, hp_loss: 2.60445/33.00%, j_loss: 0.48543/85.00%, \n",
      "\t\tfr_loss: 0.09957/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73162\n",
      "\tTraining time elapsed: 113.74 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.00760/70.00%, bp_loss: 1.41436/59.00%, hp_loss: 3.03681/23.00%, j_loss: 1.08792/70.00%, \n",
      "\t\tfr_loss: 0.13123/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.67793\n",
      "\tPart 2 - fp_loss: 0.75657/77.00%, bp_loss: 0.99295/73.00%, hp_loss: 2.67519/33.00%, j_loss: 0.71185/78.00%, \n",
      "\t\tfr_loss: 0.13556/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.27213\n",
      "\tPart 3 - fp_loss: 0.77311/77.00%, bp_loss: 0.67110/80.00%, hp_loss: 2.41556/37.00%, j_loss: 0.50955/82.00%, \n",
      "\t\tfr_loss: 0.10583/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47515\n",
      "\tPart 4 - fp_loss: 0.60959/81.00%, bp_loss: 0.77917/77.00%, hp_loss: 2.61316/31.00%, j_loss: 0.47622/85.00%, \n",
      "\t\tfr_loss: 0.09933/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57747\n",
      "\tTraining time elapsed: 151.28 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.88768/73.00%, bp_loss: 1.39254/61.00%, hp_loss: 3.10079/22.00%, j_loss: 0.98226/73.00%, \n",
      "\t\tfr_loss: 0.14774/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51101\n",
      "\tPart 2 - fp_loss: 0.75313/79.00%, bp_loss: 1.02602/72.00%, hp_loss: 2.69547/33.00%, j_loss: 0.58977/83.00%, \n",
      "\t\tfr_loss: 0.14563/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21003\n",
      "\tPart 3 - fp_loss: 0.71218/79.00%, bp_loss: 0.70634/79.00%, hp_loss: 2.40350/38.00%, j_loss: 0.53158/83.00%, \n",
      "\t\tfr_loss: 0.11025/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46386\n",
      "\tPart 4 - fp_loss: 0.59057/84.00%, bp_loss: 0.85429/76.00%, hp_loss: 2.60521/34.00%, j_loss: 0.45696/84.00%, \n",
      "\t\tfr_loss: 0.09866/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60569\n",
      "\tTraining time elapsed: 188.79 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.99058/72.00%, bp_loss: 1.33638/60.00%, hp_loss: 3.06743/21.00%, j_loss: 1.00433/73.00%, \n",
      "\t\tfr_loss: 0.14714/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.54587\n",
      "\tPart 2 - fp_loss: 0.77859/77.00%, bp_loss: 1.07490/69.00%, hp_loss: 2.76580/32.00%, j_loss: 0.81814/77.00%, \n",
      "\t\tfr_loss: 0.13751/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57494\n",
      "\tPart 3 - fp_loss: 0.73101/78.00%, bp_loss: 0.71146/80.00%, hp_loss: 2.37929/38.00%, j_loss: 0.53409/83.00%, \n",
      "\t\tfr_loss: 0.12179/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47763\n",
      "\tPart 4 - fp_loss: 0.60798/82.00%, bp_loss: 0.74044/79.00%, hp_loss: 2.60540/32.00%, j_loss: 0.47122/84.00%, \n",
      "\t\tfr_loss: 0.10022/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52526\n",
      "\tTraining time elapsed: 226.33 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.97945/71.00%, bp_loss: 1.37515/60.00%, hp_loss: 3.06508/23.00%, j_loss: 1.03978/74.00%, \n",
      "\t\tfr_loss: 0.12403/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58349\n",
      "\tPart 2 - fp_loss: 0.78919/77.00%, bp_loss: 0.96589/72.00%, hp_loss: 2.73481/32.00%, j_loss: 0.66767/80.00%, \n",
      "\t\tfr_loss: 0.13903/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.29658\n",
      "\tPart 3 - fp_loss: 0.64628/81.00%, bp_loss: 0.69180/81.00%, hp_loss: 2.42081/38.00%, j_loss: 0.42401/86.00%, \n",
      "\t\tfr_loss: 0.11338/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.29628\n",
      "\tPart 4 - fp_loss: 0.66887/80.00%, bp_loss: 0.77759/78.00%, hp_loss: 2.66395/32.00%, j_loss: 0.47370/84.00%, \n",
      "\t\tfr_loss: 0.11175/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69587\n",
      "\tTraining time elapsed: 263.84 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.85668/75.00%, bp_loss: 1.30405/62.00%, hp_loss: 3.01890/24.00%, j_loss: 0.90551/74.00%, \n",
      "\t\tfr_loss: 0.14082/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22596\n",
      "\tPart 2 - fp_loss: 0.75064/79.00%, bp_loss: 0.98435/72.00%, hp_loss: 2.71709/32.00%, j_loss: 0.63006/80.00%, \n",
      "\t\tfr_loss: 0.14935/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.23149\n",
      "\tPart 3 - fp_loss: 0.69612/80.00%, bp_loss: 0.73226/79.00%, hp_loss: 2.41377/38.00%, j_loss: 0.47636/84.00%, \n",
      "\t\tfr_loss: 0.11198/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43049\n",
      "\tPart 4 - fp_loss: 0.69652/81.00%, bp_loss: 0.82561/76.00%, hp_loss: 2.55040/33.00%, j_loss: 0.51578/85.00%, \n",
      "\t\tfr_loss: 0.09936/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68768\n",
      "\tTraining time elapsed: 301.36 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.96823/50.00%, bp_loss: 1.54910/53.00%, hp_loss: 3.04960/22.00%, j_loss: 1.64783/53.00%, \n",
      "\t\tfr_loss: 0.22256/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.43732\n",
      "\tPart 2 - fp_loss: 1.57575/58.00%, bp_loss: 1.59095/58.00%, hp_loss: 2.73231/30.00%, j_loss: 1.42602/59.00%, \n",
      "\t\tfr_loss: 0.21213/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.53716\n",
      "\tPart 3 - fp_loss: 1.22211/70.00%, bp_loss: 0.97427/73.00%, hp_loss: 2.21690/44.00%, j_loss: 0.81265/76.00%, \n",
      "\t\tfr_loss: 0.19673/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.42267\n",
      "\tPart 4 - fp_loss: 1.42030/68.00%, bp_loss: 1.12811/69.00%, hp_loss: 2.46937/38.00%, j_loss: 0.97983/73.00%, \n",
      "\t\tfr_loss: 0.18584/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.18345\n",
      "\t`Validation time elapsed: 0.74 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.79201/53.00%, bp_loss: 1.46046/55.00%, hp_loss: 3.09977/21.00%, j_loss: 1.59093/57.00%, \n",
      "\t\tfr_loss: 0.20584/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.14902\n",
      "\tPart 2 - fp_loss: 1.65834/58.00%, bp_loss: 1.44345/59.00%, hp_loss: 2.80194/27.00%, j_loss: 1.45117/63.00%, \n",
      "\t\tfr_loss: 0.18849/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.54340\n",
      "\tPart 3 - fp_loss: 1.34580/67.00%, bp_loss: 0.89765/77.00%, hp_loss: 2.27986/43.00%, j_loss: 0.82148/76.00%, \n",
      "\t\tfr_loss: 0.17506/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.51985\n",
      "\tPart 4 - fp_loss: 1.51272/67.00%, bp_loss: 0.93877/77.00%, hp_loss: 2.47267/38.00%, j_loss: 0.88197/78.00%, \n",
      "\t\tfr_loss: 0.18410/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.99023\n",
      "\t`Validation time elapsed: 9.50 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 35.\n",
      "\n",
      "EPOCH 36\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.89002/74.00%, bp_loss: 1.31772/62.00%, hp_loss: 3.08258/22.00%, j_loss: 0.89278/75.00%, \n",
      "\t\tfr_loss: 0.14917/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33227\n",
      "\tPart 2 - fp_loss: 0.77724/78.00%, bp_loss: 1.20141/65.00%, hp_loss: 2.71953/31.00%, j_loss: 0.73403/75.00%, \n",
      "\t\tfr_loss: 0.14591/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.57812\n",
      "\tPart 3 - fp_loss: 0.73791/79.00%, bp_loss: 0.76914/79.00%, hp_loss: 2.43058/37.00%, j_loss: 0.51845/83.00%, \n",
      "\t\tfr_loss: 0.10112/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55720\n",
      "\tPart 4 - fp_loss: 0.64077/82.00%, bp_loss: 0.81697/76.00%, hp_loss: 2.60882/32.00%, j_loss: 0.48253/84.00%, \n",
      "\t\tfr_loss: 0.09434/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64343\n",
      "\tTraining time elapsed: 1.09 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.95572/72.00%, bp_loss: 1.35538/61.00%, hp_loss: 3.13287/20.00%, j_loss: 0.98944/71.00%, \n",
      "\t\tfr_loss: 0.14820/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58161\n",
      "\tPart 2 - fp_loss: 0.78424/76.00%, bp_loss: 0.89946/74.00%, hp_loss: 2.71147/31.00%, j_loss: 0.69387/79.00%, \n",
      "\t\tfr_loss: 0.12933/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21835\n",
      "\tPart 3 - fp_loss: 0.67724/81.00%, bp_loss: 0.70787/79.00%, hp_loss: 2.43295/38.00%, j_loss: 0.46251/83.00%, \n",
      "\t\tfr_loss: 0.11324/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39382\n",
      "\tPart 4 - fp_loss: 0.62357/82.00%, bp_loss: 0.86258/75.00%, hp_loss: 2.67453/29.00%, j_loss: 0.51198/84.00%, \n",
      "\t\tfr_loss: 0.11300/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.78566\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.92778/72.00%, bp_loss: 1.24541/63.00%, hp_loss: 3.09418/22.00%, j_loss: 0.99131/72.00%, \n",
      "\t\tfr_loss: 0.14104/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.39971\n",
      "\tPart 2 - fp_loss: 0.72881/78.00%, bp_loss: 1.00147/72.00%, hp_loss: 2.77858/32.00%, j_loss: 0.66479/80.00%, \n",
      "\t\tfr_loss: 0.12749/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.30113\n",
      "\tPart 3 - fp_loss: 0.69480/81.00%, bp_loss: 0.76191/78.00%, hp_loss: 2.39082/38.00%, j_loss: 0.53839/86.00%, \n",
      "\t\tfr_loss: 0.10501/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.49093\n",
      "\tPart 4 - fp_loss: 0.62915/82.00%, bp_loss: 0.91781/74.00%, hp_loss: 2.70907/29.00%, j_loss: 0.51789/85.00%, \n",
      "\t\tfr_loss: 0.10130/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.87523\n",
      "\tTraining time elapsed: 76.20 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.93105/72.00%, bp_loss: 1.27405/62.00%, hp_loss: 3.05489/24.00%, j_loss: 0.91043/73.00%, \n",
      "\t\tfr_loss: 0.15387/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.32429\n",
      "\tPart 2 - fp_loss: 0.73727/79.00%, bp_loss: 0.98586/73.00%, hp_loss: 2.79658/30.00%, j_loss: 0.61086/81.00%, \n",
      "\t\tfr_loss: 0.14184/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.27240\n",
      "\tPart 3 - fp_loss: 0.75019/78.00%, bp_loss: 0.78096/78.00%, hp_loss: 2.47417/37.00%, j_loss: 0.51691/85.00%, \n",
      "\t\tfr_loss: 0.09416/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61639\n",
      "\tPart 4 - fp_loss: 0.66818/82.00%, bp_loss: 0.81880/76.00%, hp_loss: 2.62519/33.00%, j_loss: 0.45660/85.00%, \n",
      "\t\tfr_loss: 0.10254/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.67130\n",
      "\tTraining time elapsed: 113.73 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.91759/74.00%, bp_loss: 1.35402/61.00%, hp_loss: 3.07521/24.00%, j_loss: 0.92821/74.00%, \n",
      "\t\tfr_loss: 0.13686/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41190\n",
      "\tPart 2 - fp_loss: 0.85187/74.00%, bp_loss: 0.98412/72.00%, hp_loss: 2.74522/31.00%, j_loss: 0.69426/81.00%, \n",
      "\t\tfr_loss: 0.14928/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.42475\n",
      "\tPart 3 - fp_loss: 0.70118/79.00%, bp_loss: 0.70200/80.00%, hp_loss: 2.46534/36.00%, j_loss: 0.41796/86.00%, \n",
      "\t\tfr_loss: 0.12268/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40916\n",
      "\tPart 4 - fp_loss: 0.58306/82.00%, bp_loss: 0.77810/77.00%, hp_loss: 2.65444/31.00%, j_loss: 0.42867/86.00%, \n",
      "\t\tfr_loss: 0.10284/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54711\n",
      "\tTraining time elapsed: 151.27 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.96704/71.00%, bp_loss: 1.25815/62.00%, hp_loss: 3.08617/23.00%, j_loss: 0.96852/73.00%, \n",
      "\t\tfr_loss: 0.16317/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.44306\n",
      "\tPart 2 - fp_loss: 0.91769/75.00%, bp_loss: 0.87272/75.00%, hp_loss: 2.73523/32.00%, j_loss: 0.68542/79.00%, \n",
      "\t\tfr_loss: 0.14624/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.35730\n",
      "\tPart 3 - fp_loss: 0.64864/81.00%, bp_loss: 0.69058/80.00%, hp_loss: 2.33453/40.00%, j_loss: 0.42179/85.00%, \n",
      "\t\tfr_loss: 0.11259/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.20813\n",
      "\tPart 4 - fp_loss: 0.65829/82.00%, bp_loss: 0.75430/79.00%, hp_loss: 2.55356/36.00%, j_loss: 0.41959/86.00%, \n",
      "\t\tfr_loss: 0.11631/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50205\n",
      "\tTraining time elapsed: 188.80 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.92152/73.00%, bp_loss: 1.33413/61.00%, hp_loss: 3.07426/22.00%, j_loss: 0.93585/73.00%, \n",
      "\t\tfr_loss: 0.13433/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.40010\n",
      "\tPart 2 - fp_loss: 0.79120/78.00%, bp_loss: 0.95223/73.00%, hp_loss: 2.67971/32.00%, j_loss: 0.68242/79.00%, \n",
      "\t\tfr_loss: 0.13191/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.23748\n",
      "\tPart 3 - fp_loss: 0.69838/80.00%, bp_loss: 0.76793/79.00%, hp_loss: 2.39284/37.00%, j_loss: 0.48579/84.00%, \n",
      "\t\tfr_loss: 0.09361/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43855\n",
      "\tPart 4 - fp_loss: 0.62902/81.00%, bp_loss: 0.81483/76.00%, hp_loss: 2.63748/31.00%, j_loss: 0.47443/83.00%, \n",
      "\t\tfr_loss: 0.09411/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64987\n",
      "\tTraining time elapsed: 226.37 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.93981/72.00%, bp_loss: 1.27089/62.00%, hp_loss: 3.05897/22.00%, j_loss: 0.91557/73.00%, \n",
      "\t\tfr_loss: 0.13598/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.32123\n",
      "\tPart 2 - fp_loss: 0.75470/77.00%, bp_loss: 0.92777/73.00%, hp_loss: 2.71951/32.00%, j_loss: 0.66830/78.00%, \n",
      "\t\tfr_loss: 0.14111/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21141\n",
      "\tPart 3 - fp_loss: 0.84743/77.00%, bp_loss: 0.80622/76.00%, hp_loss: 2.42660/37.00%, j_loss: 0.57869/80.00%, \n",
      "\t\tfr_loss: 0.11809/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.77702\n",
      "\tPart 4 - fp_loss: 0.63822/82.00%, bp_loss: 0.75644/76.00%, hp_loss: 2.61935/33.00%, j_loss: 0.44653/84.00%, \n",
      "\t\tfr_loss: 0.10954/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57008\n",
      "\tTraining time elapsed: 263.92 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.93304/74.00%, bp_loss: 1.32693/60.00%, hp_loss: 3.10782/22.00%, j_loss: 0.94749/76.00%, \n",
      "\t\tfr_loss: 0.13323/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.44850\n",
      "\tPart 2 - fp_loss: 0.78574/77.00%, bp_loss: 0.97361/74.00%, hp_loss: 2.73080/31.00%, j_loss: 0.65348/81.00%, \n",
      "\t\tfr_loss: 0.14043/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.28407\n",
      "\tPart 3 - fp_loss: 0.74912/78.00%, bp_loss: 0.72700/79.00%, hp_loss: 2.39959/39.00%, j_loss: 0.52839/83.00%, \n",
      "\t\tfr_loss: 0.11309/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51719\n",
      "\tPart 4 - fp_loss: 0.63643/82.00%, bp_loss: 0.75019/79.00%, hp_loss: 2.59393/35.00%, j_loss: 0.46818/85.00%, \n",
      "\t\tfr_loss: 0.09872/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54745\n",
      "\tTraining time elapsed: 301.46 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.88064/51.00%, bp_loss: 1.52649/54.00%, hp_loss: 3.06858/23.00%, j_loss: 1.61695/54.00%, \n",
      "\t\tfr_loss: 0.21049/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.30315\n",
      "\tPart 2 - fp_loss: 1.60709/60.00%, bp_loss: 1.49493/60.00%, hp_loss: 2.78602/29.00%, j_loss: 1.32286/63.00%, \n",
      "\t\tfr_loss: 0.19490/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.40581\n",
      "\tPart 3 - fp_loss: 1.21518/69.00%, bp_loss: 0.97600/72.00%, hp_loss: 2.43202/39.00%, j_loss: 0.78565/75.00%, \n",
      "\t\tfr_loss: 0.18345/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.59230\n",
      "\tPart 4 - fp_loss: 1.40842/70.00%, bp_loss: 1.15547/70.00%, hp_loss: 2.54989/36.00%, j_loss: 0.84019/77.00%, \n",
      "\t\tfr_loss: 0.17284/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.12682\n",
      "\t`Validation time elapsed: 0.79 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.78342/53.00%, bp_loss: 1.45883/53.00%, hp_loss: 3.02135/24.00%, j_loss: 1.59565/55.00%, \n",
      "\t\tfr_loss: 0.20317/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.06243\n",
      "\tPart 2 - fp_loss: 1.65342/59.00%, bp_loss: 1.25814/66.00%, hp_loss: 2.74444/29.00%, j_loss: 1.17418/67.00%, \n",
      "\t\tfr_loss: 0.18862/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.01879\n",
      "\tPart 3 - fp_loss: 1.31416/69.00%, bp_loss: 0.87341/76.00%, hp_loss: 2.32330/42.00%, j_loss: 0.81199/76.00%, \n",
      "\t\tfr_loss: 0.18300/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.50586\n",
      "\tPart 4 - fp_loss: 1.68853/67.00%, bp_loss: 0.93968/76.00%, hp_loss: 2.42665/39.00%, j_loss: 0.80540/77.00%, \n",
      "\t\tfr_loss: 0.17696/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03724\n",
      "\t`Validation time elapsed: 9.55 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 36.\n",
      "\n",
      "EPOCH 37\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.90481/74.00%, bp_loss: 1.25428/63.00%, hp_loss: 3.10099/20.00%, j_loss: 0.92424/73.00%, \n",
      "\t\tfr_loss: 0.15138/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33572\n",
      "\tPart 2 - fp_loss: 0.69342/80.00%, bp_loss: 1.13201/69.00%, hp_loss: 2.67190/33.00%, j_loss: 0.66388/79.00%, \n",
      "\t\tfr_loss: 0.15506/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.31628\n",
      "\tPart 3 - fp_loss: 0.70444/81.00%, bp_loss: 0.76082/78.00%, hp_loss: 2.42078/37.00%, j_loss: 0.50879/83.00%, \n",
      "\t\tfr_loss: 0.10685/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50168\n",
      "\tPart 4 - fp_loss: 0.57088/84.00%, bp_loss: 0.76647/78.00%, hp_loss: 2.57668/33.00%, j_loss: 0.42895/86.00%, \n",
      "\t\tfr_loss: 0.09326/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43625\n",
      "\tTraining time elapsed: 1.12 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.90422/73.00%, bp_loss: 1.32565/59.00%, hp_loss: 3.05966/24.00%, j_loss: 0.97403/72.00%, \n",
      "\t\tfr_loss: 0.13500/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.39857\n",
      "\tPart 2 - fp_loss: 0.78639/77.00%, bp_loss: 0.92192/74.00%, hp_loss: 2.72204/33.00%, j_loss: 0.64412/81.00%, \n",
      "\t\tfr_loss: 0.14296/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21744\n",
      "\tPart 3 - fp_loss: 0.74957/79.00%, bp_loss: 0.76008/78.00%, hp_loss: 2.36244/39.00%, j_loss: 0.47713/85.00%, \n",
      "\t\tfr_loss: 0.11702/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46624\n",
      "\tPart 4 - fp_loss: 0.60428/84.00%, bp_loss: 0.79521/78.00%, hp_loss: 2.61565/32.00%, j_loss: 0.38493/87.00%, \n",
      "\t\tfr_loss: 0.10507/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50514\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.98319/71.00%, bp_loss: 1.30996/60.00%, hp_loss: 3.14475/20.00%, j_loss: 1.00053/72.00%, \n",
      "\t\tfr_loss: 0.14167/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58009\n",
      "\tPart 2 - fp_loss: 0.77551/78.00%, bp_loss: 0.92367/72.00%, hp_loss: 2.77434/30.00%, j_loss: 0.64625/80.00%, \n",
      "\t\tfr_loss: 0.12360/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.24337\n",
      "\tPart 3 - fp_loss: 0.66097/81.00%, bp_loss: 0.73384/79.00%, hp_loss: 2.32949/39.00%, j_loss: 0.47246/84.00%, \n",
      "\t\tfr_loss: 0.09209/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28886\n",
      "\tPart 4 - fp_loss: 0.55400/83.00%, bp_loss: 0.83387/77.00%, hp_loss: 2.63611/31.00%, j_loss: 0.44523/86.00%, \n",
      "\t\tfr_loss: 0.08349/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55269\n",
      "\tTraining time elapsed: 76.16 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.91332/74.00%, bp_loss: 1.29408/61.00%, hp_loss: 3.09408/21.00%, j_loss: 0.89146/75.00%, \n",
      "\t\tfr_loss: 0.14385/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33679\n",
      "\tPart 2 - fp_loss: 0.70552/79.00%, bp_loss: 0.99556/71.00%, hp_loss: 2.67714/32.00%, j_loss: 0.64113/80.00%, \n",
      "\t\tfr_loss: 0.12815/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.14750\n",
      "\tPart 3 - fp_loss: 0.73352/80.00%, bp_loss: 0.77882/78.00%, hp_loss: 2.40692/39.00%, j_loss: 0.50626/85.00%, \n",
      "\t\tfr_loss: 0.11482/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54035\n",
      "\tPart 4 - fp_loss: 0.60740/83.00%, bp_loss: 0.80231/77.00%, hp_loss: 2.57630/33.00%, j_loss: 0.45246/87.00%, \n",
      "\t\tfr_loss: 0.09864/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53711\n",
      "\tTraining time elapsed: 113.69 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 1.07483/70.00%, bp_loss: 1.29370/60.00%, hp_loss: 3.09297/21.00%, j_loss: 1.05091/72.00%, \n",
      "\t\tfr_loss: 0.15130/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.66371\n",
      "\tPart 2 - fp_loss: 0.76714/78.00%, bp_loss: 0.98955/71.00%, hp_loss: 2.79281/29.00%, j_loss: 0.67837/80.00%, \n",
      "\t\tfr_loss: 0.11388/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.34175\n",
      "\tPart 3 - fp_loss: 0.76869/79.00%, bp_loss: 0.73670/80.00%, hp_loss: 2.46812/36.00%, j_loss: 0.45504/84.00%, \n",
      "\t\tfr_loss: 0.10096/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52951\n",
      "\tPart 4 - fp_loss: 0.61172/83.00%, bp_loss: 0.73671/79.00%, hp_loss: 2.57436/34.00%, j_loss: 0.42981/87.00%, \n",
      "\t\tfr_loss: 0.09846/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45107\n",
      "\tTraining time elapsed: 151.21 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.92611/72.00%, bp_loss: 1.30641/62.00%, hp_loss: 3.13630/20.00%, j_loss: 0.93482/74.00%, \n",
      "\t\tfr_loss: 0.12572/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.42936\n",
      "\tPart 2 - fp_loss: 0.72841/79.00%, bp_loss: 0.94215/73.00%, hp_loss: 2.73987/31.00%, j_loss: 0.65173/80.00%, \n",
      "\t\tfr_loss: 0.13758/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.19975\n",
      "\tPart 3 - fp_loss: 0.73503/78.00%, bp_loss: 0.73242/79.00%, hp_loss: 2.30698/41.00%, j_loss: 0.49931/82.00%, \n",
      "\t\tfr_loss: 0.12723/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40097\n",
      "\tPart 4 - fp_loss: 0.60893/82.00%, bp_loss: 0.72924/80.00%, hp_loss: 2.53672/35.00%, j_loss: 0.44472/86.00%, \n",
      "\t\tfr_loss: 0.10051/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42012\n",
      "\tTraining time elapsed: 188.72 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.94356/72.00%, bp_loss: 1.28075/63.00%, hp_loss: 3.04728/23.00%, j_loss: 0.93183/75.00%, \n",
      "\t\tfr_loss: 0.15719/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36061\n",
      "\tPart 2 - fp_loss: 0.78859/76.00%, bp_loss: 0.86975/74.00%, hp_loss: 2.73445/31.00%, j_loss: 0.66404/78.00%, \n",
      "\t\tfr_loss: 0.14384/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.20068\n",
      "\tPart 3 - fp_loss: 0.78103/78.00%, bp_loss: 0.83872/76.00%, hp_loss: 2.50043/34.00%, j_loss: 0.60532/82.00%, \n",
      "\t\tfr_loss: 0.11618/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.84168\n",
      "\tPart 4 - fp_loss: 0.63971/81.00%, bp_loss: 0.80908/77.00%, hp_loss: 2.69166/31.00%, j_loss: 0.49351/84.00%, \n",
      "\t\tfr_loss: 0.11301/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.74697\n",
      "\tTraining time elapsed: 226.26 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.95658/73.00%, bp_loss: 1.29159/62.00%, hp_loss: 3.07050/24.00%, j_loss: 0.93245/74.00%, \n",
      "\t\tfr_loss: 0.13541/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.38653\n",
      "\tPart 2 - fp_loss: 0.79011/77.00%, bp_loss: 0.86809/75.00%, hp_loss: 2.73244/32.00%, j_loss: 0.63750/79.00%, \n",
      "\t\tfr_loss: 0.14365/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.17180\n",
      "\tPart 3 - fp_loss: 0.76822/79.00%, bp_loss: 0.67135/80.00%, hp_loss: 2.34441/40.00%, j_loss: 0.47941/83.00%, \n",
      "\t\tfr_loss: 0.11262/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37600\n",
      "\tPart 4 - fp_loss: 0.60715/84.00%, bp_loss: 0.77010/79.00%, hp_loss: 2.49779/37.00%, j_loss: 0.41304/85.00%, \n",
      "\t\tfr_loss: 0.09744/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38552\n",
      "\tTraining time elapsed: 263.79 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.95256/72.00%, bp_loss: 1.33368/60.00%, hp_loss: 3.00196/24.00%, j_loss: 1.01213/71.00%, \n",
      "\t\tfr_loss: 0.16280/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.46313\n",
      "\tPart 2 - fp_loss: 0.78570/76.00%, bp_loss: 0.99697/72.00%, hp_loss: 2.74792/31.00%, j_loss: 0.76208/78.00%, \n",
      "\t\tfr_loss: 0.13078/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.42346\n",
      "\tPart 3 - fp_loss: 0.78109/78.00%, bp_loss: 0.69657/79.00%, hp_loss: 2.37154/37.00%, j_loss: 0.52567/83.00%, \n",
      "\t\tfr_loss: 0.12363/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.49849\n",
      "\tPart 4 - fp_loss: 0.60667/83.00%, bp_loss: 0.83323/75.00%, hp_loss: 2.58244/32.00%, j_loss: 0.46459/83.00%, \n",
      "\t\tfr_loss: 0.08853/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57545\n",
      "\tTraining time elapsed: 301.30 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.83025/51.00%, bp_loss: 1.54627/54.00%, hp_loss: 3.04315/23.00%, j_loss: 1.61902/54.00%, \n",
      "\t\tfr_loss: 0.21155/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.25023\n",
      "\tPart 2 - fp_loss: 1.55290/60.00%, bp_loss: 1.43567/60.00%, hp_loss: 2.69529/30.00%, j_loss: 1.29407/61.00%, \n",
      "\t\tfr_loss: 0.19020/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.16814\n",
      "\tPart 3 - fp_loss: 1.28957/70.00%, bp_loss: 0.97819/74.00%, hp_loss: 2.26838/42.00%, j_loss: 0.80589/75.00%, \n",
      "\t\tfr_loss: 0.18893/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.53095\n",
      "\tPart 4 - fp_loss: 1.43436/69.00%, bp_loss: 0.96589/74.00%, hp_loss: 2.37074/40.00%, j_loss: 0.81049/75.00%, \n",
      "\t\tfr_loss: 0.19141/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77288\n",
      "\t`Validation time elapsed: 0.77 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.84563/52.00%, bp_loss: 1.45489/56.00%, hp_loss: 3.02780/24.00%, j_loss: 1.57648/57.00%, \n",
      "\t\tfr_loss: 0.21503/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.11984\n",
      "\tPart 2 - fp_loss: 1.66584/58.00%, bp_loss: 1.23240/64.00%, hp_loss: 2.68991/30.00%, j_loss: 1.35831/64.00%, \n",
      "\t\tfr_loss: 0.18656/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.13301\n",
      "\tPart 3 - fp_loss: 1.24528/70.00%, bp_loss: 0.86660/77.00%, hp_loss: 2.22462/44.00%, j_loss: 0.76058/78.00%, \n",
      "\t\tfr_loss: 0.16918/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.26626\n",
      "\tPart 4 - fp_loss: 1.39891/70.00%, bp_loss: 0.94189/75.00%, hp_loss: 2.40171/39.00%, j_loss: 0.82277/77.00%, \n",
      "\t\tfr_loss: 0.17242/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.73770\n",
      "\t`Validation time elapsed: 9.54 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 37.\n",
      "\n",
      "EPOCH 38\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.85256/76.00%, bp_loss: 1.27053/62.00%, hp_loss: 3.09499/22.00%, j_loss: 0.87929/75.00%, \n",
      "\t\tfr_loss: 0.12790/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22526\n",
      "\tPart 2 - fp_loss: 0.65877/81.00%, bp_loss: 1.08056/69.00%, hp_loss: 2.64658/33.00%, j_loss: 0.66750/78.00%, \n",
      "\t\tfr_loss: 0.12795/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18135\n",
      "\tPart 3 - fp_loss: 0.63784/81.00%, bp_loss: 0.70129/80.00%, hp_loss: 2.36720/39.00%, j_loss: 0.47161/83.00%, \n",
      "\t\tfr_loss: 0.09091/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.26885\n",
      "\tPart 4 - fp_loss: 0.57886/84.00%, bp_loss: 0.65910/80.00%, hp_loss: 2.60139/33.00%, j_loss: 0.37645/86.00%, \n",
      "\t\tfr_loss: 0.09926/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.31506\n",
      "\tTraining time elapsed: 1.11 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.91441/74.00%, bp_loss: 1.33486/60.00%, hp_loss: 3.05359/21.00%, j_loss: 0.91297/76.00%, \n",
      "\t\tfr_loss: 0.13062/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.34646\n",
      "\tPart 2 - fp_loss: 0.74235/78.00%, bp_loss: 0.91583/74.00%, hp_loss: 2.72226/31.00%, j_loss: 0.63430/80.00%, \n",
      "\t\tfr_loss: 0.12785/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.14259\n",
      "\tPart 3 - fp_loss: 0.72269/80.00%, bp_loss: 0.75355/79.00%, hp_loss: 2.36061/39.00%, j_loss: 0.49021/82.00%, \n",
      "\t\tfr_loss: 0.11215/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43921\n",
      "\tPart 4 - fp_loss: 0.61643/80.00%, bp_loss: 0.78230/77.00%, hp_loss: 2.56588/34.00%, j_loss: 0.47303/84.00%, \n",
      "\t\tfr_loss: 0.10129/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53893\n",
      "\tTraining time elapsed: 38.67 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.92219/72.00%, bp_loss: 1.25109/64.00%, hp_loss: 3.11489/23.00%, j_loss: 0.96330/73.00%, \n",
      "\t\tfr_loss: 0.16209/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41355\n",
      "\tPart 2 - fp_loss: 0.80342/76.00%, bp_loss: 0.89678/74.00%, hp_loss: 2.78812/31.00%, j_loss: 0.68803/79.00%, \n",
      "\t\tfr_loss: 0.13025/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.30662\n",
      "\tPart 3 - fp_loss: 0.67147/80.00%, bp_loss: 0.74326/80.00%, hp_loss: 2.35105/39.00%, j_loss: 0.42200/86.00%, \n",
      "\t\tfr_loss: 0.10842/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.29620\n",
      "\tPart 4 - fp_loss: 0.60661/82.00%, bp_loss: 0.74038/78.00%, hp_loss: 2.52342/35.00%, j_loss: 0.44835/85.00%, \n",
      "\t\tfr_loss: 0.10478/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42354\n",
      "\tTraining time elapsed: 76.19 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.90771/73.00%, bp_loss: 1.21356/63.00%, hp_loss: 3.05245/23.00%, j_loss: 0.90299/74.00%, \n",
      "\t\tfr_loss: 0.13869/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.21540\n",
      "\tPart 2 - fp_loss: 0.78849/78.00%, bp_loss: 0.96750/73.00%, hp_loss: 2.75833/31.00%, j_loss: 0.63229/80.00%, \n",
      "\t\tfr_loss: 0.13365/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.28026\n",
      "\tPart 3 - fp_loss: 0.72905/79.00%, bp_loss: 0.75110/78.00%, hp_loss: 2.45844/37.00%, j_loss: 0.51388/84.00%, \n",
      "\t\tfr_loss: 0.12475/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57721\n",
      "\tPart 4 - fp_loss: 0.60405/82.00%, bp_loss: 0.84682/76.00%, hp_loss: 2.60897/33.00%, j_loss: 0.47454/86.00%, \n",
      "\t\tfr_loss: 0.10259/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63697\n",
      "\tTraining time elapsed: 113.72 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.90768/73.00%, bp_loss: 1.28445/62.00%, hp_loss: 3.07443/23.00%, j_loss: 0.91065/73.00%, \n",
      "\t\tfr_loss: 0.13343/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31065\n",
      "\tPart 2 - fp_loss: 0.80572/77.00%, bp_loss: 1.01046/70.00%, hp_loss: 2.83064/29.00%, j_loss: 0.69556/80.00%, \n",
      "\t\tfr_loss: 0.14250/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.48488\n",
      "\tPart 3 - fp_loss: 0.72549/78.00%, bp_loss: 0.75342/79.00%, hp_loss: 2.35887/40.00%, j_loss: 0.52237/83.00%, \n",
      "\t\tfr_loss: 0.10025/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46040\n",
      "\tPart 4 - fp_loss: 0.62885/81.00%, bp_loss: 0.82083/76.00%, hp_loss: 2.58156/35.00%, j_loss: 0.49881/84.00%, \n",
      "\t\tfr_loss: 0.11748/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64753\n",
      "\tTraining time elapsed: 151.28 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.88920/74.00%, bp_loss: 1.34166/61.00%, hp_loss: 3.08140/20.00%, j_loss: 0.87721/76.00%, \n",
      "\t\tfr_loss: 0.11710/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30657\n",
      "\tPart 2 - fp_loss: 0.80480/77.00%, bp_loss: 0.92140/73.00%, hp_loss: 2.68828/32.00%, j_loss: 0.64045/80.00%, \n",
      "\t\tfr_loss: 0.12659/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18152\n",
      "\tPart 3 - fp_loss: 0.73604/79.00%, bp_loss: 0.83676/76.00%, hp_loss: 2.32838/38.00%, j_loss: 0.52842/83.00%, \n",
      "\t\tfr_loss: 0.11627/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54588\n",
      "\tPart 4 - fp_loss: 0.63755/82.00%, bp_loss: 0.77591/77.00%, hp_loss: 2.58439/33.00%, j_loss: 0.47501/83.00%, \n",
      "\t\tfr_loss: 0.10669/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57955\n",
      "\tTraining time elapsed: 188.82 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.87894/74.00%, bp_loss: 1.26837/62.00%, hp_loss: 3.05293/23.00%, j_loss: 0.92439/75.00%, \n",
      "\t\tfr_loss: 0.15157/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.27620\n",
      "\tPart 2 - fp_loss: 0.82167/76.00%, bp_loss: 0.83610/76.00%, hp_loss: 2.74254/32.00%, j_loss: 0.65575/81.00%, \n",
      "\t\tfr_loss: 0.12915/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18522\n",
      "\tPart 3 - fp_loss: 0.73683/80.00%, bp_loss: 0.75411/79.00%, hp_loss: 2.37429/39.00%, j_loss: 0.48078/85.00%, \n",
      "\t\tfr_loss: 0.11854/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46454\n",
      "\tPart 4 - fp_loss: 0.61301/83.00%, bp_loss: 0.81256/76.00%, hp_loss: 2.62046/34.00%, j_loss: 0.46509/86.00%, \n",
      "\t\tfr_loss: 0.08410/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.59522\n",
      "\tTraining time elapsed: 226.35 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.05086/68.00%, bp_loss: 1.36604/59.00%, hp_loss: 3.07449/21.00%, j_loss: 1.07004/72.00%, \n",
      "\t\tfr_loss: 0.16521/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.72664\n",
      "\tPart 2 - fp_loss: 0.82229/76.00%, bp_loss: 0.94305/73.00%, hp_loss: 2.74014/31.00%, j_loss: 0.69945/79.00%, \n",
      "\t\tfr_loss: 0.13949/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.34443\n",
      "\tPart 3 - fp_loss: 0.72922/78.00%, bp_loss: 0.87201/76.00%, hp_loss: 2.40557/37.00%, j_loss: 0.58413/80.00%, \n",
      "\t\tfr_loss: 0.11018/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.70111\n",
      "\tPart 4 - fp_loss: 0.60953/82.00%, bp_loss: 0.80169/78.00%, hp_loss: 2.65187/33.00%, j_loss: 0.47266/84.00%, \n",
      "\t\tfr_loss: 0.10278/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63853\n",
      "\tTraining time elapsed: 263.89 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.97024/69.00%, bp_loss: 1.27272/62.00%, hp_loss: 3.07020/23.00%, j_loss: 0.99489/70.00%, \n",
      "\t\tfr_loss: 0.14170/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.44974\n",
      "\tPart 2 - fp_loss: 0.75121/77.00%, bp_loss: 0.90781/74.00%, hp_loss: 2.73102/32.00%, j_loss: 0.63953/80.00%, \n",
      "\t\tfr_loss: 0.15225/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18182\n",
      "\tPart 3 - fp_loss: 0.73893/78.00%, bp_loss: 0.81218/78.00%, hp_loss: 2.35146/38.00%, j_loss: 0.56555/83.00%, \n",
      "\t\tfr_loss: 0.10616/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57429\n",
      "\tPart 4 - fp_loss: 0.59438/83.00%, bp_loss: 0.87604/76.00%, hp_loss: 2.58172/34.00%, j_loss: 0.48855/84.00%, \n",
      "\t\tfr_loss: 0.11638/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65706\n",
      "\tTraining time elapsed: 301.42 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.99392/49.00%, bp_loss: 1.48133/56.00%, hp_loss: 3.02773/22.00%, j_loss: 1.62741/53.00%, \n",
      "\t\tfr_loss: 0.21355/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.34393\n",
      "\tPart 2 - fp_loss: 1.70666/58.00%, bp_loss: 1.26785/65.00%, hp_loss: 2.59766/34.00%, j_loss: 1.23472/62.00%, \n",
      "\t\tfr_loss: 0.19231/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.99919\n",
      "\tPart 3 - fp_loss: 1.17828/71.00%, bp_loss: 0.85697/76.00%, hp_loss: 2.20612/46.00%, j_loss: 0.84294/76.00%, \n",
      "\t\tfr_loss: 0.16641/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.25072\n",
      "\tPart 4 - fp_loss: 1.50813/69.00%, bp_loss: 0.93160/74.00%, hp_loss: 2.33824/42.00%, j_loss: 0.79195/74.00%, \n",
      "\t\tfr_loss: 0.18107/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75099\n",
      "\t`Validation time elapsed: 0.77 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.86693/52.00%, bp_loss: 1.37404/58.00%, hp_loss: 2.99288/25.00%, j_loss: 1.54044/57.00%, \n",
      "\t\tfr_loss: 0.19878/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.97308\n",
      "\tPart 2 - fp_loss: 1.63364/60.00%, bp_loss: 1.18387/66.00%, hp_loss: 2.75314/28.00%, j_loss: 1.17430/67.00%, \n",
      "\t\tfr_loss: 0.20707/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.95202\n",
      "\tPart 3 - fp_loss: 1.18522/71.00%, bp_loss: 0.88010/75.00%, hp_loss: 2.23022/44.00%, j_loss: 0.72607/78.00%, \n",
      "\t\tfr_loss: 0.17160/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.19322\n",
      "\tPart 4 - fp_loss: 1.39964/70.00%, bp_loss: 0.94676/75.00%, hp_loss: 2.37831/42.00%, j_loss: 0.82177/77.00%, \n",
      "\t\tfr_loss: 0.17389/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.72038\n",
      "\t`Validation time elapsed: 9.51 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 38.\n",
      "\n",
      "EPOCH 39\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.90904/73.00%, bp_loss: 1.29161/61.00%, hp_loss: 3.10525/22.00%, j_loss: 0.96842/72.00%, \n",
      "\t\tfr_loss: 0.14156/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41587\n",
      "\tPart 2 - fp_loss: 0.71236/79.00%, bp_loss: 1.08768/70.00%, hp_loss: 2.71080/30.00%, j_loss: 0.72176/76.00%, \n",
      "\t\tfr_loss: 0.12061/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.35321\n",
      "\tPart 3 - fp_loss: 0.66920/81.00%, bp_loss: 0.72077/80.00%, hp_loss: 2.43072/37.00%, j_loss: 0.47376/86.00%, \n",
      "\t\tfr_loss: 0.10482/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39926\n",
      "\tPart 4 - fp_loss: 0.53334/85.00%, bp_loss: 0.68799/80.00%, hp_loss: 2.54789/35.00%, j_loss: 0.37172/88.00%, \n",
      "\t\tfr_loss: 0.09124/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.23219\n",
      "\tTraining time elapsed: 1.08 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.94082/73.00%, bp_loss: 1.29588/61.00%, hp_loss: 3.03408/22.00%, j_loss: 0.94500/74.00%, \n",
      "\t\tfr_loss: 0.13393/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.34972\n",
      "\tPart 2 - fp_loss: 0.73886/79.00%, bp_loss: 0.96281/72.00%, hp_loss: 2.81792/29.00%, j_loss: 0.65147/80.00%, \n",
      "\t\tfr_loss: 0.15147/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.32253\n",
      "\tPart 3 - fp_loss: 0.63097/81.00%, bp_loss: 0.91207/75.00%, hp_loss: 2.46559/36.00%, j_loss: 0.45788/85.00%, \n",
      "\t\tfr_loss: 0.12205/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58856\n",
      "\tPart 4 - fp_loss: 0.63124/83.00%, bp_loss: 0.77093/77.00%, hp_loss: 2.64489/29.00%, j_loss: 0.42976/84.00%, \n",
      "\t\tfr_loss: 0.09026/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56709\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.94661/71.00%, bp_loss: 1.26981/64.00%, hp_loss: 3.02161/25.00%, j_loss: 0.90525/76.00%, \n",
      "\t\tfr_loss: 0.15938/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30265\n",
      "\tPart 2 - fp_loss: 0.81832/76.00%, bp_loss: 0.88258/75.00%, hp_loss: 2.73012/31.00%, j_loss: 0.66057/81.00%, \n",
      "\t\tfr_loss: 0.12344/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21503\n",
      "\tPart 3 - fp_loss: 0.71770/79.00%, bp_loss: 0.81155/79.00%, hp_loss: 2.40595/38.00%, j_loss: 0.49507/86.00%, \n",
      "\t\tfr_loss: 0.11419/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54445\n",
      "\tPart 4 - fp_loss: 0.60945/83.00%, bp_loss: 0.70239/80.00%, hp_loss: 2.65270/32.00%, j_loss: 0.43522/86.00%, \n",
      "\t\tfr_loss: 0.10453/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50429\n",
      "\tTraining time elapsed: 76.17 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.93426/71.00%, bp_loss: 1.30213/62.00%, hp_loss: 3.04089/25.00%, j_loss: 1.00653/72.00%, \n",
      "\t\tfr_loss: 0.14377/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.42758\n",
      "\tPart 2 - fp_loss: 0.71932/81.00%, bp_loss: 0.92509/74.00%, hp_loss: 2.72805/34.00%, j_loss: 0.58872/81.00%, \n",
      "\t\tfr_loss: 0.12509/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.08627\n",
      "\tPart 3 - fp_loss: 0.69824/80.00%, bp_loss: 0.78213/79.00%, hp_loss: 2.41928/37.00%, j_loss: 0.48707/85.00%, \n",
      "\t\tfr_loss: 0.11618/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50289\n",
      "\tPart 4 - fp_loss: 0.57302/82.00%, bp_loss: 0.82660/76.00%, hp_loss: 2.54807/35.00%, j_loss: 0.50575/84.00%, \n",
      "\t\tfr_loss: 0.10991/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56335\n",
      "\tTraining time elapsed: 113.71 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.91028/73.00%, bp_loss: 1.24224/63.00%, hp_loss: 3.03617/22.00%, j_loss: 0.89534/76.00%, \n",
      "\t\tfr_loss: 0.13686/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22089\n",
      "\tPart 2 - fp_loss: 0.70610/79.00%, bp_loss: 0.97087/73.00%, hp_loss: 2.70198/31.00%, j_loss: 0.58977/80.00%, \n",
      "\t\tfr_loss: 0.11982/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.08855\n",
      "\tPart 3 - fp_loss: 0.73938/80.00%, bp_loss: 0.90304/76.00%, hp_loss: 2.47147/36.00%, j_loss: 0.53155/83.00%, \n",
      "\t\tfr_loss: 0.11349/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.75892\n",
      "\tPart 4 - fp_loss: 0.67788/80.00%, bp_loss: 0.80917/76.00%, hp_loss: 2.64246/32.00%, j_loss: 0.47219/84.00%, \n",
      "\t\tfr_loss: 0.11385/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71556\n",
      "\tTraining time elapsed: 151.22 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.99681/72.00%, bp_loss: 1.34057/60.00%, hp_loss: 3.10801/21.00%, j_loss: 1.01435/74.00%, \n",
      "\t\tfr_loss: 0.14937/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.60912\n",
      "\tPart 2 - fp_loss: 0.71104/79.00%, bp_loss: 0.80486/76.00%, hp_loss: 2.62081/35.00%, j_loss: 0.62148/79.00%, \n",
      "\t\tfr_loss: 0.12709/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88527\n",
      "\tPart 3 - fp_loss: 0.65073/81.00%, bp_loss: 0.80543/79.00%, hp_loss: 2.34724/40.00%, j_loss: 0.47487/87.00%, \n",
      "\t\tfr_loss: 0.09570/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37398\n",
      "\tPart 4 - fp_loss: 0.58822/83.00%, bp_loss: 0.78337/79.00%, hp_loss: 2.52138/35.00%, j_loss: 0.44425/85.00%, \n",
      "\t\tfr_loss: 0.10427/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44150\n",
      "\tTraining time elapsed: 188.71 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.88364/74.00%, bp_loss: 1.31869/61.00%, hp_loss: 3.07602/21.00%, j_loss: 0.93863/74.00%, \n",
      "\t\tfr_loss: 0.12671/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.34369\n",
      "\tPart 2 - fp_loss: 0.75405/79.00%, bp_loss: 0.92488/74.00%, hp_loss: 2.75441/30.00%, j_loss: 0.64466/80.00%, \n",
      "\t\tfr_loss: 0.14028/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.21828\n",
      "\tPart 3 - fp_loss: 0.67922/82.00%, bp_loss: 0.83019/78.00%, hp_loss: 2.32009/42.00%, j_loss: 0.51610/85.00%, \n",
      "\t\tfr_loss: 0.09976/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44535\n",
      "\tPart 4 - fp_loss: 0.59873/84.00%, bp_loss: 0.82854/77.00%, hp_loss: 2.58919/33.00%, j_loss: 0.41247/87.00%, \n",
      "\t\tfr_loss: 0.10194/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53086\n",
      "\tTraining time elapsed: 226.24 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.96229/73.00%, bp_loss: 1.24762/62.00%, hp_loss: 3.07503/23.00%, j_loss: 0.94713/73.00%, \n",
      "\t\tfr_loss: 0.14393/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.37600\n",
      "\tPart 2 - fp_loss: 0.78021/77.00%, bp_loss: 0.95169/73.00%, hp_loss: 2.72950/31.00%, j_loss: 0.65607/79.00%, \n",
      "\t\tfr_loss: 0.12436/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.24183\n",
      "\tPart 3 - fp_loss: 0.72489/80.00%, bp_loss: 0.81226/79.00%, hp_loss: 2.24357/44.00%, j_loss: 0.50174/83.00%, \n",
      "\t\tfr_loss: 0.11419/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39666\n",
      "\tPart 4 - fp_loss: 0.60625/83.00%, bp_loss: 0.90449/75.00%, hp_loss: 2.51533/36.00%, j_loss: 0.42470/87.00%, \n",
      "\t\tfr_loss: 0.10585/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55662\n",
      "\tTraining time elapsed: 263.78 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.98125/70.00%, bp_loss: 1.31497/61.00%, hp_loss: 3.13915/20.00%, j_loss: 1.04674/72.00%, \n",
      "\t\tfr_loss: 0.12989/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.61201\n",
      "\tPart 2 - fp_loss: 0.83318/78.00%, bp_loss: 0.97541/71.00%, hp_loss: 2.76234/31.00%, j_loss: 0.69581/80.00%, \n",
      "\t\tfr_loss: 0.13485/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40158\n",
      "\tPart 3 - fp_loss: 0.77089/78.00%, bp_loss: 0.88508/76.00%, hp_loss: 2.49830/35.00%, j_loss: 0.58875/83.00%, \n",
      "\t\tfr_loss: 0.10941/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.85244\n",
      "\tPart 4 - fp_loss: 0.67393/80.00%, bp_loss: 0.80855/78.00%, hp_loss: 2.67474/32.00%, j_loss: 0.44027/86.00%, \n",
      "\t\tfr_loss: 0.11029/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.70777\n",
      "\tTraining time elapsed: 301.31 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.86158/54.00%, bp_loss: 1.39090/58.00%, hp_loss: 3.07503/24.00%, j_loss: 1.47184/56.00%, \n",
      "\t\tfr_loss: 0.23433/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.03368\n",
      "\tPart 2 - fp_loss: 1.47219/63.00%, bp_loss: 1.36830/61.00%, hp_loss: 2.70664/30.00%, j_loss: 1.22740/62.00%, \n",
      "\t\tfr_loss: 0.19741/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.97195\n",
      "\tPart 3 - fp_loss: 1.25887/68.00%, bp_loss: 1.18311/67.00%, hp_loss: 2.28930/43.00%, j_loss: 1.04803/76.00%, \n",
      "\t\tfr_loss: 0.17602/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.95533\n",
      "\tPart 4 - fp_loss: 1.35102/72.00%, bp_loss: 0.96835/73.00%, hp_loss: 2.45090/39.00%, j_loss: 0.80039/76.00%, \n",
      "\t\tfr_loss: 0.16952/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.74019\n",
      "\t`Validation time elapsed: 0.78 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.98335/50.00%, bp_loss: 1.39401/57.00%, hp_loss: 3.08135/22.00%, j_loss: 1.68691/54.00%, \n",
      "\t\tfr_loss: 0.20547/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.35109\n",
      "\tPart 2 - fp_loss: 1.70526/58.00%, bp_loss: 1.20601/65.00%, hp_loss: 2.66891/30.00%, j_loss: 1.24683/66.00%, \n",
      "\t\tfr_loss: 0.18973/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.01673\n",
      "\tPart 3 - fp_loss: 1.31883/69.00%, bp_loss: 1.06962/71.00%, hp_loss: 2.26749/43.00%, j_loss: 0.93495/79.00%, \n",
      "\t\tfr_loss: 0.16418/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75506\n",
      "\tPart 4 - fp_loss: 1.43386/69.00%, bp_loss: 0.94741/75.00%, hp_loss: 2.43286/38.00%, j_loss: 0.79546/76.00%, \n",
      "\t\tfr_loss: 0.16825/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.77784\n",
      "\t`Validation time elapsed: 9.55 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Completed epoch 39.\n",
      "\n",
      "EPOCH 40\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.88820/74.00%, bp_loss: 1.31765/60.00%, hp_loss: 3.12319/21.00%, j_loss: 0.97075/72.00%, \n",
      "\t\tfr_loss: 0.13836/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.43816\n",
      "\tPart 2 - fp_loss: 0.75283/79.00%, bp_loss: 1.01534/71.00%, hp_loss: 2.79598/30.00%, j_loss: 0.64851/77.00%, \n",
      "\t\tfr_loss: 0.11470/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.32736\n",
      "\tPart 3 - fp_loss: 0.76837/78.00%, bp_loss: 1.12632/68.00%, hp_loss: 2.39132/39.00%, j_loss: 0.69067/83.00%, \n",
      "\t\tfr_loss: 0.11050/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.08717\n",
      "\tPart 4 - fp_loss: 0.55122/84.00%, bp_loss: 0.78056/78.00%, hp_loss: 2.54939/35.00%, j_loss: 0.42279/85.00%, \n",
      "\t\tfr_loss: 0.08466/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38862\n",
      "\tTraining time elapsed: 1.11 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.95931/72.00%, bp_loss: 1.37989/60.00%, hp_loss: 3.14987/20.00%, j_loss: 0.98323/73.00%, \n",
      "\t\tfr_loss: 0.13227/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.60457\n",
      "\tPart 2 - fp_loss: 0.75120/78.00%, bp_loss: 0.85434/75.00%, hp_loss: 2.67760/33.00%, j_loss: 0.62205/81.00%, \n",
      "\t\tfr_loss: 0.14117/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.04636\n",
      "\tPart 3 - fp_loss: 0.64810/82.00%, bp_loss: 0.76948/79.00%, hp_loss: 2.39103/40.00%, j_loss: 0.43538/86.00%, \n",
      "\t\tfr_loss: 0.09361/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33761\n",
      "\tPart 4 - fp_loss: 0.53026/85.00%, bp_loss: 0.75491/77.00%, hp_loss: 2.54649/32.00%, j_loss: 0.39048/86.00%, \n",
      "\t\tfr_loss: 0.10231/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32446\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.93567/72.00%, bp_loss: 1.22771/63.00%, hp_loss: 3.07623/23.00%, j_loss: 1.00121/72.00%, \n",
      "\t\tfr_loss: 0.13822/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.37904\n",
      "\tPart 2 - fp_loss: 0.78721/76.00%, bp_loss: 0.90222/74.00%, hp_loss: 2.69290/33.00%, j_loss: 0.68070/78.00%, \n",
      "\t\tfr_loss: 0.13996/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.20299\n",
      "\tPart 3 - fp_loss: 0.69456/81.00%, bp_loss: 0.79661/78.00%, hp_loss: 2.35035/40.00%, j_loss: 0.47380/84.00%, \n",
      "\t\tfr_loss: 0.11153/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42686\n",
      "\tPart 4 - fp_loss: 0.59589/83.00%, bp_loss: 0.78602/77.00%, hp_loss: 2.52812/35.00%, j_loss: 0.42691/86.00%, \n",
      "\t\tfr_loss: 0.11018/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44712\n",
      "\tTraining time elapsed: 76.17 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.95368/72.00%, bp_loss: 1.24335/64.00%, hp_loss: 3.12220/22.00%, j_loss: 0.90178/72.00%, \n",
      "\t\tfr_loss: 0.14169/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36270\n",
      "\tPart 2 - fp_loss: 0.84916/76.00%, bp_loss: 0.81106/76.00%, hp_loss: 2.71175/33.00%, j_loss: 0.65535/79.00%, \n",
      "\t\tfr_loss: 0.14016/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16748\n",
      "\tPart 3 - fp_loss: 0.63415/81.00%, bp_loss: 0.74463/79.00%, hp_loss: 2.45817/38.00%, j_loss: 0.44207/84.00%, \n",
      "\t\tfr_loss: 0.11038/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38939\n",
      "\tPart 4 - fp_loss: 0.66436/81.00%, bp_loss: 0.79686/78.00%, hp_loss: 2.63877/32.00%, j_loss: 0.45683/85.00%, \n",
      "\t\tfr_loss: 0.10043/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65726\n",
      "\tTraining time elapsed: 113.68 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.99507/71.00%, bp_loss: 1.20654/64.00%, hp_loss: 3.11647/21.00%, j_loss: 0.95469/74.00%, \n",
      "\t\tfr_loss: 0.15781/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.43057\n",
      "\tPart 2 - fp_loss: 0.74299/79.00%, bp_loss: 0.85733/75.00%, hp_loss: 2.76639/31.00%, j_loss: 0.56828/81.00%, \n",
      "\t\tfr_loss: 0.12914/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06412\n",
      "\tPart 3 - fp_loss: 0.71848/80.00%, bp_loss: 0.86023/77.00%, hp_loss: 2.48543/36.00%, j_loss: 0.51075/85.00%, \n",
      "\t\tfr_loss: 0.11331/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68820\n",
      "\tPart 4 - fp_loss: 0.54235/83.00%, bp_loss: 0.75983/79.00%, hp_loss: 2.69888/29.00%, j_loss: 0.43821/87.00%, \n",
      "\t\tfr_loss: 0.10707/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54634\n",
      "\tTraining time elapsed: 151.22 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.99536/70.00%, bp_loss: 1.33982/61.00%, hp_loss: 3.11871/20.00%, j_loss: 0.99233/72.00%, \n",
      "\t\tfr_loss: 0.13603/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58224\n",
      "\tPart 2 - fp_loss: 0.82817/76.00%, bp_loss: 0.95488/71.00%, hp_loss: 2.77155/30.00%, j_loss: 0.69272/78.00%, \n",
      "\t\tfr_loss: 0.14020/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.38753\n",
      "\tPart 3 - fp_loss: 0.69818/79.00%, bp_loss: 0.81046/78.00%, hp_loss: 2.41869/35.00%, j_loss: 0.49355/85.00%, \n",
      "\t\tfr_loss: 0.11008/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53096\n",
      "\tPart 4 - fp_loss: 0.70191/79.00%, bp_loss: 0.79455/79.00%, hp_loss: 2.66649/33.00%, j_loss: 0.47882/84.00%, \n",
      "\t\tfr_loss: 0.10999/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.75176\n",
      "\tTraining time elapsed: 188.73 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.97617/72.00%, bp_loss: 1.26193/62.00%, hp_loss: 3.10308/22.00%, j_loss: 0.96592/72.00%, \n",
      "\t\tfr_loss: 0.14453/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.45162\n",
      "\tPart 2 - fp_loss: 0.73282/79.00%, bp_loss: 0.87666/74.00%, hp_loss: 2.69298/32.00%, j_loss: 0.55209/84.00%, \n",
      "\t\tfr_loss: 0.11861/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97316\n",
      "\tPart 3 - fp_loss: 0.75143/79.00%, bp_loss: 0.83603/78.00%, hp_loss: 2.31305/41.00%, j_loss: 0.49617/82.00%, \n",
      "\t\tfr_loss: 0.11090/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50759\n",
      "\tPart 4 - fp_loss: 0.59359/83.00%, bp_loss: 0.71818/80.00%, hp_loss: 2.55168/37.00%, j_loss: 0.42271/85.00%, \n",
      "\t\tfr_loss: 0.11151/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39767\n",
      "\tTraining time elapsed: 226.26 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.89198/74.00%, bp_loss: 1.23509/64.00%, hp_loss: 3.02668/24.00%, j_loss: 0.91290/75.00%, \n",
      "\t\tfr_loss: 0.12867/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19532\n",
      "\tPart 2 - fp_loss: 0.72730/79.00%, bp_loss: 0.92592/73.00%, hp_loss: 2.73937/31.00%, j_loss: 0.58276/82.00%, \n",
      "\t\tfr_loss: 0.13047/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10581\n",
      "\tPart 3 - fp_loss: 0.77117/79.00%, bp_loss: 0.79158/79.00%, hp_loss: 2.40388/38.00%, j_loss: 0.53748/84.00%, \n",
      "\t\tfr_loss: 0.10727/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61137\n",
      "\tPart 4 - fp_loss: 0.63702/81.00%, bp_loss: 0.79774/77.00%, hp_loss: 2.62425/31.00%, j_loss: 0.45851/85.00%, \n",
      "\t\tfr_loss: 0.09326/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61079\n",
      "\tTraining time elapsed: 263.79 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.98181/72.00%, bp_loss: 1.24063/63.00%, hp_loss: 3.07836/24.00%, j_loss: 0.92260/74.00%, \n",
      "\t\tfr_loss: 0.14108/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36449\n",
      "\tPart 2 - fp_loss: 0.78646/75.00%, bp_loss: 0.91175/74.00%, hp_loss: 2.69164/31.00%, j_loss: 0.66551/78.00%, \n",
      "\t\tfr_loss: 0.13340/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18875\n",
      "\tPart 3 - fp_loss: 0.67123/81.00%, bp_loss: 0.77249/79.00%, hp_loss: 2.43105/37.00%, j_loss: 0.49708/83.00%, \n",
      "\t\tfr_loss: 0.10653/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47838\n",
      "\tPart 4 - fp_loss: 0.59178/83.00%, bp_loss: 0.80456/78.00%, hp_loss: 2.63229/32.00%, j_loss: 0.43558/86.00%, \n",
      "\t\tfr_loss: 0.08597/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55018\n",
      "\tTraining time elapsed: 301.33 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.89485/49.00%, bp_loss: 1.33451/59.00%, hp_loss: 3.04224/23.00%, j_loss: 1.56790/56.00%, \n",
      "\t\tfr_loss: 0.21779/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.05728\n",
      "\tPart 2 - fp_loss: 1.53523/60.00%, bp_loss: 1.23507/65.00%, hp_loss: 2.69829/30.00%, j_loss: 1.23509/63.00%, \n",
      "\t\tfr_loss: 0.16785/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.87154\n",
      "\tPart 3 - fp_loss: 1.26471/69.00%, bp_loss: 0.96178/73.00%, hp_loss: 2.21345/44.00%, j_loss: 0.77130/76.00%, \n",
      "\t\tfr_loss: 0.17770/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.38893\n",
      "\tPart 4 - fp_loss: 1.41701/70.00%, bp_loss: 0.94784/73.00%, hp_loss: 2.37066/40.00%, j_loss: 0.83938/75.00%, \n",
      "\t\tfr_loss: 0.17845/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75334\n",
      "\t`Validation time elapsed: 0.76 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.79007/53.00%, bp_loss: 1.46055/57.00%, hp_loss: 2.98645/25.00%, j_loss: 1.54011/57.00%, \n",
      "\t\tfr_loss: 0.23640/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.01358\n",
      "\tPart 2 - fp_loss: 1.57774/59.00%, bp_loss: 1.18209/66.00%, hp_loss: 2.68595/30.00%, j_loss: 1.20618/67.00%, \n",
      "\t\tfr_loss: 0.17270/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.82465\n",
      "\tPart 3 - fp_loss: 1.22232/70.00%, bp_loss: 0.92838/75.00%, hp_loss: 2.21583/45.00%, j_loss: 0.86151/78.00%, \n",
      "\t\tfr_loss: 0.17868/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40672\n",
      "\tPart 4 - fp_loss: 1.43385/68.00%, bp_loss: 0.96725/75.00%, hp_loss: 2.44611/40.00%, j_loss: 0.88017/77.00%, \n",
      "\t\tfr_loss: 0.19481/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92218\n",
      "\t`Validation time elapsed: 9.52 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 40.\n",
      "\n",
      "EPOCH 41\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.90068/74.00%, bp_loss: 1.22082/63.00%, hp_loss: 3.12388/21.00%, j_loss: 0.93039/74.00%, \n",
      "\t\tfr_loss: 0.12444/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30022\n",
      "\tPart 2 - fp_loss: 0.71523/79.00%, bp_loss: 0.94332/73.00%, hp_loss: 2.72585/31.00%, j_loss: 0.61938/80.00%, \n",
      "\t\tfr_loss: 0.12002/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.12379\n",
      "\tPart 3 - fp_loss: 0.65462/81.00%, bp_loss: 0.84282/75.00%, hp_loss: 2.37686/38.00%, j_loss: 0.55417/82.00%, \n",
      "\t\tfr_loss: 0.11824/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54672\n",
      "\tPart 4 - fp_loss: 0.59025/83.00%, bp_loss: 0.77581/78.00%, hp_loss: 2.59423/32.00%, j_loss: 0.41940/86.00%, \n",
      "\t\tfr_loss: 0.09212/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47182\n",
      "\tTraining time elapsed: 1.13 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.95194/71.00%, bp_loss: 1.21712/64.00%, hp_loss: 3.01400/23.00%, j_loss: 0.95492/74.00%, \n",
      "\t\tfr_loss: 0.13711/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.27509\n",
      "\tPart 2 - fp_loss: 0.71268/79.00%, bp_loss: 0.87931/75.00%, hp_loss: 2.77326/29.00%, j_loss: 0.60449/80.00%, \n",
      "\t\tfr_loss: 0.13518/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10492\n",
      "\tPart 3 - fp_loss: 0.69351/80.00%, bp_loss: 0.81860/76.00%, hp_loss: 2.44815/37.00%, j_loss: 0.49383/85.00%, \n",
      "\t\tfr_loss: 0.09636/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55045\n",
      "\tPart 4 - fp_loss: 0.63056/82.00%, bp_loss: 0.75485/77.00%, hp_loss: 2.69210/30.00%, j_loss: 0.42571/86.00%, \n",
      "\t\tfr_loss: 0.08855/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.59175\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.94893/71.00%, bp_loss: 1.29632/63.00%, hp_loss: 3.05348/22.00%, j_loss: 0.98707/73.00%, \n",
      "\t\tfr_loss: 0.13989/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.42569\n",
      "\tPart 2 - fp_loss: 0.72577/78.00%, bp_loss: 0.89615/75.00%, hp_loss: 2.66149/33.00%, j_loss: 0.59929/81.00%, \n",
      "\t\tfr_loss: 0.12853/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01122\n",
      "\tPart 3 - fp_loss: 0.68779/79.00%, bp_loss: 0.77037/78.00%, hp_loss: 2.32260/40.00%, j_loss: 0.49297/83.00%, \n",
      "\t\tfr_loss: 0.10843/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38217\n",
      "\tPart 4 - fp_loss: 0.59965/83.00%, bp_loss: 0.81819/77.00%, hp_loss: 2.59956/33.00%, j_loss: 0.42543/84.00%, \n",
      "\t\tfr_loss: 0.08779/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53063\n",
      "\tTraining time elapsed: 76.09 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.91875/73.00%, bp_loss: 1.32706/62.00%, hp_loss: 3.14201/21.00%, j_loss: 0.94826/74.00%, \n",
      "\t\tfr_loss: 0.13829/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47438\n",
      "\tPart 2 - fp_loss: 0.70984/77.00%, bp_loss: 0.92462/74.00%, hp_loss: 2.67418/34.00%, j_loss: 0.62016/81.00%, \n",
      "\t\tfr_loss: 0.14095/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06975\n",
      "\tPart 3 - fp_loss: 0.66164/80.00%, bp_loss: 0.76604/80.00%, hp_loss: 2.35070/39.00%, j_loss: 0.48163/85.00%, \n",
      "\t\tfr_loss: 0.09785/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35785\n",
      "\tPart 4 - fp_loss: 0.63291/82.00%, bp_loss: 0.78715/77.00%, hp_loss: 2.64628/32.00%, j_loss: 0.45736/85.00%, \n",
      "\t\tfr_loss: 0.09656/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62026\n",
      "\tTraining time elapsed: 113.61 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.92148/73.00%, bp_loss: 1.21897/65.00%, hp_loss: 3.03577/23.00%, j_loss: 0.89108/75.00%, \n",
      "\t\tfr_loss: 0.12014/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.18745\n",
      "\tPart 2 - fp_loss: 0.73749/78.00%, bp_loss: 0.87382/75.00%, hp_loss: 2.72826/31.00%, j_loss: 0.66236/80.00%, \n",
      "\t\tfr_loss: 0.12512/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.12705\n",
      "\tPart 3 - fp_loss: 0.65648/81.00%, bp_loss: 0.82443/77.00%, hp_loss: 2.36221/39.00%, j_loss: 0.50498/85.00%, \n",
      "\t\tfr_loss: 0.10448/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45257\n",
      "\tPart 4 - fp_loss: 0.58186/83.00%, bp_loss: 0.71790/79.00%, hp_loss: 2.52769/35.00%, j_loss: 0.41557/86.00%, \n",
      "\t\tfr_loss: 0.10276/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34578\n",
      "\tTraining time elapsed: 151.11 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.92330/74.00%, bp_loss: 1.24021/64.00%, hp_loss: 2.97754/24.00%, j_loss: 0.91346/75.00%, \n",
      "\t\tfr_loss: 0.14495/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19946\n",
      "\tPart 2 - fp_loss: 0.77535/77.00%, bp_loss: 0.89317/74.00%, hp_loss: 2.70666/32.00%, j_loss: 0.66283/80.00%, \n",
      "\t\tfr_loss: 0.12064/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.15865\n",
      "\tPart 3 - fp_loss: 0.70415/80.00%, bp_loss: 0.74792/79.00%, hp_loss: 2.34595/39.00%, j_loss: 0.47083/83.00%, \n",
      "\t\tfr_loss: 0.11226/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38111\n",
      "\tPart 4 - fp_loss: 0.63340/82.00%, bp_loss: 0.70702/79.00%, hp_loss: 2.59541/33.00%, j_loss: 0.45702/85.00%, \n",
      "\t\tfr_loss: 0.10841/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50126\n",
      "\tTraining time elapsed: 188.62 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.86135/74.00%, bp_loss: 1.18851/65.00%, hp_loss: 3.02387/25.00%, j_loss: 0.91279/76.00%, \n",
      "\t\tfr_loss: 0.13030/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11681\n",
      "\tPart 2 - fp_loss: 0.69265/78.00%, bp_loss: 0.83988/76.00%, hp_loss: 2.71750/31.00%, j_loss: 0.62185/81.00%, \n",
      "\t\tfr_loss: 0.14395/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01583\n",
      "\tPart 3 - fp_loss: 0.72824/79.00%, bp_loss: 0.75689/79.00%, hp_loss: 2.38355/38.00%, j_loss: 0.48802/84.00%, \n",
      "\t\tfr_loss: 0.11528/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47198\n",
      "\tPart 4 - fp_loss: 0.70421/80.00%, bp_loss: 0.72161/79.00%, hp_loss: 2.56289/33.00%, j_loss: 0.48328/85.00%, \n",
      "\t\tfr_loss: 0.09746/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56946\n",
      "\tTraining time elapsed: 226.13 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.84423/74.00%, bp_loss: 1.23475/63.00%, hp_loss: 2.99869/25.00%, j_loss: 0.87844/76.00%, \n",
      "\t\tfr_loss: 0.13657/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09269\n",
      "\tPart 2 - fp_loss: 0.70136/79.00%, bp_loss: 0.85539/75.00%, hp_loss: 2.63994/34.00%, j_loss: 0.61433/80.00%, \n",
      "\t\tfr_loss: 0.13204/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94307\n",
      "\tPart 3 - fp_loss: 0.72618/79.00%, bp_loss: 0.67082/82.00%, hp_loss: 2.39212/40.00%, j_loss: 0.47132/85.00%, \n",
      "\t\tfr_loss: 0.12275/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38319\n",
      "\tPart 4 - fp_loss: 0.54459/86.00%, bp_loss: 0.78389/78.00%, hp_loss: 2.60026/33.00%, j_loss: 0.36484/88.00%, \n",
      "\t\tfr_loss: 0.10266/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39623\n",
      "\tTraining time elapsed: 263.62 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.91066/71.00%, bp_loss: 1.23901/63.00%, hp_loss: 3.11857/20.00%, j_loss: 0.94579/73.00%, \n",
      "\t\tfr_loss: 0.13575/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.34978\n",
      "\tPart 2 - fp_loss: 0.77577/76.00%, bp_loss: 0.92649/73.00%, hp_loss: 2.76628/30.00%, j_loss: 0.70558/78.00%, \n",
      "\t\tfr_loss: 0.12139/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.29551\n",
      "\tPart 3 - fp_loss: 0.73589/79.00%, bp_loss: 0.81847/77.00%, hp_loss: 2.50726/34.00%, j_loss: 0.54637/84.00%, \n",
      "\t\tfr_loss: 0.11187/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71985\n",
      "\tPart 4 - fp_loss: 0.59295/83.00%, bp_loss: 0.71241/79.00%, hp_loss: 2.57974/34.00%, j_loss: 0.42890/87.00%, \n",
      "\t\tfr_loss: 0.09991/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41391\n",
      "\tTraining time elapsed: 301.12 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.99987/48.00%, bp_loss: 1.42049/58.00%, hp_loss: 3.00494/24.00%, j_loss: 1.61393/54.00%, \n",
      "\t\tfr_loss: 0.19916/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.23839\n",
      "\tPart 2 - fp_loss: 1.80943/58.00%, bp_loss: 1.21328/66.00%, hp_loss: 2.65344/31.00%, j_loss: 1.24943/62.00%, \n",
      "\t\tfr_loss: 0.20750/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.13308\n",
      "\tPart 3 - fp_loss: 1.29497/70.00%, bp_loss: 0.98288/73.00%, hp_loss: 2.22698/45.00%, j_loss: 0.76956/75.00%, \n",
      "\t\tfr_loss: 0.17620/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.45059\n",
      "\tPart 4 - fp_loss: 1.49954/68.00%, bp_loss: 1.03710/72.00%, hp_loss: 2.39116/41.00%, j_loss: 0.91704/73.00%, \n",
      "\t\tfr_loss: 0.17313/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01798\n",
      "\t`Validation time elapsed: 0.77 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.90815/52.00%, bp_loss: 1.35339/60.00%, hp_loss: 3.03564/24.00%, j_loss: 1.51811/56.00%, \n",
      "\t\tfr_loss: 0.22639/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.04168\n",
      "\tPart 2 - fp_loss: 1.63318/58.00%, bp_loss: 1.13002/67.00%, hp_loss: 2.71165/29.00%, j_loss: 1.16734/67.00%, \n",
      "\t\tfr_loss: 0.20159/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.84378\n",
      "\tPart 3 - fp_loss: 1.19628/70.00%, bp_loss: 0.85590/78.00%, hp_loss: 2.24752/43.00%, j_loss: 0.74169/80.00%, \n",
      "\t\tfr_loss: 0.18014/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.22153\n",
      "\tPart 4 - fp_loss: 1.43022/71.00%, bp_loss: 0.86848/78.00%, hp_loss: 2.45182/40.00%, j_loss: 0.75962/80.00%, \n",
      "\t\tfr_loss: 0.17222/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.68237\n",
      "\t`Validation time elapsed: 9.53 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 41.\n",
      "\n",
      "EPOCH 42\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.90813/72.00%, bp_loss: 1.20444/64.00%, hp_loss: 3.07268/24.00%, j_loss: 0.92747/73.00%, \n",
      "\t\tfr_loss: 0.13241/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24513\n",
      "\tPart 2 - fp_loss: 0.73353/78.00%, bp_loss: 0.90985/74.00%, hp_loss: 2.72707/32.00%, j_loss: 0.62567/80.00%, \n",
      "\t\tfr_loss: 0.13047/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.12659\n",
      "\tPart 3 - fp_loss: 0.63996/82.00%, bp_loss: 0.78831/79.00%, hp_loss: 2.34410/40.00%, j_loss: 0.45737/84.00%, \n",
      "\t\tfr_loss: 0.11012/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33986\n",
      "\tPart 4 - fp_loss: 0.52447/85.00%, bp_loss: 0.74952/78.00%, hp_loss: 2.51784/35.00%, j_loss: 0.39028/86.00%, \n",
      "\t\tfr_loss: 0.09858/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28069\n",
      "\tTraining time elapsed: 1.11 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.93499/72.00%, bp_loss: 1.25760/63.00%, hp_loss: 3.07698/22.00%, j_loss: 0.93256/72.00%, \n",
      "\t\tfr_loss: 0.13070/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33283\n",
      "\tPart 2 - fp_loss: 0.76642/76.00%, bp_loss: 0.82761/77.00%, hp_loss: 2.71901/32.00%, j_loss: 0.63009/81.00%, \n",
      "\t\tfr_loss: 0.14917/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09231\n",
      "\tPart 3 - fp_loss: 0.69064/81.00%, bp_loss: 0.77692/79.00%, hp_loss: 2.46596/38.00%, j_loss: 0.45097/85.00%, \n",
      "\t\tfr_loss: 0.12071/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50521\n",
      "\tPart 4 - fp_loss: 0.58988/83.00%, bp_loss: 0.76313/78.00%, hp_loss: 2.70446/32.00%, j_loss: 0.42334/86.00%, \n",
      "\t\tfr_loss: 0.09981/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58062\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.98036/70.00%, bp_loss: 1.27228/62.00%, hp_loss: 3.00151/25.00%, j_loss: 0.95352/74.00%, \n",
      "\t\tfr_loss: 0.15777/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36544\n",
      "\tPart 2 - fp_loss: 0.77214/78.00%, bp_loss: 0.86974/75.00%, hp_loss: 2.67029/33.00%, j_loss: 0.61066/80.00%, \n",
      "\t\tfr_loss: 0.14191/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06474\n",
      "\tPart 3 - fp_loss: 0.64815/81.00%, bp_loss: 0.86698/77.00%, hp_loss: 2.37626/39.00%, j_loss: 0.49611/85.00%, \n",
      "\t\tfr_loss: 0.10775/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.49524\n",
      "\tPart 4 - fp_loss: 0.59006/83.00%, bp_loss: 0.73389/79.00%, hp_loss: 2.58855/34.00%, j_loss: 0.43870/85.00%, \n",
      "\t\tfr_loss: 0.09700/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44820\n",
      "\tTraining time elapsed: 76.14 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.88697/74.00%, bp_loss: 1.25876/63.00%, hp_loss: 3.11487/21.00%, j_loss: 0.84784/76.00%, \n",
      "\t\tfr_loss: 0.13132/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23977\n",
      "\tPart 2 - fp_loss: 0.77795/78.00%, bp_loss: 0.85845/75.00%, hp_loss: 2.77426/30.00%, j_loss: 0.61699/80.00%, \n",
      "\t\tfr_loss: 0.12159/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.14924\n",
      "\tPart 3 - fp_loss: 0.69058/81.00%, bp_loss: 0.83440/77.00%, hp_loss: 2.45940/36.00%, j_loss: 0.48954/85.00%, \n",
      "\t\tfr_loss: 0.09647/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57038\n",
      "\tPart 4 - fp_loss: 0.63732/81.00%, bp_loss: 0.78217/77.00%, hp_loss: 2.60158/31.00%, j_loss: 0.45333/85.00%, \n",
      "\t\tfr_loss: 0.09692/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57131\n",
      "\tTraining time elapsed: 113.64 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.97859/70.00%, bp_loss: 1.28225/62.00%, hp_loss: 3.14022/19.00%, j_loss: 0.97390/72.00%, \n",
      "\t\tfr_loss: 0.13583/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51078\n",
      "\tPart 2 - fp_loss: 0.79721/76.00%, bp_loss: 0.83845/75.00%, hp_loss: 2.65393/33.00%, j_loss: 0.64699/79.00%, \n",
      "\t\tfr_loss: 0.13947/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.07605\n",
      "\tPart 3 - fp_loss: 0.66821/81.00%, bp_loss: 0.72931/80.00%, hp_loss: 2.35300/39.00%, j_loss: 0.44728/85.00%, \n",
      "\t\tfr_loss: 0.11832/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.31611\n",
      "\tPart 4 - fp_loss: 0.57978/83.00%, bp_loss: 0.73843/79.00%, hp_loss: 2.51673/35.00%, j_loss: 0.38137/86.00%, \n",
      "\t\tfr_loss: 0.07633/93.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.29264\n",
      "\tTraining time elapsed: 151.14 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.93428/73.00%, bp_loss: 1.29358/62.00%, hp_loss: 3.15588/21.00%, j_loss: 0.89984/76.00%, \n",
      "\t\tfr_loss: 0.12142/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.40501\n",
      "\tPart 2 - fp_loss: 0.71677/79.00%, bp_loss: 0.85767/74.00%, hp_loss: 2.72819/30.00%, j_loss: 0.63436/81.00%, \n",
      "\t\tfr_loss: 0.13531/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.07230\n",
      "\tPart 3 - fp_loss: 0.72657/79.00%, bp_loss: 0.79367/78.00%, hp_loss: 2.42310/37.00%, j_loss: 0.51412/81.00%, \n",
      "\t\tfr_loss: 0.12366/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58112\n",
      "\tPart 4 - fp_loss: 0.57799/83.00%, bp_loss: 0.76359/78.00%, hp_loss: 2.63752/32.00%, j_loss: 0.47785/84.00%, \n",
      "\t\tfr_loss: 0.10633/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56327\n",
      "\tTraining time elapsed: 188.65 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.92985/71.00%, bp_loss: 1.25185/64.00%, hp_loss: 3.06815/24.00%, j_loss: 0.94654/72.00%, \n",
      "\t\tfr_loss: 0.13604/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33243\n",
      "\tPart 2 - fp_loss: 0.76222/78.00%, bp_loss: 0.88582/73.00%, hp_loss: 2.67023/34.00%, j_loss: 0.66106/79.00%, \n",
      "\t\tfr_loss: 0.13573/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.11505\n",
      "\tPart 3 - fp_loss: 0.71856/80.00%, bp_loss: 0.76137/80.00%, hp_loss: 2.38441/39.00%, j_loss: 0.47424/85.00%, \n",
      "\t\tfr_loss: 0.11726/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45585\n",
      "\tPart 4 - fp_loss: 0.64406/81.00%, bp_loss: 0.76643/78.00%, hp_loss: 2.64485/33.00%, j_loss: 0.42114/85.00%, \n",
      "\t\tfr_loss: 0.10048/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57696\n",
      "\tTraining time elapsed: 226.15 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.96320/71.00%, bp_loss: 1.33624/59.00%, hp_loss: 3.12310/20.00%, j_loss: 1.01265/73.00%, \n",
      "\t\tfr_loss: 0.15166/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58685\n",
      "\tPart 2 - fp_loss: 0.76565/77.00%, bp_loss: 0.83749/75.00%, hp_loss: 2.71542/32.00%, j_loss: 0.64152/79.00%, \n",
      "\t\tfr_loss: 0.14664/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10671\n",
      "\tPart 3 - fp_loss: 0.71630/79.00%, bp_loss: 0.75978/79.00%, hp_loss: 2.44982/38.00%, j_loss: 0.49388/84.00%, \n",
      "\t\tfr_loss: 0.10515/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52493\n",
      "\tPart 4 - fp_loss: 0.64433/81.00%, bp_loss: 0.70738/80.00%, hp_loss: 2.59562/32.00%, j_loss: 0.41359/85.00%, \n",
      "\t\tfr_loss: 0.09143/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45235\n",
      "\tTraining time elapsed: 263.66 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.92255/73.00%, bp_loss: 1.18991/66.00%, hp_loss: 3.02674/22.00%, j_loss: 0.83526/76.00%, \n",
      "\t\tfr_loss: 0.12385/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09830\n",
      "\tPart 2 - fp_loss: 0.80683/76.00%, bp_loss: 0.86701/75.00%, hp_loss: 2.74523/31.00%, j_loss: 0.61697/80.00%, \n",
      "\t\tfr_loss: 0.13564/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.17168\n",
      "\tPart 3 - fp_loss: 0.68822/79.00%, bp_loss: 0.86026/76.00%, hp_loss: 2.48542/37.00%, j_loss: 0.52488/83.00%, \n",
      "\t\tfr_loss: 0.11170/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.67047\n",
      "\tPart 4 - fp_loss: 0.55503/84.00%, bp_loss: 0.79539/76.00%, hp_loss: 2.61125/34.00%, j_loss: 0.45004/84.00%, \n",
      "\t\tfr_loss: 0.07764/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48933\n",
      "\tTraining time elapsed: 301.17 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.91174/52.00%, bp_loss: 1.46949/56.00%, hp_loss: 3.00108/23.00%, j_loss: 1.59274/56.00%, \n",
      "\t\tfr_loss: 0.22525/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.20030\n",
      "\tPart 2 - fp_loss: 1.61869/61.00%, bp_loss: 1.13447/67.00%, hp_loss: 2.65675/31.00%, j_loss: 1.11885/64.00%, \n",
      "\t\tfr_loss: 0.19218/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.72094\n",
      "\tPart 3 - fp_loss: 1.13945/71.00%, bp_loss: 1.00321/74.00%, hp_loss: 2.19232/46.00%, j_loss: 0.81767/77.00%, \n",
      "\t\tfr_loss: 0.15794/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.31058\n",
      "\tPart 4 - fp_loss: 1.51603/69.00%, bp_loss: 0.95966/74.00%, hp_loss: 2.39700/40.00%, j_loss: 0.87322/74.00%, \n",
      "\t\tfr_loss: 0.17564/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92155\n",
      "\t`Validation time elapsed: 0.77 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.94266/52.00%, bp_loss: 1.37270/59.00%, hp_loss: 3.06706/23.00%, j_loss: 1.49860/57.00%, \n",
      "\t\tfr_loss: 0.20859/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.08961\n",
      "\tPart 2 - fp_loss: 1.83020/54.00%, bp_loss: 1.22246/65.00%, hp_loss: 2.72425/28.00%, j_loss: 1.33826/62.00%, \n",
      "\t\tfr_loss: 0.19607/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.31124\n",
      "\tPart 3 - fp_loss: 1.34536/68.00%, bp_loss: 0.91202/76.00%, hp_loss: 2.35284/39.00%, j_loss: 0.73672/79.00%, \n",
      "\t\tfr_loss: 0.17745/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.52439\n",
      "\tPart 4 - fp_loss: 1.44791/70.00%, bp_loss: 0.89050/76.00%, hp_loss: 2.44521/36.00%, j_loss: 0.78919/79.00%, \n",
      "\t\tfr_loss: 0.17881/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.75163\n",
      "\t`Validation time elapsed: 9.55 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 42.\n",
      "\n",
      "EPOCH 43\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.91018/74.00%, bp_loss: 1.39969/57.00%, hp_loss: 3.09216/21.00%, j_loss: 1.00695/73.00%, \n",
      "\t\tfr_loss: 0.13124/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.54021\n",
      "\tPart 2 - fp_loss: 0.67548/80.00%, bp_loss: 0.84233/75.00%, hp_loss: 2.69955/33.00%, j_loss: 0.61819/80.00%, \n",
      "\t\tfr_loss: 0.11743/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.95299\n",
      "\tPart 3 - fp_loss: 0.67038/81.00%, bp_loss: 0.95524/73.00%, hp_loss: 2.40992/38.00%, j_loss: 0.55032/82.00%, \n",
      "\t\tfr_loss: 0.09548/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68134\n",
      "\tPart 4 - fp_loss: 0.51823/85.00%, bp_loss: 0.78761/78.00%, hp_loss: 2.55588/36.00%, j_loss: 0.41374/85.00%, \n",
      "\t\tfr_loss: 0.10396/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37941\n",
      "\tTraining time elapsed: 1.12 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.97162/71.00%, bp_loss: 1.25158/64.00%, hp_loss: 3.06283/24.00%, j_loss: 0.95495/73.00%, \n",
      "\t\tfr_loss: 0.17488/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41586\n",
      "\tPart 2 - fp_loss: 0.73969/79.00%, bp_loss: 0.95180/73.00%, hp_loss: 2.75937/31.00%, j_loss: 0.60450/80.00%, \n",
      "\t\tfr_loss: 0.14549/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.20084\n",
      "\tPart 3 - fp_loss: 0.65183/80.00%, bp_loss: 0.77487/79.00%, hp_loss: 2.39487/38.00%, j_loss: 0.51813/85.00%, \n",
      "\t\tfr_loss: 0.12291/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46261\n",
      "\tPart 4 - fp_loss: 0.57102/82.00%, bp_loss: 0.75816/79.00%, hp_loss: 2.62555/33.00%, j_loss: 0.43432/87.00%, \n",
      "\t\tfr_loss: 0.09873/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48777\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.90191/72.00%, bp_loss: 1.30059/60.00%, hp_loss: 3.09617/22.00%, j_loss: 0.95620/74.00%, \n",
      "\t\tfr_loss: 0.13184/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.38671\n",
      "\tPart 2 - fp_loss: 0.67336/81.00%, bp_loss: 0.87496/74.00%, hp_loss: 2.69806/32.00%, j_loss: 0.55440/81.00%, \n",
      "\t\tfr_loss: 0.12009/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92087\n",
      "\tPart 3 - fp_loss: 0.67477/80.00%, bp_loss: 0.74773/79.00%, hp_loss: 2.32531/38.00%, j_loss: 0.44125/84.00%, \n",
      "\t\tfr_loss: 0.11153/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.30061\n",
      "\tPart 4 - fp_loss: 0.64972/81.00%, bp_loss: 0.77535/78.00%, hp_loss: 2.58364/33.00%, j_loss: 0.49428/85.00%, \n",
      "\t\tfr_loss: 0.10181/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60480\n",
      "\tTraining time elapsed: 76.15 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.90713/73.00%, bp_loss: 1.29057/62.00%, hp_loss: 3.09379/22.00%, j_loss: 0.88369/75.00%, \n",
      "\t\tfr_loss: 0.14112/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31629\n",
      "\tPart 2 - fp_loss: 0.75012/78.00%, bp_loss: 0.90276/74.00%, hp_loss: 2.74799/32.00%, j_loss: 0.66607/81.00%, \n",
      "\t\tfr_loss: 0.13324/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.20018\n",
      "\tPart 3 - fp_loss: 0.73898/80.00%, bp_loss: 0.69496/80.00%, hp_loss: 2.45877/37.00%, j_loss: 0.49824/84.00%, \n",
      "\t\tfr_loss: 0.11395/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50491\n",
      "\tPart 4 - fp_loss: 0.56989/83.00%, bp_loss: 0.73921/78.00%, hp_loss: 2.58248/34.00%, j_loss: 0.41976/87.00%, \n",
      "\t\tfr_loss: 0.08168/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39301\n",
      "\tTraining time elapsed: 113.67 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.92051/74.00%, bp_loss: 1.28948/61.00%, hp_loss: 3.09084/22.00%, j_loss: 0.92117/73.00%, \n",
      "\t\tfr_loss: 0.15604/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.37805\n",
      "\tPart 2 - fp_loss: 0.72683/80.00%, bp_loss: 0.82922/76.00%, hp_loss: 2.71622/33.00%, j_loss: 0.59402/81.00%, \n",
      "\t\tfr_loss: 0.12832/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.99462\n",
      "\tPart 3 - fp_loss: 0.70513/79.00%, bp_loss: 0.75688/78.00%, hp_loss: 2.43133/36.00%, j_loss: 0.49537/84.00%, \n",
      "\t\tfr_loss: 0.11003/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.49873\n",
      "\tPart 4 - fp_loss: 0.60257/82.00%, bp_loss: 0.76143/77.00%, hp_loss: 2.58371/33.00%, j_loss: 0.45742/84.00%, \n",
      "\t\tfr_loss: 0.10310/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50824\n",
      "\tTraining time elapsed: 151.19 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.97989/70.00%, bp_loss: 1.27977/63.00%, hp_loss: 3.09847/21.00%, j_loss: 0.99516/72.00%, \n",
      "\t\tfr_loss: 0.13729/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.49058\n",
      "\tPart 2 - fp_loss: 0.76077/78.00%, bp_loss: 0.89270/75.00%, hp_loss: 2.75155/31.00%, j_loss: 0.65316/80.00%, \n",
      "\t\tfr_loss: 0.12968/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18787\n",
      "\tPart 3 - fp_loss: 0.77020/79.00%, bp_loss: 0.79227/77.00%, hp_loss: 2.44036/38.00%, j_loss: 0.54059/83.00%, \n",
      "\t\tfr_loss: 0.10420/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64763\n",
      "\tPart 4 - fp_loss: 0.60273/83.00%, bp_loss: 0.78744/77.00%, hp_loss: 2.67213/32.00%, j_loss: 0.42621/86.00%, \n",
      "\t\tfr_loss: 0.09464/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58314\n",
      "\tTraining time elapsed: 188.71 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.91923/74.00%, bp_loss: 1.24200/63.00%, hp_loss: 3.05589/25.00%, j_loss: 0.89929/75.00%, \n",
      "\t\tfr_loss: 0.13992/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25632\n",
      "\tPart 2 - fp_loss: 0.75793/78.00%, bp_loss: 0.87196/75.00%, hp_loss: 2.67528/34.00%, j_loss: 0.64750/80.00%, \n",
      "\t\tfr_loss: 0.14222/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09489\n",
      "\tPart 3 - fp_loss: 0.75935/80.00%, bp_loss: 0.68970/80.00%, hp_loss: 2.41671/37.00%, j_loss: 0.48428/85.00%, \n",
      "\t\tfr_loss: 0.10950/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45955\n",
      "\tPart 4 - fp_loss: 0.64845/82.00%, bp_loss: 0.73159/78.00%, hp_loss: 2.55943/34.00%, j_loss: 0.44340/86.00%, \n",
      "\t\tfr_loss: 0.08451/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46739\n",
      "\tTraining time elapsed: 226.23 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 1.00296/72.00%, bp_loss: 1.22981/65.00%, hp_loss: 3.02105/24.00%, j_loss: 0.91327/73.00%, \n",
      "\t\tfr_loss: 0.14865/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31574\n",
      "\tPart 2 - fp_loss: 0.74337/77.00%, bp_loss: 0.82226/76.00%, hp_loss: 2.72140/32.00%, j_loss: 0.59800/80.00%, \n",
      "\t\tfr_loss: 0.13337/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01841\n",
      "\tPart 3 - fp_loss: 0.68155/80.00%, bp_loss: 0.77805/78.00%, hp_loss: 2.41643/38.00%, j_loss: 0.47972/85.00%, \n",
      "\t\tfr_loss: 0.11832/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47407\n",
      "\tPart 4 - fp_loss: 0.66537/81.00%, bp_loss: 0.73754/79.00%, hp_loss: 2.60602/32.00%, j_loss: 0.45195/85.00%, \n",
      "\t\tfr_loss: 0.10559/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56647\n",
      "\tTraining time elapsed: 263.75 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.86431/75.00%, bp_loss: 1.28656/62.00%, hp_loss: 3.06791/23.00%, j_loss: 0.87978/75.00%, \n",
      "\t\tfr_loss: 0.14431/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24287\n",
      "\tPart 2 - fp_loss: 0.78726/77.00%, bp_loss: 0.85738/74.00%, hp_loss: 2.65225/34.00%, j_loss: 0.66257/79.00%, \n",
      "\t\tfr_loss: 0.13888/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09834\n",
      "\tPart 3 - fp_loss: 0.68491/80.00%, bp_loss: 0.79467/79.00%, hp_loss: 2.33957/40.00%, j_loss: 0.51752/84.00%, \n",
      "\t\tfr_loss: 0.11281/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44948\n",
      "\tPart 4 - fp_loss: 0.59448/81.00%, bp_loss: 0.75047/78.00%, hp_loss: 2.56865/36.00%, j_loss: 0.43301/85.00%, \n",
      "\t\tfr_loss: 0.09688/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44350\n",
      "\tTraining time elapsed: 301.26 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.88265/51.00%, bp_loss: 1.44663/58.00%, hp_loss: 3.03752/23.00%, j_loss: 1.51835/57.00%, \n",
      "\t\tfr_loss: 0.21739/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.10255\n",
      "\tPart 2 - fp_loss: 1.65178/57.00%, bp_loss: 1.16721/67.00%, hp_loss: 2.68290/30.00%, j_loss: 1.19906/64.00%, \n",
      "\t\tfr_loss: 0.19690/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.89785\n",
      "\tPart 3 - fp_loss: 1.25593/69.00%, bp_loss: 1.01619/72.00%, hp_loss: 2.24093/43.00%, j_loss: 0.91698/75.00%, \n",
      "\t\tfr_loss: 0.17966/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.60968\n",
      "\tPart 4 - fp_loss: 1.55096/67.00%, bp_loss: 1.06234/72.00%, hp_loss: 2.41096/39.00%, j_loss: 0.92247/73.00%, \n",
      "\t\tfr_loss: 0.16895/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11569\n",
      "\t`Validation time elapsed: 0.77 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.90361/51.00%, bp_loss: 1.38387/59.00%, hp_loss: 3.06776/23.00%, j_loss: 1.52026/57.00%, \n",
      "\t\tfr_loss: 0.20120/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.07671\n",
      "\tPart 2 - fp_loss: 1.65501/59.00%, bp_loss: 1.15537/68.00%, hp_loss: 2.80712/29.00%, j_loss: 1.15319/67.00%, \n",
      "\t\tfr_loss: 0.18750/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.95819\n",
      "\tPart 3 - fp_loss: 1.27328/69.00%, bp_loss: 0.88950/75.00%, hp_loss: 2.31295/43.00%, j_loss: 0.80053/79.00%, \n",
      "\t\tfr_loss: 0.17196/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44823\n",
      "\tPart 4 - fp_loss: 1.44355/69.00%, bp_loss: 1.03016/73.00%, hp_loss: 2.44763/37.00%, j_loss: 0.84052/78.00%, \n",
      "\t\tfr_loss: 0.16529/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92715\n",
      "\t`Validation time elapsed: 9.54 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 43.\n",
      "\n",
      "EPOCH 44\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.90489/74.00%, bp_loss: 1.21689/63.00%, hp_loss: 3.05567/22.00%, j_loss: 0.87049/75.00%, \n",
      "\t\tfr_loss: 0.10721/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15516\n",
      "\tPart 2 - fp_loss: 0.73783/79.00%, bp_loss: 0.94998/72.00%, hp_loss: 2.76209/31.00%, j_loss: 0.63037/78.00%, \n",
      "\t\tfr_loss: 0.12294/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.20320\n",
      "\tPart 3 - fp_loss: 0.60421/82.00%, bp_loss: 0.85893/76.00%, hp_loss: 2.45178/37.00%, j_loss: 0.51521/83.00%, \n",
      "\t\tfr_loss: 0.09212/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52226\n",
      "\tPart 4 - fp_loss: 0.61693/84.00%, bp_loss: 0.80676/77.00%, hp_loss: 2.57559/34.00%, j_loss: 0.43949/86.00%, \n",
      "\t\tfr_loss: 0.09180/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53057\n",
      "\tTraining time elapsed: 1.13 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.97620/70.00%, bp_loss: 1.28258/63.00%, hp_loss: 3.10709/21.00%, j_loss: 0.95584/75.00%, \n",
      "\t\tfr_loss: 0.12968/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.45139\n",
      "\tPart 2 - fp_loss: 0.66091/81.00%, bp_loss: 0.89580/74.00%, hp_loss: 2.67409/33.00%, j_loss: 0.57053/81.00%, \n",
      "\t\tfr_loss: 0.12771/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92904\n",
      "\tPart 3 - fp_loss: 0.65212/81.00%, bp_loss: 0.77346/79.00%, hp_loss: 2.42147/39.00%, j_loss: 0.47085/83.00%, \n",
      "\t\tfr_loss: 0.09549/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41340\n",
      "\tPart 4 - fp_loss: 0.61889/82.00%, bp_loss: 0.78053/78.00%, hp_loss: 2.57469/33.00%, j_loss: 0.44769/83.00%, \n",
      "\t\tfr_loss: 0.09751/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51931\n",
      "\tTraining time elapsed: 38.65 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.85201/75.00%, bp_loss: 1.23340/63.00%, hp_loss: 3.04871/23.00%, j_loss: 0.86515/75.00%, \n",
      "\t\tfr_loss: 0.14458/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14385\n",
      "\tPart 2 - fp_loss: 0.73953/78.00%, bp_loss: 0.86456/76.00%, hp_loss: 2.74823/30.00%, j_loss: 0.60309/78.00%, \n",
      "\t\tfr_loss: 0.15960/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.11501\n",
      "\tPart 3 - fp_loss: 0.64867/81.00%, bp_loss: 0.70854/80.00%, hp_loss: 2.45835/37.00%, j_loss: 0.46414/84.00%, \n",
      "\t\tfr_loss: 0.10614/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38584\n",
      "\tPart 4 - fp_loss: 0.56539/84.00%, bp_loss: 0.76498/78.00%, hp_loss: 2.59269/34.00%, j_loss: 0.41420/87.00%, \n",
      "\t\tfr_loss: 0.08213/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41939\n",
      "\tTraining time elapsed: 76.18 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.95298/70.00%, bp_loss: 1.31044/60.00%, hp_loss: 3.08678/22.00%, j_loss: 1.00065/72.00%, \n",
      "\t\tfr_loss: 0.13465/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.48551\n",
      "\tPart 2 - fp_loss: 0.76199/77.00%, bp_loss: 0.84792/75.00%, hp_loss: 2.73485/29.00%, j_loss: 0.68455/79.00%, \n",
      "\t\tfr_loss: 0.14822/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.17754\n",
      "\tPart 3 - fp_loss: 0.64425/81.00%, bp_loss: 0.75674/79.00%, hp_loss: 2.34678/40.00%, j_loss: 0.48510/85.00%, \n",
      "\t\tfr_loss: 0.11050/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34337\n",
      "\tPart 4 - fp_loss: 0.53241/84.00%, bp_loss: 0.70761/80.00%, hp_loss: 2.50576/37.00%, j_loss: 0.35861/87.00%, \n",
      "\t\tfr_loss: 0.08366/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.18804\n",
      "\tTraining time elapsed: 113.70 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.89688/74.00%, bp_loss: 1.24487/63.00%, hp_loss: 3.09118/22.00%, j_loss: 0.89556/74.00%, \n",
      "\t\tfr_loss: 0.13493/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26343\n",
      "\tPart 2 - fp_loss: 0.73736/79.00%, bp_loss: 0.89054/74.00%, hp_loss: 2.73399/31.00%, j_loss: 0.61115/80.00%, \n",
      "\t\tfr_loss: 0.13662/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10965\n",
      "\tPart 3 - fp_loss: 0.65914/80.00%, bp_loss: 0.67998/81.00%, hp_loss: 2.31382/40.00%, j_loss: 0.43879/85.00%, \n",
      "\t\tfr_loss: 0.11079/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.20252\n",
      "\tPart 4 - fp_loss: 0.56033/84.00%, bp_loss: 0.69892/79.00%, hp_loss: 2.51723/34.00%, j_loss: 0.41425/87.00%, \n",
      "\t\tfr_loss: 0.10660/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.29732\n",
      "\tTraining time elapsed: 151.19 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.90191/72.00%, bp_loss: 1.18117/64.00%, hp_loss: 3.08736/22.00%, j_loss: 0.90604/74.00%, \n",
      "\t\tfr_loss: 0.15609/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23257\n",
      "\tPart 2 - fp_loss: 0.72937/77.00%, bp_loss: 0.83708/74.00%, hp_loss: 2.71222/32.00%, j_loss: 0.64808/80.00%, \n",
      "\t\tfr_loss: 0.13271/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05946\n",
      "\tPart 3 - fp_loss: 0.61989/82.00%, bp_loss: 0.71012/81.00%, hp_loss: 2.37622/39.00%, j_loss: 0.42049/86.00%, \n",
      "\t\tfr_loss: 0.10659/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.23332\n",
      "\tPart 4 - fp_loss: 0.51840/86.00%, bp_loss: 0.79498/78.00%, hp_loss: 2.54122/36.00%, j_loss: 0.39871/87.00%, \n",
      "\t\tfr_loss: 0.10038/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35368\n",
      "\tTraining time elapsed: 188.71 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.90913/72.00%, bp_loss: 1.18600/65.00%, hp_loss: 3.03947/24.00%, j_loss: 0.85739/73.00%, \n",
      "\t\tfr_loss: 0.13075/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.12274\n",
      "\tPart 2 - fp_loss: 0.74164/79.00%, bp_loss: 0.89080/73.00%, hp_loss: 2.68974/33.00%, j_loss: 0.61091/77.00%, \n",
      "\t\tfr_loss: 0.14512/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.07822\n",
      "\tPart 3 - fp_loss: 0.64988/81.00%, bp_loss: 0.73513/80.00%, hp_loss: 2.44002/37.00%, j_loss: 0.44634/83.00%, \n",
      "\t\tfr_loss: 0.09935/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37071\n",
      "\tPart 4 - fp_loss: 0.58562/84.00%, bp_loss: 0.79310/76.00%, hp_loss: 2.65281/31.00%, j_loss: 0.38803/87.00%, \n",
      "\t\tfr_loss: 0.09549/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51505\n",
      "\tTraining time elapsed: 226.22 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.92941/73.00%, bp_loss: 1.28913/61.00%, hp_loss: 3.13323/20.00%, j_loss: 0.93380/76.00%, \n",
      "\t\tfr_loss: 0.15790/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.44347\n",
      "\tPart 2 - fp_loss: 0.78125/76.00%, bp_loss: 0.92095/73.00%, hp_loss: 2.72870/31.00%, j_loss: 0.68851/79.00%, \n",
      "\t\tfr_loss: 0.11635/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.23576\n",
      "\tPart 3 - fp_loss: 0.68725/80.00%, bp_loss: 0.73079/80.00%, hp_loss: 2.35394/38.00%, j_loss: 0.44945/85.00%, \n",
      "\t\tfr_loss: 0.09942/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32084\n",
      "\tPart 4 - fp_loss: 0.54319/84.00%, bp_loss: 0.72991/79.00%, hp_loss: 2.51612/33.00%, j_loss: 0.41226/86.00%, \n",
      "\t\tfr_loss: 0.08451/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28600\n",
      "\tTraining time elapsed: 263.74 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.96400/72.00%, bp_loss: 1.32627/61.00%, hp_loss: 3.11125/21.00%, j_loss: 0.99524/72.00%, \n",
      "\t\tfr_loss: 0.14262/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.53939\n",
      "\tPart 2 - fp_loss: 0.73399/79.00%, bp_loss: 0.84375/75.00%, hp_loss: 2.72189/33.00%, j_loss: 0.58425/83.00%, \n",
      "\t\tfr_loss: 0.13878/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02267\n",
      "\tPart 3 - fp_loss: 0.69184/81.00%, bp_loss: 0.74236/79.00%, hp_loss: 2.42464/37.00%, j_loss: 0.45428/85.00%, \n",
      "\t\tfr_loss: 0.10721/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42034\n",
      "\tPart 4 - fp_loss: 0.58142/84.00%, bp_loss: 0.80646/77.00%, hp_loss: 2.56937/33.00%, j_loss: 0.45653/84.00%, \n",
      "\t\tfr_loss: 0.09296/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50674\n",
      "\tTraining time elapsed: 301.27 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.77115/53.00%, bp_loss: 1.35385/59.00%, hp_loss: 3.07011/22.00%, j_loss: 1.43919/56.00%, \n",
      "\t\tfr_loss: 0.22554/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.85984\n",
      "\tPart 2 - fp_loss: 1.76112/58.00%, bp_loss: 1.17467/67.00%, hp_loss: 2.77192/27.00%, j_loss: 1.23044/63.00%, \n",
      "\t\tfr_loss: 0.19145/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.12958\n",
      "\tPart 3 - fp_loss: 1.34180/69.00%, bp_loss: 1.02294/73.00%, hp_loss: 2.34492/41.00%, j_loss: 0.85409/76.00%, \n",
      "\t\tfr_loss: 0.16447/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.72822\n",
      "\tPart 4 - fp_loss: 1.52563/68.00%, bp_loss: 1.06886/72.00%, hp_loss: 2.46603/39.00%, j_loss: 0.88815/72.00%, \n",
      "\t\tfr_loss: 0.15130/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09997\n",
      "\t`Validation time elapsed: 0.76 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.96277/48.00%, bp_loss: 1.45409/57.00%, hp_loss: 3.03305/23.00%, j_loss: 1.64624/52.00%, \n",
      "\t\tfr_loss: 0.22993/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.32607\n",
      "\tPart 2 - fp_loss: 1.62243/62.00%, bp_loss: 1.12528/68.00%, hp_loss: 2.70496/30.00%, j_loss: 1.10898/69.00%, \n",
      "\t\tfr_loss: 0.19209/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.75374\n",
      "\tPart 3 - fp_loss: 1.22244/69.00%, bp_loss: 0.93733/75.00%, hp_loss: 2.24012/46.00%, j_loss: 0.83911/78.00%, \n",
      "\t\tfr_loss: 0.16043/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.39943\n",
      "\tPart 4 - fp_loss: 1.46793/69.00%, bp_loss: 0.92186/75.00%, hp_loss: 2.39039/40.00%, j_loss: 0.84635/77.00%, \n",
      "\t\tfr_loss: 0.15822/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.78475\n",
      "\t`Validation time elapsed: 9.51 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 44.\n",
      "\n",
      "EPOCH 45\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.89108/73.00%, bp_loss: 1.20712/63.00%, hp_loss: 3.14260/20.00%, j_loss: 0.90747/72.00%, \n",
      "\t\tfr_loss: 0.13188/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.28015\n",
      "\tPart 2 - fp_loss: 0.70242/79.00%, bp_loss: 0.91047/73.00%, hp_loss: 2.73933/31.00%, j_loss: 0.62560/80.00%, \n",
      "\t\tfr_loss: 0.12156/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09937\n",
      "\tPart 3 - fp_loss: 0.68200/80.00%, bp_loss: 0.86744/78.00%, hp_loss: 2.43855/37.00%, j_loss: 0.51001/84.00%, \n",
      "\t\tfr_loss: 0.11100/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60900\n",
      "\tPart 4 - fp_loss: 0.55140/85.00%, bp_loss: 0.82962/76.00%, hp_loss: 2.64038/31.00%, j_loss: 0.44033/86.00%, \n",
      "\t\tfr_loss: 0.08487/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54660\n",
      "\tTraining time elapsed: 1.12 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.85349/74.00%, bp_loss: 1.24487/64.00%, hp_loss: 3.06149/23.00%, j_loss: 0.88516/73.00%, \n",
      "\t\tfr_loss: 0.15675/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.20176\n",
      "\tPart 2 - fp_loss: 0.74350/78.00%, bp_loss: 0.81475/76.00%, hp_loss: 2.72012/32.00%, j_loss: 0.61439/80.00%, \n",
      "\t\tfr_loss: 0.12903/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02178\n",
      "\tPart 3 - fp_loss: 0.71410/81.00%, bp_loss: 0.75700/79.00%, hp_loss: 2.45184/36.00%, j_loss: 0.45510/85.00%, \n",
      "\t\tfr_loss: 0.10348/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48152\n",
      "\tPart 4 - fp_loss: 0.64726/80.00%, bp_loss: 0.80631/78.00%, hp_loss: 2.65366/31.00%, j_loss: 0.45391/85.00%, \n",
      "\t\tfr_loss: 0.10168/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.66281\n",
      "\tTraining time elapsed: 38.60 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.99239/71.00%, bp_loss: 1.20986/62.00%, hp_loss: 3.10663/22.00%, j_loss: 0.95120/72.00%, \n",
      "\t\tfr_loss: 0.12951/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.38958\n",
      "\tPart 2 - fp_loss: 0.73562/80.00%, bp_loss: 0.82254/76.00%, hp_loss: 2.68110/34.00%, j_loss: 0.58119/82.00%, \n",
      "\t\tfr_loss: 0.12182/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94227\n",
      "\tPart 3 - fp_loss: 0.69956/81.00%, bp_loss: 0.72879/80.00%, hp_loss: 2.33223/40.00%, j_loss: 0.46784/84.00%, \n",
      "\t\tfr_loss: 0.10886/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33728\n",
      "\tPart 4 - fp_loss: 0.55281/84.00%, bp_loss: 0.76493/79.00%, hp_loss: 2.66158/30.00%, j_loss: 0.37897/87.00%, \n",
      "\t\tfr_loss: 0.09187/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45017\n",
      "\tTraining time elapsed: 76.11 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.98015/72.00%, bp_loss: 1.19592/64.00%, hp_loss: 3.07662/21.00%, j_loss: 0.92131/74.00%, \n",
      "\t\tfr_loss: 0.13458/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30858\n",
      "\tPart 2 - fp_loss: 0.74578/79.00%, bp_loss: 0.81686/76.00%, hp_loss: 2.68201/32.00%, j_loss: 0.56585/80.00%, \n",
      "\t\tfr_loss: 0.12983/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94033\n",
      "\tPart 3 - fp_loss: 0.68244/79.00%, bp_loss: 0.78117/79.00%, hp_loss: 2.41611/38.00%, j_loss: 0.55164/83.00%, \n",
      "\t\tfr_loss: 0.12357/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55493\n",
      "\tPart 4 - fp_loss: 0.58985/83.00%, bp_loss: 0.75513/78.00%, hp_loss: 2.68924/31.00%, j_loss: 0.40508/87.00%, \n",
      "\t\tfr_loss: 0.08477/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52407\n",
      "\tTraining time elapsed: 113.60 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.82949/76.00%, bp_loss: 1.23599/65.00%, hp_loss: 3.07258/23.00%, j_loss: 0.82357/75.00%, \n",
      "\t\tfr_loss: 0.14812/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.10976\n",
      "\tPart 2 - fp_loss: 0.67525/79.00%, bp_loss: 0.86444/75.00%, hp_loss: 2.68949/34.00%, j_loss: 0.57451/82.00%, \n",
      "\t\tfr_loss: 0.13751/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94120\n",
      "\tPart 3 - fp_loss: 0.67026/82.00%, bp_loss: 0.81331/78.00%, hp_loss: 2.43906/37.00%, j_loss: 0.43951/87.00%, \n",
      "\t\tfr_loss: 0.11363/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47577\n",
      "\tPart 4 - fp_loss: 0.58001/83.00%, bp_loss: 0.80133/76.00%, hp_loss: 2.61191/32.00%, j_loss: 0.44374/85.00%, \n",
      "\t\tfr_loss: 0.10230/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53930\n",
      "\tTraining time elapsed: 151.12 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.91373/73.00%, bp_loss: 1.24475/63.00%, hp_loss: 3.09235/22.00%, j_loss: 0.90328/75.00%, \n",
      "\t\tfr_loss: 0.14302/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29712\n",
      "\tPart 2 - fp_loss: 0.76236/77.00%, bp_loss: 0.92448/73.00%, hp_loss: 2.71341/33.00%, j_loss: 0.62735/81.00%, \n",
      "\t\tfr_loss: 0.12559/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.15317\n",
      "\tPart 3 - fp_loss: 0.67095/81.00%, bp_loss: 0.86680/77.00%, hp_loss: 2.41285/36.00%, j_loss: 0.50925/83.00%, \n",
      "\t\tfr_loss: 0.11075/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57060\n",
      "\tPart 4 - fp_loss: 0.58230/82.00%, bp_loss: 0.77087/77.00%, hp_loss: 2.59753/33.00%, j_loss: 0.41325/85.00%, \n",
      "\t\tfr_loss: 0.09801/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46195\n",
      "\tTraining time elapsed: 188.62 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.92242/74.00%, bp_loss: 1.28277/63.00%, hp_loss: 3.05129/22.00%, j_loss: 0.90165/75.00%, \n",
      "\t\tfr_loss: 0.14094/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29907\n",
      "\tPart 2 - fp_loss: 0.79274/77.00%, bp_loss: 0.94021/74.00%, hp_loss: 2.80176/30.00%, j_loss: 0.68162/79.00%, \n",
      "\t\tfr_loss: 0.13490/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.35123\n",
      "\tPart 3 - fp_loss: 0.73047/78.00%, bp_loss: 0.74529/79.00%, hp_loss: 2.45994/37.00%, j_loss: 0.52491/85.00%, \n",
      "\t\tfr_loss: 0.12601/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58661\n",
      "\tPart 4 - fp_loss: 0.58581/84.00%, bp_loss: 0.68789/80.00%, hp_loss: 2.55942/35.00%, j_loss: 0.33780/89.00%, \n",
      "\t\tfr_loss: 0.11514/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28606\n",
      "\tTraining time elapsed: 226.09 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.89796/72.00%, bp_loss: 1.24399/64.00%, hp_loss: 3.03332/24.00%, j_loss: 0.91178/74.00%, \n",
      "\t\tfr_loss: 0.14717/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23422\n",
      "\tPart 2 - fp_loss: 0.79897/77.00%, bp_loss: 0.85286/76.00%, hp_loss: 2.69699/33.00%, j_loss: 0.60885/80.00%, \n",
      "\t\tfr_loss: 0.13274/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09042\n",
      "\tPart 3 - fp_loss: 0.69318/81.00%, bp_loss: 0.67393/81.00%, hp_loss: 2.33398/40.00%, j_loss: 0.50340/84.00%, \n",
      "\t\tfr_loss: 0.10255/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.30704\n",
      "\tPart 4 - fp_loss: 0.59473/83.00%, bp_loss: 0.67083/81.00%, hp_loss: 2.65514/32.00%, j_loss: 0.40574/86.00%, \n",
      "\t\tfr_loss: 0.09199/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41842\n",
      "\tTraining time elapsed: 263.59 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.94624/73.00%, bp_loss: 1.21494/64.00%, hp_loss: 3.09432/23.00%, j_loss: 0.91300/75.00%, \n",
      "\t\tfr_loss: 0.12802/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29652\n",
      "\tPart 2 - fp_loss: 0.67165/81.00%, bp_loss: 0.91288/73.00%, hp_loss: 2.70957/32.00%, j_loss: 0.57270/82.00%, \n",
      "\t\tfr_loss: 0.14674/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01355\n",
      "\tPart 3 - fp_loss: 0.67945/80.00%, bp_loss: 0.73997/80.00%, hp_loss: 2.44590/37.00%, j_loss: 0.43719/86.00%, \n",
      "\t\tfr_loss: 0.11471/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41723\n",
      "\tPart 4 - fp_loss: 0.55984/82.00%, bp_loss: 0.78161/78.00%, hp_loss: 2.62223/32.00%, j_loss: 0.43416/85.00%, \n",
      "\t\tfr_loss: 0.10734/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50517\n",
      "\tTraining time elapsed: 301.09 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.97313/49.00%, bp_loss: 1.37046/57.00%, hp_loss: 3.06160/22.00%, j_loss: 1.63770/53.00%, \n",
      "\t\tfr_loss: 0.21294/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.25584\n",
      "\tPart 2 - fp_loss: 1.75496/59.00%, bp_loss: 1.19308/63.00%, hp_loss: 2.75002/29.00%, j_loss: 1.33475/63.00%, \n",
      "\t\tfr_loss: 0.19357/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.22640\n",
      "\tPart 3 - fp_loss: 1.30645/70.00%, bp_loss: 0.92899/74.00%, hp_loss: 2.27679/41.00%, j_loss: 0.85904/75.00%, \n",
      "\t\tfr_loss: 0.18080/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55207\n",
      "\tPart 4 - fp_loss: 1.60443/66.00%, bp_loss: 1.08678/73.00%, hp_loss: 2.33582/39.00%, j_loss: 0.95651/72.00%, \n",
      "\t\tfr_loss: 0.16494/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14849\n",
      "\t`Validation time elapsed: 0.78 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.99415/51.00%, bp_loss: 1.46310/56.00%, hp_loss: 3.03199/22.00%, j_loss: 1.61731/55.00%, \n",
      "\t\tfr_loss: 0.21946/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.32601\n",
      "\tPart 2 - fp_loss: 1.56595/60.00%, bp_loss: 1.14970/67.00%, hp_loss: 2.71840/28.00%, j_loss: 1.14844/66.00%, \n",
      "\t\tfr_loss: 0.17567/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.75816\n",
      "\tPart 3 - fp_loss: 1.13977/72.00%, bp_loss: 0.84221/77.00%, hp_loss: 2.27663/42.00%, j_loss: 0.68173/82.00%, \n",
      "\t\tfr_loss: 0.16320/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10353\n",
      "\tPart 4 - fp_loss: 1.43204/69.00%, bp_loss: 0.97585/73.00%, hp_loss: 2.46543/37.00%, j_loss: 0.82660/78.00%, \n",
      "\t\tfr_loss: 0.17979/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.87970\n",
      "\t`Validation time elapsed: 9.57 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 45.\n",
      "\n",
      "EPOCH 46\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.82440/76.00%, bp_loss: 1.20642/64.00%, hp_loss: 3.10680/21.00%, j_loss: 0.83930/77.00%, \n",
      "\t\tfr_loss: 0.13271/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.10963\n",
      "\tPart 2 - fp_loss: 0.68986/79.00%, bp_loss: 0.95740/71.00%, hp_loss: 2.76704/30.00%, j_loss: 0.66705/77.00%, \n",
      "\t\tfr_loss: 0.10917/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.19051\n",
      "\tPart 3 - fp_loss: 0.64429/81.00%, bp_loss: 0.73480/79.00%, hp_loss: 2.43589/37.00%, j_loss: 0.44983/84.00%, \n",
      "\t\tfr_loss: 0.09246/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35727\n",
      "\tPart 4 - fp_loss: 0.52785/85.00%, bp_loss: 0.66056/82.00%, hp_loss: 2.56729/33.00%, j_loss: 0.35506/86.00%, \n",
      "\t\tfr_loss: 0.08541/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.19616\n",
      "\tTraining time elapsed: 1.12 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.97227/73.00%, bp_loss: 1.32651/61.00%, hp_loss: 3.05055/22.00%, j_loss: 1.01992/75.00%, \n",
      "\t\tfr_loss: 0.13624/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.50549\n",
      "\tPart 2 - fp_loss: 0.67717/82.00%, bp_loss: 0.85899/75.00%, hp_loss: 2.66707/32.00%, j_loss: 0.57083/81.00%, \n",
      "\t\tfr_loss: 0.09565/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.86971\n",
      "\tPart 3 - fp_loss: 0.67216/81.00%, bp_loss: 0.73008/80.00%, hp_loss: 2.41152/38.00%, j_loss: 0.48028/84.00%, \n",
      "\t\tfr_loss: 0.10493/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39896\n",
      "\tPart 4 - fp_loss: 0.58498/85.00%, bp_loss: 0.73737/79.00%, hp_loss: 2.59530/34.00%, j_loss: 0.40685/86.00%, \n",
      "\t\tfr_loss: 0.08955/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41405\n",
      "\tTraining time elapsed: 38.61 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 1.01064/69.00%, bp_loss: 1.19538/64.00%, hp_loss: 3.07573/22.00%, j_loss: 1.01401/72.00%, \n",
      "\t\tfr_loss: 0.14159/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.43735\n",
      "\tPart 2 - fp_loss: 0.80031/78.00%, bp_loss: 0.82303/75.00%, hp_loss: 2.69954/32.00%, j_loss: 0.61863/81.00%, \n",
      "\t\tfr_loss: 0.13167/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.07318\n",
      "\tPart 3 - fp_loss: 0.69104/78.00%, bp_loss: 0.77013/80.00%, hp_loss: 2.32430/40.00%, j_loss: 0.48828/84.00%, \n",
      "\t\tfr_loss: 0.09379/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36755\n",
      "\tPart 4 - fp_loss: 0.65107/81.00%, bp_loss: 0.67063/81.00%, hp_loss: 2.53883/35.00%, j_loss: 0.43096/84.00%, \n",
      "\t\tfr_loss: 0.09423/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38573\n",
      "\tTraining time elapsed: 76.12 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.87239/74.00%, bp_loss: 1.34417/59.00%, hp_loss: 3.18445/19.00%, j_loss: 0.96500/74.00%, \n",
      "\t\tfr_loss: 0.13361/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.49961\n",
      "\tPart 2 - fp_loss: 0.76934/78.00%, bp_loss: 0.80247/77.00%, hp_loss: 2.65127/33.00%, j_loss: 0.57416/82.00%, \n",
      "\t\tfr_loss: 0.12386/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92108\n",
      "\tPart 3 - fp_loss: 0.73829/79.00%, bp_loss: 0.77154/79.00%, hp_loss: 2.37897/38.00%, j_loss: 0.47631/83.00%, \n",
      "\t\tfr_loss: 0.10583/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47093\n",
      "\tPart 4 - fp_loss: 0.62841/81.00%, bp_loss: 0.75784/77.00%, hp_loss: 2.61014/32.00%, j_loss: 0.44313/82.00%, \n",
      "\t\tfr_loss: 0.09448/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53401\n",
      "\tTraining time elapsed: 113.65 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.91604/73.00%, bp_loss: 1.27632/62.00%, hp_loss: 3.01918/23.00%, j_loss: 0.89357/76.00%, \n",
      "\t\tfr_loss: 0.13137/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23648\n",
      "\tPart 2 - fp_loss: 0.74382/78.00%, bp_loss: 0.85550/74.00%, hp_loss: 2.75760/32.00%, j_loss: 0.65258/79.00%, \n",
      "\t\tfr_loss: 0.13032/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.13981\n",
      "\tPart 3 - fp_loss: 0.66530/81.00%, bp_loss: 0.67149/81.00%, hp_loss: 2.43778/36.00%, j_loss: 0.41065/86.00%, \n",
      "\t\tfr_loss: 0.09980/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28502\n",
      "\tPart 4 - fp_loss: 0.59420/83.00%, bp_loss: 0.69173/79.00%, hp_loss: 2.65829/31.00%, j_loss: 0.41890/87.00%, \n",
      "\t\tfr_loss: 0.09596/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45908\n",
      "\tTraining time elapsed: 151.17 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.93334/73.00%, bp_loss: 1.25815/63.00%, hp_loss: 3.05257/22.00%, j_loss: 0.86991/75.00%, \n",
      "\t\tfr_loss: 0.15588/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26986\n",
      "\tPart 2 - fp_loss: 0.76743/78.00%, bp_loss: 0.92377/73.00%, hp_loss: 2.75744/32.00%, j_loss: 0.66635/79.00%, \n",
      "\t\tfr_loss: 0.13532/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.25031\n",
      "\tPart 3 - fp_loss: 0.69994/79.00%, bp_loss: 0.74030/79.00%, hp_loss: 2.48987/36.00%, j_loss: 0.48366/86.00%, \n",
      "\t\tfr_loss: 0.10789/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52166\n",
      "\tPart 4 - fp_loss: 0.60271/83.00%, bp_loss: 0.76841/76.00%, hp_loss: 2.67281/32.00%, j_loss: 0.43261/85.00%, \n",
      "\t\tfr_loss: 0.09358/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57012\n",
      "\tTraining time elapsed: 188.65 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.89960/72.00%, bp_loss: 1.23539/63.00%, hp_loss: 3.04460/21.00%, j_loss: 0.89577/74.00%, \n",
      "\t\tfr_loss: 0.14154/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.21690\n",
      "\tPart 2 - fp_loss: 0.81612/76.00%, bp_loss: 0.82188/77.00%, hp_loss: 2.73322/31.00%, j_loss: 0.62762/80.00%, \n",
      "\t\tfr_loss: 0.13354/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.13238\n",
      "\tPart 3 - fp_loss: 0.73320/79.00%, bp_loss: 0.68143/82.00%, hp_loss: 2.40872/38.00%, j_loss: 0.44162/84.00%, \n",
      "\t\tfr_loss: 0.11602/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38099\n",
      "\tPart 4 - fp_loss: 0.61749/82.00%, bp_loss: 0.66203/81.00%, hp_loss: 2.58308/33.00%, j_loss: 0.40899/85.00%, \n",
      "\t\tfr_loss: 0.08955/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36114\n",
      "\tTraining time elapsed: 226.14 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.92243/73.00%, bp_loss: 1.21094/65.00%, hp_loss: 3.09747/22.00%, j_loss: 0.88769/76.00%, \n",
      "\t\tfr_loss: 0.15620/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.27472\n",
      "\tPart 2 - fp_loss: 0.79087/77.00%, bp_loss: 0.94824/72.00%, hp_loss: 2.72898/29.00%, j_loss: 0.69887/79.00%, \n",
      "\t\tfr_loss: 0.13737/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.30433\n",
      "\tPart 3 - fp_loss: 0.73414/79.00%, bp_loss: 0.76703/78.00%, hp_loss: 2.46759/36.00%, j_loss: 0.50101/84.00%, \n",
      "\t\tfr_loss: 0.10105/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57084\n",
      "\tPart 4 - fp_loss: 0.60269/82.00%, bp_loss: 0.79013/76.00%, hp_loss: 2.71430/29.00%, j_loss: 0.43464/86.00%, \n",
      "\t\tfr_loss: 0.09094/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63270\n",
      "\tTraining time elapsed: 263.64 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.91606/74.00%, bp_loss: 1.34611/60.00%, hp_loss: 3.09997/21.00%, j_loss: 0.95359/75.00%, \n",
      "\t\tfr_loss: 0.12881/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.44454\n",
      "\tPart 2 - fp_loss: 0.72334/78.00%, bp_loss: 0.84142/76.00%, hp_loss: 2.68811/33.00%, j_loss: 0.59025/82.00%, \n",
      "\t\tfr_loss: 0.14086/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.98398\n",
      "\tPart 3 - fp_loss: 0.75532/78.00%, bp_loss: 0.78847/78.00%, hp_loss: 2.40924/39.00%, j_loss: 0.47792/84.00%, \n",
      "\t\tfr_loss: 0.12126/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55221\n",
      "\tPart 4 - fp_loss: 0.66207/80.00%, bp_loss: 0.84740/76.00%, hp_loss: 2.62054/32.00%, j_loss: 0.55672/83.00%, \n",
      "\t\tfr_loss: 0.10478/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.79151\n",
      "\tTraining time elapsed: 301.12 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.79393/53.00%, bp_loss: 1.33946/59.00%, hp_loss: 3.04587/23.00%, j_loss: 1.42534/58.00%, \n",
      "\t\tfr_loss: 0.19752/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.80211\n",
      "\tPart 2 - fp_loss: 1.76552/58.00%, bp_loss: 1.12012/67.00%, hp_loss: 2.68388/29.00%, j_loss: 1.19479/64.00%, \n",
      "\t\tfr_loss: 0.18453/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.94885\n",
      "\tPart 3 - fp_loss: 1.31763/68.00%, bp_loss: 0.88568/76.00%, hp_loss: 2.19562/47.00%, j_loss: 0.78350/77.00%, \n",
      "\t\tfr_loss: 0.18096/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.36339\n",
      "\tPart 4 - fp_loss: 1.58906/67.00%, bp_loss: 0.88631/76.00%, hp_loss: 2.46337/37.00%, j_loss: 0.80856/74.00%, \n",
      "\t\tfr_loss: 0.18173/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.92904\n",
      "\t`Validation time elapsed: 0.76 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.96155/50.00%, bp_loss: 1.42254/58.00%, hp_loss: 3.03257/23.00%, j_loss: 1.58488/54.00%, \n",
      "\t\tfr_loss: 0.23211/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.23366\n",
      "\tPart 2 - fp_loss: 1.69179/58.00%, bp_loss: 1.10412/68.00%, hp_loss: 2.70189/30.00%, j_loss: 1.22193/66.00%, \n",
      "\t\tfr_loss: 0.22540/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.94512\n",
      "\tPart 3 - fp_loss: 1.33047/68.00%, bp_loss: 0.81619/77.00%, hp_loss: 2.28234/42.00%, j_loss: 0.76616/76.00%, \n",
      "\t\tfr_loss: 0.16658/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.36173\n",
      "\tPart 4 - fp_loss: 1.44624/69.00%, bp_loss: 0.84455/78.00%, hp_loss: 2.36483/41.00%, j_loss: 0.76902/79.00%, \n",
      "\t\tfr_loss: 0.17370/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.59834\n",
      "\t`Validation time elapsed: 9.51 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 46.\n",
      "\n",
      "EPOCH 47\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.80638/76.00%, bp_loss: 1.22652/63.00%, hp_loss: 3.11543/21.00%, j_loss: 0.82455/76.00%, \n",
      "\t\tfr_loss: 0.12454/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09742\n",
      "\tPart 2 - fp_loss: 0.65063/80.00%, bp_loss: 0.79450/78.00%, hp_loss: 2.67347/33.00%, j_loss: 0.55509/80.00%, \n",
      "\t\tfr_loss: 0.14501/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.81870\n",
      "\tPart 3 - fp_loss: 0.69795/80.00%, bp_loss: 0.77400/77.00%, hp_loss: 2.40925/38.00%, j_loss: 0.50733/82.00%, \n",
      "\t\tfr_loss: 0.11861/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50714\n",
      "\tPart 4 - fp_loss: 0.51678/84.00%, bp_loss: 0.74657/77.00%, hp_loss: 2.59596/32.00%, j_loss: 0.41015/86.00%, \n",
      "\t\tfr_loss: 0.10916/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37862\n",
      "\tTraining time elapsed: 1.14 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.87837/74.00%, bp_loss: 1.23235/64.00%, hp_loss: 3.08516/22.00%, j_loss: 0.88460/75.00%, \n",
      "\t\tfr_loss: 0.14387/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22435\n",
      "\tPart 2 - fp_loss: 0.70033/81.00%, bp_loss: 0.91806/74.00%, hp_loss: 2.72629/32.00%, j_loss: 0.54233/83.00%, \n",
      "\t\tfr_loss: 0.13072/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01774\n",
      "\tPart 3 - fp_loss: 0.60997/84.00%, bp_loss: 0.79364/79.00%, hp_loss: 2.43585/39.00%, j_loss: 0.39953/84.00%, \n",
      "\t\tfr_loss: 0.11435/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35334\n",
      "\tPart 4 - fp_loss: 0.59347/82.00%, bp_loss: 0.74060/79.00%, hp_loss: 2.59369/34.00%, j_loss: 0.43578/84.00%, \n",
      "\t\tfr_loss: 0.10010/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46365\n",
      "\tTraining time elapsed: 38.64 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.87596/74.00%, bp_loss: 1.20765/64.00%, hp_loss: 3.00481/25.00%, j_loss: 0.86208/76.00%, \n",
      "\t\tfr_loss: 0.15109/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.10159\n",
      "\tPart 2 - fp_loss: 0.73960/79.00%, bp_loss: 0.93974/72.00%, hp_loss: 2.70791/32.00%, j_loss: 0.64694/80.00%, \n",
      "\t\tfr_loss: 0.13310/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16729\n",
      "\tPart 3 - fp_loss: 0.59545/82.00%, bp_loss: 0.77627/78.00%, hp_loss: 2.25577/41.00%, j_loss: 0.48504/83.00%, \n",
      "\t\tfr_loss: 0.09669/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.20922\n",
      "\tPart 4 - fp_loss: 0.54191/83.00%, bp_loss: 0.69317/80.00%, hp_loss: 2.57208/33.00%, j_loss: 0.43440/87.00%, \n",
      "\t\tfr_loss: 0.09064/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33221\n",
      "\tTraining time elapsed: 76.18 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.91219/73.00%, bp_loss: 1.26670/63.00%, hp_loss: 3.10774/20.00%, j_loss: 0.86767/73.00%, \n",
      "\t\tfr_loss: 0.13026/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.28455\n",
      "\tPart 2 - fp_loss: 0.74906/79.00%, bp_loss: 0.88410/75.00%, hp_loss: 2.70466/31.00%, j_loss: 0.58742/80.00%, \n",
      "\t\tfr_loss: 0.13396/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05919\n",
      "\tPart 3 - fp_loss: 0.67673/81.00%, bp_loss: 0.77734/79.00%, hp_loss: 2.53981/36.00%, j_loss: 0.48412/84.00%, \n",
      "\t\tfr_loss: 0.10318/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58118\n",
      "\tPart 4 - fp_loss: 0.62103/82.00%, bp_loss: 0.71401/79.00%, hp_loss: 2.57723/34.00%, j_loss: 0.41324/85.00%, \n",
      "\t\tfr_loss: 0.09832/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42383\n",
      "\tTraining time elapsed: 113.70 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.86770/74.00%, bp_loss: 1.28896/60.00%, hp_loss: 3.07430/21.00%, j_loss: 0.92047/74.00%, \n",
      "\t\tfr_loss: 0.14750/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29893\n",
      "\tPart 2 - fp_loss: 0.66192/79.00%, bp_loss: 0.84945/75.00%, hp_loss: 2.70160/33.00%, j_loss: 0.62657/79.00%, \n",
      "\t\tfr_loss: 0.10107/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94059\n",
      "\tPart 3 - fp_loss: 0.71435/79.00%, bp_loss: 0.78723/78.00%, hp_loss: 2.39961/37.00%, j_loss: 0.51963/83.00%, \n",
      "\t\tfr_loss: 0.11723/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53805\n",
      "\tPart 4 - fp_loss: 0.51249/85.00%, bp_loss: 0.73555/77.00%, hp_loss: 2.50543/34.00%, j_loss: 0.34951/87.00%, \n",
      "\t\tfr_loss: 0.08187/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.18486\n",
      "\tTraining time elapsed: 151.19 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.87276/75.00%, bp_loss: 1.15453/65.00%, hp_loss: 3.05759/24.00%, j_loss: 0.88547/75.00%, \n",
      "\t\tfr_loss: 0.14345/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11379\n",
      "\tPart 2 - fp_loss: 0.74698/78.00%, bp_loss: 0.83224/75.00%, hp_loss: 2.70700/33.00%, j_loss: 0.60212/79.00%, \n",
      "\t\tfr_loss: 0.13808/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02641\n",
      "\tPart 3 - fp_loss: 0.69572/80.00%, bp_loss: 0.76887/79.00%, hp_loss: 2.38152/38.00%, j_loss: 0.47035/86.00%, \n",
      "\t\tfr_loss: 0.10681/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42327\n",
      "\tPart 4 - fp_loss: 0.54572/84.00%, bp_loss: 0.70655/80.00%, hp_loss: 2.50858/34.00%, j_loss: 0.36628/87.00%, \n",
      "\t\tfr_loss: 0.09628/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.22341\n",
      "\tTraining time elapsed: 188.72 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.85005/74.00%, bp_loss: 1.17394/65.00%, hp_loss: 3.08291/23.00%, j_loss: 0.86354/76.00%, \n",
      "\t\tfr_loss: 0.12791/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09834\n",
      "\tPart 2 - fp_loss: 0.71851/78.00%, bp_loss: 0.87469/74.00%, hp_loss: 2.68217/31.00%, j_loss: 0.59822/80.00%, \n",
      "\t\tfr_loss: 0.12452/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.99812\n",
      "\tPart 3 - fp_loss: 0.62997/81.00%, bp_loss: 0.78422/78.00%, hp_loss: 2.37316/37.00%, j_loss: 0.43498/84.00%, \n",
      "\t\tfr_loss: 0.10774/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33006\n",
      "\tPart 4 - fp_loss: 0.69267/81.00%, bp_loss: 0.71777/78.00%, hp_loss: 2.56753/32.00%, j_loss: 0.46932/85.00%, \n",
      "\t\tfr_loss: 0.10600/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55329\n",
      "\tTraining time elapsed: 226.27 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.86010/74.00%, bp_loss: 1.26285/63.00%, hp_loss: 3.07709/21.00%, j_loss: 0.90960/76.00%, \n",
      "\t\tfr_loss: 0.14909/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25872\n",
      "\tPart 2 - fp_loss: 0.79133/76.00%, bp_loss: 0.84061/75.00%, hp_loss: 2.70984/32.00%, j_loss: 0.67320/79.00%, \n",
      "\t\tfr_loss: 0.13312/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.14810\n",
      "\tPart 3 - fp_loss: 0.65545/80.00%, bp_loss: 0.79894/78.00%, hp_loss: 2.41130/37.00%, j_loss: 0.44510/84.00%, \n",
      "\t\tfr_loss: 0.11428/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42506\n",
      "\tPart 4 - fp_loss: 0.65907/81.00%, bp_loss: 0.77743/77.00%, hp_loss: 2.63691/31.00%, j_loss: 0.46141/85.00%, \n",
      "\t\tfr_loss: 0.11120/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64604\n",
      "\tTraining time elapsed: 263.79 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.96635/70.00%, bp_loss: 1.15544/65.00%, hp_loss: 3.08099/24.00%, j_loss: 0.90473/75.00%, \n",
      "\t\tfr_loss: 0.14874/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25625\n",
      "\tPart 2 - fp_loss: 0.74357/78.00%, bp_loss: 0.85878/75.00%, hp_loss: 2.70165/32.00%, j_loss: 0.61755/80.00%, \n",
      "\t\tfr_loss: 0.12935/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05091\n",
      "\tPart 3 - fp_loss: 0.62204/82.00%, bp_loss: 0.74208/80.00%, hp_loss: 2.42454/37.00%, j_loss: 0.40539/86.00%, \n",
      "\t\tfr_loss: 0.10789/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.30194\n",
      "\tPart 4 - fp_loss: 0.57332/84.00%, bp_loss: 0.81732/75.00%, hp_loss: 2.64940/29.00%, j_loss: 0.42086/86.00%, \n",
      "\t\tfr_loss: 0.10845/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56934\n",
      "\tTraining time elapsed: 301.33 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.84233/53.00%, bp_loss: 1.34339/59.00%, hp_loss: 3.09929/22.00%, j_loss: 1.49273/57.00%, \n",
      "\t\tfr_loss: 0.21058/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.98832\n",
      "\tPart 2 - fp_loss: 1.70153/59.00%, bp_loss: 1.16673/66.00%, hp_loss: 2.75402/29.00%, j_loss: 1.24424/64.00%, \n",
      "\t\tfr_loss: 0.18933/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.05585\n",
      "\tPart 3 - fp_loss: 1.19633/73.00%, bp_loss: 0.93818/74.00%, hp_loss: 2.26936/44.00%, j_loss: 0.71990/80.00%, \n",
      "\t\tfr_loss: 0.17366/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.29742\n",
      "\tPart 4 - fp_loss: 1.66034/67.00%, bp_loss: 1.15672/70.00%, hp_loss: 2.45546/38.00%, j_loss: 1.04181/71.00%, \n",
      "\t\tfr_loss: 0.18835/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.50268\n",
      "\t`Validation time elapsed: 0.79 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.03483/50.00%, bp_loss: 1.49841/55.00%, hp_loss: 3.13661/20.00%, j_loss: 1.66561/55.00%, \n",
      "\t\tfr_loss: 0.22783/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.56330\n",
      "\tPart 2 - fp_loss: 1.61832/61.00%, bp_loss: 1.14283/67.00%, hp_loss: 2.67850/31.00%, j_loss: 1.11250/67.00%, \n",
      "\t\tfr_loss: 0.18821/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.74035\n",
      "\tPart 3 - fp_loss: 1.27754/70.00%, bp_loss: 0.92646/74.00%, hp_loss: 2.24527/42.00%, j_loss: 0.85140/77.00%, \n",
      "\t\tfr_loss: 0.18036/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.48102\n",
      "\tPart 4 - fp_loss: 1.29833/72.00%, bp_loss: 0.93738/75.00%, hp_loss: 2.35248/41.00%, j_loss: 0.75664/79.00%, \n",
      "\t\tfr_loss: 0.15814/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.50296\n",
      "\t`Validation time elapsed: 9.56 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 47.\n",
      "\n",
      "EPOCH 48\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.88021/73.00%, bp_loss: 1.19373/64.00%, hp_loss: 3.10866/22.00%, j_loss: 0.89813/71.00%, \n",
      "\t\tfr_loss: 0.13195/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.21268\n",
      "\tPart 2 - fp_loss: 0.68363/80.00%, bp_loss: 0.89882/74.00%, hp_loss: 2.68330/33.00%, j_loss: 0.61469/79.00%, \n",
      "\t\tfr_loss: 0.13164/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01209\n",
      "\tPart 3 - fp_loss: 0.56944/84.00%, bp_loss: 0.71532/79.00%, hp_loss: 2.31369/41.00%, j_loss: 0.46059/84.00%, \n",
      "\t\tfr_loss: 0.10042/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.15946\n",
      "\tPart 4 - fp_loss: 0.58202/83.00%, bp_loss: 0.72409/79.00%, hp_loss: 2.60313/34.00%, j_loss: 0.40581/85.00%, \n",
      "\t\tfr_loss: 0.09055/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40560\n",
      "\tTraining time elapsed: 1.13 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.83473/76.00%, bp_loss: 1.27162/62.00%, hp_loss: 3.07271/22.00%, j_loss: 0.82736/74.00%, \n",
      "\t\tfr_loss: 0.13595/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14237\n",
      "\tPart 2 - fp_loss: 0.67177/80.00%, bp_loss: 0.85924/76.00%, hp_loss: 2.65993/34.00%, j_loss: 0.50507/82.00%, \n",
      "\t\tfr_loss: 0.12617/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.82218\n",
      "\tPart 3 - fp_loss: 0.68840/80.00%, bp_loss: 0.70769/81.00%, hp_loss: 2.42915/37.00%, j_loss: 0.40657/86.00%, \n",
      "\t\tfr_loss: 0.11379/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34560\n",
      "\tPart 4 - fp_loss: 0.58581/84.00%, bp_loss: 0.72477/80.00%, hp_loss: 2.66240/32.00%, j_loss: 0.34648/88.00%, \n",
      "\t\tfr_loss: 0.09481/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41428\n",
      "\tTraining time elapsed: 38.69 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.88008/72.00%, bp_loss: 1.29012/62.00%, hp_loss: 3.01080/24.00%, j_loss: 0.99665/73.00%, \n",
      "\t\tfr_loss: 0.13140/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30904\n",
      "\tPart 2 - fp_loss: 0.75257/78.00%, bp_loss: 0.81935/75.00%, hp_loss: 2.74563/31.00%, j_loss: 0.61152/79.00%, \n",
      "\t\tfr_loss: 0.12754/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05661\n",
      "\tPart 3 - fp_loss: 0.60991/84.00%, bp_loss: 0.71487/80.00%, hp_loss: 2.41668/39.00%, j_loss: 0.43610/87.00%, \n",
      "\t\tfr_loss: 0.09905/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.27662\n",
      "\tPart 4 - fp_loss: 0.53197/85.00%, bp_loss: 0.76713/78.00%, hp_loss: 2.60361/33.00%, j_loss: 0.39351/87.00%, \n",
      "\t\tfr_loss: 0.09249/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38870\n",
      "\tTraining time elapsed: 76.18 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.92408/72.00%, bp_loss: 1.29181/61.00%, hp_loss: 3.12798/21.00%, j_loss: 0.92565/74.00%, \n",
      "\t\tfr_loss: 0.14065/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41018\n",
      "\tPart 2 - fp_loss: 0.74039/78.00%, bp_loss: 0.89381/73.00%, hp_loss: 2.80328/29.00%, j_loss: 0.62955/79.00%, \n",
      "\t\tfr_loss: 0.11745/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18448\n",
      "\tPart 3 - fp_loss: 0.69063/80.00%, bp_loss: 0.81134/78.00%, hp_loss: 2.29490/40.00%, j_loss: 0.51125/84.00%, \n",
      "\t\tfr_loss: 0.11612/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42425\n",
      "\tPart 4 - fp_loss: 0.59492/83.00%, bp_loss: 0.78758/78.00%, hp_loss: 2.55179/34.00%, j_loss: 0.42797/85.00%, \n",
      "\t\tfr_loss: 0.09480/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45706\n",
      "\tTraining time elapsed: 113.70 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.95486/72.00%, bp_loss: 1.26538/62.00%, hp_loss: 3.07024/23.00%, j_loss: 0.97759/72.00%, \n",
      "\t\tfr_loss: 0.14227/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41034\n",
      "\tPart 2 - fp_loss: 0.70404/78.00%, bp_loss: 0.88281/75.00%, hp_loss: 2.75075/31.00%, j_loss: 0.63713/81.00%, \n",
      "\t\tfr_loss: 0.12156/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09631\n",
      "\tPart 3 - fp_loss: 0.72308/80.00%, bp_loss: 0.73710/78.00%, hp_loss: 2.42239/37.00%, j_loss: 0.48173/85.00%, \n",
      "\t\tfr_loss: 0.10668/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47098\n",
      "\tPart 4 - fp_loss: 0.52454/84.00%, bp_loss: 0.77003/77.00%, hp_loss: 2.61411/32.00%, j_loss: 0.39858/86.00%, \n",
      "\t\tfr_loss: 0.09514/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40240\n",
      "\tTraining time elapsed: 151.24 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.93869/73.00%, bp_loss: 1.28933/61.00%, hp_loss: 3.07778/20.00%, j_loss: 0.90750/76.00%, \n",
      "\t\tfr_loss: 0.13846/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.35176\n",
      "\tPart 2 - fp_loss: 0.70812/78.00%, bp_loss: 0.86245/74.00%, hp_loss: 2.72158/32.00%, j_loss: 0.57956/82.00%, \n",
      "\t\tfr_loss: 0.13162/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.00333\n",
      "\tPart 3 - fp_loss: 0.68446/82.00%, bp_loss: 0.69368/81.00%, hp_loss: 2.29203/42.00%, j_loss: 0.46292/87.00%, \n",
      "\t\tfr_loss: 0.08455/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.21764\n",
      "\tPart 4 - fp_loss: 0.59769/85.00%, bp_loss: 0.73618/79.00%, hp_loss: 2.53207/33.00%, j_loss: 0.39992/88.00%, \n",
      "\t\tfr_loss: 0.09911/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36497\n",
      "\tTraining time elapsed: 188.77 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.91086/72.00%, bp_loss: 1.31884/61.00%, hp_loss: 3.03704/23.00%, j_loss: 0.96136/72.00%, \n",
      "\t\tfr_loss: 0.13481/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36290\n",
      "\tPart 2 - fp_loss: 0.73053/78.00%, bp_loss: 0.92994/73.00%, hp_loss: 2.66982/33.00%, j_loss: 0.64601/78.00%, \n",
      "\t\tfr_loss: 0.12868/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10497\n",
      "\tPart 3 - fp_loss: 0.64528/80.00%, bp_loss: 0.72895/80.00%, hp_loss: 2.40015/40.00%, j_loss: 0.43858/86.00%, \n",
      "\t\tfr_loss: 0.10675/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.31972\n",
      "\tPart 4 - fp_loss: 0.59322/83.00%, bp_loss: 0.75734/79.00%, hp_loss: 2.51631/35.00%, j_loss: 0.39143/85.00%, \n",
      "\t\tfr_loss: 0.09324/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35154\n",
      "\tTraining time elapsed: 226.30 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.86242/75.00%, bp_loss: 1.22143/64.00%, hp_loss: 3.10061/22.00%, j_loss: 0.84507/75.00%, \n",
      "\t\tfr_loss: 0.13892/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16844\n",
      "\tPart 2 - fp_loss: 0.67418/80.00%, bp_loss: 0.84922/74.00%, hp_loss: 2.74239/30.00%, j_loss: 0.61161/80.00%, \n",
      "\t\tfr_loss: 0.12394/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.00134\n",
      "\tPart 3 - fp_loss: 0.70720/80.00%, bp_loss: 0.71511/79.00%, hp_loss: 2.43729/37.00%, j_loss: 0.47417/86.00%, \n",
      "\t\tfr_loss: 0.11313/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44691\n",
      "\tPart 4 - fp_loss: 0.55339/84.00%, bp_loss: 0.85142/77.00%, hp_loss: 2.50589/34.00%, j_loss: 0.41519/87.00%, \n",
      "\t\tfr_loss: 0.10732/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43321\n",
      "\tTraining time elapsed: 263.83 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.89341/72.00%, bp_loss: 1.28559/61.00%, hp_loss: 3.07325/22.00%, j_loss: 0.94994/73.00%, \n",
      "\t\tfr_loss: 0.12881/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33101\n",
      "\tPart 2 - fp_loss: 0.70376/79.00%, bp_loss: 0.86631/75.00%, hp_loss: 2.78254/30.00%, j_loss: 0.60687/81.00%, \n",
      "\t\tfr_loss: 0.11072/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.07019\n",
      "\tPart 3 - fp_loss: 0.70735/80.00%, bp_loss: 0.72501/79.00%, hp_loss: 2.45676/37.00%, j_loss: 0.46928/84.00%, \n",
      "\t\tfr_loss: 0.12317/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48157\n",
      "\tPart 4 - fp_loss: 0.62942/84.00%, bp_loss: 0.80481/77.00%, hp_loss: 2.62360/32.00%, j_loss: 0.41854/86.00%, \n",
      "\t\tfr_loss: 0.08710/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56347\n",
      "\tTraining time elapsed: 301.37 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.96825/50.00%, bp_loss: 1.35106/59.00%, hp_loss: 3.00193/24.00%, j_loss: 1.55772/53.00%, \n",
      "\t\tfr_loss: 0.21430/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.09325\n",
      "\tPart 2 - fp_loss: 1.64875/59.00%, bp_loss: 1.11177/68.00%, hp_loss: 2.64361/32.00%, j_loss: 1.12926/63.00%, \n",
      "\t\tfr_loss: 0.19416/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.72755\n",
      "\tPart 3 - fp_loss: 1.32580/70.00%, bp_loss: 0.89511/75.00%, hp_loss: 2.23500/44.00%, j_loss: 0.77367/76.00%, \n",
      "\t\tfr_loss: 0.17893/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40850\n",
      "\tPart 4 - fp_loss: 1.57984/67.00%, bp_loss: 1.00084/74.00%, hp_loss: 2.45927/38.00%, j_loss: 0.88905/74.00%, \n",
      "\t\tfr_loss: 0.18736/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11636\n",
      "\t`Validation time elapsed: 0.79 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.02306/50.00%, bp_loss: 1.38872/58.00%, hp_loss: 3.06396/23.00%, j_loss: 1.54223/55.00%, \n",
      "\t\tfr_loss: 0.21625/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.23422\n",
      "\tPart 2 - fp_loss: 1.76345/55.00%, bp_loss: 1.14020/68.00%, hp_loss: 2.71872/31.00%, j_loss: 1.34822/62.00%, \n",
      "\t\tfr_loss: 0.20930/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.17989\n",
      "\tPart 3 - fp_loss: 1.36724/67.00%, bp_loss: 0.84049/78.00%, hp_loss: 2.27374/44.00%, j_loss: 0.78160/78.00%, \n",
      "\t\tfr_loss: 0.14913/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.41220\n",
      "\tPart 4 - fp_loss: 1.48221/69.00%, bp_loss: 0.96402/76.00%, hp_loss: 2.38127/38.00%, j_loss: 0.82070/79.00%, \n",
      "\t\tfr_loss: 0.16125/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.80945\n",
      "\t`Validation time elapsed: 9.56 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 48.\n",
      "\n",
      "EPOCH 49\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.83468/76.00%, bp_loss: 1.15271/67.00%, hp_loss: 2.97986/25.00%, j_loss: 0.76842/78.00%, \n",
      "\t\tfr_loss: 0.14474/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.88042\n",
      "\tPart 2 - fp_loss: 0.67371/81.00%, bp_loss: 0.87545/73.00%, hp_loss: 2.71794/32.00%, j_loss: 0.57521/80.00%, \n",
      "\t\tfr_loss: 0.13393/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97625\n",
      "\tPart 3 - fp_loss: 0.57029/83.00%, bp_loss: 0.67960/81.00%, hp_loss: 2.36283/39.00%, j_loss: 0.41645/86.00%, \n",
      "\t\tfr_loss: 0.07964/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.10882\n",
      "\tPart 4 - fp_loss: 0.52297/85.00%, bp_loss: 0.81133/76.00%, hp_loss: 2.60462/32.00%, j_loss: 0.38918/86.00%, \n",
      "\t\tfr_loss: 0.09957/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42768\n",
      "\tTraining time elapsed: 1.10 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.91422/75.00%, bp_loss: 1.23959/63.00%, hp_loss: 3.05207/23.00%, j_loss: 0.87228/75.00%, \n",
      "\t\tfr_loss: 0.13670/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.21486\n",
      "\tPart 2 - fp_loss: 0.72170/80.00%, bp_loss: 0.87093/75.00%, hp_loss: 2.73646/31.00%, j_loss: 0.53116/82.00%, \n",
      "\t\tfr_loss: 0.11830/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97855\n",
      "\tPart 3 - fp_loss: 0.57067/83.00%, bp_loss: 0.74839/79.00%, hp_loss: 2.36929/39.00%, j_loss: 0.45772/84.00%, \n",
      "\t\tfr_loss: 0.10838/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25446\n",
      "\tPart 4 - fp_loss: 0.62310/81.00%, bp_loss: 0.93474/74.00%, hp_loss: 2.62421/34.00%, j_loss: 0.52434/84.00%, \n",
      "\t\tfr_loss: 0.10161/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.80800\n",
      "\tTraining time elapsed: 38.65 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.92373/72.00%, bp_loss: 1.24832/62.00%, hp_loss: 3.06777/22.00%, j_loss: 0.90255/73.00%, \n",
      "\t\tfr_loss: 0.12877/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.27115\n",
      "\tPart 2 - fp_loss: 0.62753/81.00%, bp_loss: 0.84024/75.00%, hp_loss: 2.72298/32.00%, j_loss: 0.50193/82.00%, \n",
      "\t\tfr_loss: 0.12260/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.81529\n",
      "\tPart 3 - fp_loss: 0.68151/81.00%, bp_loss: 0.75560/80.00%, hp_loss: 2.50731/34.00%, j_loss: 0.46609/85.00%, \n",
      "\t\tfr_loss: 0.11331/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52381\n",
      "\tPart 4 - fp_loss: 0.57526/82.00%, bp_loss: 0.81786/77.00%, hp_loss: 2.67664/30.00%, j_loss: 0.45240/84.00%, \n",
      "\t\tfr_loss: 0.09690/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61906\n",
      "\tTraining time elapsed: 76.21 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.96382/71.00%, bp_loss: 1.17182/64.00%, hp_loss: 3.10483/22.00%, j_loss: 0.91541/74.00%, \n",
      "\t\tfr_loss: 0.14594/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30182\n",
      "\tPart 2 - fp_loss: 0.67726/79.00%, bp_loss: 0.82785/77.00%, hp_loss: 2.73250/31.00%, j_loss: 0.55678/82.00%, \n",
      "\t\tfr_loss: 0.13106/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92544\n",
      "\tPart 3 - fp_loss: 0.66969/81.00%, bp_loss: 0.67212/80.00%, hp_loss: 2.38505/39.00%, j_loss: 0.44494/85.00%, \n",
      "\t\tfr_loss: 0.10882/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28061\n",
      "\tPart 4 - fp_loss: 0.57616/83.00%, bp_loss: 0.75553/77.00%, hp_loss: 2.52311/34.00%, j_loss: 0.43546/84.00%, \n",
      "\t\tfr_loss: 0.09621/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38648\n",
      "\tTraining time elapsed: 113.69 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.87024/74.00%, bp_loss: 1.32043/60.00%, hp_loss: 3.08483/22.00%, j_loss: 0.89003/74.00%, \n",
      "\t\tfr_loss: 0.14558/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31111\n",
      "\tPart 2 - fp_loss: 0.60496/82.00%, bp_loss: 0.85855/75.00%, hp_loss: 2.64376/33.00%, j_loss: 0.56018/83.00%, \n",
      "\t\tfr_loss: 0.12420/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.79165\n",
      "\tPart 3 - fp_loss: 0.64195/82.00%, bp_loss: 0.68663/79.00%, hp_loss: 2.35770/37.00%, j_loss: 0.46771/84.00%, \n",
      "\t\tfr_loss: 0.09637/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25036\n",
      "\tPart 4 - fp_loss: 0.53827/83.00%, bp_loss: 0.81920/77.00%, hp_loss: 2.50308/35.00%, j_loss: 0.37268/86.00%, \n",
      "\t\tfr_loss: 0.09489/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32812\n",
      "\tTraining time elapsed: 151.22 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.92767/73.00%, bp_loss: 1.21702/64.00%, hp_loss: 3.08107/22.00%, j_loss: 0.88719/76.00%, \n",
      "\t\tfr_loss: 0.13979/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25275\n",
      "\tPart 2 - fp_loss: 0.72537/79.00%, bp_loss: 0.85966/75.00%, hp_loss: 2.68548/31.00%, j_loss: 0.60239/80.00%, \n",
      "\t\tfr_loss: 0.13150/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.00440\n",
      "\tPart 3 - fp_loss: 0.69358/80.00%, bp_loss: 0.78675/79.00%, hp_loss: 2.39545/37.00%, j_loss: 0.51183/84.00%, \n",
      "\t\tfr_loss: 0.12128/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50889\n",
      "\tPart 4 - fp_loss: 0.56278/83.00%, bp_loss: 0.76169/78.00%, hp_loss: 2.64247/31.00%, j_loss: 0.42762/87.00%, \n",
      "\t\tfr_loss: 0.09170/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48627\n",
      "\tTraining time elapsed: 188.74 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.88312/74.00%, bp_loss: 1.19442/65.00%, hp_loss: 3.02887/25.00%, j_loss: 0.90926/74.00%, \n",
      "\t\tfr_loss: 0.14878/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16445\n",
      "\tPart 2 - fp_loss: 0.65494/80.00%, bp_loss: 0.87181/74.00%, hp_loss: 2.68946/33.00%, j_loss: 0.58900/81.00%, \n",
      "\t\tfr_loss: 0.10935/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.91458\n",
      "\tPart 3 - fp_loss: 0.75968/78.00%, bp_loss: 0.78144/78.00%, hp_loss: 2.43965/35.00%, j_loss: 0.56867/82.00%, \n",
      "\t\tfr_loss: 0.12102/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.67045\n",
      "\tPart 4 - fp_loss: 0.59747/81.00%, bp_loss: 0.79644/77.00%, hp_loss: 2.58410/33.00%, j_loss: 0.47371/84.00%, \n",
      "\t\tfr_loss: 0.08750/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53922\n",
      "\tTraining time elapsed: 226.24 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.87677/74.00%, bp_loss: 1.23270/62.00%, hp_loss: 3.05530/23.00%, j_loss: 0.89916/74.00%, \n",
      "\t\tfr_loss: 0.15123/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.21517\n",
      "\tPart 2 - fp_loss: 0.76762/77.00%, bp_loss: 0.85476/76.00%, hp_loss: 2.73294/32.00%, j_loss: 0.65375/81.00%, \n",
      "\t\tfr_loss: 0.12287/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.13193\n",
      "\tPart 3 - fp_loss: 0.71651/79.00%, bp_loss: 0.70339/80.00%, hp_loss: 2.46598/35.00%, j_loss: 0.49853/84.00%, \n",
      "\t\tfr_loss: 0.10160/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48601\n",
      "\tPart 4 - fp_loss: 0.62065/82.00%, bp_loss: 0.85700/76.00%, hp_loss: 2.67482/33.00%, j_loss: 0.42177/86.00%, \n",
      "\t\tfr_loss: 0.08989/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.66414\n",
      "\tTraining time elapsed: 263.76 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.94681/72.00%, bp_loss: 1.25617/63.00%, hp_loss: 3.10756/23.00%, j_loss: 0.92755/75.00%, \n",
      "\t\tfr_loss: 0.12760/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36569\n",
      "\tPart 2 - fp_loss: 0.69426/78.00%, bp_loss: 0.87234/75.00%, hp_loss: 2.73778/32.00%, j_loss: 0.61680/81.00%, \n",
      "\t\tfr_loss: 0.13091/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05209\n",
      "\tPart 3 - fp_loss: 0.68848/80.00%, bp_loss: 0.69010/80.00%, hp_loss: 2.46252/36.00%, j_loss: 0.47797/83.00%, \n",
      "\t\tfr_loss: 0.11229/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43135\n",
      "\tPart 4 - fp_loss: 0.64666/81.00%, bp_loss: 0.81243/76.00%, hp_loss: 2.64190/30.00%, j_loss: 0.46249/84.00%, \n",
      "\t\tfr_loss: 0.09512/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65859\n",
      "\tTraining time elapsed: 301.25 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.82760/52.00%, bp_loss: 1.41995/57.00%, hp_loss: 3.04895/22.00%, j_loss: 1.52358/54.00%, \n",
      "\t\tfr_loss: 0.20988/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.02995\n",
      "\tPart 2 - fp_loss: 1.70973/57.00%, bp_loss: 1.16912/65.00%, hp_loss: 2.77028/27.00%, j_loss: 1.30063/62.00%, \n",
      "\t\tfr_loss: 0.18149/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.13124\n",
      "\tPart 3 - fp_loss: 1.25737/69.00%, bp_loss: 0.86963/75.00%, hp_loss: 2.31907/43.00%, j_loss: 0.82604/76.00%, \n",
      "\t\tfr_loss: 0.17658/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44869\n",
      "\tPart 4 - fp_loss: 1.60289/66.00%, bp_loss: 1.06247/72.00%, hp_loss: 2.46076/35.00%, j_loss: 0.94243/74.00%, \n",
      "\t\tfr_loss: 0.16851/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23706\n",
      "\t`Validation time elapsed: 0.78 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.00113/49.00%, bp_loss: 1.48155/57.00%, hp_loss: 2.97586/24.00%, j_loss: 1.71121/54.00%, \n",
      "\t\tfr_loss: 0.22895/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.39869\n",
      "\tPart 2 - fp_loss: 1.71430/60.00%, bp_loss: 1.18997/65.00%, hp_loss: 2.72468/28.00%, j_loss: 1.18865/66.00%, \n",
      "\t\tfr_loss: 0.18928/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.00687\n",
      "\tPart 3 - fp_loss: 1.32507/69.00%, bp_loss: 0.92009/75.00%, hp_loss: 2.23430/41.00%, j_loss: 0.79204/76.00%, \n",
      "\t\tfr_loss: 0.18477/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.45627\n",
      "\tPart 4 - fp_loss: 1.50640/68.00%, bp_loss: 0.95637/75.00%, hp_loss: 2.35298/39.00%, j_loss: 0.86730/77.00%, \n",
      "\t\tfr_loss: 0.18922/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.87227\n",
      "\t`Validation time elapsed: 9.53 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Completed epoch 49.\n",
      "\n",
      "EPOCH 50\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.86048/75.00%, bp_loss: 1.16590/65.00%, hp_loss: 3.05317/24.00%, j_loss: 0.84029/77.00%, \n",
      "\t\tfr_loss: 0.13109/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05093\n",
      "\tPart 2 - fp_loss: 0.74363/79.00%, bp_loss: 0.86965/75.00%, hp_loss: 2.68813/33.00%, j_loss: 0.60875/80.00%, \n",
      "\t\tfr_loss: 0.14747/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.05763\n",
      "\tPart 3 - fp_loss: 0.66136/81.00%, bp_loss: 0.74878/79.00%, hp_loss: 2.43938/38.00%, j_loss: 0.48715/82.00%, \n",
      "\t\tfr_loss: 0.10463/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44130\n",
      "\tPart 4 - fp_loss: 0.54425/83.00%, bp_loss: 0.79476/77.00%, hp_loss: 2.60655/32.00%, j_loss: 0.46414/83.00%, \n",
      "\t\tfr_loss: 0.08767/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.49737\n",
      "\tTraining time elapsed: 1.13 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.85936/75.00%, bp_loss: 1.22996/61.00%, hp_loss: 3.05332/22.00%, j_loss: 0.86472/76.00%, \n",
      "\t\tfr_loss: 0.12957/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13692\n",
      "\tPart 2 - fp_loss: 0.65949/81.00%, bp_loss: 0.91017/73.00%, hp_loss: 2.70451/34.00%, j_loss: 0.57437/82.00%, \n",
      "\t\tfr_loss: 0.12851/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97705\n",
      "\tPart 3 - fp_loss: 0.62021/82.00%, bp_loss: 0.75359/79.00%, hp_loss: 2.35339/39.00%, j_loss: 0.43453/84.00%, \n",
      "\t\tfr_loss: 0.09768/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25940\n",
      "\tPart 4 - fp_loss: 0.61974/82.00%, bp_loss: 0.84387/76.00%, hp_loss: 2.57613/34.00%, j_loss: 0.48312/83.00%, \n",
      "\t\tfr_loss: 0.09571/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61857\n",
      "\tTraining time elapsed: 38.67 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.85702/74.00%, bp_loss: 1.21834/62.00%, hp_loss: 3.06408/22.00%, j_loss: 0.89189/74.00%, \n",
      "\t\tfr_loss: 0.12145/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15278\n",
      "\tPart 2 - fp_loss: 0.73162/77.00%, bp_loss: 0.80505/77.00%, hp_loss: 2.76688/31.00%, j_loss: 0.61327/81.00%, \n",
      "\t\tfr_loss: 0.12597/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.04278\n",
      "\tPart 3 - fp_loss: 0.68364/80.00%, bp_loss: 0.68436/80.00%, hp_loss: 2.38900/37.00%, j_loss: 0.44312/83.00%, \n",
      "\t\tfr_loss: 0.11476/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.31488\n",
      "\tPart 4 - fp_loss: 0.59028/83.00%, bp_loss: 0.78426/77.00%, hp_loss: 2.61468/33.00%, j_loss: 0.45002/85.00%, \n",
      "\t\tfr_loss: 0.08222/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52146\n",
      "\tTraining time elapsed: 76.22 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.90099/73.00%, bp_loss: 1.17696/66.00%, hp_loss: 3.09261/21.00%, j_loss: 0.87880/74.00%, \n",
      "\t\tfr_loss: 0.14556/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19492\n",
      "\tPart 2 - fp_loss: 0.67255/80.00%, bp_loss: 0.87476/74.00%, hp_loss: 2.73046/30.00%, j_loss: 0.55846/82.00%, \n",
      "\t\tfr_loss: 0.12540/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.96162\n",
      "\tPart 3 - fp_loss: 0.64989/79.00%, bp_loss: 0.77437/78.00%, hp_loss: 2.42508/37.00%, j_loss: 0.47173/84.00%, \n",
      "\t\tfr_loss: 0.09732/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41838\n",
      "\tPart 4 - fp_loss: 0.62611/82.00%, bp_loss: 0.88319/75.00%, hp_loss: 2.60270/33.00%, j_loss: 0.49097/83.00%, \n",
      "\t\tfr_loss: 0.10765/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71063\n",
      "\tTraining time elapsed: 113.77 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.91899/73.00%, bp_loss: 1.23161/63.00%, hp_loss: 3.06919/21.00%, j_loss: 0.90526/74.00%, \n",
      "\t\tfr_loss: 0.13603/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26109\n",
      "\tPart 2 - fp_loss: 0.84134/77.00%, bp_loss: 0.93409/74.00%, hp_loss: 2.74670/30.00%, j_loss: 0.63587/79.00%, \n",
      "\t\tfr_loss: 0.14490/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.30290\n",
      "\tPart 3 - fp_loss: 0.66752/79.00%, bp_loss: 0.80857/78.00%, hp_loss: 2.41654/37.00%, j_loss: 0.51564/84.00%, \n",
      "\t\tfr_loss: 0.09601/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50428\n",
      "\tPart 4 - fp_loss: 0.60575/83.00%, bp_loss: 0.76683/78.00%, hp_loss: 2.62933/31.00%, j_loss: 0.45839/86.00%, \n",
      "\t\tfr_loss: 0.10798/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.56828\n",
      "\tTraining time elapsed: 151.32 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.87354/74.00%, bp_loss: 1.17754/65.00%, hp_loss: 3.08804/20.00%, j_loss: 0.85341/76.00%, \n",
      "\t\tfr_loss: 0.11627/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.10880\n",
      "\tPart 2 - fp_loss: 0.77118/79.00%, bp_loss: 0.87666/74.00%, hp_loss: 2.73069/30.00%, j_loss: 0.58114/80.00%, \n",
      "\t\tfr_loss: 0.12618/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.08585\n",
      "\tPart 3 - fp_loss: 0.67143/80.00%, bp_loss: 0.77452/78.00%, hp_loss: 2.40292/39.00%, j_loss: 0.50081/85.00%, \n",
      "\t\tfr_loss: 0.09425/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44392\n",
      "\tPart 4 - fp_loss: 0.56625/83.00%, bp_loss: 0.74211/79.00%, hp_loss: 2.61957/32.00%, j_loss: 0.41705/86.00%, \n",
      "\t\tfr_loss: 0.10749/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45248\n",
      "\tTraining time elapsed: 188.88 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.99657/71.00%, bp_loss: 1.29080/62.00%, hp_loss: 3.08536/22.00%, j_loss: 1.00416/72.00%, \n",
      "\t\tfr_loss: 0.15845/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.53533\n",
      "\tPart 2 - fp_loss: 0.72512/80.00%, bp_loss: 0.93250/73.00%, hp_loss: 2.75970/30.00%, j_loss: 0.63388/80.00%, \n",
      "\t\tfr_loss: 0.13805/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18925\n",
      "\tPart 3 - fp_loss: 0.65385/81.00%, bp_loss: 0.67525/81.00%, hp_loss: 2.35444/41.00%, j_loss: 0.44746/84.00%, \n",
      "\t\tfr_loss: 0.10840/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.23941\n",
      "\tPart 4 - fp_loss: 0.62476/83.00%, bp_loss: 0.76127/78.00%, hp_loss: 2.56500/35.00%, j_loss: 0.41043/87.00%, \n",
      "\t\tfr_loss: 0.09929/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46075\n",
      "\tTraining time elapsed: 226.40 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.90898/73.00%, bp_loss: 1.27492/62.00%, hp_loss: 3.08473/21.00%, j_loss: 0.90894/75.00%, \n",
      "\t\tfr_loss: 0.12057/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29814\n",
      "\tPart 2 - fp_loss: 0.71667/79.00%, bp_loss: 0.80123/76.00%, hp_loss: 2.65728/32.00%, j_loss: 0.58130/81.00%, \n",
      "\t\tfr_loss: 0.11968/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.87615\n",
      "\tPart 3 - fp_loss: 0.74247/79.00%, bp_loss: 0.82555/77.00%, hp_loss: 2.43531/37.00%, j_loss: 0.51790/83.00%, \n",
      "\t\tfr_loss: 0.11210/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63332\n",
      "\tPart 4 - fp_loss: 0.61957/82.00%, bp_loss: 0.75552/78.00%, hp_loss: 2.63719/32.00%, j_loss: 0.43478/86.00%, \n",
      "\t\tfr_loss: 0.10382/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55088\n",
      "\tTraining time elapsed: 263.96 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.85343/74.00%, bp_loss: 1.23510/63.00%, hp_loss: 3.07117/22.00%, j_loss: 0.91871/75.00%, \n",
      "\t\tfr_loss: 0.12962/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.20802\n",
      "\tPart 2 - fp_loss: 0.66108/80.00%, bp_loss: 0.82409/76.00%, hp_loss: 2.65467/35.00%, j_loss: 0.57004/82.00%, \n",
      "\t\tfr_loss: 0.12432/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.83420\n",
      "\tPart 3 - fp_loss: 0.68584/82.00%, bp_loss: 0.85180/76.00%, hp_loss: 2.38097/37.00%, j_loss: 0.51903/83.00%, \n",
      "\t\tfr_loss: 0.13602/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.57366\n",
      "\tPart 4 - fp_loss: 0.59336/82.00%, bp_loss: 0.77144/78.00%, hp_loss: 2.62293/32.00%, j_loss: 0.43153/85.00%, \n",
      "\t\tfr_loss: 0.11553/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53479\n",
      "\tTraining time elapsed: 301.49 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.85358/54.00%, bp_loss: 1.32576/60.00%, hp_loss: 3.03546/23.00%, j_loss: 1.45168/57.00%, \n",
      "\t\tfr_loss: 0.21508/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.88156\n",
      "\tPart 2 - fp_loss: 1.67714/59.00%, bp_loss: 1.15778/67.00%, hp_loss: 2.74979/30.00%, j_loss: 1.23233/63.00%, \n",
      "\t\tfr_loss: 0.19076/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.00779\n",
      "\tPart 3 - fp_loss: 1.31406/70.00%, bp_loss: 0.94146/75.00%, hp_loss: 2.30167/42.00%, j_loss: 0.81326/77.00%, \n",
      "\t\tfr_loss: 0.18057/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55102\n",
      "\tPart 4 - fp_loss: 1.44064/70.00%, bp_loss: 0.94647/74.00%, hp_loss: 2.36655/39.00%, j_loss: 0.89731/78.00%, \n",
      "\t\tfr_loss: 0.16569/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.81665\n",
      "\t`Validation time elapsed: 0.80 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.90691/51.00%, bp_loss: 1.37996/58.00%, hp_loss: 3.04445/22.00%, j_loss: 1.51998/57.00%, \n",
      "\t\tfr_loss: 0.22071/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.07201\n",
      "\tPart 2 - fp_loss: 1.67201/61.00%, bp_loss: 1.16045/67.00%, hp_loss: 2.71713/30.00%, j_loss: 1.17919/67.00%, \n",
      "\t\tfr_loss: 0.18766/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.91644\n",
      "\tPart 3 - fp_loss: 1.34873/71.00%, bp_loss: 0.87275/76.00%, hp_loss: 2.28348/43.00%, j_loss: 0.77442/79.00%, \n",
      "\t\tfr_loss: 0.18016/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.45955\n",
      "\tPart 4 - fp_loss: 1.56872/68.00%, bp_loss: 0.88896/77.00%, hp_loss: 2.46524/37.00%, j_loss: 0.82414/78.00%, \n",
      "\t\tfr_loss: 0.16133/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.90838\n",
      "\t`Validation time elapsed: 9.55 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 50.\n",
      "\n",
      "EPOCH 51\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.81538/76.00%, bp_loss: 1.11917/66.00%, hp_loss: 3.11130/21.00%, j_loss: 0.79105/77.00%, \n",
      "\t\tfr_loss: 0.11878/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.95567\n",
      "\tPart 2 - fp_loss: 0.67991/80.00%, bp_loss: 0.83192/76.00%, hp_loss: 2.67560/32.00%, j_loss: 0.55418/83.00%, \n",
      "\t\tfr_loss: 0.13322/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.87483\n",
      "\tPart 3 - fp_loss: 0.70124/81.00%, bp_loss: 0.84962/76.00%, hp_loss: 2.45903/38.00%, j_loss: 0.52381/83.00%, \n",
      "\t\tfr_loss: 0.10251/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63622\n",
      "\tPart 4 - fp_loss: 0.57485/84.00%, bp_loss: 0.70438/79.00%, hp_loss: 2.55675/34.00%, j_loss: 0.40862/87.00%, \n",
      "\t\tfr_loss: 0.08237/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32697\n",
      "\tTraining time elapsed: 1.18 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.87683/75.00%, bp_loss: 1.18368/64.00%, hp_loss: 3.05411/22.00%, j_loss: 0.83692/76.00%, \n",
      "\t\tfr_loss: 0.14649/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09802\n",
      "\tPart 2 - fp_loss: 0.64411/81.00%, bp_loss: 0.75098/77.00%, hp_loss: 2.71125/32.00%, j_loss: 0.55344/82.00%, \n",
      "\t\tfr_loss: 0.13532/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.79509\n",
      "\tPart 3 - fp_loss: 0.67235/81.00%, bp_loss: 0.68987/81.00%, hp_loss: 2.34931/39.00%, j_loss: 0.41686/84.00%, \n",
      "\t\tfr_loss: 0.12213/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25052\n",
      "\tPart 4 - fp_loss: 0.60652/82.00%, bp_loss: 0.78004/78.00%, hp_loss: 2.53083/33.00%, j_loss: 0.47374/84.00%, \n",
      "\t\tfr_loss: 0.11235/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50348\n",
      "\tTraining time elapsed: 38.73 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.82595/76.00%, bp_loss: 1.22229/63.00%, hp_loss: 3.01195/23.00%, j_loss: 0.82654/77.00%, \n",
      "\t\tfr_loss: 0.14025/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.02698\n",
      "\tPart 2 - fp_loss: 0.67025/79.00%, bp_loss: 0.91230/74.00%, hp_loss: 2.73941/31.00%, j_loss: 0.59472/80.00%, \n",
      "\t\tfr_loss: 0.13144/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.04812\n",
      "\tPart 3 - fp_loss: 0.63941/81.00%, bp_loss: 0.77098/78.00%, hp_loss: 2.46856/37.00%, j_loss: 0.48455/83.00%, \n",
      "\t\tfr_loss: 0.09486/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45835\n",
      "\tPart 4 - fp_loss: 0.53045/84.00%, bp_loss: 0.77096/79.00%, hp_loss: 2.60049/33.00%, j_loss: 0.41889/86.00%, \n",
      "\t\tfr_loss: 0.09792/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41871\n",
      "\tTraining time elapsed: 76.29 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.91152/73.00%, bp_loss: 1.25420/63.00%, hp_loss: 3.06982/23.00%, j_loss: 0.92454/75.00%, \n",
      "\t\tfr_loss: 0.14911/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30919\n",
      "\tPart 2 - fp_loss: 0.75081/78.00%, bp_loss: 0.90250/73.00%, hp_loss: 2.77550/29.00%, j_loss: 0.60487/79.00%, \n",
      "\t\tfr_loss: 0.12898/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16267\n",
      "\tPart 3 - fp_loss: 0.63173/81.00%, bp_loss: 0.81119/78.00%, hp_loss: 2.43352/38.00%, j_loss: 0.45489/85.00%, \n",
      "\t\tfr_loss: 0.11081/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44214\n",
      "\tPart 4 - fp_loss: 0.56236/85.00%, bp_loss: 0.76221/77.00%, hp_loss: 2.55001/34.00%, j_loss: 0.42722/85.00%, \n",
      "\t\tfr_loss: 0.10457/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40636\n",
      "\tTraining time elapsed: 113.86 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.97407/70.00%, bp_loss: 1.21506/63.00%, hp_loss: 3.11908/21.00%, j_loss: 0.98557/72.00%, \n",
      "\t\tfr_loss: 0.15928/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.45307\n",
      "\tPart 2 - fp_loss: 0.76030/79.00%, bp_loss: 0.88444/76.00%, hp_loss: 2.73737/32.00%, j_loss: 0.59533/81.00%, \n",
      "\t\tfr_loss: 0.13701/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.11445\n",
      "\tPart 3 - fp_loss: 0.71570/78.00%, bp_loss: 0.83567/77.00%, hp_loss: 2.45636/36.00%, j_loss: 0.54996/81.00%, \n",
      "\t\tfr_loss: 0.10915/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.66685\n",
      "\tPart 4 - fp_loss: 0.61631/82.00%, bp_loss: 0.79629/78.00%, hp_loss: 2.65761/32.00%, j_loss: 0.42756/86.00%, \n",
      "\t\tfr_loss: 0.10313/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60091\n",
      "\tTraining time elapsed: 151.40 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.90608/74.00%, bp_loss: 1.27581/63.00%, hp_loss: 3.11308/22.00%, j_loss: 0.86330/76.00%, \n",
      "\t\tfr_loss: 0.13657/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.29484\n",
      "\tPart 2 - fp_loss: 0.68515/80.00%, bp_loss: 0.94752/73.00%, hp_loss: 2.75172/31.00%, j_loss: 0.65439/81.00%, \n",
      "\t\tfr_loss: 0.11345/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.15224\n",
      "\tPart 3 - fp_loss: 0.63397/82.00%, bp_loss: 0.75150/79.00%, hp_loss: 2.34537/40.00%, j_loss: 0.44543/84.00%, \n",
      "\t\tfr_loss: 0.11249/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28877\n",
      "\tPart 4 - fp_loss: 0.54749/85.00%, bp_loss: 0.71031/80.00%, hp_loss: 2.62878/31.00%, j_loss: 0.33989/88.00%, \n",
      "\t\tfr_loss: 0.09520/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32167\n",
      "\tTraining time elapsed: 188.93 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.96540/71.00%, bp_loss: 1.25534/63.00%, hp_loss: 3.09020/21.00%, j_loss: 0.99230/72.00%, \n",
      "\t\tfr_loss: 0.13290/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.43614\n",
      "\tPart 2 - fp_loss: 0.79820/78.00%, bp_loss: 0.90331/74.00%, hp_loss: 2.80009/29.00%, j_loss: 0.68554/78.00%, \n",
      "\t\tfr_loss: 0.12407/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.31121\n",
      "\tPart 3 - fp_loss: 0.64911/81.00%, bp_loss: 0.76029/79.00%, hp_loss: 2.48829/36.00%, j_loss: 0.46103/86.00%, \n",
      "\t\tfr_loss: 0.10350/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46222\n",
      "\tPart 4 - fp_loss: 0.62986/82.00%, bp_loss: 0.80037/77.00%, hp_loss: 2.69272/31.00%, j_loss: 0.41866/86.00%, \n",
      "\t\tfr_loss: 0.09864/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64026\n",
      "\tTraining time elapsed: 226.50 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.93940/73.00%, bp_loss: 1.17476/64.00%, hp_loss: 3.06647/21.00%, j_loss: 0.90423/73.00%, \n",
      "\t\tfr_loss: 0.14506/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22992\n",
      "\tPart 2 - fp_loss: 0.75564/79.00%, bp_loss: 0.87825/75.00%, hp_loss: 2.74969/31.00%, j_loss: 0.59858/81.00%, \n",
      "\t\tfr_loss: 0.13591/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.11808\n",
      "\tPart 3 - fp_loss: 0.66068/81.00%, bp_loss: 0.78434/77.00%, hp_loss: 2.42070/37.00%, j_loss: 0.48647/83.00%, \n",
      "\t\tfr_loss: 0.11008/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46227\n",
      "\tPart 4 - fp_loss: 0.59615/83.00%, bp_loss: 0.77819/78.00%, hp_loss: 2.61488/31.00%, j_loss: 0.40188/86.00%, \n",
      "\t\tfr_loss: 0.10080/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.49190\n",
      "\tTraining time elapsed: 264.05 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.80627/74.00%, bp_loss: 1.27429/63.00%, hp_loss: 3.06703/24.00%, j_loss: 0.86828/74.00%, \n",
      "\t\tfr_loss: 0.13933/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15520\n",
      "\tPart 2 - fp_loss: 0.70660/80.00%, bp_loss: 0.80764/76.00%, hp_loss: 2.69926/32.00%, j_loss: 0.56161/80.00%, \n",
      "\t\tfr_loss: 0.14528/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92040\n",
      "\tPart 3 - fp_loss: 0.60150/82.00%, bp_loss: 0.68193/81.00%, hp_loss: 2.41268/40.00%, j_loss: 0.42320/86.00%, \n",
      "\t\tfr_loss: 0.10864/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.22796\n",
      "\tPart 4 - fp_loss: 0.59539/82.00%, bp_loss: 0.70451/79.00%, hp_loss: 2.64248/31.00%, j_loss: 0.41255/86.00%, \n",
      "\t\tfr_loss: 0.10356/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45850\n",
      "\tTraining time elapsed: 301.60 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 2.01532/49.00%, bp_loss: 1.36413/58.00%, hp_loss: 2.99943/24.00%, j_loss: 1.64206/53.00%, \n",
      "\t\tfr_loss: 0.21800/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.23895\n",
      "\tPart 2 - fp_loss: 1.67620/59.00%, bp_loss: 1.10114/68.00%, hp_loss: 2.67362/30.00%, j_loss: 1.21537/64.00%, \n",
      "\t\tfr_loss: 0.17619/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.84251\n",
      "\tPart 3 - fp_loss: 1.31848/70.00%, bp_loss: 1.08248/70.00%, hp_loss: 2.19547/44.00%, j_loss: 0.84326/75.00%, \n",
      "\t\tfr_loss: 0.17501/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.61470\n",
      "\tPart 4 - fp_loss: 1.60203/66.00%, bp_loss: 0.99598/74.00%, hp_loss: 2.38658/40.00%, j_loss: 0.87939/75.00%, \n",
      "\t\tfr_loss: 0.17242/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03640\n",
      "\t`Validation time elapsed: 0.78 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.01242/47.00%, bp_loss: 1.42515/55.00%, hp_loss: 3.09179/22.00%, j_loss: 1.66654/53.00%, \n",
      "\t\tfr_loss: 0.23494/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.43085\n",
      "\tPart 2 - fp_loss: 1.83670/56.00%, bp_loss: 1.22774/67.00%, hp_loss: 2.76077/30.00%, j_loss: 1.28739/65.00%, \n",
      "\t\tfr_loss: 0.20019/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.31279\n",
      "\tPart 3 - fp_loss: 1.34575/70.00%, bp_loss: 0.86163/78.00%, hp_loss: 2.23206/46.00%, j_loss: 0.78636/77.00%, \n",
      "\t\tfr_loss: 0.16045/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.38624\n",
      "\tPart 4 - fp_loss: 1.49635/69.00%, bp_loss: 0.89133/77.00%, hp_loss: 2.34628/41.00%, j_loss: 0.79235/78.00%, \n",
      "\t\tfr_loss: 0.16729/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.69360\n",
      "\t`Validation time elapsed: 9.54 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 51.\n",
      "\n",
      "EPOCH 52\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.89697/74.00%, bp_loss: 1.16622/65.00%, hp_loss: 3.08180/23.00%, j_loss: 0.90102/74.00%, \n",
      "\t\tfr_loss: 0.15171/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19772\n",
      "\tPart 2 - fp_loss: 0.64575/81.00%, bp_loss: 0.93836/73.00%, hp_loss: 2.76585/30.00%, j_loss: 0.58653/80.00%, \n",
      "\t\tfr_loss: 0.12989/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06638\n",
      "\tPart 3 - fp_loss: 0.65878/82.00%, bp_loss: 0.82394/76.00%, hp_loss: 2.36656/40.00%, j_loss: 0.51255/82.00%, \n",
      "\t\tfr_loss: 0.11907/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48089\n",
      "\tPart 4 - fp_loss: 0.54279/84.00%, bp_loss: 0.78693/76.00%, hp_loss: 2.59802/33.00%, j_loss: 0.45149/85.00%, \n",
      "\t\tfr_loss: 0.10481/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48404\n",
      "\tTraining time elapsed: 1.15 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.82674/74.00%, bp_loss: 1.22404/64.00%, hp_loss: 3.03867/24.00%, j_loss: 0.86380/76.00%, \n",
      "\t\tfr_loss: 0.13227/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.08552\n",
      "\tPart 2 - fp_loss: 0.72930/80.00%, bp_loss: 0.84107/76.00%, hp_loss: 2.67293/33.00%, j_loss: 0.57966/81.00%, \n",
      "\t\tfr_loss: 0.13342/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.95638\n",
      "\tPart 3 - fp_loss: 0.65914/81.00%, bp_loss: 0.75033/79.00%, hp_loss: 2.40943/38.00%, j_loss: 0.45550/85.00%, \n",
      "\t\tfr_loss: 0.12582/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40023\n",
      "\tPart 4 - fp_loss: 0.59508/84.00%, bp_loss: 0.81285/77.00%, hp_loss: 2.61321/32.00%, j_loss: 0.40276/86.00%, \n",
      "\t\tfr_loss: 0.10516/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52906\n",
      "\tTraining time elapsed: 38.69 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.96137/70.00%, bp_loss: 1.28376/62.00%, hp_loss: 3.12611/19.00%, j_loss: 0.97767/73.00%, \n",
      "\t\tfr_loss: 0.15143/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.50034\n",
      "\tPart 2 - fp_loss: 0.67223/80.00%, bp_loss: 0.79967/77.00%, hp_loss: 2.65647/34.00%, j_loss: 0.58263/82.00%, \n",
      "\t\tfr_loss: 0.12969/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.84070\n",
      "\tPart 3 - fp_loss: 0.68725/81.00%, bp_loss: 0.81494/78.00%, hp_loss: 2.37371/39.00%, j_loss: 0.46804/85.00%, \n",
      "\t\tfr_loss: 0.10826/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45220\n",
      "\tPart 4 - fp_loss: 0.57442/84.00%, bp_loss: 0.72558/79.00%, hp_loss: 2.59880/33.00%, j_loss: 0.37395/87.00%, \n",
      "\t\tfr_loss: 0.09590/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36865\n",
      "\tTraining time elapsed: 76.23 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.84928/74.00%, bp_loss: 1.24439/63.00%, hp_loss: 3.08739/21.00%, j_loss: 0.87832/74.00%, \n",
      "\t\tfr_loss: 0.11285/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.17223\n",
      "\tPart 2 - fp_loss: 0.72094/78.00%, bp_loss: 0.97605/72.00%, hp_loss: 2.66690/33.00%, j_loss: 0.67260/79.00%, \n",
      "\t\tfr_loss: 0.11152/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.14801\n",
      "\tPart 3 - fp_loss: 0.55794/82.00%, bp_loss: 0.81025/78.00%, hp_loss: 2.39414/40.00%, j_loss: 0.45669/84.00%, \n",
      "\t\tfr_loss: 0.09748/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.31651\n",
      "\tPart 4 - fp_loss: 0.51193/85.00%, bp_loss: 0.82764/76.00%, hp_loss: 2.58532/33.00%, j_loss: 0.42203/85.00%, \n",
      "\t\tfr_loss: 0.08819/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43511\n",
      "\tTraining time elapsed: 113.77 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.92039/73.00%, bp_loss: 1.14987/66.00%, hp_loss: 3.06394/24.00%, j_loss: 0.83902/76.00%, \n",
      "\t\tfr_loss: 0.14602/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11924\n",
      "\tPart 2 - fp_loss: 0.67564/80.00%, bp_loss: 0.91568/74.00%, hp_loss: 2.70152/32.00%, j_loss: 0.60411/82.00%, \n",
      "\t\tfr_loss: 0.11945/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01640\n",
      "\tPart 3 - fp_loss: 0.67619/80.00%, bp_loss: 0.91349/77.00%, hp_loss: 2.39340/37.00%, j_loss: 0.49329/84.00%, \n",
      "\t\tfr_loss: 0.11400/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.59037\n",
      "\tPart 4 - fp_loss: 0.53796/84.00%, bp_loss: 0.81164/76.00%, hp_loss: 2.55052/34.00%, j_loss: 0.41940/86.00%, \n",
      "\t\tfr_loss: 0.09254/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41207\n",
      "\tTraining time elapsed: 151.26 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.86785/75.00%, bp_loss: 1.28314/62.00%, hp_loss: 3.06962/22.00%, j_loss: 0.86597/76.00%, \n",
      "\t\tfr_loss: 0.13812/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22470\n",
      "\tPart 2 - fp_loss: 0.74605/78.00%, bp_loss: 0.85776/75.00%, hp_loss: 2.73554/31.00%, j_loss: 0.62177/79.00%, \n",
      "\t\tfr_loss: 0.14881/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10993\n",
      "\tPart 3 - fp_loss: 0.60528/83.00%, bp_loss: 0.80214/78.00%, hp_loss: 2.36272/40.00%, j_loss: 0.44251/87.00%, \n",
      "\t\tfr_loss: 0.10262/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.31527\n",
      "\tPart 4 - fp_loss: 0.54726/84.00%, bp_loss: 0.81405/77.00%, hp_loss: 2.60508/33.00%, j_loss: 0.41818/87.00%, \n",
      "\t\tfr_loss: 0.09501/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47958\n",
      "\tTraining time elapsed: 188.75 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.98382/70.00%, bp_loss: 1.21859/65.00%, hp_loss: 3.10642/22.00%, j_loss: 0.98925/73.00%, \n",
      "\t\tfr_loss: 0.14291/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.44099\n",
      "\tPart 2 - fp_loss: 0.74859/79.00%, bp_loss: 0.86618/74.00%, hp_loss: 2.72594/31.00%, j_loss: 0.60551/80.00%, \n",
      "\t\tfr_loss: 0.13831/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.08453\n",
      "\tPart 3 - fp_loss: 0.58663/82.00%, bp_loss: 0.73235/79.00%, hp_loss: 2.42979/37.00%, j_loss: 0.45023/84.00%, \n",
      "\t\tfr_loss: 0.09793/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.29692\n",
      "\tPart 4 - fp_loss: 0.59744/83.00%, bp_loss: 0.78434/77.00%, hp_loss: 2.62458/30.00%, j_loss: 0.45434/85.00%, \n",
      "\t\tfr_loss: 0.09029/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.55099\n",
      "\tTraining time elapsed: 226.26 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.89959/74.00%, bp_loss: 1.31318/61.00%, hp_loss: 3.09377/22.00%, j_loss: 0.89047/76.00%, \n",
      "\t\tfr_loss: 0.10784/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30485\n",
      "\tPart 2 - fp_loss: 0.66954/80.00%, bp_loss: 0.90161/74.00%, hp_loss: 2.68194/33.00%, j_loss: 0.58955/81.00%, \n",
      "\t\tfr_loss: 0.12238/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.96502\n",
      "\tPart 3 - fp_loss: 0.66860/81.00%, bp_loss: 0.69176/81.00%, hp_loss: 2.36040/40.00%, j_loss: 0.43225/86.00%, \n",
      "\t\tfr_loss: 0.11863/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.27164\n",
      "\tPart 4 - fp_loss: 0.55684/83.00%, bp_loss: 0.72058/79.00%, hp_loss: 2.48599/36.00%, j_loss: 0.46195/84.00%, \n",
      "\t\tfr_loss: 0.09884/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32420\n",
      "\tTraining time elapsed: 263.78 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.83996/77.00%, bp_loss: 1.24828/62.00%, hp_loss: 3.04706/21.00%, j_loss: 0.86627/77.00%, \n",
      "\t\tfr_loss: 0.13755/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13912\n",
      "\tPart 2 - fp_loss: 0.68491/79.00%, bp_loss: 0.87064/74.00%, hp_loss: 2.74416/29.00%, j_loss: 0.53801/82.00%, \n",
      "\t\tfr_loss: 0.13997/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97768\n",
      "\tPart 3 - fp_loss: 0.64636/81.00%, bp_loss: 0.73165/79.00%, hp_loss: 2.45427/38.00%, j_loss: 0.44363/87.00%, \n",
      "\t\tfr_loss: 0.11580/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39171\n",
      "\tPart 4 - fp_loss: 0.63305/81.00%, bp_loss: 0.77274/77.00%, hp_loss: 2.60038/31.00%, j_loss: 0.44247/84.00%, \n",
      "\t\tfr_loss: 0.08695/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.53558\n",
      "\tTraining time elapsed: 301.33 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.99078/49.00%, bp_loss: 1.31244/58.00%, hp_loss: 3.09850/21.00%, j_loss: 1.58520/51.00%, \n",
      "\t\tfr_loss: 0.24196/75.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.22888\n",
      "\tPart 2 - fp_loss: 1.74946/58.00%, bp_loss: 1.16127/67.00%, hp_loss: 2.80284/27.00%, j_loss: 1.19005/65.00%, \n",
      "\t\tfr_loss: 0.18768/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.09130\n",
      "\tPart 3 - fp_loss: 1.28032/69.00%, bp_loss: 0.90058/75.00%, hp_loss: 2.28787/43.00%, j_loss: 0.81232/77.00%, \n",
      "\t\tfr_loss: 0.18991/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.47100\n",
      "\tPart 4 - fp_loss: 1.56617/68.00%, bp_loss: 0.90075/74.00%, hp_loss: 2.40489/37.00%, j_loss: 0.90247/76.00%, \n",
      "\t\tfr_loss: 0.16523/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.93951\n",
      "\t`Validation time elapsed: 0.82 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.95354/52.00%, bp_loss: 1.33762/61.00%, hp_loss: 3.05783/22.00%, j_loss: 1.46291/56.00%, \n",
      "\t\tfr_loss: 0.22543/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.03732\n",
      "\tPart 2 - fp_loss: 1.75799/59.00%, bp_loss: 1.09766/68.00%, hp_loss: 2.69754/28.00%, j_loss: 1.12525/66.00%, \n",
      "\t\tfr_loss: 0.21007/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.88851\n",
      "\tPart 3 - fp_loss: 1.35215/69.00%, bp_loss: 0.84823/79.00%, hp_loss: 2.22383/44.00%, j_loss: 0.74911/79.00%, \n",
      "\t\tfr_loss: 0.19812/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.37144\n",
      "\tPart 4 - fp_loss: 1.57841/68.00%, bp_loss: 0.88297/77.00%, hp_loss: 2.35281/38.00%, j_loss: 0.75737/79.00%, \n",
      "\t\tfr_loss: 0.19080/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.76237\n",
      "\t`Validation time elapsed: 9.57 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 52.\n",
      "\n",
      "EPOCH 53\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.81012/77.00%, bp_loss: 1.16519/65.00%, hp_loss: 3.10654/22.00%, j_loss: 0.82937/76.00%, \n",
      "\t\tfr_loss: 0.11831/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.02953\n",
      "\tPart 2 - fp_loss: 0.67167/81.00%, bp_loss: 0.83990/76.00%, hp_loss: 2.73338/30.00%, j_loss: 0.56026/82.00%, \n",
      "\t\tfr_loss: 0.12880/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.93402\n",
      "\tPart 3 - fp_loss: 0.64908/81.00%, bp_loss: 0.81182/77.00%, hp_loss: 2.43909/36.00%, j_loss: 0.50665/83.00%, \n",
      "\t\tfr_loss: 0.11839/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52503\n",
      "\tPart 4 - fp_loss: 0.52823/85.00%, bp_loss: 0.68134/81.00%, hp_loss: 2.58438/33.00%, j_loss: 0.38417/86.00%, \n",
      "\t\tfr_loss: 0.07404/93.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25217\n",
      "\tTraining time elapsed: 1.13 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.85277/75.00%, bp_loss: 1.24937/63.00%, hp_loss: 3.04319/24.00%, j_loss: 0.88687/74.00%, \n",
      "\t\tfr_loss: 0.13622/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16843\n",
      "\tPart 2 - fp_loss: 0.70332/79.00%, bp_loss: 0.94765/72.00%, hp_loss: 2.67778/32.00%, j_loss: 0.64688/80.00%, \n",
      "\t\tfr_loss: 0.11613/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09176\n",
      "\tPart 3 - fp_loss: 0.68356/79.00%, bp_loss: 1.51340/70.00%, hp_loss: 2.44164/38.00%, j_loss: 0.72353/82.00%, \n",
      "\t\tfr_loss: 0.11788/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.48001\n",
      "\tPart 4 - fp_loss: 0.52310/85.00%, bp_loss: 0.75508/78.00%, hp_loss: 2.58060/32.00%, j_loss: 0.40728/87.00%, \n",
      "\t\tfr_loss: 0.08286/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34892\n",
      "\tTraining time elapsed: 38.67 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.89292/74.00%, bp_loss: 1.13053/65.00%, hp_loss: 3.10597/20.00%, j_loss: 0.80874/76.00%, \n",
      "\t\tfr_loss: 0.12049/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05866\n",
      "\tPart 2 - fp_loss: 0.77231/77.00%, bp_loss: 0.82665/76.00%, hp_loss: 2.71473/30.00%, j_loss: 0.59332/79.00%, \n",
      "\t\tfr_loss: 0.12788/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.03489\n",
      "\tPart 3 - fp_loss: 0.62273/82.00%, bp_loss: 0.68174/81.00%, hp_loss: 2.45711/37.00%, j_loss: 0.39333/86.00%, \n",
      "\t\tfr_loss: 0.10162/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25654\n",
      "\tPart 4 - fp_loss: 0.58666/83.00%, bp_loss: 0.70872/80.00%, hp_loss: 2.64356/32.00%, j_loss: 0.39200/85.00%, \n",
      "\t\tfr_loss: 0.09741/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42835\n",
      "\tTraining time elapsed: 76.16 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.80626/75.00%, bp_loss: 1.19028/65.00%, hp_loss: 3.06893/24.00%, j_loss: 0.84332/75.00%, \n",
      "\t\tfr_loss: 0.15467/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.06345\n",
      "\tPart 2 - fp_loss: 0.76706/77.00%, bp_loss: 0.83886/75.00%, hp_loss: 2.77219/30.00%, j_loss: 0.68232/78.00%, \n",
      "\t\tfr_loss: 0.13598/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.19640\n",
      "\tPart 3 - fp_loss: 0.62838/82.00%, bp_loss: 0.76845/80.00%, hp_loss: 2.42012/38.00%, j_loss: 0.44485/86.00%, \n",
      "\t\tfr_loss: 0.10809/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36990\n",
      "\tPart 4 - fp_loss: 0.56125/83.00%, bp_loss: 0.72731/79.00%, hp_loss: 2.50690/35.00%, j_loss: 0.40130/86.00%, \n",
      "\t\tfr_loss: 0.09276/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.28952\n",
      "\tTraining time elapsed: 113.69 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.86420/74.00%, bp_loss: 1.22181/63.00%, hp_loss: 3.03935/22.00%, j_loss: 0.86759/75.00%, \n",
      "\t\tfr_loss: 0.12752/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.12046\n",
      "\tPart 2 - fp_loss: 0.63619/82.00%, bp_loss: 0.79351/77.00%, hp_loss: 2.67199/34.00%, j_loss: 0.50515/83.00%, \n",
      "\t\tfr_loss: 0.12805/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73489\n",
      "\tPart 3 - fp_loss: 0.66769/79.00%, bp_loss: 0.74375/78.00%, hp_loss: 2.38922/39.00%, j_loss: 0.56244/82.00%, \n",
      "\t\tfr_loss: 0.10373/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46684\n",
      "\tPart 4 - fp_loss: 0.56955/83.00%, bp_loss: 0.74690/80.00%, hp_loss: 2.53518/35.00%, j_loss: 0.47765/85.00%, \n",
      "\t\tfr_loss: 0.09008/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41936\n",
      "\tTraining time elapsed: 151.19 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.89254/73.00%, bp_loss: 1.22373/63.00%, hp_loss: 3.12470/20.00%, j_loss: 0.88576/73.00%, \n",
      "\t\tfr_loss: 0.13901/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26574\n",
      "\tPart 2 - fp_loss: 0.67959/81.00%, bp_loss: 0.89574/75.00%, hp_loss: 2.71071/31.00%, j_loss: 0.54324/83.00%, \n",
      "\t\tfr_loss: 0.13575/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.96502\n",
      "\tPart 3 - fp_loss: 0.65258/81.00%, bp_loss: 0.78591/78.00%, hp_loss: 2.35514/39.00%, j_loss: 0.52025/83.00%, \n",
      "\t\tfr_loss: 0.11156/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42544\n",
      "\tPart 4 - fp_loss: 0.60940/83.00%, bp_loss: 0.79232/78.00%, hp_loss: 2.59593/33.00%, j_loss: 0.41973/85.00%, \n",
      "\t\tfr_loss: 0.09096/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50833\n",
      "\tTraining time elapsed: 188.69 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.81180/75.00%, bp_loss: 1.28306/62.00%, hp_loss: 3.16199/20.00%, j_loss: 0.87343/75.00%, \n",
      "\t\tfr_loss: 0.13279/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26306\n",
      "\tPart 2 - fp_loss: 0.69095/80.00%, bp_loss: 0.82181/77.00%, hp_loss: 2.73809/33.00%, j_loss: 0.54273/84.00%, \n",
      "\t\tfr_loss: 0.11583/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.90940\n",
      "\tPart 3 - fp_loss: 0.64217/81.00%, bp_loss: 0.75353/79.00%, hp_loss: 2.44752/38.00%, j_loss: 0.45826/86.00%, \n",
      "\t\tfr_loss: 0.09395/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39543\n",
      "\tPart 4 - fp_loss: 0.57133/84.00%, bp_loss: 0.78593/77.00%, hp_loss: 2.60790/33.00%, j_loss: 0.41291/87.00%, \n",
      "\t\tfr_loss: 0.08807/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46615\n",
      "\tTraining time elapsed: 226.23 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.89150/73.00%, bp_loss: 1.17233/65.00%, hp_loss: 3.09809/22.00%, j_loss: 0.85559/75.00%, \n",
      "\t\tfr_loss: 0.13177/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14928\n",
      "\tPart 2 - fp_loss: 0.67781/80.00%, bp_loss: 0.88322/74.00%, hp_loss: 2.68959/32.00%, j_loss: 0.62483/80.00%, \n",
      "\t\tfr_loss: 0.13594/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01138\n",
      "\tPart 3 - fp_loss: 0.64085/81.00%, bp_loss: 0.71119/81.00%, hp_loss: 2.34897/39.00%, j_loss: 0.42428/85.00%, \n",
      "\t\tfr_loss: 0.10553/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.23083\n",
      "\tPart 4 - fp_loss: 0.50209/85.00%, bp_loss: 0.76158/78.00%, hp_loss: 2.54665/33.00%, j_loss: 0.35132/88.00%, \n",
      "\t\tfr_loss: 0.08887/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25051\n",
      "\tTraining time elapsed: 263.77 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.90602/71.00%, bp_loss: 1.22859/63.00%, hp_loss: 3.13166/20.00%, j_loss: 0.94835/73.00%, \n",
      "\t\tfr_loss: 0.13122/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.34584\n",
      "\tPart 2 - fp_loss: 0.67874/81.00%, bp_loss: 0.85914/75.00%, hp_loss: 2.70056/31.00%, j_loss: 0.56466/82.00%, \n",
      "\t\tfr_loss: 0.13734/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94044\n",
      "\tPart 3 - fp_loss: 0.72134/81.00%, bp_loss: 0.68242/80.00%, hp_loss: 2.37246/40.00%, j_loss: 0.45608/86.00%, \n",
      "\t\tfr_loss: 0.11201/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34431\n",
      "\tPart 4 - fp_loss: 0.59916/83.00%, bp_loss: 0.79455/77.00%, hp_loss: 2.56259/34.00%, j_loss: 0.44459/86.00%, \n",
      "\t\tfr_loss: 0.10888/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.50976\n",
      "\tTraining time elapsed: 301.31 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.96782/50.00%, bp_loss: 1.38494/57.00%, hp_loss: 3.05001/23.00%, j_loss: 1.64015/53.00%, \n",
      "\t\tfr_loss: 0.23571/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.27863\n",
      "\tPart 2 - fp_loss: 1.73796/58.00%, bp_loss: 1.20390/66.00%, hp_loss: 2.72852/29.00%, j_loss: 1.26540/64.00%, \n",
      "\t\tfr_loss: 0.20097/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.13674\n",
      "\tPart 3 - fp_loss: 1.38787/68.00%, bp_loss: 0.85658/76.00%, hp_loss: 2.23971/43.00%, j_loss: 0.77279/77.00%, \n",
      "\t\tfr_loss: 0.18709/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.44405\n",
      "\tPart 4 - fp_loss: 1.65545/67.00%, bp_loss: 0.92089/75.00%, hp_loss: 2.37561/40.00%, j_loss: 0.90059/76.00%, \n",
      "\t\tfr_loss: 0.18574/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03828\n",
      "\t`Validation time elapsed: 0.79 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.05481/49.00%, bp_loss: 1.38435/57.00%, hp_loss: 3.02260/23.00%, j_loss: 1.67038/54.00%, \n",
      "\t\tfr_loss: 0.20585/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.33798\n",
      "\tPart 2 - fp_loss: 1.62352/62.00%, bp_loss: 1.08903/68.00%, hp_loss: 2.68509/30.00%, j_loss: 1.08923/67.00%, \n",
      "\t\tfr_loss: 0.22100/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.70786\n",
      "\tPart 3 - fp_loss: 1.31728/69.00%, bp_loss: 0.88795/78.00%, hp_loss: 2.26754/43.00%, j_loss: 0.73349/79.00%, \n",
      "\t\tfr_loss: 0.16938/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.37563\n",
      "\tPart 4 - fp_loss: 1.59437/68.00%, bp_loss: 0.95154/74.00%, hp_loss: 2.42096/37.00%, j_loss: 0.80565/77.00%, \n",
      "\t\tfr_loss: 0.17882/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.95135\n",
      "\t`Validation time elapsed: 9.55 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 53.\n",
      "\n",
      "EPOCH 54\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.86102/75.00%, bp_loss: 1.14614/65.00%, hp_loss: 3.08887/20.00%, j_loss: 0.85619/74.00%, \n",
      "\t\tfr_loss: 0.12607/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.07828\n",
      "\tPart 2 - fp_loss: 0.69432/80.00%, bp_loss: 0.83930/76.00%, hp_loss: 2.78102/29.00%, j_loss: 0.53341/82.00%, \n",
      "\t\tfr_loss: 0.13257/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.98063\n",
      "\tPart 3 - fp_loss: 0.65404/81.00%, bp_loss: 0.83971/77.00%, hp_loss: 2.40247/37.00%, j_loss: 0.50533/83.00%, \n",
      "\t\tfr_loss: 0.09826/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.49981\n",
      "\tPart 4 - fp_loss: 0.51436/86.00%, bp_loss: 0.83464/76.00%, hp_loss: 2.55269/34.00%, j_loss: 0.39342/87.00%, \n",
      "\t\tfr_loss: 0.08209/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37720\n",
      "\tTraining time elapsed: 1.14 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.83538/75.00%, bp_loss: 1.19865/65.00%, hp_loss: 3.03482/24.00%, j_loss: 0.84169/75.00%, \n",
      "\t\tfr_loss: 0.12626/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03680\n",
      "\tPart 2 - fp_loss: 0.62684/82.00%, bp_loss: 0.89409/73.00%, hp_loss: 2.73158/30.00%, j_loss: 0.57432/83.00%, \n",
      "\t\tfr_loss: 0.12166/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94849\n",
      "\tPart 3 - fp_loss: 0.68306/80.00%, bp_loss: 0.73095/80.00%, hp_loss: 2.39115/37.00%, j_loss: 0.43740/85.00%, \n",
      "\t\tfr_loss: 0.09614/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.33871\n",
      "\tPart 4 - fp_loss: 0.55109/83.00%, bp_loss: 0.76951/77.00%, hp_loss: 2.66968/30.00%, j_loss: 0.47220/85.00%, \n",
      "\t\tfr_loss: 0.08044/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54292\n",
      "\tTraining time elapsed: 38.63 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.92282/70.00%, bp_loss: 1.25388/61.00%, hp_loss: 3.06477/22.00%, j_loss: 1.00015/73.00%, \n",
      "\t\tfr_loss: 0.16807/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.40969\n",
      "\tPart 2 - fp_loss: 0.74017/78.00%, bp_loss: 0.83546/75.00%, hp_loss: 2.75964/30.00%, j_loss: 0.60604/81.00%, \n",
      "\t\tfr_loss: 0.10448/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.04579\n",
      "\tPart 3 - fp_loss: 0.73075/79.00%, bp_loss: 0.84334/77.00%, hp_loss: 2.42358/38.00%, j_loss: 0.55375/85.00%, \n",
      "\t\tfr_loss: 0.11130/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.66272\n",
      "\tPart 4 - fp_loss: 0.55598/83.00%, bp_loss: 0.78200/77.00%, hp_loss: 2.56775/34.00%, j_loss: 0.44730/87.00%, \n",
      "\t\tfr_loss: 0.08868/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44170\n",
      "\tTraining time elapsed: 76.16 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.89024/74.00%, bp_loss: 1.20439/64.00%, hp_loss: 3.07986/22.00%, j_loss: 0.86508/76.00%, \n",
      "\t\tfr_loss: 0.11461/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15418\n",
      "\tPart 2 - fp_loss: 0.71673/80.00%, bp_loss: 0.87000/75.00%, hp_loss: 2.70828/32.00%, j_loss: 0.61951/81.00%, \n",
      "\t\tfr_loss: 0.11653/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.03105\n",
      "\tPart 3 - fp_loss: 0.62523/81.00%, bp_loss: 0.72367/81.00%, hp_loss: 2.31979/41.00%, j_loss: 0.44979/85.00%, \n",
      "\t\tfr_loss: 0.09414/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.21262\n",
      "\tPart 4 - fp_loss: 0.57489/82.00%, bp_loss: 0.78427/78.00%, hp_loss: 2.52362/36.00%, j_loss: 0.46598/85.00%, \n",
      "\t\tfr_loss: 0.09501/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44378\n",
      "\tTraining time elapsed: 113.68 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.83083/77.00%, bp_loss: 1.19455/64.00%, hp_loss: 3.09603/22.00%, j_loss: 0.80919/77.00%, \n",
      "\t\tfr_loss: 0.12239/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05299\n",
      "\tPart 2 - fp_loss: 0.68862/81.00%, bp_loss: 0.84275/74.00%, hp_loss: 2.70783/30.00%, j_loss: 0.58777/80.00%, \n",
      "\t\tfr_loss: 0.12900/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.95597\n",
      "\tPart 3 - fp_loss: 0.72007/80.00%, bp_loss: 0.66894/80.00%, hp_loss: 2.40008/38.00%, j_loss: 0.48007/85.00%, \n",
      "\t\tfr_loss: 0.09157/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36073\n",
      "\tPart 4 - fp_loss: 0.57320/83.00%, bp_loss: 0.71481/78.00%, hp_loss: 2.52916/34.00%, j_loss: 0.43896/85.00%, \n",
      "\t\tfr_loss: 0.09435/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35047\n",
      "\tTraining time elapsed: 151.20 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.88839/72.00%, bp_loss: 1.28944/62.00%, hp_loss: 3.08497/22.00%, j_loss: 0.92662/74.00%, \n",
      "\t\tfr_loss: 0.11982/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30924\n",
      "\tPart 2 - fp_loss: 0.68173/79.00%, bp_loss: 0.87036/75.00%, hp_loss: 2.73741/32.00%, j_loss: 0.54128/83.00%, \n",
      "\t\tfr_loss: 0.12878/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.95954\n",
      "\tPart 3 - fp_loss: 0.70956/81.00%, bp_loss: 0.77208/78.00%, hp_loss: 2.43203/38.00%, j_loss: 0.49484/85.00%, \n",
      "\t\tfr_loss: 0.10434/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.51284\n",
      "\tPart 4 - fp_loss: 0.50499/83.00%, bp_loss: 0.76122/79.00%, hp_loss: 2.61444/32.00%, j_loss: 0.38386/86.00%, \n",
      "\t\tfr_loss: 0.09458/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.35909\n",
      "\tTraining time elapsed: 188.74 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.88917/73.00%, bp_loss: 1.25581/65.00%, hp_loss: 3.07232/23.00%, j_loss: 0.89699/75.00%, \n",
      "\t\tfr_loss: 0.15019/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26448\n",
      "\tPart 2 - fp_loss: 0.70225/79.00%, bp_loss: 0.84288/76.00%, hp_loss: 2.68898/33.00%, j_loss: 0.54634/81.00%, \n",
      "\t\tfr_loss: 0.14312/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92358\n",
      "\tPart 3 - fp_loss: 0.69342/80.00%, bp_loss: 0.75078/80.00%, hp_loss: 2.46593/37.00%, j_loss: 0.46853/85.00%, \n",
      "\t\tfr_loss: 0.10869/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48735\n",
      "\tPart 4 - fp_loss: 0.56467/83.00%, bp_loss: 0.78279/78.00%, hp_loss: 2.60844/32.00%, j_loss: 0.41460/86.00%, \n",
      "\t\tfr_loss: 0.09426/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.46476\n",
      "\tTraining time elapsed: 226.29 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.97512/72.00%, bp_loss: 1.28796/62.00%, hp_loss: 3.07850/21.00%, j_loss: 0.95113/72.00%, \n",
      "\t\tfr_loss: 0.13361/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.42631\n",
      "\tPart 2 - fp_loss: 0.67168/79.00%, bp_loss: 0.86847/75.00%, hp_loss: 2.73741/30.00%, j_loss: 0.58255/83.00%, \n",
      "\t\tfr_loss: 0.12171/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.98183\n",
      "\tPart 3 - fp_loss: 0.63678/81.00%, bp_loss: 0.78842/77.00%, hp_loss: 2.44617/36.00%, j_loss: 0.49484/83.00%, \n",
      "\t\tfr_loss: 0.11134/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47755\n",
      "\tPart 4 - fp_loss: 0.50401/85.00%, bp_loss: 0.74639/78.00%, hp_loss: 2.61105/33.00%, j_loss: 0.37854/87.00%, \n",
      "\t\tfr_loss: 0.10184/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34183\n",
      "\tTraining time elapsed: 263.84 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.01580/71.00%, bp_loss: 1.32261/61.00%, hp_loss: 3.12872/21.00%, j_loss: 0.98051/73.00%, \n",
      "\t\tfr_loss: 0.13731/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.58495\n",
      "\tPart 2 - fp_loss: 0.74600/78.00%, bp_loss: 0.90398/73.00%, hp_loss: 2.77535/30.00%, j_loss: 0.63467/80.00%, \n",
      "\t\tfr_loss: 0.12883/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18883\n",
      "\tPart 3 - fp_loss: 0.67486/81.00%, bp_loss: 0.75683/78.00%, hp_loss: 2.41465/37.00%, j_loss: 0.43910/85.00%, \n",
      "\t\tfr_loss: 0.10822/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.39367\n",
      "\tPart 4 - fp_loss: 0.55081/84.00%, bp_loss: 0.76473/78.00%, hp_loss: 2.59818/33.00%, j_loss: 0.41766/86.00%, \n",
      "\t\tfr_loss: 0.09338/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42476\n",
      "\tTraining time elapsed: 301.36 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.99620/50.00%, bp_loss: 1.34170/58.00%, hp_loss: 3.05122/23.00%, j_loss: 1.52399/54.00%, \n",
      "\t\tfr_loss: 0.20676/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.11986\n",
      "\tPart 2 - fp_loss: 1.65614/59.00%, bp_loss: 0.97189/72.00%, hp_loss: 2.65873/31.00%, j_loss: 1.04040/69.00%, \n",
      "\t\tfr_loss: 0.19145/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.51861\n",
      "\tPart 3 - fp_loss: 1.38092/67.00%, bp_loss: 0.84205/76.00%, hp_loss: 2.24366/42.00%, j_loss: 0.77380/75.00%, \n",
      "\t\tfr_loss: 0.16824/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40866\n",
      "\tPart 4 - fp_loss: 1.69950/67.00%, bp_loss: 0.98419/73.00%, hp_loss: 2.42814/38.00%, j_loss: 0.93732/76.00%, \n",
      "\t\tfr_loss: 0.18628/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.23543\n",
      "\t`Validation time elapsed: 0.80 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.98622/50.00%, bp_loss: 1.32958/60.00%, hp_loss: 3.03532/24.00%, j_loss: 1.57730/57.00%, \n",
      "\t\tfr_loss: 0.19853/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.12696\n",
      "\tPart 2 - fp_loss: 1.79282/57.00%, bp_loss: 1.13484/69.00%, hp_loss: 2.76733/28.00%, j_loss: 1.12528/65.00%, \n",
      "\t\tfr_loss: 0.17033/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.99061\n",
      "\tPart 3 - fp_loss: 1.30967/70.00%, bp_loss: 0.81950/78.00%, hp_loss: 2.29188/41.00%, j_loss: 0.75756/80.00%, \n",
      "\t\tfr_loss: 0.16379/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.34240\n",
      "\tPart 4 - fp_loss: 1.56705/67.00%, bp_loss: 0.95864/75.00%, hp_loss: 2.42347/38.00%, j_loss: 0.87970/77.00%, \n",
      "\t\tfr_loss: 0.17507/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.00393\n",
      "\t`Validation time elapsed: 9.56 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 54.\n",
      "\n",
      "EPOCH 55\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.87579/74.00%, bp_loss: 1.15451/65.00%, hp_loss: 3.06987/23.00%, j_loss: 0.89448/74.00%, \n",
      "\t\tfr_loss: 0.13727/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13192\n",
      "\tPart 2 - fp_loss: 0.61911/81.00%, bp_loss: 0.78179/77.00%, hp_loss: 2.61351/35.00%, j_loss: 0.55653/80.00%, \n",
      "\t\tfr_loss: 0.11804/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.68898\n",
      "\tPart 3 - fp_loss: 0.60518/82.00%, bp_loss: 0.71846/79.00%, hp_loss: 2.26668/42.00%, j_loss: 0.41852/84.00%, \n",
      "\t\tfr_loss: 0.09375/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.10258\n",
      "\tPart 4 - fp_loss: 0.49745/86.00%, bp_loss: 0.79981/76.00%, hp_loss: 2.57467/34.00%, j_loss: 0.41905/85.00%, \n",
      "\t\tfr_loss: 0.07543/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36641\n",
      "\tTraining time elapsed: 1.14 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.83663/75.00%, bp_loss: 1.26571/62.00%, hp_loss: 3.07154/23.00%, j_loss: 0.83986/76.00%, \n",
      "\t\tfr_loss: 0.13662/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15036\n",
      "\tPart 2 - fp_loss: 0.69950/79.00%, bp_loss: 0.89247/73.00%, hp_loss: 2.75753/31.00%, j_loss: 0.61697/80.00%, \n",
      "\t\tfr_loss: 0.11893/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.08540\n",
      "\tPart 3 - fp_loss: 0.66120/80.00%, bp_loss: 0.71637/80.00%, hp_loss: 2.30402/42.00%, j_loss: 0.43986/84.00%, \n",
      "\t\tfr_loss: 0.08579/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.20724\n",
      "\tPart 4 - fp_loss: 0.55355/84.00%, bp_loss: 0.83845/76.00%, hp_loss: 2.52899/34.00%, j_loss: 0.45840/87.00%, \n",
      "\t\tfr_loss: 0.09678/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47617\n",
      "\tTraining time elapsed: 38.71 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.93428/73.00%, bp_loss: 1.17983/65.00%, hp_loss: 3.08167/22.00%, j_loss: 0.91096/74.00%, \n",
      "\t\tfr_loss: 0.14637/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25311\n",
      "\tPart 2 - fp_loss: 0.73879/78.00%, bp_loss: 0.80383/78.00%, hp_loss: 2.69855/33.00%, j_loss: 0.60423/81.00%, \n",
      "\t\tfr_loss: 0.13149/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97690\n",
      "\tPart 3 - fp_loss: 0.60212/82.00%, bp_loss: 0.68720/81.00%, hp_loss: 2.37329/40.00%, j_loss: 0.43303/87.00%, \n",
      "\t\tfr_loss: 0.09400/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.18964\n",
      "\tPart 4 - fp_loss: 0.54022/84.00%, bp_loss: 0.76885/79.00%, hp_loss: 2.64512/31.00%, j_loss: 0.41455/88.00%, \n",
      "\t\tfr_loss: 0.08098/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44973\n",
      "\tTraining time elapsed: 76.27 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.98288/71.00%, bp_loss: 1.28734/62.00%, hp_loss: 3.10157/22.00%, j_loss: 0.97512/72.00%, \n",
      "\t\tfr_loss: 0.12566/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47257\n",
      "\tPart 2 - fp_loss: 0.70464/80.00%, bp_loss: 0.92240/74.00%, hp_loss: 2.74244/32.00%, j_loss: 0.57637/83.00%, \n",
      "\t\tfr_loss: 0.12054/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06640\n",
      "\tPart 3 - fp_loss: 0.71915/79.00%, bp_loss: 0.68776/81.00%, hp_loss: 2.39064/39.00%, j_loss: 0.43591/84.00%, \n",
      "\t\tfr_loss: 0.09065/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32411\n",
      "\tPart 4 - fp_loss: 0.52213/85.00%, bp_loss: 0.78639/78.00%, hp_loss: 2.59705/34.00%, j_loss: 0.37773/87.00%, \n",
      "\t\tfr_loss: 0.09048/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37378\n",
      "\tTraining time elapsed: 113.80 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.83991/74.00%, bp_loss: 1.30223/62.00%, hp_loss: 3.10042/20.00%, j_loss: 0.89073/74.00%, \n",
      "\t\tfr_loss: 0.13362/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26691\n",
      "\tPart 2 - fp_loss: 0.68238/79.00%, bp_loss: 0.80410/77.00%, hp_loss: 2.62370/35.00%, j_loss: 0.56831/80.00%, \n",
      "\t\tfr_loss: 0.13022/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.80872\n",
      "\tPart 3 - fp_loss: 0.68766/81.00%, bp_loss: 0.73366/79.00%, hp_loss: 2.33752/38.00%, j_loss: 0.48324/85.00%, \n",
      "\t\tfr_loss: 0.10162/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.34371\n",
      "\tPart 4 - fp_loss: 0.54956/84.00%, bp_loss: 0.73442/79.00%, hp_loss: 2.58344/33.00%, j_loss: 0.45950/86.00%, \n",
      "\t\tfr_loss: 0.10302/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42994\n",
      "\tTraining time elapsed: 151.35 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.92340/72.00%, bp_loss: 1.26590/63.00%, hp_loss: 3.09402/22.00%, j_loss: 0.95427/74.00%, \n",
      "\t\tfr_loss: 0.12925/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.36684\n",
      "\tPart 2 - fp_loss: 0.70020/80.00%, bp_loss: 0.83671/76.00%, hp_loss: 2.70618/33.00%, j_loss: 0.55335/81.00%, \n",
      "\t\tfr_loss: 0.12980/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92624\n",
      "\tPart 3 - fp_loss: 0.69282/78.00%, bp_loss: 0.73025/80.00%, hp_loss: 2.37725/38.00%, j_loss: 0.50599/83.00%, \n",
      "\t\tfr_loss: 0.10115/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40745\n",
      "\tPart 4 - fp_loss: 0.57489/83.00%, bp_loss: 0.82236/76.00%, hp_loss: 2.58566/32.00%, j_loss: 0.45106/85.00%, \n",
      "\t\tfr_loss: 0.09134/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.52531\n",
      "\tTraining time elapsed: 188.91 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.85570/74.00%, bp_loss: 1.18195/64.00%, hp_loss: 3.07697/21.00%, j_loss: 0.85960/74.00%, \n",
      "\t\tfr_loss: 0.11766/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09187\n",
      "\tPart 2 - fp_loss: 0.72612/78.00%, bp_loss: 0.88491/75.00%, hp_loss: 2.73857/31.00%, j_loss: 0.60215/81.00%, \n",
      "\t\tfr_loss: 0.14433/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09608\n",
      "\tPart 3 - fp_loss: 0.63575/81.00%, bp_loss: 0.75934/79.00%, hp_loss: 2.41176/37.00%, j_loss: 0.47058/83.00%, \n",
      "\t\tfr_loss: 0.09315/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37058\n",
      "\tPart 4 - fp_loss: 0.58212/84.00%, bp_loss: 0.79449/77.00%, hp_loss: 2.63525/32.00%, j_loss: 0.39027/86.00%, \n",
      "\t\tfr_loss: 0.08232/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48445\n",
      "\tTraining time elapsed: 226.49 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.89515/73.00%, bp_loss: 1.15060/65.00%, hp_loss: 3.04118/24.00%, j_loss: 0.87688/74.00%, \n",
      "\t\tfr_loss: 0.14908/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11289\n",
      "\tPart 2 - fp_loss: 0.63539/81.00%, bp_loss: 0.84290/76.00%, hp_loss: 2.64004/34.00%, j_loss: 0.52978/81.00%, \n",
      "\t\tfr_loss: 0.12670/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.77481\n",
      "\tPart 3 - fp_loss: 0.67475/81.00%, bp_loss: 0.70948/81.00%, hp_loss: 2.35105/40.00%, j_loss: 0.44255/84.00%, \n",
      "\t\tfr_loss: 0.11721/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.29504\n",
      "\tPart 4 - fp_loss: 0.54974/84.00%, bp_loss: 0.79570/78.00%, hp_loss: 2.55359/35.00%, j_loss: 0.43189/87.00%, \n",
      "\t\tfr_loss: 0.09983/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.43074\n",
      "\tTraining time elapsed: 264.05 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.88406/74.00%, bp_loss: 1.19331/63.00%, hp_loss: 3.10773/20.00%, j_loss: 0.84742/75.00%, \n",
      "\t\tfr_loss: 0.11370/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14623\n",
      "\tPart 2 - fp_loss: 0.70607/79.00%, bp_loss: 0.74537/78.00%, hp_loss: 2.71745/30.00%, j_loss: 0.55859/80.00%, \n",
      "\t\tfr_loss: 0.10940/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.83687\n",
      "\tPart 3 - fp_loss: 0.69120/80.00%, bp_loss: 0.75113/78.00%, hp_loss: 2.37874/38.00%, j_loss: 0.48682/85.00%, \n",
      "\t\tfr_loss: 0.10927/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41715\n",
      "\tPart 4 - fp_loss: 0.56441/83.00%, bp_loss: 0.81507/77.00%, hp_loss: 2.58219/32.00%, j_loss: 0.42130/88.00%, \n",
      "\t\tfr_loss: 0.09810/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.48107\n",
      "\tTraining time elapsed: 301.59 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 2.03805/51.00%, bp_loss: 1.36033/58.00%, hp_loss: 3.01575/24.00%, j_loss: 1.55170/56.00%, \n",
      "\t\tfr_loss: 0.23045/76.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.19629\n",
      "\tPart 2 - fp_loss: 1.64960/60.00%, bp_loss: 1.10107/68.00%, hp_loss: 2.67351/30.00%, j_loss: 1.08495/66.00%, \n",
      "\t\tfr_loss: 0.19774/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.70687\n",
      "\tPart 3 - fp_loss: 1.19240/72.00%, bp_loss: 0.85173/76.00%, hp_loss: 2.24215/44.00%, j_loss: 0.72997/77.00%, \n",
      "\t\tfr_loss: 0.16741/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.18366\n",
      "\tPart 4 - fp_loss: 1.41492/70.00%, bp_loss: 0.95138/74.00%, hp_loss: 2.33090/40.00%, j_loss: 0.75929/78.00%, \n",
      "\t\tfr_loss: 0.15590/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.61238\n",
      "\t`Validation time elapsed: 0.81 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.01291/50.00%, bp_loss: 1.39371/58.00%, hp_loss: 3.01692/23.00%, j_loss: 1.57885/54.00%, \n",
      "\t\tfr_loss: 0.22466/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.22705\n",
      "\tPart 2 - fp_loss: 1.53779/61.00%, bp_loss: 1.13635/68.00%, hp_loss: 2.70052/30.00%, j_loss: 1.16413/66.00%, \n",
      "\t\tfr_loss: 0.19046/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.72926\n",
      "\tPart 3 - fp_loss: 1.27176/71.00%, bp_loss: 0.87745/76.00%, hp_loss: 2.25986/43.00%, j_loss: 0.79675/80.00%, \n",
      "\t\tfr_loss: 0.16498/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.37080\n",
      "\tPart 4 - fp_loss: 1.57987/69.00%, bp_loss: 0.92938/76.00%, hp_loss: 2.34731/40.00%, j_loss: 0.79491/79.00%, \n",
      "\t\tfr_loss: 0.17395/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.82542\n",
      "\t`Validation time elapsed: 9.56 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 55.\n",
      "\n",
      "EPOCH 56\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.75958/78.00%, bp_loss: 1.09986/66.00%, hp_loss: 3.06882/23.00%, j_loss: 0.80047/77.00%, \n",
      "\t\tfr_loss: 0.12320/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.85192\n",
      "\tPart 2 - fp_loss: 0.70792/79.00%, bp_loss: 0.81743/76.00%, hp_loss: 2.75108/31.00%, j_loss: 0.60106/82.00%, \n",
      "\t\tfr_loss: 0.11679/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.99427\n",
      "\tPart 3 - fp_loss: 0.65780/82.00%, bp_loss: 0.68977/80.00%, hp_loss: 2.32864/41.00%, j_loss: 0.48398/82.00%, \n",
      "\t\tfr_loss: 0.10626/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.26644\n",
      "\tPart 4 - fp_loss: 0.54721/84.00%, bp_loss: 0.75310/78.00%, hp_loss: 2.58762/34.00%, j_loss: 0.39766/86.00%, \n",
      "\t\tfr_loss: 0.09226/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37785\n",
      "\tTraining time elapsed: 1.17 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.89365/75.00%, bp_loss: 1.27237/63.00%, hp_loss: 3.03887/23.00%, j_loss: 0.89260/76.00%, \n",
      "\t\tfr_loss: 0.12921/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22670\n",
      "\tPart 2 - fp_loss: 0.61716/82.00%, bp_loss: 0.88277/75.00%, hp_loss: 2.66778/34.00%, j_loss: 0.53386/83.00%, \n",
      "\t\tfr_loss: 0.10595/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.80751\n",
      "\tPart 3 - fp_loss: 0.67055/80.00%, bp_loss: 0.71788/78.00%, hp_loss: 2.40613/38.00%, j_loss: 0.49022/82.00%, \n",
      "\t\tfr_loss: 0.09643/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38121\n",
      "\tPart 4 - fp_loss: 0.53521/85.00%, bp_loss: 0.72893/79.00%, hp_loss: 2.55738/34.00%, j_loss: 0.40982/88.00%, \n",
      "\t\tfr_loss: 0.09209/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32342\n",
      "\tTraining time elapsed: 38.70 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.86374/75.00%, bp_loss: 1.26326/62.00%, hp_loss: 3.09862/21.00%, j_loss: 0.91396/75.00%, \n",
      "\t\tfr_loss: 0.13959/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.27918\n",
      "\tPart 2 - fp_loss: 0.65915/80.00%, bp_loss: 0.83410/75.00%, hp_loss: 2.64134/35.00%, j_loss: 0.58022/81.00%, \n",
      "\t\tfr_loss: 0.12953/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.84433\n",
      "\tPart 3 - fp_loss: 0.68223/82.00%, bp_loss: 0.83495/78.00%, hp_loss: 2.35408/40.00%, j_loss: 0.45677/85.00%, \n",
      "\t\tfr_loss: 0.10018/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42822\n",
      "\tPart 4 - fp_loss: 0.55233/84.00%, bp_loss: 0.67950/80.00%, hp_loss: 2.57009/34.00%, j_loss: 0.36015/87.00%, \n",
      "\t\tfr_loss: 0.09489/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25696\n",
      "\tTraining time elapsed: 76.24 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.86681/74.00%, bp_loss: 1.23514/65.00%, hp_loss: 3.12072/21.00%, j_loss: 0.88565/76.00%, \n",
      "\t\tfr_loss: 0.14125/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24956\n",
      "\tPart 2 - fp_loss: 0.73495/79.00%, bp_loss: 0.86816/75.00%, hp_loss: 2.69551/32.00%, j_loss: 0.59114/81.00%, \n",
      "\t\tfr_loss: 0.14040/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.03017\n",
      "\tPart 3 - fp_loss: 0.58989/83.00%, bp_loss: 0.65029/82.00%, hp_loss: 2.33546/41.00%, j_loss: 0.37116/86.00%, \n",
      "\t\tfr_loss: 0.10546/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.05228\n",
      "\tPart 4 - fp_loss: 0.53092/85.00%, bp_loss: 0.75447/79.00%, hp_loss: 2.57900/33.00%, j_loss: 0.36912/87.00%, \n",
      "\t\tfr_loss: 0.08908/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.32258\n",
      "\tTraining time elapsed: 113.78 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.87106/73.00%, bp_loss: 1.26064/62.00%, hp_loss: 3.08329/21.00%, j_loss: 0.91310/72.00%, \n",
      "\t\tfr_loss: 0.13652/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.26461\n",
      "\tPart 2 - fp_loss: 0.68337/79.00%, bp_loss: 0.87826/75.00%, hp_loss: 2.68075/32.00%, j_loss: 0.59486/81.00%, \n",
      "\t\tfr_loss: 0.12886/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.96610\n",
      "\tPart 3 - fp_loss: 0.62403/82.00%, bp_loss: 0.84338/77.00%, hp_loss: 2.38004/39.00%, j_loss: 0.44711/86.00%, \n",
      "\t\tfr_loss: 0.11849/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41305\n",
      "\tPart 4 - fp_loss: 0.52327/84.00%, bp_loss: 0.77012/78.00%, hp_loss: 2.54475/34.00%, j_loss: 0.43507/86.00%, \n",
      "\t\tfr_loss: 0.09219/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.36540\n",
      "\tTraining time elapsed: 151.31 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.89701/73.00%, bp_loss: 1.23363/63.00%, hp_loss: 3.11623/20.00%, j_loss: 0.86612/75.00%, \n",
      "\t\tfr_loss: 0.14123/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.25422\n",
      "\tPart 2 - fp_loss: 0.69078/80.00%, bp_loss: 0.87528/75.00%, hp_loss: 2.64840/33.00%, j_loss: 0.58070/82.00%, \n",
      "\t\tfr_loss: 0.14494/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.94011\n",
      "\tPart 3 - fp_loss: 0.63525/82.00%, bp_loss: 0.72836/79.00%, hp_loss: 2.47192/34.00%, j_loss: 0.48504/86.00%, \n",
      "\t\tfr_loss: 0.10240/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.42298\n",
      "\tPart 4 - fp_loss: 0.61877/83.00%, bp_loss: 0.80489/77.00%, hp_loss: 2.61480/30.00%, j_loss: 0.45091/86.00%, \n",
      "\t\tfr_loss: 0.11946/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60882\n",
      "\tTraining time elapsed: 188.83 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.85416/75.00%, bp_loss: 1.21705/62.00%, hp_loss: 3.04670/22.00%, j_loss: 0.91951/74.00%, \n",
      "\t\tfr_loss: 0.15807/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19549\n",
      "\tPart 2 - fp_loss: 0.69579/80.00%, bp_loss: 0.87150/74.00%, hp_loss: 2.68203/32.00%, j_loss: 0.62434/79.00%, \n",
      "\t\tfr_loss: 0.13755/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.01120\n",
      "\tPart 3 - fp_loss: 0.66824/82.00%, bp_loss: 0.74831/79.00%, hp_loss: 2.44801/37.00%, j_loss: 0.48187/85.00%, \n",
      "\t\tfr_loss: 0.11135/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45777\n",
      "\tPart 4 - fp_loss: 0.58897/82.00%, bp_loss: 0.75243/79.00%, hp_loss: 2.56005/33.00%, j_loss: 0.38842/86.00%, \n",
      "\t\tfr_loss: 0.09028/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.38016\n",
      "\tTraining time elapsed: 226.36 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.83810/75.00%, bp_loss: 1.20147/65.00%, hp_loss: 3.03625/23.00%, j_loss: 0.86290/76.00%, \n",
      "\t\tfr_loss: 0.13584/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.07457\n",
      "\tPart 2 - fp_loss: 0.68267/79.00%, bp_loss: 0.80302/77.00%, hp_loss: 2.67435/34.00%, j_loss: 0.54090/82.00%, \n",
      "\t\tfr_loss: 0.12770/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.82864\n",
      "\tPart 3 - fp_loss: 0.61818/82.00%, bp_loss: 0.75615/79.00%, hp_loss: 2.31907/39.00%, j_loss: 0.45125/86.00%, \n",
      "\t\tfr_loss: 0.12153/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.26617\n",
      "\tPart 4 - fp_loss: 0.56651/84.00%, bp_loss: 0.79734/77.00%, hp_loss: 2.54922/34.00%, j_loss: 0.43794/87.00%, \n",
      "\t\tfr_loss: 0.09104/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.44205\n",
      "\tTraining time elapsed: 263.91 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 1.00029/71.00%, bp_loss: 1.30334/61.00%, hp_loss: 3.07025/22.00%, j_loss: 1.02758/72.00%, \n",
      "\t\tfr_loss: 0.14749/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.54895\n",
      "\tPart 2 - fp_loss: 0.70236/81.00%, bp_loss: 0.89204/73.00%, hp_loss: 2.69011/31.00%, j_loss: 0.57357/83.00%, \n",
      "\t\tfr_loss: 0.13814/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.99623\n",
      "\tPart 3 - fp_loss: 0.70013/79.00%, bp_loss: 0.86546/78.00%, hp_loss: 2.42398/38.00%, j_loss: 0.52310/84.00%, \n",
      "\t\tfr_loss: 0.10004/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61271\n",
      "\tPart 4 - fp_loss: 0.54287/85.00%, bp_loss: 0.77382/77.00%, hp_loss: 2.60383/33.00%, j_loss: 0.39490/87.00%, \n",
      "\t\tfr_loss: 0.08475/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.40017\n",
      "\tTraining time elapsed: 301.47 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.98042/47.00%, bp_loss: 1.39931/58.00%, hp_loss: 3.16519/17.00%, j_loss: 1.69729/51.00%, \n",
      "\t\tfr_loss: 0.20308/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.44528\n",
      "\tPart 2 - fp_loss: 1.86291/55.00%, bp_loss: 1.09704/67.00%, hp_loss: 2.70617/29.00%, j_loss: 1.20851/63.00%, \n",
      "\t\tfr_loss: 0.20606/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.08069\n",
      "\tPart 3 - fp_loss: 1.21880/72.00%, bp_loss: 0.88590/76.00%, hp_loss: 2.22353/44.00%, j_loss: 0.69314/79.00%, \n",
      "\t\tfr_loss: 0.18303/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.20439\n",
      "\tPart 4 - fp_loss: 1.66633/68.00%, bp_loss: 0.90689/75.00%, hp_loss: 2.35783/39.00%, j_loss: 0.77276/77.00%, \n",
      "\t\tfr_loss: 0.18344/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.88725\n",
      "\t`Validation time elapsed: 0.82 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 1.86503/54.00%, bp_loss: 1.36617/59.00%, hp_loss: 3.00031/25.00%, j_loss: 1.46095/60.00%, \n",
      "\t\tfr_loss: 0.19881/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.89127\n",
      "\tPart 2 - fp_loss: 1.62258/59.00%, bp_loss: 1.04210/69.00%, hp_loss: 2.66019/31.00%, j_loss: 1.09726/67.00%, \n",
      "\t\tfr_loss: 0.20911/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.63123\n",
      "\tPart 3 - fp_loss: 1.31883/72.00%, bp_loss: 1.01659/74.00%, hp_loss: 2.14682/47.00%, j_loss: 0.82525/79.00%, \n",
      "\t\tfr_loss: 0.17303/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.48052\n",
      "\tPart 4 - fp_loss: 1.69996/66.00%, bp_loss: 0.89617/77.00%, hp_loss: 2.32889/42.00%, j_loss: 0.91803/75.00%, \n",
      "\t\tfr_loss: 0.17184/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01489\n",
      "\t`Validation time elapsed: 9.57 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 56.\n",
      "\n",
      "EPOCH 57\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.87301/75.00%, bp_loss: 1.12902/65.00%, hp_loss: 3.06247/21.00%, j_loss: 0.85385/76.00%, \n",
      "\t\tfr_loss: 0.13746/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.05581\n",
      "\tPart 2 - fp_loss: 0.65478/80.00%, bp_loss: 0.81920/75.00%, hp_loss: 2.74368/30.00%, j_loss: 0.54669/81.00%, \n",
      "\t\tfr_loss: 0.12234/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88668\n",
      "\tPart 3 - fp_loss: 0.55015/85.00%, bp_loss: 0.75949/78.00%, hp_loss: 2.39014/37.00%, j_loss: 0.43768/87.00%, \n",
      "\t\tfr_loss: 0.10273/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.24019\n",
      "\tPart 4 - fp_loss: 0.47827/85.00%, bp_loss: 0.76271/78.00%, hp_loss: 2.51109/35.00%, j_loss: 0.40963/87.00%, \n",
      "\t\tfr_loss: 0.09478/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.25648\n",
      "\tTraining time elapsed: 1.16 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.81868/76.00%, bp_loss: 1.22306/64.00%, hp_loss: 3.09744/22.00%, j_loss: 0.89171/76.00%, \n",
      "\t\tfr_loss: 0.12631/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15720\n",
      "\tPart 2 - fp_loss: 0.74081/79.00%, bp_loss: 0.77619/78.00%, hp_loss: 2.68449/33.00%, j_loss: 0.49774/82.00%, \n",
      "\t\tfr_loss: 0.13306/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.83229\n",
      "\tPart 3 - fp_loss: 0.73044/79.00%, bp_loss: 0.75739/79.00%, hp_loss: 2.39710/37.00%, j_loss: 0.48225/84.00%, \n",
      "\t\tfr_loss: 0.10789/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.47507\n",
      "\tPart 4 - fp_loss: 0.52761/85.00%, bp_loss: 0.78724/78.00%, hp_loss: 2.57151/32.00%, j_loss: 0.41297/87.00%, \n",
      "\t\tfr_loss: 0.07790/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.37723\n",
      "\tTraining time elapsed: 38.69 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.81441/75.00%, bp_loss: 1.24358/63.00%, hp_loss: 3.08009/22.00%, j_loss: 0.88673/75.00%, \n",
      "\t\tfr_loss: 0.13047/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.15527\n",
      "\tPart 2 - fp_loss: 0.70075/80.00%, bp_loss: 0.89002/73.00%, hp_loss: 2.70619/34.00%, j_loss: 0.63978/80.00%, \n",
      "\t\tfr_loss: 0.12391/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06064\n",
      "\tPart 3 - fp_loss: 0.60135/82.00%, bp_loss: 2.08997/41.00%, hp_loss: 2.40443/38.00%, j_loss: 0.92880/82.00%, \n",
      "\t\tfr_loss: 0.10340/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.12794\n",
      "\tPart 4 - fp_loss: 0.62704/82.00%, bp_loss: 0.80840/77.00%, hp_loss: 2.69402/29.00%, j_loss: 0.45256/86.00%, \n",
      "\t\tfr_loss: 0.11329/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69532\n",
      "\tTraining time elapsed: 76.24 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.83838/75.00%, bp_loss: 1.14433/66.00%, hp_loss: 3.09857/22.00%, j_loss: 0.81664/76.00%, \n",
      "\t\tfr_loss: 0.13649/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.03441\n",
      "\tPart 2 - fp_loss: 0.64908/81.00%, bp_loss: 0.84010/75.00%, hp_loss: 2.68007/33.00%, j_loss: 0.56909/82.00%, \n",
      "\t\tfr_loss: 0.12282/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.86115\n",
      "\tPart 3 - fp_loss: 0.60537/82.00%, bp_loss: 2.06544/44.00%, hp_loss: 2.29669/42.00%, j_loss: 0.89534/82.00%, \n",
      "\t\tfr_loss: 0.11227/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.97510\n",
      "\tPart 4 - fp_loss: 0.50332/85.00%, bp_loss: 0.76334/78.00%, hp_loss: 2.57876/35.00%, j_loss: 0.35975/87.00%, \n",
      "\t\tfr_loss: 0.09159/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.29676\n",
      "\tTraining time elapsed: 113.78 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.91564/73.00%, bp_loss: 1.28991/61.00%, hp_loss: 3.18308/20.00%, j_loss: 0.96317/74.00%, \n",
      "\t\tfr_loss: 0.12658/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.47839\n",
      "\tPart 2 - fp_loss: 0.73280/78.00%, bp_loss: 0.85687/75.00%, hp_loss: 2.70285/33.00%, j_loss: 0.61029/81.00%, \n",
      "\t\tfr_loss: 0.10501/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.00782\n",
      "\tPart 3 - fp_loss: 0.69248/81.00%, bp_loss: 1.94200/46.00%, hp_loss: 2.39896/36.00%, j_loss: 0.91634/81.00%, \n",
      "\t\tfr_loss: 0.11245/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.06224\n",
      "\tPart 4 - fp_loss: 0.60834/82.00%, bp_loss: 0.86260/76.00%, hp_loss: 2.58113/32.00%, j_loss: 0.50868/85.00%, \n",
      "\t\tfr_loss: 0.09779/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.65855\n",
      "\tTraining time elapsed: 151.32 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.84569/74.00%, bp_loss: 1.18518/64.00%, hp_loss: 3.05978/23.00%, j_loss: 0.82942/76.00%, \n",
      "\t\tfr_loss: 0.14703/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.06711\n",
      "\tPart 2 - fp_loss: 0.63722/81.00%, bp_loss: 0.85863/76.00%, hp_loss: 2.70413/33.00%, j_loss: 0.49339/83.00%, \n",
      "\t\tfr_loss: 0.12636/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.81973\n",
      "\tPart 3 - fp_loss: 0.61218/82.00%, bp_loss: 1.87191/45.00%, hp_loss: 2.38660/38.00%, j_loss: 0.87004/81.00%, \n",
      "\t\tfr_loss: 0.09110/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.83183\n",
      "\tPart 4 - fp_loss: 0.57613/84.00%, bp_loss: 0.76735/78.00%, hp_loss: 2.56198/32.00%, j_loss: 0.42216/86.00%, \n",
      "\t\tfr_loss: 0.09072/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.41835\n",
      "\tTraining time elapsed: 188.90 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.81763/77.00%, bp_loss: 1.23097/64.00%, hp_loss: 3.07253/23.00%, j_loss: 0.81965/76.00%, \n",
      "\t\tfr_loss: 0.12762/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.06840\n",
      "\tPart 2 - fp_loss: 0.75971/76.00%, bp_loss: 0.85549/75.00%, hp_loss: 2.74729/30.00%, j_loss: 0.59594/78.00%, \n",
      "\t\tfr_loss: 0.12564/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.08407\n",
      "\tPart 3 - fp_loss: 0.67035/80.00%, bp_loss: 1.63192/54.00%, hp_loss: 2.38566/40.00%, j_loss: 0.85011/80.00%, \n",
      "\t\tfr_loss: 0.10114/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.63918\n",
      "\tPart 4 - fp_loss: 0.62488/82.00%, bp_loss: 0.83112/77.00%, hp_loss: 2.57389/34.00%, j_loss: 0.51173/84.00%, \n",
      "\t\tfr_loss: 0.08898/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.63061\n",
      "\tTraining time elapsed: 226.44 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.86114/73.00%, bp_loss: 1.22683/63.00%, hp_loss: 3.09990/21.00%, j_loss: 0.89070/74.00%, \n",
      "\t\tfr_loss: 0.12793/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.20649\n",
      "\tPart 2 - fp_loss: 0.72673/79.00%, bp_loss: 0.89152/74.00%, hp_loss: 2.71283/31.00%, j_loss: 0.57989/81.00%, \n",
      "\t\tfr_loss: 0.11383/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02480\n",
      "\tPart 3 - fp_loss: 0.72267/79.00%, bp_loss: 1.67840/54.00%, hp_loss: 2.49563/36.00%, j_loss: 0.91181/79.00%, \n",
      "\t\tfr_loss: 0.10762/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.91614\n",
      "\tPart 4 - fp_loss: 0.54678/83.00%, bp_loss: 0.96890/74.00%, hp_loss: 2.58711/34.00%, j_loss: 0.41556/85.00%, \n",
      "\t\tfr_loss: 0.09667/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61503\n",
      "\tTraining time elapsed: 263.99 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.92753/74.00%, bp_loss: 1.24889/63.00%, hp_loss: 3.08777/22.00%, j_loss: 0.91695/75.00%, \n",
      "\t\tfr_loss: 0.15434/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.33549\n",
      "\tPart 2 - fp_loss: 0.74885/78.00%, bp_loss: 0.88490/74.00%, hp_loss: 2.69582/33.00%, j_loss: 0.68347/78.00%, \n",
      "\t\tfr_loss: 0.12103/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.13407\n",
      "\tPart 3 - fp_loss: 0.70455/79.00%, bp_loss: 1.54997/58.00%, hp_loss: 2.35912/39.00%, j_loss: 0.83393/80.00%, \n",
      "\t\tfr_loss: 0.10840/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.55597\n",
      "\tPart 4 - fp_loss: 0.57751/83.00%, bp_loss: 0.89050/75.00%, hp_loss: 2.57041/34.00%, j_loss: 0.40541/85.00%, \n",
      "\t\tfr_loss: 0.10392/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.54775\n",
      "\tTraining time elapsed: 301.56 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 2.00659/49.00%, bp_loss: 1.31073/61.00%, hp_loss: 3.08761/22.00%, j_loss: 1.52630/53.00%, \n",
      "\t\tfr_loss: 0.20537/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.13659\n",
      "\tPart 2 - fp_loss: 1.81649/57.00%, bp_loss: 1.15419/68.00%, hp_loss: 2.80585/27.00%, j_loss: 1.17858/66.00%, \n",
      "\t\tfr_loss: 0.19419/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.14929\n",
      "\tPart 3 - fp_loss: 1.33530/70.00%, bp_loss: 1.53233/55.00%, hp_loss: 2.27271/42.00%, j_loss: 1.22511/70.00%, \n",
      "\t\tfr_loss: 0.15501/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.52046\n",
      "\tPart 4 - fp_loss: 1.60060/67.00%, bp_loss: 1.05549/74.00%, hp_loss: 2.39862/38.00%, j_loss: 0.90139/74.00%, \n",
      "\t\tfr_loss: 0.16522/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.12131\n",
      "\t`Validation time elapsed: 0.82 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.00985/50.00%, bp_loss: 1.35436/59.00%, hp_loss: 3.00623/24.00%, j_loss: 1.57958/55.00%, \n",
      "\t\tfr_loss: 0.21271/78.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.16274\n",
      "\tPart 2 - fp_loss: 1.75818/59.00%, bp_loss: 1.24915/64.00%, hp_loss: 2.73613/29.00%, j_loss: 1.28121/65.00%, \n",
      "\t\tfr_loss: 0.19704/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.22170\n",
      "\tPart 3 - fp_loss: 1.40862/69.00%, bp_loss: 1.56567/57.00%, hp_loss: 2.22365/44.00%, j_loss: 1.23380/70.00%, \n",
      "\t\tfr_loss: 0.18814/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.61988\n",
      "\tPart 4 - fp_loss: 1.70680/68.00%, bp_loss: 0.98919/75.00%, hp_loss: 2.40125/40.00%, j_loss: 0.92712/75.00%, \n",
      "\t\tfr_loss: 0.17086/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19521\n",
      "\t`Validation time elapsed: 9.58 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 57.\n",
      "\n",
      "EPOCH 58\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.82342/75.00%, bp_loss: 1.15363/65.00%, hp_loss: 3.04964/23.00%, j_loss: 0.79860/75.00%, \n",
      "\t\tfr_loss: 0.13372/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.95901\n",
      "\tPart 2 - fp_loss: 0.62558/82.00%, bp_loss: 0.79236/77.00%, hp_loss: 2.73305/29.00%, j_loss: 0.49960/83.00%, \n",
      "\t\tfr_loss: 0.10661/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.75720\n",
      "\tPart 3 - fp_loss: 0.63778/81.00%, bp_loss: 1.62534/56.00%, hp_loss: 2.46686/37.00%, j_loss: 0.80769/82.00%, \n",
      "\t\tfr_loss: 0.09777/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.63543\n",
      "\tPart 4 - fp_loss: 0.57292/84.00%, bp_loss: 0.89659/77.00%, hp_loss: 2.61387/30.00%, j_loss: 0.43890/85.00%, \n",
      "\t\tfr_loss: 0.09063/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.61290\n",
      "\tTraining time elapsed: 1.12 seconds\n",
      "\n",
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.85058/76.00%, bp_loss: 1.45198/59.00%, hp_loss: 3.06820/24.00%, j_loss: 0.92182/77.00%, \n",
      "\t\tfr_loss: 0.12122/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.41380\n",
      "\tPart 2 - fp_loss: 0.64256/80.00%, bp_loss: 0.83253/77.00%, hp_loss: 2.75871/30.00%, j_loss: 0.52796/83.00%, \n",
      "\t\tfr_loss: 0.12386/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88562\n",
      "\tPart 3 - fp_loss: 0.62748/82.00%, bp_loss: 1.49320/59.00%, hp_loss: 2.43742/37.00%, j_loss: 0.73909/83.00%, \n",
      "\t\tfr_loss: 0.10513/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.40232\n",
      "\tPart 4 - fp_loss: 0.57323/84.00%, bp_loss: 0.96968/73.00%, hp_loss: 2.62723/32.00%, j_loss: 0.43707/86.00%, \n",
      "\t\tfr_loss: 0.10631/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.71352\n",
      "\tTraining time elapsed: 38.69 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.81429/76.00%, bp_loss: 1.19402/67.00%, hp_loss: 3.07433/24.00%, j_loss: 0.75666/78.00%, \n",
      "\t\tfr_loss: 0.13926/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.97856\n",
      "\tPart 2 - fp_loss: 0.63920/82.00%, bp_loss: 0.88037/75.00%, hp_loss: 2.69601/32.00%, j_loss: 0.52832/84.00%, \n",
      "\t\tfr_loss: 0.13663/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88053\n",
      "\tPart 3 - fp_loss: 0.61817/82.00%, bp_loss: 1.45145/60.00%, hp_loss: 2.36500/41.00%, j_loss: 0.69279/83.00%, \n",
      "\t\tfr_loss: 0.10530/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.23271\n",
      "\tPart 4 - fp_loss: 0.56419/83.00%, bp_loss: 2.03717/41.00%, hp_loss: 2.55193/34.00%, j_loss: 0.87845/82.00%, \n",
      "\t\tfr_loss: 0.10026/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.13200\n",
      "\tTraining time elapsed: 76.23 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.91972/74.00%, bp_loss: 1.20334/64.00%, hp_loss: 3.14011/19.00%, j_loss: 0.83442/75.00%, \n",
      "\t\tfr_loss: 0.14943/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.24702\n",
      "\tPart 2 - fp_loss: 0.70222/79.00%, bp_loss: 0.90712/73.00%, hp_loss: 2.75334/31.00%, j_loss: 0.64337/80.00%, \n",
      "\t\tfr_loss: 0.11855/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.12461\n",
      "\tPart 3 - fp_loss: 0.61269/83.00%, bp_loss: 1.40836/61.00%, hp_loss: 2.46196/36.00%, j_loss: 0.70477/83.00%, \n",
      "\t\tfr_loss: 0.07492/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.26270\n",
      "\tPart 4 - fp_loss: 0.48939/84.00%, bp_loss: 1.72892/53.00%, hp_loss: 2.56167/33.00%, j_loss: 0.70284/84.00%, \n",
      "\t\tfr_loss: 0.07866/92.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.56147\n",
      "\tTraining time elapsed: 113.76 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.85847/72.00%, bp_loss: 1.16128/65.00%, hp_loss: 3.04739/22.00%, j_loss: 0.88097/74.00%, \n",
      "\t\tfr_loss: 0.14830/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.09641\n",
      "\tPart 2 - fp_loss: 0.73487/79.00%, bp_loss: 0.90534/74.00%, hp_loss: 2.73421/31.00%, j_loss: 0.61999/80.00%, \n",
      "\t\tfr_loss: 0.12079/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.11520\n",
      "\tPart 3 - fp_loss: 0.62307/81.00%, bp_loss: 1.35492/63.00%, hp_loss: 2.39857/38.00%, j_loss: 0.67764/82.00%, \n",
      "\t\tfr_loss: 0.10621/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.16040\n",
      "\tPart 4 - fp_loss: 0.66438/81.00%, bp_loss: 1.26510/65.00%, hp_loss: 2.61110/32.00%, j_loss: 0.62920/82.00%, \n",
      "\t\tfr_loss: 0.10058/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.27036\n",
      "\tTraining time elapsed: 151.31 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.93932/73.00%, bp_loss: 1.21431/63.00%, hp_loss: 3.12822/19.00%, j_loss: 0.91888/75.00%, \n",
      "\t\tfr_loss: 0.14564/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.34638\n",
      "\tPart 2 - fp_loss: 0.67780/80.00%, bp_loss: 0.83113/76.00%, hp_loss: 2.67553/32.00%, j_loss: 0.55012/82.00%, \n",
      "\t\tfr_loss: 0.14690/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88148\n",
      "\tPart 3 - fp_loss: 0.64251/82.00%, bp_loss: 1.37147/63.00%, hp_loss: 2.39586/39.00%, j_loss: 0.71103/82.00%, \n",
      "\t\tfr_loss: 0.10310/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.22398\n",
      "\tPart 4 - fp_loss: 0.62654/82.00%, bp_loss: 1.14862/69.00%, hp_loss: 2.66090/31.00%, j_loss: 0.57537/83.00%, \n",
      "\t\tfr_loss: 0.09824/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10968\n",
      "\tTraining time elapsed: 188.85 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.86923/74.00%, bp_loss: 1.26273/63.00%, hp_loss: 3.08492/22.00%, j_loss: 0.87457/75.00%, \n",
      "\t\tfr_loss: 0.12976/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.22121\n",
      "\tPart 2 - fp_loss: 0.71075/79.00%, bp_loss: 0.98438/72.00%, hp_loss: 2.81793/28.00%, j_loss: 0.65468/81.00%, \n",
      "\t\tfr_loss: 0.13335/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.30111\n",
      "\tPart 3 - fp_loss: 0.69755/79.00%, bp_loss: 1.30584/64.00%, hp_loss: 2.45586/36.00%, j_loss: 0.72861/81.00%, \n",
      "\t\tfr_loss: 0.11869/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.30656\n",
      "\tPart 4 - fp_loss: 0.53621/84.00%, bp_loss: 0.95959/74.00%, hp_loss: 2.62302/31.00%, j_loss: 0.37746/86.00%, \n",
      "\t\tfr_loss: 0.08777/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58406\n",
      "\tTraining time elapsed: 226.41 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.87700/73.00%, bp_loss: 1.25859/62.00%, hp_loss: 3.01306/24.00%, j_loss: 0.90661/73.00%, \n",
      "\t\tfr_loss: 0.13014/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.18539\n",
      "\tPart 2 - fp_loss: 0.66706/81.00%, bp_loss: 0.80023/76.00%, hp_loss: 2.64488/35.00%, j_loss: 0.53354/81.00%, \n",
      "\t\tfr_loss: 0.11178/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.75750\n",
      "\tPart 3 - fp_loss: 0.63270/82.00%, bp_loss: 1.17088/67.00%, hp_loss: 2.38540/38.00%, j_loss: 0.62752/83.00%, \n",
      "\t\tfr_loss: 0.10375/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92025\n",
      "\tPart 4 - fp_loss: 0.53771/84.00%, bp_loss: 1.02310/72.00%, hp_loss: 2.58330/33.00%, j_loss: 0.45914/85.00%, \n",
      "\t\tfr_loss: 0.08792/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.69117\n",
      "\tTraining time elapsed: 263.95 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.86516/74.00%, bp_loss: 1.20992/64.00%, hp_loss: 3.04937/24.00%, j_loss: 0.89051/76.00%, \n",
      "\t\tfr_loss: 0.15419/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16915\n",
      "\tPart 2 - fp_loss: 0.73237/78.00%, bp_loss: 0.86616/75.00%, hp_loss: 2.62498/34.00%, j_loss: 0.60102/81.00%, \n",
      "\t\tfr_loss: 0.14085/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.96539\n",
      "\tPart 3 - fp_loss: 0.65108/83.00%, bp_loss: 1.16050/69.00%, hp_loss: 2.41815/38.00%, j_loss: 0.57675/83.00%, \n",
      "\t\tfr_loss: 0.10122/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.90771\n",
      "\tPart 4 - fp_loss: 0.55135/82.00%, bp_loss: 1.00130/73.00%, hp_loss: 2.61017/33.00%, j_loss: 0.46784/85.00%, \n",
      "\t\tfr_loss: 0.09620/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.72686\n",
      "\tTraining time elapsed: 301.53 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 1.99509/49.00%, bp_loss: 1.25730/60.00%, hp_loss: 3.04893/22.00%, j_loss: 1.55746/53.00%, \n",
      "\t\tfr_loss: 0.20823/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.06701\n",
      "\tPart 2 - fp_loss: 1.81308/57.00%, bp_loss: 1.12494/67.00%, hp_loss: 2.72966/30.00%, j_loss: 1.18521/65.00%, \n",
      "\t\tfr_loss: 0.20284/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.05572\n",
      "\tPart 3 - fp_loss: 1.29651/68.00%, bp_loss: 1.55605/58.00%, hp_loss: 2.31194/41.00%, j_loss: 1.08531/69.00%, \n",
      "\t\tfr_loss: 0.18013/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.42994\n",
      "\tPart 4 - fp_loss: 1.68130/66.00%, bp_loss: 1.70589/58.00%, hp_loss: 2.41980/39.00%, j_loss: 1.21092/67.00%, \n",
      "\t\tfr_loss: 0.19721/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.21512\n",
      "\t`Validation time elapsed: 0.80 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.00463/50.00%, bp_loss: 1.32715/61.00%, hp_loss: 2.97031/26.00%, j_loss: 1.50185/55.00%, \n",
      "\t\tfr_loss: 0.20322/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.00716\n",
      "\tPart 2 - fp_loss: 1.57915/61.00%, bp_loss: 1.08542/68.00%, hp_loss: 2.69737/30.00%, j_loss: 1.13583/68.00%, \n",
      "\t\tfr_loss: 0.19855/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.69631\n",
      "\tPart 3 - fp_loss: 1.24801/71.00%, bp_loss: 1.35973/65.00%, hp_loss: 2.30406/41.00%, j_loss: 0.97451/74.00%, \n",
      "\t\tfr_loss: 0.16236/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.04866\n",
      "\tPart 4 - fp_loss: 1.62757/67.00%, bp_loss: 1.17262/70.00%, hp_loss: 2.38210/39.00%, j_loss: 0.96080/73.00%, \n",
      "\t\tfr_loss: 0.15877/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.30186\n",
      "\t`Validation time elapsed: 9.56 seconds\n",
      "`\n",
      "-----------\n",
      "Completed epoch 58.\n",
      "\n",
      "EPOCH 59\n",
      "-----------\n",
      "Train iter 0/809:\n",
      "\tPart 1 - fp_loss: 0.85129/75.00%, bp_loss: 1.20956/65.00%, hp_loss: 3.09143/22.00%, j_loss: 0.86603/75.00%, \n",
      "\t\tfr_loss: 0.12600/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.14431\n",
      "\tPart 2 - fp_loss: 0.60327/83.00%, bp_loss: 0.77742/77.00%, hp_loss: 2.75633/31.00%, j_loss: 0.50156/82.00%, \n",
      "\t\tfr_loss: 0.12173/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.76031\n",
      "\tPart 3 - fp_loss: 0.55657/84.00%, bp_loss: 1.42806/61.00%, hp_loss: 2.37323/38.00%, j_loss: 0.66108/82.00%, \n",
      "\t\tfr_loss: 0.09780/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.11674\n",
      "\tPart 4 - fp_loss: 0.49469/85.00%, bp_loss: 1.44337/65.00%, hp_loss: 2.50586/33.00%, j_loss: 0.56138/82.00%, \n",
      "\t\tfr_loss: 0.09567/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.10096\n",
      "\tTraining time elapsed: 1.14 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter 100/809:\n",
      "\tPart 1 - fp_loss: 0.86731/74.00%, bp_loss: 1.26602/62.00%, hp_loss: 3.12863/21.00%, j_loss: 0.90894/75.00%, \n",
      "\t\tfr_loss: 0.14769/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.31860\n",
      "\tPart 2 - fp_loss: 0.67414/79.00%, bp_loss: 0.88515/74.00%, hp_loss: 2.70726/30.00%, j_loss: 0.59494/81.00%, \n",
      "\t\tfr_loss: 0.10952/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.97101\n",
      "\tPart 3 - fp_loss: 0.58957/83.00%, bp_loss: 1.21709/67.00%, hp_loss: 2.42374/37.00%, j_loss: 0.58321/85.00%, \n",
      "\t\tfr_loss: 0.10147/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.91509\n",
      "\tPart 4 - fp_loss: 0.49128/86.00%, bp_loss: 0.92911/73.00%, hp_loss: 2.53348/33.00%, j_loss: 0.39951/87.00%, \n",
      "\t\tfr_loss: 0.09757/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.45095\n",
      "\tTraining time elapsed: 38.71 seconds\n",
      "\n",
      "Train iter 200/809:\n",
      "\tPart 1 - fp_loss: 0.83593/75.00%, bp_loss: 1.23710/63.00%, hp_loss: 3.06930/23.00%, j_loss: 0.81666/76.00%, \n",
      "\t\tfr_loss: 0.14486/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.10384\n",
      "\tPart 2 - fp_loss: 0.61353/82.00%, bp_loss: 0.89943/74.00%, hp_loss: 2.72739/30.00%, j_loss: 0.56065/82.00%, \n",
      "\t\tfr_loss: 0.12813/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.92913\n",
      "\tPart 3 - fp_loss: 0.67975/80.00%, bp_loss: 1.10880/69.00%, hp_loss: 2.39986/37.00%, j_loss: 0.57577/82.00%, \n",
      "\t\tfr_loss: 0.10384/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.86800\n",
      "\tPart 4 - fp_loss: 0.56302/83.00%, bp_loss: 0.89094/75.00%, hp_loss: 2.57519/32.00%, j_loss: 0.47816/85.00%, \n",
      "\t\tfr_loss: 0.08840/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.59572\n",
      "\tTraining time elapsed: 76.26 seconds\n",
      "\n",
      "Train iter 300/809:\n",
      "\tPart 1 - fp_loss: 0.85964/74.00%, bp_loss: 1.25848/62.00%, hp_loss: 3.10397/21.00%, j_loss: 0.90181/75.00%, \n",
      "\t\tfr_loss: 0.15441/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.27831\n",
      "\tPart 2 - fp_loss: 0.65053/81.00%, bp_loss: 0.85676/76.00%, hp_loss: 2.66365/32.00%, j_loss: 0.57709/81.00%, \n",
      "\t\tfr_loss: 0.11195/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.85998\n",
      "\tPart 3 - fp_loss: 0.65272/81.00%, bp_loss: 1.18000/67.00%, hp_loss: 2.48350/36.00%, j_loss: 0.65270/81.00%, \n",
      "\t\tfr_loss: 0.10424/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.07316\n",
      "\tPart 4 - fp_loss: 0.52199/85.00%, bp_loss: 0.92764/74.00%, hp_loss: 2.65075/30.00%, j_loss: 0.39848/87.00%, \n",
      "\t\tfr_loss: 0.08684/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58570\n",
      "\tTraining time elapsed: 113.83 seconds\n",
      "\n",
      "Train iter 400/809:\n",
      "\tPart 1 - fp_loss: 0.82587/75.00%, bp_loss: 1.26476/63.00%, hp_loss: 3.03837/25.00%, j_loss: 0.86330/76.00%, \n",
      "\t\tfr_loss: 0.13013/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.12244\n",
      "\tPart 2 - fp_loss: 0.65617/81.00%, bp_loss: 0.92228/74.00%, hp_loss: 2.64310/34.00%, j_loss: 0.54943/82.00%, \n",
      "\t\tfr_loss: 0.12509/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.89607\n",
      "\tPart 3 - fp_loss: 0.61535/82.00%, bp_loss: 1.02370/73.00%, hp_loss: 2.36243/40.00%, j_loss: 0.53723/85.00%, \n",
      "\t\tfr_loss: 0.10853/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.64724\n",
      "\tPart 4 - fp_loss: 0.55999/84.00%, bp_loss: 0.88718/75.00%, hp_loss: 2.59658/32.00%, j_loss: 0.45931/84.00%, \n",
      "\t\tfr_loss: 0.10423/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60729\n",
      "\tTraining time elapsed: 151.37 seconds\n",
      "\n",
      "Train iter 500/809:\n",
      "\tPart 1 - fp_loss: 0.86583/74.00%, bp_loss: 1.19093/64.00%, hp_loss: 3.02338/24.00%, j_loss: 0.87308/74.00%, \n",
      "\t\tfr_loss: 0.15722/84.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.11044\n",
      "\tPart 2 - fp_loss: 0.74427/79.00%, bp_loss: 0.83877/76.00%, hp_loss: 2.76283/30.00%, j_loss: 0.54682/83.00%, \n",
      "\t\tfr_loss: 0.13530/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02800\n",
      "\tPart 3 - fp_loss: 0.67016/81.00%, bp_loss: 1.17146/69.00%, hp_loss: 2.45775/36.00%, j_loss: 0.65092/82.00%, \n",
      "\t\tfr_loss: 0.11063/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.06092\n",
      "\tPart 4 - fp_loss: 0.53375/84.00%, bp_loss: 0.91164/74.00%, hp_loss: 2.60487/33.00%, j_loss: 0.43825/85.00%, \n",
      "\t\tfr_loss: 0.09459/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.58309\n",
      "\tTraining time elapsed: 188.88 seconds\n",
      "\n",
      "Train iter 600/809:\n",
      "\tPart 1 - fp_loss: 0.88315/73.00%, bp_loss: 1.09964/69.00%, hp_loss: 3.04147/23.00%, j_loss: 0.82991/75.00%, \n",
      "\t\tfr_loss: 0.14474/85.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.99891\n",
      "\tPart 2 - fp_loss: 0.70656/79.00%, bp_loss: 0.89334/73.00%, hp_loss: 2.78239/29.00%, j_loss: 0.58427/80.00%, \n",
      "\t\tfr_loss: 0.12745/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.09401\n",
      "\tPart 3 - fp_loss: 0.73619/79.00%, bp_loss: 1.00701/74.00%, hp_loss: 2.42941/36.00%, j_loss: 0.59836/82.00%, \n",
      "\t\tfr_loss: 0.11654/88.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.88751\n",
      "\tPart 4 - fp_loss: 0.60186/83.00%, bp_loss: 0.95540/73.00%, hp_loss: 2.61356/29.00%, j_loss: 0.47172/85.00%, \n",
      "\t\tfr_loss: 0.08411/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.72665\n",
      "\tTraining time elapsed: 226.41 seconds\n",
      "\n",
      "Train iter 700/809:\n",
      "\tPart 1 - fp_loss: 0.84570/75.00%, bp_loss: 1.21489/63.00%, hp_loss: 3.10437/22.00%, j_loss: 0.87063/76.00%, \n",
      "\t\tfr_loss: 0.12698/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.16257\n",
      "\tPart 2 - fp_loss: 0.69375/81.00%, bp_loss: 0.80248/76.00%, hp_loss: 2.73223/32.00%, j_loss: 0.54229/83.00%, \n",
      "\t\tfr_loss: 0.12968/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.90043\n",
      "\tPart 3 - fp_loss: 0.66396/80.00%, bp_loss: 1.12015/70.00%, hp_loss: 2.39790/36.00%, j_loss: 0.53797/83.00%, \n",
      "\t\tfr_loss: 0.08874/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.80872\n",
      "\tPart 4 - fp_loss: 0.58737/83.00%, bp_loss: 0.92757/75.00%, hp_loss: 2.56026/33.00%, j_loss: 0.46677/86.00%, \n",
      "\t\tfr_loss: 0.08302/91.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.62499\n",
      "\tTraining time elapsed: 263.96 seconds\n",
      "\n",
      "Train iter 800/809:\n",
      "\tPart 1 - fp_loss: 0.87405/74.00%, bp_loss: 1.17622/64.00%, hp_loss: 3.12731/22.00%, j_loss: 0.87909/74.00%, \n",
      "\t\tfr_loss: 0.13658/86.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.19326\n",
      "\tPart 2 - fp_loss: 0.70284/79.00%, bp_loss: 0.89894/74.00%, hp_loss: 2.69652/32.00%, j_loss: 0.59609/81.00%, \n",
      "\t\tfr_loss: 0.12622/87.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.02061\n",
      "\tPart 3 - fp_loss: 0.60146/82.00%, bp_loss: 1.02401/73.00%, hp_loss: 2.36387/39.00%, j_loss: 0.51082/85.00%, \n",
      "\t\tfr_loss: 0.10574/89.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.60590\n",
      "\tPart 4 - fp_loss: 0.56119/83.00%, bp_loss: 0.99124/73.00%, hp_loss: 2.59823/32.00%, j_loss: 0.48422/86.00%, \n",
      "\t\tfr_loss: 0.10069/90.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 4.73557\n",
      "\tTraining time elapsed: 301.53 seconds\n",
      "\n",
      "Valid iter 0/147:\n",
      "\tPart 1 - fp_loss: 2.04412/50.00%, bp_loss: 1.37343/58.00%, hp_loss: 3.07864/22.00%, j_loss: 1.56356/54.00%, \n",
      "\t\tfr_loss: 0.20741/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.26717\n",
      "\tPart 2 - fp_loss: 1.75439/57.00%, bp_loss: 1.06550/69.00%, hp_loss: 2.71187/31.00%, j_loss: 1.18584/63.00%, \n",
      "\t\tfr_loss: 0.20873/79.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.92632\n",
      "\tPart 3 - fp_loss: 1.44219/69.00%, bp_loss: 1.58018/59.00%, hp_loss: 2.25731/42.00%, j_loss: 1.12213/67.00%, \n",
      "\t\tfr_loss: 0.19085/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.59265\n",
      "\tPart 4 - fp_loss: 1.72327/66.00%, bp_loss: 1.52368/62.00%, hp_loss: 2.42900/38.00%, j_loss: 1.16305/69.00%, \n",
      "\t\tfr_loss: 0.18421/81.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 7.02321\n",
      "\t`Validation time elapsed: 0.82 seconds\n",
      "`\n",
      "Valid iter 100/147:\n",
      "\tPart 1 - fp_loss: 2.03454/49.00%, bp_loss: 1.37310/58.00%, hp_loss: 3.01211/22.00%, j_loss: 1.60495/52.00%, \n",
      "\t\tfr_loss: 0.22474/77.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 8.24945\n",
      "\tPart 2 - fp_loss: 1.73265/59.00%, bp_loss: 1.17074/66.00%, hp_loss: 2.72495/29.00%, j_loss: 1.16453/66.00%, \n",
      "\t\tfr_loss: 0.19596/80.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.98883\n",
      "\tPart 3 - fp_loss: 1.27411/72.00%, bp_loss: 1.13560/71.00%, hp_loss: 2.28375/44.00%, j_loss: 0.83331/77.00%, \n",
      "\t\tfr_loss: 0.17640/82.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 5.70317\n",
      "\tPart 4 - fp_loss: 1.44475/70.00%, bp_loss: 1.12478/71.00%, hp_loss: 2.39012/39.00%, j_loss: 0.88351/76.00%, \n",
      "\t\tfr_loss: 0.17288/83.00%, p_loss: 0.00000/100.00%, \n",
      "\t\ttotal weighted loss: 6.01604\n",
      "\t`Validation time elapsed: 9.57 seconds\n",
      "`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "Completed epoch 59.\n",
      "\n",
      "Training completed! Saving files.\n"
     ]
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "\n",
    "SKIP_TRAIN = False\n",
    "\n",
    "if not SKIP_TRAIN:\n",
    "    train_stats = []\n",
    "    val_stats = []\n",
    "    saved_models = []\n",
    "\n",
    "    try:\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            print(\"EPOCH {}\".format(epoch))\n",
    "            print(\"-----------\")\n",
    "            train_stat, models = train(models, optims, loader_train, \n",
    "                                  model_names=model_names, \n",
    "                                  loss_weights=LOSS_WEIGHTS,\n",
    "                                  device=device,\n",
    "                                  print_iter=100)\n",
    "\n",
    "            val_stat, models = validate(models, loader_val,\n",
    "                                     model_names=model_names,\n",
    "                                     device=device,\n",
    "                                     print_iter=100)\n",
    "\n",
    "            print(\"-----------\")\n",
    "            print(\"Completed epoch {}.\".format(epoch))\n",
    "            print(\"\")\n",
    "            train_stats.append(train_stat)\n",
    "            val_stats.append(val_stat)\n",
    "            saved_models.append(copy.deepcopy(models))\n",
    "\n",
    "\n",
    "        print(\"Training completed! Saving files.\")\n",
    "        \n",
    "    except Exception as error:\n",
    "        print(\"Encountered error: {}\".format(error))\n",
    "    finally:\n",
    "        # clear CUDA cache\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # create a folder to store all of the stats and models\n",
    "    mkdir(OUTPUT_PATH)\n",
    "    stats_file_name = RUN_ID + \"_\" + RUN_TIME + \".stat\"\n",
    "    stats_file_path = OUTPUT_PATH + \"/\" + stats_file_name\n",
    "    models_file_name = RUN_ID + \"_\" + RUN_TIME + \".models\"\n",
    "    models_file_path = OUTPUT_PATH + \"/\" + models_file_name\n",
    "\n",
    "    with open(stats_file_path, \"wb\") as file:\n",
    "        pickle.dump((train_stats, val_stats), file)\n",
    "    with open(models_file_path, \"wb\") as file:\n",
    "        pickle.dump(saved_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD SAVED STATS\n",
    "\n",
    "if not(train_stats and len(train_stats) > 0 and val_stats and len(val_stats) > 0):\n",
    "    stats_file_path = OUTPUT_PATH + \"/12-09_21-52-24_C1F0E8.stat\"\n",
    "\n",
    "    with open(stats_file_path, \"rb\") as file:\n",
    "        saved_stats = pickle.load(file)\n",
    "\n",
    "    train_stats, val_stats = saved_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 384
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GRAPH WEIGHTED LOSSES\n",
    "\n",
    "train_weighted_losses = np.array([ S['losses'] for S in train_stats]).mean(axis=1)\n",
    "val_weighted_losses = np.array([ S['losses'] for S in val_stats]).mean(axis=1)\n",
    "\n",
    "\n",
    "plt.plot(train_weighted_losses)\n",
    "plt.plot(val_weighted_losses)\n",
    "plt.xticks(range(len(val_weighted_losses)))\n",
    "\n",
    "plt.title(\"Weighted Validation Loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend([\"weighted train loss\", \"weighted valid loss\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 387
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 384
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_judge_losses = np.array([ S['j_losses'] for S in val_stats]).mean(axis=1)\n",
    "val_judge_accs = np.array([ S['j_accs'] for S in val_stats]).mean(axis=1)\n",
    "\n",
    "plt.plot(val_judge_losses)\n",
    "plt.xticks(range(len(val_judge_losses)))\n",
    "plt.title(\"Judge Model Losses\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Losses')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_judge_accs)\n",
    "plt.yticks(np.linspace(55, 75, 10, dtype=\"int8\"))\n",
    "plt.title(\"Judge Model Accuracies\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('% Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 0/24576000\n",
      "current iter: 1000/24576000\n",
      "current iter: 2000/24576000\n",
      "current iter: 3000/24576000\n",
      "current iter: 4000/24576000\n",
      "current iter: 5000/24576000\n",
      "current iter: 6000/24576000\n",
      "current iter: 7000/24576000\n",
      "current iter: 8000/24576000\n",
      "current iter: 9000/24576000\n",
      "current iter: 10000/24576000\n",
      "current iter: 11000/24576000\n",
      "current iter: 12000/24576000\n",
      "current iter: 13000/24576000\n",
      "current iter: 14000/24576000\n",
      "current iter: 15000/24576000\n",
      "current iter: 16000/24576000\n",
      "current iter: 17000/24576000\n",
      "current iter: 18000/24576000\n",
      "current iter: 19000/24576000\n",
      "current iter: 20000/24576000\n",
      "current iter: 21000/24576000\n",
      "current iter: 22000/24576000\n",
      "current iter: 23000/24576000\n",
      "current iter: 24000/24576000\n",
      "current iter: 25000/24576000\n",
      "current iter: 26000/24576000\n",
      "current iter: 27000/24576000\n",
      "current iter: 28000/24576000\n",
      "current iter: 29000/24576000\n",
      "current iter: 30000/24576000\n",
      "current iter: 31000/24576000\n",
      "current iter: 32000/24576000\n",
      "current iter: 33000/24576000\n",
      "current iter: 34000/24576000\n",
      "current iter: 35000/24576000\n",
      "current iter: 36000/24576000\n",
      "current iter: 37000/24576000\n",
      "current iter: 38000/24576000\n",
      "current iter: 39000/24576000\n",
      "current iter: 40000/24576000\n",
      "current iter: 41000/24576000\n",
      "current iter: 42000/24576000\n",
      "current iter: 43000/24576000\n",
      "current iter: 44000/24576000\n",
      "current iter: 45000/24576000\n",
      "current iter: 46000/24576000\n",
      "current iter: 47000/24576000\n",
      "current iter: 48000/24576000\n",
      "current iter: 49000/24576000\n",
      "current iter: 50000/24576000\n",
      "current iter: 51000/24576000\n",
      "current iter: 52000/24576000\n",
      "current iter: 53000/24576000\n",
      "current iter: 54000/24576000\n",
      "current iter: 55000/24576000\n",
      "current iter: 56000/24576000\n",
      "current iter: 57000/24576000\n",
      "current iter: 58000/24576000\n",
      "current iter: 59000/24576000\n",
      "current iter: 60000/24576000\n",
      "current iter: 61000/24576000\n",
      "current iter: 62000/24576000\n",
      "current iter: 63000/24576000\n",
      "current iter: 64000/24576000\n",
      "current iter: 65000/24576000\n",
      "current iter: 66000/24576000\n",
      "current iter: 67000/24576000\n",
      "current iter: 68000/24576000\n",
      "current iter: 69000/24576000\n",
      "current iter: 70000/24576000\n",
      "current iter: 71000/24576000\n",
      "current iter: 72000/24576000\n",
      "current iter: 73000/24576000\n",
      "current iter: 74000/24576000\n",
      "current iter: 75000/24576000\n",
      "current iter: 76000/24576000\n",
      "current iter: 77000/24576000\n",
      "current iter: 78000/24576000\n",
      "current iter: 79000/24576000\n",
      "current iter: 80000/24576000\n",
      "current iter: 81000/24576000\n",
      "current iter: 82000/24576000\n",
      "current iter: 83000/24576000\n",
      "current iter: 84000/24576000\n",
      "current iter: 85000/24576000\n",
      "current iter: 86000/24576000\n",
      "current iter: 87000/24576000\n",
      "current iter: 88000/24576000\n",
      "current iter: 89000/24576000\n",
      "current iter: 90000/24576000\n",
      "current iter: 91000/24576000\n",
      "current iter: 92000/24576000\n",
      "current iter: 93000/24576000\n",
      "current iter: 94000/24576000\n",
      "current iter: 95000/24576000\n",
      "current iter: 96000/24576000\n",
      "current iter: 97000/24576000\n",
      "current iter: 98000/24576000\n",
      "current iter: 99000/24576000\n",
      "current iter: 100000/24576000\n",
      "current iter: 101000/24576000\n",
      "current iter: 102000/24576000\n",
      "current iter: 103000/24576000\n",
      "current iter: 104000/24576000\n",
      "current iter: 105000/24576000\n",
      "current iter: 106000/24576000\n",
      "current iter: 107000/24576000\n",
      "current iter: 108000/24576000\n",
      "current iter: 109000/24576000\n",
      "current iter: 110000/24576000\n",
      "current iter: 111000/24576000\n",
      "current iter: 112000/24576000\n",
      "current iter: 113000/24576000\n",
      "current iter: 114000/24576000\n",
      "current iter: 115000/24576000\n",
      "current iter: 116000/24576000\n",
      "current iter: 117000/24576000\n",
      "current iter: 118000/24576000\n",
      "current iter: 119000/24576000\n",
      "current iter: 120000/24576000\n",
      "current iter: 121000/24576000\n",
      "current iter: 122000/24576000\n",
      "current iter: 123000/24576000\n",
      "current iter: 124000/24576000\n",
      "current iter: 125000/24576000\n",
      "current iter: 126000/24576000\n",
      "current iter: 127000/24576000\n",
      "current iter: 128000/24576000\n",
      "current iter: 129000/24576000\n",
      "current iter: 130000/24576000\n",
      "current iter: 131000/24576000\n",
      "current iter: 132000/24576000\n",
      "current iter: 133000/24576000\n",
      "current iter: 134000/24576000\n",
      "current iter: 135000/24576000\n",
      "current iter: 136000/24576000\n",
      "current iter: 137000/24576000\n",
      "current iter: 138000/24576000\n",
      "current iter: 139000/24576000\n",
      "current iter: 140000/24576000\n",
      "current iter: 141000/24576000\n",
      "current iter: 142000/24576000\n",
      "current iter: 143000/24576000\n",
      "current iter: 144000/24576000\n",
      "current iter: 145000/24576000\n",
      "current iter: 146000/24576000\n",
      "current iter: 147000/24576000\n",
      "current iter: 148000/24576000\n",
      "current iter: 149000/24576000\n",
      "current iter: 150000/24576000\n",
      "current iter: 151000/24576000\n",
      "current iter: 152000/24576000\n",
      "current iter: 153000/24576000\n",
      "current iter: 154000/24576000\n",
      "current iter: 155000/24576000\n",
      "current iter: 156000/24576000\n",
      "current iter: 157000/24576000\n",
      "current iter: 158000/24576000\n",
      "current iter: 159000/24576000\n",
      "current iter: 160000/24576000\n",
      "current iter: 161000/24576000\n",
      "current iter: 162000/24576000\n",
      "current iter: 163000/24576000\n",
      "current iter: 164000/24576000\n",
      "current iter: 165000/24576000\n",
      "current iter: 166000/24576000\n",
      "current iter: 167000/24576000\n",
      "current iter: 168000/24576000\n",
      "current iter: 169000/24576000\n",
      "current iter: 170000/24576000\n",
      "current iter: 171000/24576000\n",
      "current iter: 172000/24576000\n",
      "current iter: 173000/24576000\n",
      "current iter: 174000/24576000\n",
      "current iter: 175000/24576000\n",
      "current iter: 176000/24576000\n",
      "current iter: 177000/24576000\n",
      "current iter: 178000/24576000\n",
      "current iter: 179000/24576000\n",
      "current iter: 180000/24576000\n",
      "current iter: 181000/24576000\n",
      "current iter: 182000/24576000\n",
      "current iter: 183000/24576000\n",
      "current iter: 184000/24576000\n",
      "current iter: 185000/24576000\n",
      "current iter: 186000/24576000\n",
      "current iter: 187000/24576000\n",
      "current iter: 188000/24576000\n",
      "current iter: 189000/24576000\n",
      "current iter: 190000/24576000\n",
      "current iter: 191000/24576000\n",
      "current iter: 192000/24576000\n",
      "current iter: 193000/24576000\n",
      "current iter: 194000/24576000\n",
      "current iter: 195000/24576000\n",
      "current iter: 196000/24576000\n",
      "current iter: 197000/24576000\n",
      "current iter: 198000/24576000\n",
      "current iter: 199000/24576000\n",
      "current iter: 200000/24576000\n",
      "current iter: 201000/24576000\n",
      "current iter: 202000/24576000\n",
      "current iter: 203000/24576000\n",
      "current iter: 204000/24576000\n",
      "current iter: 205000/24576000\n",
      "current iter: 206000/24576000\n",
      "current iter: 207000/24576000\n",
      "current iter: 208000/24576000\n",
      "current iter: 209000/24576000\n",
      "current iter: 210000/24576000\n",
      "current iter: 211000/24576000\n",
      "current iter: 212000/24576000\n",
      "current iter: 213000/24576000\n",
      "current iter: 214000/24576000\n",
      "current iter: 215000/24576000\n",
      "current iter: 216000/24576000\n",
      "current iter: 217000/24576000\n",
      "current iter: 218000/24576000\n",
      "current iter: 219000/24576000\n",
      "current iter: 220000/24576000\n",
      "current iter: 221000/24576000\n",
      "current iter: 222000/24576000\n",
      "current iter: 223000/24576000\n",
      "current iter: 224000/24576000\n",
      "current iter: 225000/24576000\n",
      "current iter: 226000/24576000\n",
      "current iter: 227000/24576000\n",
      "current iter: 228000/24576000\n",
      "current iter: 229000/24576000\n",
      "current iter: 230000/24576000\n",
      "current iter: 231000/24576000\n",
      "current iter: 232000/24576000\n",
      "current iter: 233000/24576000\n",
      "current iter: 234000/24576000\n",
      "current iter: 235000/24576000\n",
      "current iter: 236000/24576000\n",
      "current iter: 237000/24576000\n",
      "current iter: 238000/24576000\n",
      "current iter: 239000/24576000\n",
      "current iter: 240000/24576000\n",
      "current iter: 241000/24576000\n",
      "current iter: 242000/24576000\n",
      "current iter: 243000/24576000\n",
      "current iter: 244000/24576000\n",
      "current iter: 245000/24576000\n",
      "current iter: 246000/24576000\n",
      "current iter: 247000/24576000\n",
      "current iter: 248000/24576000\n",
      "current iter: 249000/24576000\n",
      "current iter: 250000/24576000\n",
      "current iter: 251000/24576000\n",
      "current iter: 252000/24576000\n",
      "current iter: 253000/24576000\n",
      "current iter: 254000/24576000\n",
      "current iter: 255000/24576000\n",
      "current iter: 256000/24576000\n",
      "current iter: 257000/24576000\n",
      "current iter: 258000/24576000\n",
      "current iter: 259000/24576000\n",
      "current iter: 260000/24576000\n",
      "current iter: 261000/24576000\n",
      "current iter: 262000/24576000\n",
      "current iter: 263000/24576000\n",
      "current iter: 264000/24576000\n",
      "current iter: 265000/24576000\n",
      "current iter: 266000/24576000\n",
      "current iter: 267000/24576000\n",
      "current iter: 268000/24576000\n",
      "current iter: 269000/24576000\n",
      "current iter: 270000/24576000\n",
      "current iter: 271000/24576000\n",
      "current iter: 272000/24576000\n",
      "current iter: 273000/24576000\n",
      "current iter: 274000/24576000\n",
      "current iter: 275000/24576000\n",
      "current iter: 276000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 277000/24576000\n",
      "current iter: 278000/24576000\n",
      "current iter: 279000/24576000\n",
      "current iter: 280000/24576000\n",
      "current iter: 281000/24576000\n",
      "current iter: 282000/24576000\n",
      "current iter: 283000/24576000\n",
      "current iter: 284000/24576000\n",
      "current iter: 285000/24576000\n",
      "current iter: 286000/24576000\n",
      "current iter: 287000/24576000\n",
      "current iter: 288000/24576000\n",
      "current iter: 289000/24576000\n",
      "current iter: 290000/24576000\n",
      "current iter: 291000/24576000\n",
      "current iter: 292000/24576000\n",
      "current iter: 293000/24576000\n",
      "current iter: 294000/24576000\n",
      "current iter: 295000/24576000\n",
      "current iter: 296000/24576000\n",
      "current iter: 297000/24576000\n",
      "current iter: 298000/24576000\n",
      "current iter: 299000/24576000\n",
      "current iter: 300000/24576000\n",
      "current iter: 301000/24576000\n",
      "current iter: 302000/24576000\n",
      "current iter: 303000/24576000\n",
      "current iter: 304000/24576000\n",
      "current iter: 305000/24576000\n",
      "current iter: 306000/24576000\n",
      "current iter: 307000/24576000\n",
      "current iter: 308000/24576000\n",
      "current iter: 309000/24576000\n",
      "current iter: 310000/24576000\n",
      "current iter: 311000/24576000\n",
      "current iter: 312000/24576000\n",
      "current iter: 313000/24576000\n",
      "current iter: 314000/24576000\n",
      "current iter: 315000/24576000\n",
      "current iter: 316000/24576000\n",
      "current iter: 317000/24576000\n",
      "current iter: 318000/24576000\n",
      "current iter: 319000/24576000\n",
      "current iter: 320000/24576000\n",
      "current iter: 321000/24576000\n",
      "current iter: 322000/24576000\n",
      "current iter: 323000/24576000\n",
      "current iter: 324000/24576000\n",
      "current iter: 325000/24576000\n",
      "current iter: 326000/24576000\n",
      "current iter: 327000/24576000\n",
      "current iter: 328000/24576000\n",
      "current iter: 329000/24576000\n",
      "current iter: 330000/24576000\n",
      "current iter: 331000/24576000\n",
      "current iter: 332000/24576000\n",
      "current iter: 333000/24576000\n",
      "current iter: 334000/24576000\n",
      "current iter: 335000/24576000\n",
      "current iter: 336000/24576000\n",
      "current iter: 337000/24576000\n",
      "current iter: 338000/24576000\n",
      "current iter: 339000/24576000\n",
      "current iter: 340000/24576000\n",
      "current iter: 341000/24576000\n",
      "current iter: 342000/24576000\n",
      "current iter: 343000/24576000\n",
      "current iter: 344000/24576000\n",
      "current iter: 345000/24576000\n",
      "current iter: 346000/24576000\n",
      "current iter: 347000/24576000\n",
      "current iter: 348000/24576000\n",
      "current iter: 349000/24576000\n",
      "current iter: 350000/24576000\n",
      "current iter: 351000/24576000\n",
      "current iter: 352000/24576000\n",
      "current iter: 353000/24576000\n",
      "current iter: 354000/24576000\n",
      "current iter: 355000/24576000\n",
      "current iter: 356000/24576000\n",
      "current iter: 357000/24576000\n",
      "current iter: 358000/24576000\n",
      "current iter: 359000/24576000\n",
      "current iter: 360000/24576000\n",
      "current iter: 361000/24576000\n",
      "current iter: 362000/24576000\n",
      "current iter: 363000/24576000\n",
      "current iter: 364000/24576000\n",
      "current iter: 365000/24576000\n",
      "current iter: 366000/24576000\n",
      "current iter: 367000/24576000\n",
      "current iter: 368000/24576000\n",
      "current iter: 369000/24576000\n",
      "current iter: 370000/24576000\n",
      "current iter: 371000/24576000\n",
      "current iter: 372000/24576000\n",
      "current iter: 373000/24576000\n",
      "current iter: 374000/24576000\n",
      "current iter: 375000/24576000\n",
      "current iter: 376000/24576000\n",
      "current iter: 377000/24576000\n",
      "current iter: 378000/24576000\n",
      "current iter: 379000/24576000\n",
      "current iter: 380000/24576000\n",
      "current iter: 381000/24576000\n",
      "current iter: 382000/24576000\n",
      "current iter: 383000/24576000\n",
      "current iter: 384000/24576000\n",
      "current iter: 385000/24576000\n",
      "current iter: 386000/24576000\n",
      "current iter: 387000/24576000\n",
      "current iter: 388000/24576000\n",
      "current iter: 389000/24576000\n",
      "current iter: 390000/24576000\n",
      "current iter: 391000/24576000\n",
      "current iter: 392000/24576000\n",
      "current iter: 393000/24576000\n",
      "current iter: 394000/24576000\n",
      "current iter: 395000/24576000\n",
      "current iter: 396000/24576000\n",
      "current iter: 397000/24576000\n",
      "current iter: 398000/24576000\n",
      "current iter: 399000/24576000\n",
      "current iter: 400000/24576000\n",
      "current iter: 401000/24576000\n",
      "current iter: 402000/24576000\n",
      "current iter: 403000/24576000\n",
      "current iter: 404000/24576000\n",
      "current iter: 405000/24576000\n",
      "current iter: 406000/24576000\n",
      "current iter: 407000/24576000\n",
      "current iter: 408000/24576000\n",
      "current iter: 409000/24576000\n",
      "current iter: 410000/24576000\n",
      "current iter: 411000/24576000\n",
      "current iter: 412000/24576000\n",
      "current iter: 413000/24576000\n",
      "current iter: 414000/24576000\n",
      "current iter: 415000/24576000\n",
      "current iter: 416000/24576000\n",
      "current iter: 417000/24576000\n",
      "current iter: 418000/24576000\n",
      "current iter: 419000/24576000\n",
      "current iter: 420000/24576000\n",
      "current iter: 421000/24576000\n",
      "current iter: 422000/24576000\n",
      "current iter: 423000/24576000\n",
      "current iter: 424000/24576000\n",
      "current iter: 425000/24576000\n",
      "current iter: 426000/24576000\n",
      "current iter: 427000/24576000\n",
      "current iter: 428000/24576000\n",
      "current iter: 429000/24576000\n",
      "current iter: 430000/24576000\n",
      "current iter: 431000/24576000\n",
      "current iter: 432000/24576000\n",
      "current iter: 433000/24576000\n",
      "current iter: 434000/24576000\n",
      "current iter: 435000/24576000\n",
      "current iter: 436000/24576000\n",
      "current iter: 437000/24576000\n",
      "current iter: 438000/24576000\n",
      "current iter: 439000/24576000\n",
      "current iter: 440000/24576000\n",
      "current iter: 441000/24576000\n",
      "current iter: 442000/24576000\n",
      "current iter: 443000/24576000\n",
      "current iter: 444000/24576000\n",
      "current iter: 445000/24576000\n",
      "current iter: 446000/24576000\n",
      "current iter: 447000/24576000\n",
      "current iter: 448000/24576000\n",
      "current iter: 449000/24576000\n",
      "current iter: 450000/24576000\n",
      "current iter: 451000/24576000\n",
      "current iter: 452000/24576000\n",
      "current iter: 453000/24576000\n",
      "current iter: 454000/24576000\n",
      "current iter: 455000/24576000\n",
      "current iter: 456000/24576000\n",
      "current iter: 457000/24576000\n",
      "current iter: 458000/24576000\n",
      "current iter: 459000/24576000\n",
      "current iter: 460000/24576000\n",
      "current iter: 461000/24576000\n",
      "current iter: 462000/24576000\n",
      "current iter: 463000/24576000\n",
      "current iter: 464000/24576000\n",
      "current iter: 465000/24576000\n",
      "current iter: 466000/24576000\n",
      "current iter: 467000/24576000\n",
      "current iter: 468000/24576000\n",
      "current iter: 469000/24576000\n",
      "current iter: 470000/24576000\n",
      "current iter: 471000/24576000\n",
      "current iter: 472000/24576000\n",
      "current iter: 473000/24576000\n",
      "current iter: 474000/24576000\n",
      "current iter: 475000/24576000\n",
      "current iter: 476000/24576000\n",
      "current iter: 477000/24576000\n",
      "current iter: 478000/24576000\n",
      "current iter: 479000/24576000\n",
      "current iter: 480000/24576000\n",
      "current iter: 481000/24576000\n",
      "current iter: 482000/24576000\n",
      "current iter: 483000/24576000\n",
      "current iter: 484000/24576000\n",
      "current iter: 485000/24576000\n",
      "current iter: 486000/24576000\n",
      "current iter: 487000/24576000\n",
      "current iter: 488000/24576000\n",
      "current iter: 489000/24576000\n",
      "current iter: 490000/24576000\n",
      "current iter: 491000/24576000\n",
      "current iter: 492000/24576000\n",
      "current iter: 493000/24576000\n",
      "current iter: 494000/24576000\n",
      "current iter: 495000/24576000\n",
      "current iter: 496000/24576000\n",
      "current iter: 497000/24576000\n",
      "current iter: 498000/24576000\n",
      "current iter: 499000/24576000\n",
      "current iter: 500000/24576000\n",
      "current iter: 501000/24576000\n",
      "current iter: 502000/24576000\n",
      "current iter: 503000/24576000\n",
      "current iter: 504000/24576000\n",
      "current iter: 505000/24576000\n",
      "current iter: 506000/24576000\n",
      "current iter: 507000/24576000\n",
      "current iter: 508000/24576000\n",
      "current iter: 509000/24576000\n",
      "current iter: 510000/24576000\n",
      "current iter: 511000/24576000\n",
      "current iter: 512000/24576000\n",
      "current iter: 513000/24576000\n",
      "current iter: 514000/24576000\n",
      "current iter: 515000/24576000\n",
      "current iter: 516000/24576000\n",
      "current iter: 517000/24576000\n",
      "current iter: 518000/24576000\n",
      "current iter: 519000/24576000\n",
      "current iter: 520000/24576000\n",
      "current iter: 521000/24576000\n",
      "current iter: 522000/24576000\n",
      "current iter: 523000/24576000\n",
      "current iter: 524000/24576000\n",
      "current iter: 525000/24576000\n",
      "current iter: 526000/24576000\n",
      "current iter: 527000/24576000\n",
      "current iter: 528000/24576000\n",
      "current iter: 529000/24576000\n",
      "current iter: 530000/24576000\n",
      "current iter: 531000/24576000\n",
      "current iter: 532000/24576000\n",
      "current iter: 533000/24576000\n",
      "current iter: 534000/24576000\n",
      "current iter: 535000/24576000\n",
      "current iter: 536000/24576000\n",
      "current iter: 537000/24576000\n",
      "current iter: 538000/24576000\n",
      "current iter: 539000/24576000\n",
      "current iter: 540000/24576000\n",
      "current iter: 541000/24576000\n",
      "current iter: 542000/24576000\n",
      "current iter: 543000/24576000\n",
      "current iter: 544000/24576000\n",
      "current iter: 545000/24576000\n",
      "current iter: 546000/24576000\n",
      "current iter: 547000/24576000\n",
      "current iter: 548000/24576000\n",
      "current iter: 549000/24576000\n",
      "current iter: 550000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 551000/24576000\n",
      "current iter: 552000/24576000\n",
      "current iter: 553000/24576000\n",
      "current iter: 554000/24576000\n",
      "current iter: 555000/24576000\n",
      "current iter: 556000/24576000\n",
      "current iter: 557000/24576000\n",
      "current iter: 558000/24576000\n",
      "current iter: 559000/24576000\n",
      "current iter: 560000/24576000\n",
      "current iter: 561000/24576000\n",
      "current iter: 562000/24576000\n",
      "current iter: 563000/24576000\n",
      "current iter: 564000/24576000\n",
      "current iter: 565000/24576000\n",
      "current iter: 566000/24576000\n",
      "current iter: 567000/24576000\n",
      "current iter: 568000/24576000\n",
      "current iter: 569000/24576000\n",
      "current iter: 570000/24576000\n",
      "current iter: 571000/24576000\n",
      "current iter: 572000/24576000\n",
      "current iter: 573000/24576000\n",
      "current iter: 574000/24576000\n",
      "current iter: 575000/24576000\n",
      "current iter: 576000/24576000\n",
      "current iter: 577000/24576000\n",
      "current iter: 578000/24576000\n",
      "current iter: 579000/24576000\n",
      "current iter: 580000/24576000\n",
      "current iter: 581000/24576000\n",
      "current iter: 582000/24576000\n",
      "current iter: 583000/24576000\n",
      "current iter: 584000/24576000\n",
      "current iter: 585000/24576000\n",
      "current iter: 586000/24576000\n",
      "current iter: 587000/24576000\n",
      "current iter: 588000/24576000\n",
      "current iter: 589000/24576000\n",
      "current iter: 590000/24576000\n",
      "current iter: 591000/24576000\n",
      "current iter: 592000/24576000\n",
      "current iter: 593000/24576000\n",
      "current iter: 594000/24576000\n",
      "current iter: 595000/24576000\n",
      "current iter: 596000/24576000\n",
      "current iter: 597000/24576000\n",
      "current iter: 598000/24576000\n",
      "current iter: 599000/24576000\n",
      "current iter: 600000/24576000\n",
      "current iter: 601000/24576000\n",
      "current iter: 602000/24576000\n",
      "current iter: 603000/24576000\n",
      "current iter: 604000/24576000\n",
      "current iter: 605000/24576000\n",
      "current iter: 606000/24576000\n",
      "current iter: 607000/24576000\n",
      "current iter: 608000/24576000\n",
      "current iter: 609000/24576000\n",
      "current iter: 610000/24576000\n",
      "current iter: 611000/24576000\n",
      "current iter: 612000/24576000\n",
      "current iter: 613000/24576000\n",
      "current iter: 614000/24576000\n",
      "current iter: 615000/24576000\n",
      "current iter: 616000/24576000\n",
      "current iter: 617000/24576000\n",
      "current iter: 618000/24576000\n",
      "current iter: 619000/24576000\n",
      "current iter: 620000/24576000\n",
      "current iter: 621000/24576000\n",
      "current iter: 622000/24576000\n",
      "current iter: 623000/24576000\n",
      "current iter: 624000/24576000\n",
      "current iter: 625000/24576000\n",
      "current iter: 626000/24576000\n",
      "current iter: 627000/24576000\n",
      "current iter: 628000/24576000\n",
      "current iter: 629000/24576000\n",
      "current iter: 630000/24576000\n",
      "current iter: 631000/24576000\n",
      "current iter: 632000/24576000\n",
      "current iter: 633000/24576000\n",
      "current iter: 634000/24576000\n",
      "current iter: 635000/24576000\n",
      "current iter: 636000/24576000\n",
      "current iter: 637000/24576000\n",
      "current iter: 638000/24576000\n",
      "current iter: 639000/24576000\n",
      "current iter: 640000/24576000\n",
      "current iter: 641000/24576000\n",
      "current iter: 642000/24576000\n",
      "current iter: 643000/24576000\n",
      "current iter: 644000/24576000\n",
      "current iter: 645000/24576000\n",
      "current iter: 646000/24576000\n",
      "current iter: 647000/24576000\n",
      "current iter: 648000/24576000\n",
      "current iter: 649000/24576000\n",
      "current iter: 650000/24576000\n",
      "current iter: 651000/24576000\n",
      "current iter: 652000/24576000\n",
      "current iter: 653000/24576000\n",
      "current iter: 654000/24576000\n",
      "current iter: 655000/24576000\n",
      "current iter: 656000/24576000\n",
      "current iter: 657000/24576000\n",
      "current iter: 658000/24576000\n",
      "current iter: 659000/24576000\n",
      "current iter: 660000/24576000\n",
      "current iter: 661000/24576000\n",
      "current iter: 662000/24576000\n",
      "current iter: 663000/24576000\n",
      "current iter: 664000/24576000\n",
      "current iter: 665000/24576000\n",
      "current iter: 666000/24576000\n",
      "current iter: 667000/24576000\n",
      "current iter: 668000/24576000\n",
      "current iter: 669000/24576000\n",
      "current iter: 670000/24576000\n",
      "current iter: 671000/24576000\n",
      "current iter: 672000/24576000\n",
      "current iter: 673000/24576000\n",
      "current iter: 674000/24576000\n",
      "current iter: 675000/24576000\n",
      "current iter: 676000/24576000\n",
      "current iter: 677000/24576000\n",
      "current iter: 678000/24576000\n",
      "current iter: 679000/24576000\n",
      "current iter: 680000/24576000\n",
      "current iter: 681000/24576000\n",
      "current iter: 682000/24576000\n",
      "current iter: 683000/24576000\n",
      "current iter: 684000/24576000\n",
      "current iter: 685000/24576000\n",
      "current iter: 686000/24576000\n",
      "current iter: 687000/24576000\n",
      "current iter: 688000/24576000\n",
      "current iter: 689000/24576000\n",
      "current iter: 690000/24576000\n",
      "current iter: 691000/24576000\n",
      "current iter: 692000/24576000\n",
      "current iter: 693000/24576000\n",
      "current iter: 694000/24576000\n",
      "current iter: 695000/24576000\n",
      "current iter: 696000/24576000\n",
      "current iter: 697000/24576000\n",
      "current iter: 698000/24576000\n",
      "current iter: 699000/24576000\n",
      "current iter: 700000/24576000\n",
      "current iter: 701000/24576000\n",
      "current iter: 702000/24576000\n",
      "current iter: 703000/24576000\n",
      "current iter: 704000/24576000\n",
      "current iter: 705000/24576000\n",
      "current iter: 706000/24576000\n",
      "current iter: 707000/24576000\n",
      "current iter: 708000/24576000\n",
      "current iter: 709000/24576000\n",
      "current iter: 710000/24576000\n",
      "current iter: 711000/24576000\n",
      "current iter: 712000/24576000\n",
      "current iter: 713000/24576000\n",
      "current iter: 714000/24576000\n",
      "current iter: 715000/24576000\n",
      "current iter: 716000/24576000\n",
      "current iter: 717000/24576000\n",
      "current iter: 718000/24576000\n",
      "current iter: 719000/24576000\n",
      "current iter: 720000/24576000\n",
      "current iter: 721000/24576000\n",
      "current iter: 722000/24576000\n",
      "current iter: 723000/24576000\n",
      "current iter: 724000/24576000\n",
      "current iter: 725000/24576000\n",
      "current iter: 726000/24576000\n",
      "current iter: 727000/24576000\n",
      "current iter: 728000/24576000\n",
      "current iter: 729000/24576000\n",
      "current iter: 730000/24576000\n",
      "current iter: 731000/24576000\n",
      "current iter: 732000/24576000\n",
      "current iter: 733000/24576000\n",
      "current iter: 734000/24576000\n",
      "current iter: 735000/24576000\n",
      "current iter: 736000/24576000\n",
      "current iter: 737000/24576000\n",
      "current iter: 738000/24576000\n",
      "current iter: 739000/24576000\n",
      "current iter: 740000/24576000\n",
      "current iter: 741000/24576000\n",
      "current iter: 742000/24576000\n",
      "current iter: 743000/24576000\n",
      "current iter: 744000/24576000\n",
      "current iter: 745000/24576000\n",
      "current iter: 746000/24576000\n",
      "current iter: 747000/24576000\n",
      "current iter: 748000/24576000\n",
      "current iter: 749000/24576000\n",
      "current iter: 750000/24576000\n",
      "current iter: 751000/24576000\n",
      "current iter: 752000/24576000\n",
      "current iter: 753000/24576000\n",
      "current iter: 754000/24576000\n",
      "current iter: 755000/24576000\n",
      "current iter: 756000/24576000\n",
      "current iter: 757000/24576000\n",
      "current iter: 758000/24576000\n",
      "current iter: 759000/24576000\n",
      "current iter: 760000/24576000\n",
      "current iter: 761000/24576000\n",
      "current iter: 762000/24576000\n",
      "current iter: 763000/24576000\n",
      "current iter: 764000/24576000\n",
      "current iter: 765000/24576000\n",
      "current iter: 766000/24576000\n",
      "current iter: 767000/24576000\n",
      "current iter: 768000/24576000\n",
      "current iter: 769000/24576000\n",
      "current iter: 770000/24576000\n",
      "current iter: 771000/24576000\n",
      "current iter: 772000/24576000\n",
      "current iter: 773000/24576000\n",
      "current iter: 774000/24576000\n",
      "current iter: 775000/24576000\n",
      "current iter: 776000/24576000\n",
      "current iter: 777000/24576000\n",
      "current iter: 778000/24576000\n",
      "current iter: 779000/24576000\n",
      "current iter: 780000/24576000\n",
      "current iter: 781000/24576000\n",
      "current iter: 782000/24576000\n",
      "current iter: 783000/24576000\n",
      "current iter: 784000/24576000\n",
      "current iter: 785000/24576000\n",
      "current iter: 786000/24576000\n",
      "current iter: 787000/24576000\n",
      "current iter: 788000/24576000\n",
      "current iter: 789000/24576000\n",
      "current iter: 790000/24576000\n",
      "current iter: 791000/24576000\n",
      "current iter: 792000/24576000\n",
      "current iter: 793000/24576000\n",
      "current iter: 794000/24576000\n",
      "current iter: 795000/24576000\n",
      "current iter: 796000/24576000\n",
      "current iter: 797000/24576000\n",
      "current iter: 798000/24576000\n",
      "current iter: 799000/24576000\n",
      "current iter: 800000/24576000\n",
      "current iter: 801000/24576000\n",
      "current iter: 802000/24576000\n",
      "current iter: 803000/24576000\n",
      "current iter: 804000/24576000\n",
      "current iter: 805000/24576000\n",
      "current iter: 806000/24576000\n",
      "current iter: 807000/24576000\n",
      "current iter: 808000/24576000\n",
      "current iter: 809000/24576000\n",
      "current iter: 810000/24576000\n",
      "current iter: 811000/24576000\n",
      "current iter: 812000/24576000\n",
      "current iter: 813000/24576000\n",
      "current iter: 814000/24576000\n",
      "current iter: 815000/24576000\n",
      "current iter: 816000/24576000\n",
      "current iter: 817000/24576000\n",
      "current iter: 818000/24576000\n",
      "current iter: 819000/24576000\n",
      "current iter: 820000/24576000\n",
      "current iter: 821000/24576000\n",
      "current iter: 822000/24576000\n",
      "current iter: 823000/24576000\n",
      "current iter: 824000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 825000/24576000\n",
      "current iter: 826000/24576000\n",
      "current iter: 827000/24576000\n",
      "current iter: 828000/24576000\n",
      "current iter: 829000/24576000\n",
      "current iter: 830000/24576000\n",
      "current iter: 831000/24576000\n",
      "current iter: 832000/24576000\n",
      "current iter: 833000/24576000\n",
      "current iter: 834000/24576000\n",
      "current iter: 835000/24576000\n",
      "current iter: 836000/24576000\n",
      "current iter: 837000/24576000\n",
      "current iter: 838000/24576000\n",
      "current iter: 839000/24576000\n",
      "current iter: 840000/24576000\n",
      "current iter: 841000/24576000\n",
      "current iter: 842000/24576000\n",
      "current iter: 843000/24576000\n",
      "current iter: 844000/24576000\n",
      "current iter: 845000/24576000\n",
      "current iter: 846000/24576000\n",
      "current iter: 847000/24576000\n",
      "current iter: 848000/24576000\n",
      "current iter: 849000/24576000\n",
      "current iter: 850000/24576000\n",
      "current iter: 851000/24576000\n",
      "current iter: 852000/24576000\n",
      "current iter: 853000/24576000\n",
      "current iter: 854000/24576000\n",
      "current iter: 855000/24576000\n",
      "current iter: 856000/24576000\n",
      "current iter: 857000/24576000\n",
      "current iter: 858000/24576000\n",
      "current iter: 859000/24576000\n",
      "current iter: 860000/24576000\n",
      "current iter: 861000/24576000\n",
      "current iter: 862000/24576000\n",
      "current iter: 863000/24576000\n",
      "current iter: 864000/24576000\n",
      "current iter: 865000/24576000\n",
      "current iter: 866000/24576000\n",
      "current iter: 867000/24576000\n",
      "current iter: 868000/24576000\n",
      "current iter: 869000/24576000\n",
      "current iter: 870000/24576000\n",
      "current iter: 871000/24576000\n",
      "current iter: 872000/24576000\n",
      "current iter: 873000/24576000\n",
      "current iter: 874000/24576000\n",
      "current iter: 875000/24576000\n",
      "current iter: 876000/24576000\n",
      "current iter: 877000/24576000\n",
      "current iter: 878000/24576000\n",
      "current iter: 879000/24576000\n",
      "current iter: 880000/24576000\n",
      "current iter: 881000/24576000\n",
      "current iter: 882000/24576000\n",
      "current iter: 883000/24576000\n",
      "current iter: 884000/24576000\n",
      "current iter: 885000/24576000\n",
      "current iter: 886000/24576000\n",
      "current iter: 887000/24576000\n",
      "current iter: 888000/24576000\n",
      "current iter: 889000/24576000\n",
      "current iter: 890000/24576000\n",
      "current iter: 891000/24576000\n",
      "current iter: 892000/24576000\n",
      "current iter: 893000/24576000\n",
      "current iter: 894000/24576000\n",
      "current iter: 895000/24576000\n",
      "current iter: 896000/24576000\n",
      "current iter: 897000/24576000\n",
      "current iter: 898000/24576000\n",
      "current iter: 899000/24576000\n",
      "current iter: 900000/24576000\n",
      "current iter: 901000/24576000\n",
      "current iter: 902000/24576000\n",
      "current iter: 903000/24576000\n",
      "current iter: 904000/24576000\n",
      "current iter: 905000/24576000\n",
      "current iter: 906000/24576000\n",
      "current iter: 907000/24576000\n",
      "current iter: 908000/24576000\n",
      "current iter: 909000/24576000\n",
      "current iter: 910000/24576000\n",
      "current iter: 911000/24576000\n",
      "current iter: 912000/24576000\n",
      "current iter: 913000/24576000\n",
      "current iter: 914000/24576000\n",
      "current iter: 915000/24576000\n",
      "current iter: 916000/24576000\n",
      "current iter: 917000/24576000\n",
      "current iter: 918000/24576000\n",
      "current iter: 919000/24576000\n",
      "current iter: 920000/24576000\n",
      "current iter: 921000/24576000\n",
      "current iter: 922000/24576000\n",
      "current iter: 923000/24576000\n",
      "current iter: 924000/24576000\n",
      "current iter: 925000/24576000\n",
      "current iter: 926000/24576000\n",
      "current iter: 927000/24576000\n",
      "current iter: 928000/24576000\n",
      "current iter: 929000/24576000\n",
      "current iter: 930000/24576000\n",
      "current iter: 931000/24576000\n",
      "current iter: 932000/24576000\n",
      "current iter: 933000/24576000\n",
      "current iter: 934000/24576000\n",
      "current iter: 935000/24576000\n",
      "current iter: 936000/24576000\n",
      "current iter: 937000/24576000\n",
      "current iter: 938000/24576000\n",
      "current iter: 939000/24576000\n",
      "current iter: 940000/24576000\n",
      "current iter: 941000/24576000\n",
      "current iter: 942000/24576000\n",
      "current iter: 943000/24576000\n",
      "current iter: 944000/24576000\n",
      "current iter: 945000/24576000\n",
      "current iter: 946000/24576000\n",
      "current iter: 947000/24576000\n",
      "current iter: 948000/24576000\n",
      "current iter: 949000/24576000\n",
      "current iter: 950000/24576000\n",
      "current iter: 951000/24576000\n",
      "current iter: 952000/24576000\n",
      "current iter: 953000/24576000\n",
      "current iter: 954000/24576000\n",
      "current iter: 955000/24576000\n",
      "current iter: 956000/24576000\n",
      "current iter: 957000/24576000\n",
      "current iter: 958000/24576000\n",
      "current iter: 959000/24576000\n",
      "current iter: 960000/24576000\n",
      "current iter: 961000/24576000\n",
      "current iter: 962000/24576000\n",
      "current iter: 963000/24576000\n",
      "current iter: 964000/24576000\n",
      "current iter: 965000/24576000\n",
      "current iter: 966000/24576000\n",
      "current iter: 967000/24576000\n",
      "current iter: 968000/24576000\n",
      "current iter: 969000/24576000\n",
      "current iter: 970000/24576000\n",
      "current iter: 971000/24576000\n",
      "current iter: 972000/24576000\n",
      "current iter: 973000/24576000\n",
      "current iter: 974000/24576000\n",
      "current iter: 975000/24576000\n",
      "current iter: 976000/24576000\n",
      "current iter: 977000/24576000\n",
      "current iter: 978000/24576000\n",
      "current iter: 979000/24576000\n",
      "current iter: 980000/24576000\n",
      "current iter: 981000/24576000\n",
      "current iter: 982000/24576000\n",
      "current iter: 983000/24576000\n",
      "current iter: 984000/24576000\n",
      "current iter: 985000/24576000\n",
      "current iter: 986000/24576000\n",
      "current iter: 987000/24576000\n",
      "current iter: 988000/24576000\n",
      "current iter: 989000/24576000\n",
      "current iter: 990000/24576000\n",
      "current iter: 991000/24576000\n",
      "current iter: 992000/24576000\n",
      "current iter: 993000/24576000\n",
      "current iter: 994000/24576000\n",
      "current iter: 995000/24576000\n",
      "current iter: 996000/24576000\n",
      "current iter: 997000/24576000\n",
      "current iter: 998000/24576000\n",
      "current iter: 999000/24576000\n",
      "current iter: 1000000/24576000\n",
      "current iter: 1001000/24576000\n",
      "current iter: 1002000/24576000\n",
      "current iter: 1003000/24576000\n",
      "current iter: 1004000/24576000\n",
      "current iter: 1005000/24576000\n",
      "current iter: 1006000/24576000\n",
      "current iter: 1007000/24576000\n",
      "current iter: 1008000/24576000\n",
      "current iter: 1009000/24576000\n",
      "current iter: 1010000/24576000\n",
      "current iter: 1011000/24576000\n",
      "current iter: 1012000/24576000\n",
      "current iter: 1013000/24576000\n",
      "current iter: 1014000/24576000\n",
      "current iter: 1015000/24576000\n",
      "current iter: 1016000/24576000\n",
      "current iter: 1017000/24576000\n",
      "current iter: 1018000/24576000\n",
      "current iter: 1019000/24576000\n",
      "current iter: 1020000/24576000\n",
      "current iter: 1021000/24576000\n",
      "current iter: 1022000/24576000\n",
      "current iter: 1023000/24576000\n",
      "current iter: 1024000/24576000\n",
      "current iter: 1025000/24576000\n",
      "current iter: 1026000/24576000\n",
      "current iter: 1027000/24576000\n",
      "current iter: 1028000/24576000\n",
      "current iter: 1029000/24576000\n",
      "current iter: 1030000/24576000\n",
      "current iter: 1031000/24576000\n",
      "current iter: 1032000/24576000\n",
      "current iter: 1033000/24576000\n",
      "current iter: 1034000/24576000\n",
      "current iter: 1035000/24576000\n",
      "current iter: 1036000/24576000\n",
      "current iter: 1037000/24576000\n",
      "current iter: 1038000/24576000\n",
      "current iter: 1039000/24576000\n",
      "current iter: 1040000/24576000\n",
      "current iter: 1041000/24576000\n",
      "current iter: 1042000/24576000\n",
      "current iter: 1043000/24576000\n",
      "current iter: 1044000/24576000\n",
      "current iter: 1045000/24576000\n",
      "current iter: 1046000/24576000\n",
      "current iter: 1047000/24576000\n",
      "current iter: 1048000/24576000\n",
      "current iter: 1049000/24576000\n",
      "current iter: 1050000/24576000\n",
      "current iter: 1051000/24576000\n",
      "current iter: 1052000/24576000\n",
      "current iter: 1053000/24576000\n",
      "current iter: 1054000/24576000\n",
      "current iter: 1055000/24576000\n",
      "current iter: 1056000/24576000\n",
      "current iter: 1057000/24576000\n",
      "current iter: 1058000/24576000\n",
      "current iter: 1059000/24576000\n",
      "current iter: 1060000/24576000\n",
      "current iter: 1061000/24576000\n",
      "current iter: 1062000/24576000\n",
      "current iter: 1063000/24576000\n",
      "current iter: 1064000/24576000\n",
      "current iter: 1065000/24576000\n",
      "current iter: 1066000/24576000\n",
      "current iter: 1067000/24576000\n",
      "current iter: 1068000/24576000\n",
      "current iter: 1069000/24576000\n",
      "current iter: 1070000/24576000\n",
      "current iter: 1071000/24576000\n",
      "current iter: 1072000/24576000\n",
      "current iter: 1073000/24576000\n",
      "current iter: 1074000/24576000\n",
      "current iter: 1075000/24576000\n",
      "current iter: 1076000/24576000\n",
      "current iter: 1077000/24576000\n",
      "current iter: 1078000/24576000\n",
      "current iter: 1079000/24576000\n",
      "current iter: 1080000/24576000\n",
      "current iter: 1081000/24576000\n",
      "current iter: 1082000/24576000\n",
      "current iter: 1083000/24576000\n",
      "current iter: 1084000/24576000\n",
      "current iter: 1085000/24576000\n",
      "current iter: 1086000/24576000\n",
      "current iter: 1087000/24576000\n",
      "current iter: 1088000/24576000\n",
      "current iter: 1089000/24576000\n",
      "current iter: 1090000/24576000\n",
      "current iter: 1091000/24576000\n",
      "current iter: 1092000/24576000\n",
      "current iter: 1093000/24576000\n",
      "current iter: 1094000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 1095000/24576000\n",
      "current iter: 1096000/24576000\n",
      "current iter: 1097000/24576000\n",
      "current iter: 1098000/24576000\n",
      "current iter: 1099000/24576000\n",
      "current iter: 1100000/24576000\n",
      "current iter: 1101000/24576000\n",
      "current iter: 1102000/24576000\n",
      "current iter: 1103000/24576000\n",
      "current iter: 1104000/24576000\n",
      "current iter: 1105000/24576000\n",
      "current iter: 1106000/24576000\n",
      "current iter: 1107000/24576000\n",
      "current iter: 1108000/24576000\n",
      "current iter: 1109000/24576000\n",
      "current iter: 1110000/24576000\n",
      "current iter: 1111000/24576000\n",
      "current iter: 1112000/24576000\n",
      "current iter: 1113000/24576000\n",
      "current iter: 1114000/24576000\n",
      "current iter: 1115000/24576000\n",
      "current iter: 1116000/24576000\n",
      "current iter: 1117000/24576000\n",
      "current iter: 1118000/24576000\n",
      "current iter: 1119000/24576000\n",
      "current iter: 1120000/24576000\n",
      "current iter: 1121000/24576000\n",
      "current iter: 1122000/24576000\n",
      "current iter: 1123000/24576000\n",
      "current iter: 1124000/24576000\n",
      "current iter: 1125000/24576000\n",
      "current iter: 1126000/24576000\n",
      "current iter: 1127000/24576000\n",
      "current iter: 1128000/24576000\n",
      "current iter: 1129000/24576000\n",
      "current iter: 1130000/24576000\n",
      "current iter: 1131000/24576000\n",
      "current iter: 1132000/24576000\n",
      "current iter: 1133000/24576000\n",
      "current iter: 1134000/24576000\n",
      "current iter: 1135000/24576000\n",
      "current iter: 1136000/24576000\n",
      "current iter: 1137000/24576000\n",
      "current iter: 1138000/24576000\n",
      "current iter: 1139000/24576000\n",
      "current iter: 1140000/24576000\n",
      "current iter: 1141000/24576000\n",
      "current iter: 1142000/24576000\n",
      "current iter: 1143000/24576000\n",
      "current iter: 1144000/24576000\n",
      "current iter: 1145000/24576000\n",
      "current iter: 1146000/24576000\n",
      "current iter: 1147000/24576000\n",
      "current iter: 1148000/24576000\n",
      "current iter: 1149000/24576000\n",
      "current iter: 1150000/24576000\n",
      "current iter: 1151000/24576000\n",
      "current iter: 1152000/24576000\n",
      "current iter: 1153000/24576000\n",
      "current iter: 1154000/24576000\n",
      "current iter: 1155000/24576000\n",
      "current iter: 1156000/24576000\n",
      "current iter: 1157000/24576000\n",
      "current iter: 1158000/24576000\n",
      "current iter: 1159000/24576000\n",
      "current iter: 1160000/24576000\n",
      "current iter: 1161000/24576000\n",
      "current iter: 1162000/24576000\n",
      "current iter: 1163000/24576000\n",
      "current iter: 1164000/24576000\n",
      "current iter: 1165000/24576000\n",
      "current iter: 1166000/24576000\n",
      "current iter: 1167000/24576000\n",
      "current iter: 1168000/24576000\n",
      "current iter: 1169000/24576000\n",
      "current iter: 1170000/24576000\n",
      "current iter: 1171000/24576000\n",
      "current iter: 1172000/24576000\n",
      "current iter: 1173000/24576000\n",
      "current iter: 1174000/24576000\n",
      "current iter: 1175000/24576000\n",
      "current iter: 1176000/24576000\n",
      "current iter: 1177000/24576000\n",
      "current iter: 1178000/24576000\n",
      "current iter: 1179000/24576000\n",
      "current iter: 1180000/24576000\n",
      "current iter: 1181000/24576000\n",
      "current iter: 1182000/24576000\n",
      "current iter: 1183000/24576000\n",
      "current iter: 1184000/24576000\n",
      "current iter: 1185000/24576000\n",
      "current iter: 1186000/24576000\n",
      "current iter: 1187000/24576000\n",
      "current iter: 1188000/24576000\n",
      "current iter: 1189000/24576000\n",
      "current iter: 1190000/24576000\n",
      "current iter: 1191000/24576000\n",
      "current iter: 1192000/24576000\n",
      "current iter: 1193000/24576000\n",
      "current iter: 1194000/24576000\n",
      "current iter: 1195000/24576000\n",
      "current iter: 1196000/24576000\n",
      "current iter: 1197000/24576000\n",
      "current iter: 1198000/24576000\n",
      "current iter: 1199000/24576000\n",
      "current iter: 1200000/24576000\n",
      "current iter: 1201000/24576000\n",
      "current iter: 1202000/24576000\n",
      "current iter: 1203000/24576000\n",
      "current iter: 1204000/24576000\n",
      "current iter: 1205000/24576000\n",
      "current iter: 1206000/24576000\n",
      "current iter: 1207000/24576000\n",
      "current iter: 1208000/24576000\n",
      "current iter: 1209000/24576000\n",
      "current iter: 1210000/24576000\n",
      "current iter: 1211000/24576000\n",
      "current iter: 1212000/24576000\n",
      "current iter: 1213000/24576000\n",
      "current iter: 1214000/24576000\n",
      "current iter: 1215000/24576000\n",
      "current iter: 1216000/24576000\n",
      "current iter: 1217000/24576000\n",
      "current iter: 1218000/24576000\n",
      "current iter: 1219000/24576000\n",
      "current iter: 1220000/24576000\n",
      "current iter: 1221000/24576000\n",
      "current iter: 1222000/24576000\n",
      "current iter: 1223000/24576000\n",
      "current iter: 1224000/24576000\n",
      "current iter: 1225000/24576000\n",
      "current iter: 1226000/24576000\n",
      "current iter: 1227000/24576000\n",
      "current iter: 1228000/24576000\n",
      "current iter: 1229000/24576000\n",
      "current iter: 1230000/24576000\n",
      "current iter: 1231000/24576000\n",
      "current iter: 1232000/24576000\n",
      "current iter: 1233000/24576000\n",
      "current iter: 1234000/24576000\n",
      "current iter: 1235000/24576000\n",
      "current iter: 1236000/24576000\n",
      "current iter: 1237000/24576000\n",
      "current iter: 1238000/24576000\n",
      "current iter: 1239000/24576000\n",
      "current iter: 1240000/24576000\n",
      "current iter: 1241000/24576000\n",
      "current iter: 1242000/24576000\n",
      "current iter: 1243000/24576000\n",
      "current iter: 1244000/24576000\n",
      "current iter: 1245000/24576000\n",
      "current iter: 1246000/24576000\n",
      "current iter: 1247000/24576000\n",
      "current iter: 1248000/24576000\n",
      "current iter: 1249000/24576000\n",
      "current iter: 1250000/24576000\n",
      "current iter: 1251000/24576000\n",
      "current iter: 1252000/24576000\n",
      "current iter: 1253000/24576000\n",
      "current iter: 1254000/24576000\n",
      "current iter: 1255000/24576000\n",
      "current iter: 1256000/24576000\n",
      "current iter: 1257000/24576000\n",
      "current iter: 1258000/24576000\n",
      "current iter: 1259000/24576000\n",
      "current iter: 1260000/24576000\n",
      "current iter: 1261000/24576000\n",
      "current iter: 1262000/24576000\n",
      "current iter: 1263000/24576000\n",
      "current iter: 1264000/24576000\n",
      "current iter: 1265000/24576000\n",
      "current iter: 1266000/24576000\n",
      "current iter: 1267000/24576000\n",
      "current iter: 1268000/24576000\n",
      "current iter: 1269000/24576000\n",
      "current iter: 1270000/24576000\n",
      "current iter: 1271000/24576000\n",
      "current iter: 1272000/24576000\n",
      "current iter: 1273000/24576000\n",
      "current iter: 1274000/24576000\n",
      "current iter: 1275000/24576000\n",
      "current iter: 1276000/24576000\n",
      "current iter: 1277000/24576000\n",
      "current iter: 1278000/24576000\n",
      "current iter: 1279000/24576000\n",
      "current iter: 1280000/24576000\n",
      "current iter: 1281000/24576000\n",
      "current iter: 1282000/24576000\n",
      "current iter: 1283000/24576000\n",
      "current iter: 1284000/24576000\n",
      "current iter: 1285000/24576000\n",
      "current iter: 1286000/24576000\n",
      "current iter: 1287000/24576000\n",
      "current iter: 1288000/24576000\n",
      "current iter: 1289000/24576000\n",
      "current iter: 1290000/24576000\n",
      "current iter: 1291000/24576000\n",
      "current iter: 1292000/24576000\n",
      "current iter: 1293000/24576000\n",
      "current iter: 1294000/24576000\n",
      "current iter: 1295000/24576000\n",
      "current iter: 1296000/24576000\n",
      "current iter: 1297000/24576000\n",
      "current iter: 1298000/24576000\n",
      "current iter: 1299000/24576000\n",
      "current iter: 1300000/24576000\n",
      "current iter: 1301000/24576000\n",
      "current iter: 1302000/24576000\n",
      "current iter: 1303000/24576000\n",
      "current iter: 1304000/24576000\n",
      "current iter: 1305000/24576000\n",
      "current iter: 1306000/24576000\n",
      "current iter: 1307000/24576000\n",
      "current iter: 1308000/24576000\n",
      "current iter: 1309000/24576000\n",
      "current iter: 1310000/24576000\n",
      "current iter: 1311000/24576000\n",
      "current iter: 1312000/24576000\n",
      "current iter: 1313000/24576000\n",
      "current iter: 1314000/24576000\n",
      "current iter: 1315000/24576000\n",
      "current iter: 1316000/24576000\n",
      "current iter: 1317000/24576000\n",
      "current iter: 1318000/24576000\n",
      "current iter: 1319000/24576000\n",
      "current iter: 1320000/24576000\n",
      "current iter: 1321000/24576000\n",
      "current iter: 1322000/24576000\n",
      "current iter: 1323000/24576000\n",
      "current iter: 1324000/24576000\n",
      "current iter: 1325000/24576000\n",
      "current iter: 1326000/24576000\n",
      "current iter: 1327000/24576000\n",
      "current iter: 1328000/24576000\n",
      "current iter: 1329000/24576000\n",
      "current iter: 1330000/24576000\n",
      "current iter: 1331000/24576000\n",
      "current iter: 1332000/24576000\n",
      "current iter: 1333000/24576000\n",
      "current iter: 1334000/24576000\n",
      "current iter: 1335000/24576000\n",
      "current iter: 1336000/24576000\n",
      "current iter: 1337000/24576000\n",
      "current iter: 1338000/24576000\n",
      "current iter: 1339000/24576000\n",
      "current iter: 1340000/24576000\n",
      "current iter: 1341000/24576000\n",
      "current iter: 1342000/24576000\n",
      "current iter: 1343000/24576000\n",
      "current iter: 1344000/24576000\n",
      "current iter: 1345000/24576000\n",
      "current iter: 1346000/24576000\n",
      "current iter: 1347000/24576000\n",
      "current iter: 1348000/24576000\n",
      "current iter: 1349000/24576000\n",
      "current iter: 1350000/24576000\n",
      "current iter: 1351000/24576000\n",
      "current iter: 1352000/24576000\n",
      "current iter: 1353000/24576000\n",
      "current iter: 1354000/24576000\n",
      "current iter: 1355000/24576000\n",
      "current iter: 1356000/24576000\n",
      "current iter: 1357000/24576000\n",
      "current iter: 1358000/24576000\n",
      "current iter: 1359000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 1360000/24576000\n",
      "current iter: 1361000/24576000\n",
      "current iter: 1362000/24576000\n",
      "current iter: 1363000/24576000\n",
      "current iter: 1364000/24576000\n",
      "current iter: 1365000/24576000\n",
      "current iter: 1366000/24576000\n",
      "current iter: 1367000/24576000\n",
      "current iter: 1368000/24576000\n",
      "current iter: 1369000/24576000\n",
      "current iter: 1370000/24576000\n",
      "current iter: 1371000/24576000\n",
      "current iter: 1372000/24576000\n",
      "current iter: 1373000/24576000\n",
      "current iter: 1374000/24576000\n",
      "current iter: 1375000/24576000\n",
      "current iter: 1376000/24576000\n",
      "current iter: 1377000/24576000\n",
      "current iter: 1378000/24576000\n",
      "current iter: 1379000/24576000\n",
      "current iter: 1380000/24576000\n",
      "current iter: 1381000/24576000\n",
      "current iter: 1382000/24576000\n",
      "current iter: 1383000/24576000\n",
      "current iter: 1384000/24576000\n",
      "current iter: 1385000/24576000\n",
      "current iter: 1386000/24576000\n",
      "current iter: 1387000/24576000\n",
      "current iter: 1388000/24576000\n",
      "current iter: 1389000/24576000\n",
      "current iter: 1390000/24576000\n",
      "current iter: 1391000/24576000\n",
      "current iter: 1392000/24576000\n",
      "current iter: 1393000/24576000\n",
      "current iter: 1394000/24576000\n",
      "current iter: 1395000/24576000\n",
      "current iter: 1396000/24576000\n",
      "current iter: 1397000/24576000\n",
      "current iter: 1398000/24576000\n",
      "current iter: 1399000/24576000\n",
      "current iter: 1400000/24576000\n",
      "current iter: 1401000/24576000\n",
      "current iter: 1402000/24576000\n",
      "current iter: 1403000/24576000\n",
      "current iter: 1404000/24576000\n",
      "current iter: 1405000/24576000\n",
      "current iter: 1406000/24576000\n",
      "current iter: 1407000/24576000\n",
      "current iter: 1408000/24576000\n",
      "current iter: 1409000/24576000\n",
      "current iter: 1410000/24576000\n",
      "current iter: 1411000/24576000\n",
      "current iter: 1412000/24576000\n",
      "current iter: 1413000/24576000\n",
      "current iter: 1414000/24576000\n",
      "current iter: 1415000/24576000\n",
      "current iter: 1416000/24576000\n",
      "current iter: 1417000/24576000\n",
      "current iter: 1418000/24576000\n",
      "current iter: 1419000/24576000\n",
      "current iter: 1420000/24576000\n",
      "current iter: 1421000/24576000\n",
      "current iter: 1422000/24576000\n",
      "current iter: 1423000/24576000\n",
      "current iter: 1424000/24576000\n",
      "current iter: 1425000/24576000\n",
      "current iter: 1426000/24576000\n",
      "current iter: 1427000/24576000\n",
      "current iter: 1428000/24576000\n",
      "current iter: 1429000/24576000\n",
      "current iter: 1430000/24576000\n",
      "current iter: 1431000/24576000\n",
      "current iter: 1432000/24576000\n",
      "current iter: 1433000/24576000\n",
      "current iter: 1434000/24576000\n",
      "current iter: 1435000/24576000\n",
      "current iter: 1436000/24576000\n",
      "current iter: 1437000/24576000\n",
      "current iter: 1438000/24576000\n",
      "current iter: 1439000/24576000\n",
      "current iter: 1440000/24576000\n",
      "current iter: 1441000/24576000\n",
      "current iter: 1442000/24576000\n",
      "current iter: 1443000/24576000\n",
      "current iter: 1444000/24576000\n",
      "current iter: 1445000/24576000\n",
      "current iter: 1446000/24576000\n",
      "current iter: 1447000/24576000\n",
      "current iter: 1448000/24576000\n",
      "current iter: 1449000/24576000\n",
      "current iter: 1450000/24576000\n",
      "current iter: 1451000/24576000\n",
      "current iter: 1452000/24576000\n",
      "current iter: 1453000/24576000\n",
      "current iter: 1454000/24576000\n",
      "current iter: 1455000/24576000\n",
      "current iter: 1456000/24576000\n",
      "current iter: 1457000/24576000\n",
      "current iter: 1458000/24576000\n",
      "current iter: 1459000/24576000\n",
      "current iter: 1460000/24576000\n",
      "current iter: 1461000/24576000\n",
      "current iter: 1462000/24576000\n",
      "current iter: 1463000/24576000\n",
      "current iter: 1464000/24576000\n",
      "current iter: 1465000/24576000\n",
      "current iter: 1466000/24576000\n",
      "current iter: 1467000/24576000\n",
      "current iter: 1468000/24576000\n",
      "current iter: 1469000/24576000\n",
      "current iter: 1470000/24576000\n",
      "current iter: 1471000/24576000\n",
      "current iter: 1472000/24576000\n",
      "current iter: 1473000/24576000\n",
      "current iter: 1474000/24576000\n",
      "current iter: 1475000/24576000\n",
      "current iter: 1476000/24576000\n",
      "current iter: 1477000/24576000\n",
      "current iter: 1478000/24576000\n",
      "current iter: 1479000/24576000\n",
      "current iter: 1480000/24576000\n",
      "current iter: 1481000/24576000\n",
      "current iter: 1482000/24576000\n",
      "current iter: 1483000/24576000\n",
      "current iter: 1484000/24576000\n",
      "current iter: 1485000/24576000\n",
      "current iter: 1486000/24576000\n",
      "current iter: 1487000/24576000\n",
      "current iter: 1488000/24576000\n",
      "current iter: 1489000/24576000\n",
      "current iter: 1490000/24576000\n",
      "current iter: 1491000/24576000\n",
      "current iter: 1492000/24576000\n",
      "current iter: 1493000/24576000\n",
      "current iter: 1494000/24576000\n",
      "current iter: 1495000/24576000\n",
      "current iter: 1496000/24576000\n",
      "current iter: 1497000/24576000\n",
      "current iter: 1498000/24576000\n",
      "current iter: 1499000/24576000\n",
      "current iter: 1500000/24576000\n",
      "current iter: 1501000/24576000\n",
      "current iter: 1502000/24576000\n",
      "current iter: 1503000/24576000\n",
      "current iter: 1504000/24576000\n",
      "current iter: 1505000/24576000\n",
      "current iter: 1506000/24576000\n",
      "current iter: 1507000/24576000\n",
      "current iter: 1508000/24576000\n",
      "current iter: 1509000/24576000\n",
      "current iter: 1510000/24576000\n",
      "current iter: 1511000/24576000\n",
      "current iter: 1512000/24576000\n",
      "current iter: 1513000/24576000\n",
      "current iter: 1514000/24576000\n",
      "current iter: 1515000/24576000\n",
      "current iter: 1516000/24576000\n",
      "current iter: 1517000/24576000\n",
      "current iter: 1518000/24576000\n",
      "current iter: 1519000/24576000\n",
      "current iter: 1520000/24576000\n",
      "current iter: 1521000/24576000\n",
      "current iter: 1522000/24576000\n",
      "current iter: 1523000/24576000\n",
      "current iter: 1524000/24576000\n",
      "current iter: 1525000/24576000\n",
      "current iter: 1526000/24576000\n",
      "current iter: 1527000/24576000\n",
      "current iter: 1528000/24576000\n",
      "current iter: 1529000/24576000\n",
      "current iter: 1530000/24576000\n",
      "current iter: 1531000/24576000\n",
      "current iter: 1532000/24576000\n",
      "current iter: 1533000/24576000\n",
      "current iter: 1534000/24576000\n",
      "current iter: 1535000/24576000\n",
      "current iter: 1536000/24576000\n",
      "current iter: 1537000/24576000\n",
      "current iter: 1538000/24576000\n",
      "current iter: 1539000/24576000\n",
      "current iter: 1540000/24576000\n",
      "current iter: 1541000/24576000\n",
      "current iter: 1542000/24576000\n",
      "current iter: 1543000/24576000\n",
      "current iter: 1544000/24576000\n",
      "current iter: 1545000/24576000\n",
      "current iter: 1546000/24576000\n",
      "current iter: 1547000/24576000\n",
      "current iter: 1548000/24576000\n",
      "current iter: 1549000/24576000\n",
      "current iter: 1550000/24576000\n",
      "current iter: 1551000/24576000\n",
      "current iter: 1552000/24576000\n",
      "current iter: 1553000/24576000\n",
      "current iter: 1554000/24576000\n",
      "current iter: 1555000/24576000\n",
      "current iter: 1556000/24576000\n",
      "current iter: 1557000/24576000\n",
      "current iter: 1558000/24576000\n",
      "current iter: 1559000/24576000\n",
      "current iter: 1560000/24576000\n",
      "current iter: 1561000/24576000\n",
      "current iter: 1562000/24576000\n",
      "current iter: 1563000/24576000\n",
      "current iter: 1564000/24576000\n",
      "current iter: 1565000/24576000\n",
      "current iter: 1566000/24576000\n",
      "current iter: 1567000/24576000\n",
      "current iter: 1568000/24576000\n",
      "current iter: 1569000/24576000\n",
      "current iter: 1570000/24576000\n",
      "current iter: 1571000/24576000\n",
      "current iter: 1572000/24576000\n",
      "current iter: 1573000/24576000\n",
      "current iter: 1574000/24576000\n",
      "current iter: 1575000/24576000\n",
      "current iter: 1576000/24576000\n",
      "current iter: 1577000/24576000\n",
      "current iter: 1578000/24576000\n",
      "current iter: 1579000/24576000\n",
      "current iter: 1580000/24576000\n",
      "current iter: 1581000/24576000\n",
      "current iter: 1582000/24576000\n",
      "current iter: 1583000/24576000\n",
      "current iter: 1584000/24576000\n",
      "current iter: 1585000/24576000\n",
      "current iter: 1586000/24576000\n",
      "current iter: 1587000/24576000\n",
      "current iter: 1588000/24576000\n",
      "current iter: 1589000/24576000\n",
      "current iter: 1590000/24576000\n",
      "current iter: 1591000/24576000\n",
      "current iter: 1592000/24576000\n",
      "current iter: 1593000/24576000\n",
      "current iter: 1594000/24576000\n",
      "current iter: 1595000/24576000\n",
      "current iter: 1596000/24576000\n",
      "current iter: 1597000/24576000\n",
      "current iter: 1598000/24576000\n",
      "current iter: 1599000/24576000\n",
      "current iter: 1600000/24576000\n",
      "current iter: 1601000/24576000\n",
      "current iter: 1602000/24576000\n",
      "current iter: 1603000/24576000\n",
      "current iter: 1604000/24576000\n",
      "current iter: 1605000/24576000\n",
      "current iter: 1606000/24576000\n",
      "current iter: 1607000/24576000\n",
      "current iter: 1608000/24576000\n",
      "current iter: 1609000/24576000\n",
      "current iter: 1610000/24576000\n",
      "current iter: 1611000/24576000\n",
      "current iter: 1612000/24576000\n",
      "current iter: 1613000/24576000\n",
      "current iter: 1614000/24576000\n",
      "current iter: 1615000/24576000\n",
      "current iter: 1616000/24576000\n",
      "current iter: 1617000/24576000\n",
      "current iter: 1618000/24576000\n",
      "current iter: 1619000/24576000\n",
      "current iter: 1620000/24576000\n",
      "current iter: 1621000/24576000\n",
      "current iter: 1622000/24576000\n",
      "current iter: 1623000/24576000\n",
      "current iter: 1624000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 1625000/24576000\n",
      "current iter: 1626000/24576000\n",
      "current iter: 1627000/24576000\n",
      "current iter: 1628000/24576000\n",
      "current iter: 1629000/24576000\n",
      "current iter: 1630000/24576000\n",
      "current iter: 1631000/24576000\n",
      "current iter: 1632000/24576000\n",
      "current iter: 1633000/24576000\n",
      "current iter: 1634000/24576000\n",
      "current iter: 1635000/24576000\n",
      "current iter: 1636000/24576000\n",
      "current iter: 1637000/24576000\n",
      "current iter: 1638000/24576000\n",
      "current iter: 1639000/24576000\n",
      "current iter: 1640000/24576000\n",
      "current iter: 1641000/24576000\n",
      "current iter: 1642000/24576000\n",
      "current iter: 1643000/24576000\n",
      "current iter: 1644000/24576000\n",
      "current iter: 1645000/24576000\n",
      "current iter: 1646000/24576000\n",
      "current iter: 1647000/24576000\n",
      "current iter: 1648000/24576000\n",
      "current iter: 1649000/24576000\n",
      "current iter: 1650000/24576000\n",
      "current iter: 1651000/24576000\n",
      "current iter: 1652000/24576000\n",
      "current iter: 1653000/24576000\n",
      "current iter: 1654000/24576000\n",
      "current iter: 1655000/24576000\n",
      "current iter: 1656000/24576000\n",
      "current iter: 1657000/24576000\n",
      "current iter: 1658000/24576000\n",
      "current iter: 1659000/24576000\n",
      "current iter: 1660000/24576000\n",
      "current iter: 1661000/24576000\n",
      "current iter: 1662000/24576000\n",
      "current iter: 1663000/24576000\n",
      "current iter: 1664000/24576000\n",
      "current iter: 1665000/24576000\n",
      "current iter: 1666000/24576000\n",
      "current iter: 1667000/24576000\n",
      "current iter: 1668000/24576000\n",
      "current iter: 1669000/24576000\n",
      "current iter: 1670000/24576000\n",
      "current iter: 1671000/24576000\n",
      "current iter: 1672000/24576000\n",
      "current iter: 1673000/24576000\n",
      "current iter: 1674000/24576000\n",
      "current iter: 1675000/24576000\n",
      "current iter: 1676000/24576000\n",
      "current iter: 1677000/24576000\n",
      "current iter: 1678000/24576000\n",
      "current iter: 1679000/24576000\n",
      "current iter: 1680000/24576000\n",
      "current iter: 1681000/24576000\n",
      "current iter: 1682000/24576000\n",
      "current iter: 1683000/24576000\n",
      "current iter: 1684000/24576000\n",
      "current iter: 1685000/24576000\n",
      "current iter: 1686000/24576000\n",
      "current iter: 1687000/24576000\n",
      "current iter: 1688000/24576000\n",
      "current iter: 1689000/24576000\n",
      "current iter: 1690000/24576000\n",
      "current iter: 1691000/24576000\n",
      "current iter: 1692000/24576000\n",
      "current iter: 1693000/24576000\n",
      "current iter: 1694000/24576000\n",
      "current iter: 1695000/24576000\n",
      "current iter: 1696000/24576000\n",
      "current iter: 1697000/24576000\n",
      "current iter: 1698000/24576000\n",
      "current iter: 1699000/24576000\n",
      "current iter: 1700000/24576000\n",
      "current iter: 1701000/24576000\n",
      "current iter: 1702000/24576000\n",
      "current iter: 1703000/24576000\n",
      "current iter: 1704000/24576000\n",
      "current iter: 1705000/24576000\n",
      "current iter: 1706000/24576000\n",
      "current iter: 1707000/24576000\n",
      "current iter: 1708000/24576000\n",
      "current iter: 1709000/24576000\n",
      "current iter: 1710000/24576000\n",
      "current iter: 1711000/24576000\n",
      "current iter: 1712000/24576000\n",
      "current iter: 1713000/24576000\n",
      "current iter: 1714000/24576000\n",
      "current iter: 1715000/24576000\n",
      "current iter: 1716000/24576000\n",
      "current iter: 1717000/24576000\n",
      "current iter: 1718000/24576000\n",
      "current iter: 1719000/24576000\n",
      "current iter: 1720000/24576000\n",
      "current iter: 1721000/24576000\n",
      "current iter: 1722000/24576000\n",
      "current iter: 1723000/24576000\n",
      "current iter: 1724000/24576000\n",
      "current iter: 1725000/24576000\n",
      "current iter: 1726000/24576000\n",
      "current iter: 1727000/24576000\n",
      "current iter: 1728000/24576000\n",
      "current iter: 1729000/24576000\n",
      "current iter: 1730000/24576000\n",
      "current iter: 1731000/24576000\n",
      "current iter: 1732000/24576000\n",
      "current iter: 1733000/24576000\n",
      "current iter: 1734000/24576000\n",
      "current iter: 1735000/24576000\n",
      "current iter: 1736000/24576000\n",
      "current iter: 1737000/24576000\n",
      "current iter: 1738000/24576000\n",
      "current iter: 1739000/24576000\n",
      "current iter: 1740000/24576000\n",
      "current iter: 1741000/24576000\n",
      "current iter: 1742000/24576000\n",
      "current iter: 1743000/24576000\n",
      "current iter: 1744000/24576000\n",
      "current iter: 1745000/24576000\n",
      "current iter: 1746000/24576000\n",
      "current iter: 1747000/24576000\n",
      "current iter: 1748000/24576000\n",
      "current iter: 1749000/24576000\n",
      "current iter: 1750000/24576000\n",
      "current iter: 1751000/24576000\n",
      "current iter: 1752000/24576000\n",
      "current iter: 1753000/24576000\n",
      "current iter: 1754000/24576000\n",
      "current iter: 1755000/24576000\n",
      "current iter: 1756000/24576000\n",
      "current iter: 1757000/24576000\n",
      "current iter: 1758000/24576000\n",
      "current iter: 1759000/24576000\n",
      "current iter: 1760000/24576000\n",
      "current iter: 1761000/24576000\n",
      "current iter: 1762000/24576000\n",
      "current iter: 1763000/24576000\n",
      "current iter: 1764000/24576000\n",
      "current iter: 1765000/24576000\n",
      "current iter: 1766000/24576000\n",
      "current iter: 1767000/24576000\n",
      "current iter: 1768000/24576000\n",
      "current iter: 1769000/24576000\n",
      "current iter: 1770000/24576000\n",
      "current iter: 1771000/24576000\n",
      "current iter: 1772000/24576000\n",
      "current iter: 1773000/24576000\n",
      "current iter: 1774000/24576000\n",
      "current iter: 1775000/24576000\n",
      "current iter: 1776000/24576000\n",
      "current iter: 1777000/24576000\n",
      "current iter: 1778000/24576000\n",
      "current iter: 1779000/24576000\n",
      "current iter: 1780000/24576000\n",
      "current iter: 1781000/24576000\n",
      "current iter: 1782000/24576000\n",
      "current iter: 1783000/24576000\n",
      "current iter: 1784000/24576000\n",
      "current iter: 1785000/24576000\n",
      "current iter: 1786000/24576000\n",
      "current iter: 1787000/24576000\n",
      "current iter: 1788000/24576000\n",
      "current iter: 1789000/24576000\n",
      "current iter: 1790000/24576000\n",
      "current iter: 1791000/24576000\n",
      "current iter: 1792000/24576000\n",
      "current iter: 1793000/24576000\n",
      "current iter: 1794000/24576000\n",
      "current iter: 1795000/24576000\n",
      "current iter: 1796000/24576000\n",
      "current iter: 1797000/24576000\n",
      "current iter: 1798000/24576000\n",
      "current iter: 1799000/24576000\n",
      "current iter: 1800000/24576000\n",
      "current iter: 1801000/24576000\n",
      "current iter: 1802000/24576000\n",
      "current iter: 1803000/24576000\n",
      "current iter: 1804000/24576000\n",
      "current iter: 1805000/24576000\n",
      "current iter: 1806000/24576000\n",
      "current iter: 1807000/24576000\n",
      "current iter: 1808000/24576000\n",
      "current iter: 1809000/24576000\n",
      "current iter: 1810000/24576000\n",
      "current iter: 1811000/24576000\n",
      "current iter: 1812000/24576000\n",
      "current iter: 1813000/24576000\n",
      "current iter: 1814000/24576000\n",
      "current iter: 1815000/24576000\n",
      "current iter: 1816000/24576000\n",
      "current iter: 1817000/24576000\n",
      "current iter: 1818000/24576000\n",
      "current iter: 1819000/24576000\n",
      "current iter: 1820000/24576000\n",
      "current iter: 1821000/24576000\n",
      "current iter: 1822000/24576000\n",
      "current iter: 1823000/24576000\n",
      "current iter: 1824000/24576000\n",
      "current iter: 1825000/24576000\n",
      "current iter: 1826000/24576000\n",
      "current iter: 1827000/24576000\n",
      "current iter: 1828000/24576000\n",
      "current iter: 1829000/24576000\n",
      "current iter: 1830000/24576000\n",
      "current iter: 1831000/24576000\n",
      "current iter: 1832000/24576000\n",
      "current iter: 1833000/24576000\n",
      "current iter: 1834000/24576000\n",
      "current iter: 1835000/24576000\n",
      "current iter: 1836000/24576000\n",
      "current iter: 1837000/24576000\n",
      "current iter: 1838000/24576000\n",
      "current iter: 1839000/24576000\n",
      "current iter: 1840000/24576000\n",
      "current iter: 1841000/24576000\n",
      "current iter: 1842000/24576000\n",
      "current iter: 1843000/24576000\n",
      "current iter: 1844000/24576000\n",
      "current iter: 1845000/24576000\n",
      "current iter: 1846000/24576000\n",
      "current iter: 1847000/24576000\n",
      "current iter: 1848000/24576000\n",
      "current iter: 1849000/24576000\n",
      "current iter: 1850000/24576000\n",
      "current iter: 1851000/24576000\n",
      "current iter: 1852000/24576000\n",
      "current iter: 1853000/24576000\n",
      "current iter: 1854000/24576000\n",
      "current iter: 1855000/24576000\n",
      "current iter: 1856000/24576000\n",
      "current iter: 1857000/24576000\n",
      "current iter: 1858000/24576000\n",
      "current iter: 1859000/24576000\n",
      "current iter: 1860000/24576000\n",
      "current iter: 1861000/24576000\n",
      "current iter: 1862000/24576000\n",
      "current iter: 1863000/24576000\n",
      "current iter: 1864000/24576000\n",
      "current iter: 1865000/24576000\n",
      "current iter: 1866000/24576000\n",
      "current iter: 1867000/24576000\n",
      "current iter: 1868000/24576000\n",
      "current iter: 1869000/24576000\n",
      "current iter: 1870000/24576000\n",
      "current iter: 1871000/24576000\n",
      "current iter: 1872000/24576000\n",
      "current iter: 1873000/24576000\n",
      "current iter: 1874000/24576000\n",
      "current iter: 1875000/24576000\n",
      "current iter: 1876000/24576000\n",
      "current iter: 1877000/24576000\n",
      "current iter: 1878000/24576000\n",
      "current iter: 1879000/24576000\n",
      "current iter: 1880000/24576000\n",
      "current iter: 1881000/24576000\n",
      "current iter: 1882000/24576000\n",
      "current iter: 1883000/24576000\n",
      "current iter: 1884000/24576000\n",
      "current iter: 1885000/24576000\n",
      "current iter: 1886000/24576000\n",
      "current iter: 1887000/24576000\n",
      "current iter: 1888000/24576000\n",
      "current iter: 1889000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 1890000/24576000\n",
      "current iter: 1891000/24576000\n",
      "current iter: 1892000/24576000\n",
      "current iter: 1893000/24576000\n",
      "current iter: 1894000/24576000\n",
      "current iter: 1895000/24576000\n",
      "current iter: 1896000/24576000\n",
      "current iter: 1897000/24576000\n",
      "current iter: 1898000/24576000\n",
      "current iter: 1899000/24576000\n",
      "current iter: 1900000/24576000\n",
      "current iter: 1901000/24576000\n",
      "current iter: 1902000/24576000\n",
      "current iter: 1903000/24576000\n",
      "current iter: 1904000/24576000\n",
      "current iter: 1905000/24576000\n",
      "current iter: 1906000/24576000\n",
      "current iter: 1907000/24576000\n",
      "current iter: 1908000/24576000\n",
      "current iter: 1909000/24576000\n",
      "current iter: 1910000/24576000\n",
      "current iter: 1911000/24576000\n",
      "current iter: 1912000/24576000\n",
      "current iter: 1913000/24576000\n",
      "current iter: 1914000/24576000\n",
      "current iter: 1915000/24576000\n",
      "current iter: 1916000/24576000\n",
      "current iter: 1917000/24576000\n",
      "current iter: 1918000/24576000\n",
      "current iter: 1919000/24576000\n",
      "current iter: 1920000/24576000\n",
      "current iter: 1921000/24576000\n",
      "current iter: 1922000/24576000\n",
      "current iter: 1923000/24576000\n",
      "current iter: 1924000/24576000\n",
      "current iter: 1925000/24576000\n",
      "current iter: 1926000/24576000\n",
      "current iter: 1927000/24576000\n",
      "current iter: 1928000/24576000\n",
      "current iter: 1929000/24576000\n",
      "current iter: 1930000/24576000\n",
      "current iter: 1931000/24576000\n",
      "current iter: 1932000/24576000\n",
      "current iter: 1933000/24576000\n",
      "current iter: 1934000/24576000\n",
      "current iter: 1935000/24576000\n",
      "current iter: 1936000/24576000\n",
      "current iter: 1937000/24576000\n",
      "current iter: 1938000/24576000\n",
      "current iter: 1939000/24576000\n",
      "current iter: 1940000/24576000\n",
      "current iter: 1941000/24576000\n",
      "current iter: 1942000/24576000\n",
      "current iter: 1943000/24576000\n",
      "current iter: 1944000/24576000\n",
      "current iter: 1945000/24576000\n",
      "current iter: 1946000/24576000\n",
      "current iter: 1947000/24576000\n",
      "current iter: 1948000/24576000\n",
      "current iter: 1949000/24576000\n",
      "current iter: 1950000/24576000\n",
      "current iter: 1951000/24576000\n",
      "current iter: 1952000/24576000\n",
      "current iter: 1953000/24576000\n",
      "current iter: 1954000/24576000\n",
      "current iter: 1955000/24576000\n",
      "current iter: 1956000/24576000\n",
      "current iter: 1957000/24576000\n",
      "current iter: 1958000/24576000\n",
      "current iter: 1959000/24576000\n",
      "current iter: 1960000/24576000\n",
      "current iter: 1961000/24576000\n",
      "current iter: 1962000/24576000\n",
      "current iter: 1963000/24576000\n",
      "current iter: 1964000/24576000\n",
      "current iter: 1965000/24576000\n",
      "current iter: 1966000/24576000\n",
      "current iter: 1967000/24576000\n",
      "current iter: 1968000/24576000\n",
      "current iter: 1969000/24576000\n",
      "current iter: 1970000/24576000\n",
      "current iter: 1971000/24576000\n",
      "current iter: 1972000/24576000\n",
      "current iter: 1973000/24576000\n",
      "current iter: 1974000/24576000\n",
      "current iter: 1975000/24576000\n",
      "current iter: 1976000/24576000\n",
      "current iter: 1977000/24576000\n",
      "current iter: 1978000/24576000\n",
      "current iter: 1979000/24576000\n",
      "current iter: 1980000/24576000\n",
      "current iter: 1981000/24576000\n",
      "current iter: 1982000/24576000\n",
      "current iter: 1983000/24576000\n",
      "current iter: 1984000/24576000\n",
      "current iter: 1985000/24576000\n",
      "current iter: 1986000/24576000\n",
      "current iter: 1987000/24576000\n",
      "current iter: 1988000/24576000\n",
      "current iter: 1989000/24576000\n",
      "current iter: 1990000/24576000\n",
      "current iter: 1991000/24576000\n",
      "current iter: 1992000/24576000\n",
      "current iter: 1993000/24576000\n",
      "current iter: 1994000/24576000\n",
      "current iter: 1995000/24576000\n",
      "current iter: 1996000/24576000\n",
      "current iter: 1997000/24576000\n",
      "current iter: 1998000/24576000\n",
      "current iter: 1999000/24576000\n",
      "current iter: 2000000/24576000\n",
      "current iter: 2001000/24576000\n",
      "current iter: 2002000/24576000\n",
      "current iter: 2003000/24576000\n",
      "current iter: 2004000/24576000\n",
      "current iter: 2005000/24576000\n",
      "current iter: 2006000/24576000\n",
      "current iter: 2007000/24576000\n",
      "current iter: 2008000/24576000\n",
      "current iter: 2009000/24576000\n",
      "current iter: 2010000/24576000\n",
      "current iter: 2011000/24576000\n",
      "current iter: 2012000/24576000\n",
      "current iter: 2013000/24576000\n",
      "current iter: 2014000/24576000\n",
      "current iter: 2015000/24576000\n",
      "current iter: 2016000/24576000\n",
      "current iter: 2017000/24576000\n",
      "current iter: 2018000/24576000\n",
      "current iter: 2019000/24576000\n",
      "current iter: 2020000/24576000\n",
      "current iter: 2021000/24576000\n",
      "current iter: 2022000/24576000\n",
      "current iter: 2023000/24576000\n",
      "current iter: 2024000/24576000\n",
      "current iter: 2025000/24576000\n",
      "current iter: 2026000/24576000\n",
      "current iter: 2027000/24576000\n",
      "current iter: 2028000/24576000\n",
      "current iter: 2029000/24576000\n",
      "current iter: 2030000/24576000\n",
      "current iter: 2031000/24576000\n",
      "current iter: 2032000/24576000\n",
      "current iter: 2033000/24576000\n",
      "current iter: 2034000/24576000\n",
      "current iter: 2035000/24576000\n",
      "current iter: 2036000/24576000\n",
      "current iter: 2037000/24576000\n",
      "current iter: 2038000/24576000\n",
      "current iter: 2039000/24576000\n",
      "current iter: 2040000/24576000\n",
      "current iter: 2041000/24576000\n",
      "current iter: 2042000/24576000\n",
      "current iter: 2043000/24576000\n",
      "current iter: 2044000/24576000\n",
      "current iter: 2045000/24576000\n",
      "current iter: 2046000/24576000\n",
      "current iter: 2047000/24576000\n",
      "current iter: 2048000/24576000\n",
      "current iter: 2049000/24576000\n",
      "current iter: 2050000/24576000\n",
      "current iter: 2051000/24576000\n",
      "current iter: 2052000/24576000\n",
      "current iter: 2053000/24576000\n",
      "current iter: 2054000/24576000\n",
      "current iter: 2055000/24576000\n",
      "current iter: 2056000/24576000\n",
      "current iter: 2057000/24576000\n",
      "current iter: 2058000/24576000\n",
      "current iter: 2059000/24576000\n",
      "current iter: 2060000/24576000\n",
      "current iter: 2061000/24576000\n",
      "current iter: 2062000/24576000\n",
      "current iter: 2063000/24576000\n",
      "current iter: 2064000/24576000\n",
      "current iter: 2065000/24576000\n",
      "current iter: 2066000/24576000\n",
      "current iter: 2067000/24576000\n",
      "current iter: 2068000/24576000\n",
      "current iter: 2069000/24576000\n",
      "current iter: 2070000/24576000\n",
      "current iter: 2071000/24576000\n",
      "current iter: 2072000/24576000\n",
      "current iter: 2073000/24576000\n",
      "current iter: 2074000/24576000\n",
      "current iter: 2075000/24576000\n",
      "current iter: 2076000/24576000\n",
      "current iter: 2077000/24576000\n",
      "current iter: 2078000/24576000\n",
      "current iter: 2079000/24576000\n",
      "current iter: 2080000/24576000\n",
      "current iter: 2081000/24576000\n",
      "current iter: 2082000/24576000\n",
      "current iter: 2083000/24576000\n",
      "current iter: 2084000/24576000\n",
      "current iter: 2085000/24576000\n",
      "current iter: 2086000/24576000\n",
      "current iter: 2087000/24576000\n",
      "current iter: 2088000/24576000\n",
      "current iter: 2089000/24576000\n",
      "current iter: 2090000/24576000\n",
      "current iter: 2091000/24576000\n",
      "current iter: 2092000/24576000\n",
      "current iter: 2093000/24576000\n",
      "current iter: 2094000/24576000\n",
      "current iter: 2095000/24576000\n",
      "current iter: 2096000/24576000\n",
      "current iter: 2097000/24576000\n",
      "current iter: 2098000/24576000\n",
      "current iter: 2099000/24576000\n",
      "current iter: 2100000/24576000\n",
      "current iter: 2101000/24576000\n",
      "current iter: 2102000/24576000\n",
      "current iter: 2103000/24576000\n",
      "current iter: 2104000/24576000\n",
      "current iter: 2105000/24576000\n",
      "current iter: 2106000/24576000\n",
      "current iter: 2107000/24576000\n",
      "current iter: 2108000/24576000\n",
      "current iter: 2109000/24576000\n",
      "current iter: 2110000/24576000\n",
      "current iter: 2111000/24576000\n",
      "current iter: 2112000/24576000\n",
      "current iter: 2113000/24576000\n",
      "current iter: 2114000/24576000\n",
      "current iter: 2115000/24576000\n",
      "current iter: 2116000/24576000\n",
      "current iter: 2117000/24576000\n",
      "current iter: 2118000/24576000\n",
      "current iter: 2119000/24576000\n",
      "current iter: 2120000/24576000\n",
      "current iter: 2121000/24576000\n",
      "current iter: 2122000/24576000\n",
      "current iter: 2123000/24576000\n",
      "current iter: 2124000/24576000\n",
      "current iter: 2125000/24576000\n",
      "current iter: 2126000/24576000\n",
      "current iter: 2127000/24576000\n",
      "current iter: 2128000/24576000\n",
      "current iter: 2129000/24576000\n",
      "current iter: 2130000/24576000\n",
      "current iter: 2131000/24576000\n",
      "current iter: 2132000/24576000\n",
      "current iter: 2133000/24576000\n",
      "current iter: 2134000/24576000\n",
      "current iter: 2135000/24576000\n",
      "current iter: 2136000/24576000\n",
      "current iter: 2137000/24576000\n",
      "current iter: 2138000/24576000\n",
      "current iter: 2139000/24576000\n",
      "current iter: 2140000/24576000\n",
      "current iter: 2141000/24576000\n",
      "current iter: 2142000/24576000\n",
      "current iter: 2143000/24576000\n",
      "current iter: 2144000/24576000\n",
      "current iter: 2145000/24576000\n",
      "current iter: 2146000/24576000\n",
      "current iter: 2147000/24576000\n",
      "current iter: 2148000/24576000\n",
      "current iter: 2149000/24576000\n",
      "current iter: 2150000/24576000\n",
      "current iter: 2151000/24576000\n",
      "current iter: 2152000/24576000\n",
      "current iter: 2153000/24576000\n",
      "current iter: 2154000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 2155000/24576000\n",
      "current iter: 2156000/24576000\n",
      "current iter: 2157000/24576000\n",
      "current iter: 2158000/24576000\n",
      "current iter: 2159000/24576000\n",
      "current iter: 2160000/24576000\n",
      "current iter: 2161000/24576000\n",
      "current iter: 2162000/24576000\n",
      "current iter: 2163000/24576000\n",
      "current iter: 2164000/24576000\n",
      "current iter: 2165000/24576000\n",
      "current iter: 2166000/24576000\n",
      "current iter: 2167000/24576000\n",
      "current iter: 2168000/24576000\n",
      "current iter: 2169000/24576000\n",
      "current iter: 2170000/24576000\n",
      "current iter: 2171000/24576000\n",
      "current iter: 2172000/24576000\n",
      "current iter: 2173000/24576000\n",
      "current iter: 2174000/24576000\n",
      "current iter: 2175000/24576000\n",
      "current iter: 2176000/24576000\n",
      "current iter: 2177000/24576000\n",
      "current iter: 2178000/24576000\n",
      "current iter: 2179000/24576000\n",
      "current iter: 2180000/24576000\n",
      "current iter: 2181000/24576000\n",
      "current iter: 2182000/24576000\n",
      "current iter: 2183000/24576000\n",
      "current iter: 2184000/24576000\n",
      "current iter: 2185000/24576000\n",
      "current iter: 2186000/24576000\n",
      "current iter: 2187000/24576000\n",
      "current iter: 2188000/24576000\n",
      "current iter: 2189000/24576000\n",
      "current iter: 2190000/24576000\n",
      "current iter: 2191000/24576000\n",
      "current iter: 2192000/24576000\n",
      "current iter: 2193000/24576000\n",
      "current iter: 2194000/24576000\n",
      "current iter: 2195000/24576000\n",
      "current iter: 2196000/24576000\n",
      "current iter: 2197000/24576000\n",
      "current iter: 2198000/24576000\n",
      "current iter: 2199000/24576000\n",
      "current iter: 2200000/24576000\n",
      "current iter: 2201000/24576000\n",
      "current iter: 2202000/24576000\n",
      "current iter: 2203000/24576000\n",
      "current iter: 2204000/24576000\n",
      "current iter: 2205000/24576000\n",
      "current iter: 2206000/24576000\n",
      "current iter: 2207000/24576000\n",
      "current iter: 2208000/24576000\n",
      "current iter: 2209000/24576000\n",
      "current iter: 2210000/24576000\n",
      "current iter: 2211000/24576000\n",
      "current iter: 2212000/24576000\n",
      "current iter: 2213000/24576000\n",
      "current iter: 2214000/24576000\n",
      "current iter: 2215000/24576000\n",
      "current iter: 2216000/24576000\n",
      "current iter: 2217000/24576000\n",
      "current iter: 2218000/24576000\n",
      "current iter: 2219000/24576000\n",
      "current iter: 2220000/24576000\n",
      "current iter: 2221000/24576000\n",
      "current iter: 2222000/24576000\n",
      "current iter: 2223000/24576000\n",
      "current iter: 2224000/24576000\n",
      "current iter: 2225000/24576000\n",
      "current iter: 2226000/24576000\n",
      "current iter: 2227000/24576000\n",
      "current iter: 2228000/24576000\n",
      "current iter: 2229000/24576000\n",
      "current iter: 2230000/24576000\n",
      "current iter: 2231000/24576000\n",
      "current iter: 2232000/24576000\n",
      "current iter: 2233000/24576000\n",
      "current iter: 2234000/24576000\n",
      "current iter: 2235000/24576000\n",
      "current iter: 2236000/24576000\n",
      "current iter: 2237000/24576000\n",
      "current iter: 2238000/24576000\n",
      "current iter: 2239000/24576000\n",
      "current iter: 2240000/24576000\n",
      "current iter: 2241000/24576000\n",
      "current iter: 2242000/24576000\n",
      "current iter: 2243000/24576000\n",
      "current iter: 2244000/24576000\n",
      "current iter: 2245000/24576000\n",
      "current iter: 2246000/24576000\n",
      "current iter: 2247000/24576000\n",
      "current iter: 2248000/24576000\n",
      "current iter: 2249000/24576000\n",
      "current iter: 2250000/24576000\n",
      "current iter: 2251000/24576000\n",
      "current iter: 2252000/24576000\n",
      "current iter: 2253000/24576000\n",
      "current iter: 2254000/24576000\n",
      "current iter: 2255000/24576000\n",
      "current iter: 2256000/24576000\n",
      "current iter: 2257000/24576000\n",
      "current iter: 2258000/24576000\n",
      "current iter: 2259000/24576000\n",
      "current iter: 2260000/24576000\n",
      "current iter: 2261000/24576000\n",
      "current iter: 2262000/24576000\n",
      "current iter: 2263000/24576000\n",
      "current iter: 2264000/24576000\n",
      "current iter: 2265000/24576000\n",
      "current iter: 2266000/24576000\n",
      "current iter: 2267000/24576000\n",
      "current iter: 2268000/24576000\n",
      "current iter: 2269000/24576000\n",
      "current iter: 2270000/24576000\n",
      "current iter: 2271000/24576000\n",
      "current iter: 2272000/24576000\n",
      "current iter: 2273000/24576000\n",
      "current iter: 2274000/24576000\n",
      "current iter: 2275000/24576000\n",
      "current iter: 2276000/24576000\n",
      "current iter: 2277000/24576000\n",
      "current iter: 2278000/24576000\n",
      "current iter: 2279000/24576000\n",
      "current iter: 2280000/24576000\n",
      "current iter: 2281000/24576000\n",
      "current iter: 2282000/24576000\n",
      "current iter: 2283000/24576000\n",
      "current iter: 2284000/24576000\n",
      "current iter: 2285000/24576000\n",
      "current iter: 2286000/24576000\n",
      "current iter: 2287000/24576000\n",
      "current iter: 2288000/24576000\n",
      "current iter: 2289000/24576000\n",
      "current iter: 2290000/24576000\n",
      "current iter: 2291000/24576000\n",
      "current iter: 2292000/24576000\n",
      "current iter: 2293000/24576000\n",
      "current iter: 2294000/24576000\n",
      "current iter: 2295000/24576000\n",
      "current iter: 2296000/24576000\n",
      "current iter: 2297000/24576000\n",
      "current iter: 2298000/24576000\n",
      "current iter: 2299000/24576000\n",
      "current iter: 2300000/24576000\n",
      "current iter: 2301000/24576000\n",
      "current iter: 2302000/24576000\n",
      "current iter: 2303000/24576000\n",
      "current iter: 2304000/24576000\n",
      "current iter: 2305000/24576000\n",
      "current iter: 2306000/24576000\n",
      "current iter: 2307000/24576000\n",
      "current iter: 2308000/24576000\n",
      "current iter: 2309000/24576000\n",
      "current iter: 2310000/24576000\n",
      "current iter: 2311000/24576000\n",
      "current iter: 2312000/24576000\n",
      "current iter: 2313000/24576000\n",
      "current iter: 2314000/24576000\n",
      "current iter: 2315000/24576000\n",
      "current iter: 2316000/24576000\n",
      "current iter: 2317000/24576000\n",
      "current iter: 2318000/24576000\n",
      "current iter: 2319000/24576000\n",
      "current iter: 2320000/24576000\n",
      "current iter: 2321000/24576000\n",
      "current iter: 2322000/24576000\n",
      "current iter: 2323000/24576000\n",
      "current iter: 2324000/24576000\n",
      "current iter: 2325000/24576000\n",
      "current iter: 2326000/24576000\n",
      "current iter: 2327000/24576000\n",
      "current iter: 2328000/24576000\n",
      "current iter: 2329000/24576000\n",
      "current iter: 2330000/24576000\n",
      "current iter: 2331000/24576000\n",
      "current iter: 2332000/24576000\n",
      "current iter: 2333000/24576000\n",
      "current iter: 2334000/24576000\n",
      "current iter: 2335000/24576000\n",
      "current iter: 2336000/24576000\n",
      "current iter: 2337000/24576000\n",
      "current iter: 2338000/24576000\n",
      "current iter: 2339000/24576000\n",
      "current iter: 2340000/24576000\n",
      "current iter: 2341000/24576000\n",
      "current iter: 2342000/24576000\n",
      "current iter: 2343000/24576000\n",
      "current iter: 2344000/24576000\n",
      "current iter: 2345000/24576000\n",
      "current iter: 2346000/24576000\n",
      "current iter: 2347000/24576000\n",
      "current iter: 2348000/24576000\n",
      "current iter: 2349000/24576000\n",
      "current iter: 2350000/24576000\n",
      "current iter: 2351000/24576000\n",
      "current iter: 2352000/24576000\n",
      "current iter: 2353000/24576000\n",
      "current iter: 2354000/24576000\n",
      "current iter: 2355000/24576000\n",
      "current iter: 2356000/24576000\n",
      "current iter: 2357000/24576000\n",
      "current iter: 2358000/24576000\n",
      "current iter: 2359000/24576000\n",
      "current iter: 2360000/24576000\n",
      "current iter: 2361000/24576000\n",
      "current iter: 2362000/24576000\n",
      "current iter: 2363000/24576000\n",
      "current iter: 2364000/24576000\n",
      "current iter: 2365000/24576000\n",
      "current iter: 2366000/24576000\n",
      "current iter: 2367000/24576000\n",
      "current iter: 2368000/24576000\n",
      "current iter: 2369000/24576000\n",
      "current iter: 2370000/24576000\n",
      "current iter: 2371000/24576000\n",
      "current iter: 2372000/24576000\n",
      "current iter: 2373000/24576000\n",
      "current iter: 2374000/24576000\n",
      "current iter: 2375000/24576000\n",
      "current iter: 2376000/24576000\n",
      "current iter: 2377000/24576000\n",
      "current iter: 2378000/24576000\n",
      "current iter: 2379000/24576000\n",
      "current iter: 2380000/24576000\n",
      "current iter: 2381000/24576000\n",
      "current iter: 2382000/24576000\n",
      "current iter: 2383000/24576000\n",
      "current iter: 2384000/24576000\n",
      "current iter: 2385000/24576000\n",
      "current iter: 2386000/24576000\n",
      "current iter: 2387000/24576000\n",
      "current iter: 2388000/24576000\n",
      "current iter: 2389000/24576000\n",
      "current iter: 2390000/24576000\n",
      "current iter: 2391000/24576000\n",
      "current iter: 2392000/24576000\n",
      "current iter: 2393000/24576000\n",
      "current iter: 2394000/24576000\n",
      "current iter: 2395000/24576000\n",
      "current iter: 2396000/24576000\n",
      "current iter: 2397000/24576000\n",
      "current iter: 2398000/24576000\n",
      "current iter: 2399000/24576000\n",
      "current iter: 2400000/24576000\n",
      "current iter: 2401000/24576000\n",
      "current iter: 2402000/24576000\n",
      "current iter: 2403000/24576000\n",
      "current iter: 2404000/24576000\n",
      "current iter: 2405000/24576000\n",
      "current iter: 2406000/24576000\n",
      "current iter: 2407000/24576000\n",
      "current iter: 2408000/24576000\n",
      "current iter: 2409000/24576000\n",
      "current iter: 2410000/24576000\n",
      "current iter: 2411000/24576000\n",
      "current iter: 2412000/24576000\n",
      "current iter: 2413000/24576000\n",
      "current iter: 2414000/24576000\n",
      "current iter: 2415000/24576000\n",
      "current iter: 2416000/24576000\n",
      "current iter: 2417000/24576000\n",
      "current iter: 2418000/24576000\n",
      "current iter: 2419000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 2420000/24576000\n",
      "current iter: 2421000/24576000\n",
      "current iter: 2422000/24576000\n",
      "current iter: 2423000/24576000\n",
      "current iter: 2424000/24576000\n",
      "current iter: 2425000/24576000\n",
      "current iter: 2426000/24576000\n",
      "current iter: 2427000/24576000\n",
      "current iter: 2428000/24576000\n",
      "current iter: 2429000/24576000\n",
      "current iter: 2430000/24576000\n",
      "current iter: 2431000/24576000\n",
      "current iter: 2432000/24576000\n",
      "current iter: 2433000/24576000\n",
      "current iter: 2434000/24576000\n",
      "current iter: 2435000/24576000\n",
      "current iter: 2436000/24576000\n",
      "current iter: 2437000/24576000\n",
      "current iter: 2438000/24576000\n",
      "current iter: 2439000/24576000\n",
      "current iter: 2440000/24576000\n",
      "current iter: 2441000/24576000\n",
      "current iter: 2442000/24576000\n",
      "current iter: 2443000/24576000\n",
      "current iter: 2444000/24576000\n",
      "current iter: 2445000/24576000\n",
      "current iter: 2446000/24576000\n",
      "current iter: 2447000/24576000\n",
      "current iter: 2448000/24576000\n",
      "current iter: 2449000/24576000\n",
      "current iter: 2450000/24576000\n",
      "current iter: 2451000/24576000\n",
      "current iter: 2452000/24576000\n",
      "current iter: 2453000/24576000\n",
      "current iter: 2454000/24576000\n",
      "current iter: 2455000/24576000\n",
      "current iter: 2456000/24576000\n",
      "current iter: 2457000/24576000\n",
      "current iter: 2458000/24576000\n",
      "current iter: 2459000/24576000\n",
      "current iter: 2460000/24576000\n",
      "current iter: 2461000/24576000\n",
      "current iter: 2462000/24576000\n",
      "current iter: 2463000/24576000\n",
      "current iter: 2464000/24576000\n",
      "current iter: 2465000/24576000\n",
      "current iter: 2466000/24576000\n",
      "current iter: 2467000/24576000\n",
      "current iter: 2468000/24576000\n",
      "current iter: 2469000/24576000\n",
      "current iter: 2470000/24576000\n",
      "current iter: 2471000/24576000\n",
      "current iter: 2472000/24576000\n",
      "current iter: 2473000/24576000\n",
      "current iter: 2474000/24576000\n",
      "current iter: 2475000/24576000\n",
      "current iter: 2476000/24576000\n",
      "current iter: 2477000/24576000\n",
      "current iter: 2478000/24576000\n",
      "current iter: 2479000/24576000\n",
      "current iter: 2480000/24576000\n",
      "current iter: 2481000/24576000\n",
      "current iter: 2482000/24576000\n",
      "current iter: 2483000/24576000\n",
      "current iter: 2484000/24576000\n",
      "current iter: 2485000/24576000\n",
      "current iter: 2486000/24576000\n",
      "current iter: 2487000/24576000\n",
      "current iter: 2488000/24576000\n",
      "current iter: 2489000/24576000\n",
      "current iter: 2490000/24576000\n",
      "current iter: 2491000/24576000\n",
      "current iter: 2492000/24576000\n",
      "current iter: 2493000/24576000\n",
      "current iter: 2494000/24576000\n",
      "current iter: 2495000/24576000\n",
      "current iter: 2496000/24576000\n",
      "current iter: 2497000/24576000\n",
      "current iter: 2498000/24576000\n",
      "current iter: 2499000/24576000\n",
      "current iter: 2500000/24576000\n",
      "current iter: 2501000/24576000\n",
      "current iter: 2502000/24576000\n",
      "current iter: 2503000/24576000\n",
      "current iter: 2504000/24576000\n",
      "current iter: 2505000/24576000\n",
      "current iter: 2506000/24576000\n",
      "current iter: 2507000/24576000\n",
      "current iter: 2508000/24576000\n",
      "current iter: 2509000/24576000\n",
      "current iter: 2510000/24576000\n",
      "current iter: 2511000/24576000\n",
      "current iter: 2512000/24576000\n",
      "current iter: 2513000/24576000\n",
      "current iter: 2514000/24576000\n",
      "current iter: 2515000/24576000\n",
      "current iter: 2516000/24576000\n",
      "current iter: 2517000/24576000\n",
      "current iter: 2518000/24576000\n",
      "current iter: 2519000/24576000\n",
      "current iter: 2520000/24576000\n",
      "current iter: 2521000/24576000\n",
      "current iter: 2522000/24576000\n",
      "current iter: 2523000/24576000\n",
      "current iter: 2524000/24576000\n",
      "current iter: 2525000/24576000\n",
      "current iter: 2526000/24576000\n",
      "current iter: 2527000/24576000\n",
      "current iter: 2528000/24576000\n",
      "current iter: 2529000/24576000\n",
      "current iter: 2530000/24576000\n",
      "current iter: 2531000/24576000\n",
      "current iter: 2532000/24576000\n",
      "current iter: 2533000/24576000\n",
      "current iter: 2534000/24576000\n",
      "current iter: 2535000/24576000\n",
      "current iter: 2536000/24576000\n",
      "current iter: 2537000/24576000\n",
      "current iter: 2538000/24576000\n",
      "current iter: 2539000/24576000\n",
      "current iter: 2540000/24576000\n",
      "current iter: 2541000/24576000\n",
      "current iter: 2542000/24576000\n",
      "current iter: 2543000/24576000\n",
      "current iter: 2544000/24576000\n",
      "current iter: 2545000/24576000\n",
      "current iter: 2546000/24576000\n",
      "current iter: 2547000/24576000\n",
      "current iter: 2548000/24576000\n",
      "current iter: 2549000/24576000\n",
      "current iter: 2550000/24576000\n",
      "current iter: 2551000/24576000\n",
      "current iter: 2552000/24576000\n",
      "current iter: 2553000/24576000\n",
      "current iter: 2554000/24576000\n",
      "current iter: 2555000/24576000\n",
      "current iter: 2556000/24576000\n",
      "current iter: 2557000/24576000\n",
      "current iter: 2558000/24576000\n",
      "current iter: 2559000/24576000\n",
      "current iter: 2560000/24576000\n",
      "current iter: 2561000/24576000\n",
      "current iter: 2562000/24576000\n",
      "current iter: 2563000/24576000\n",
      "current iter: 2564000/24576000\n",
      "current iter: 2565000/24576000\n",
      "current iter: 2566000/24576000\n",
      "current iter: 2567000/24576000\n",
      "current iter: 2568000/24576000\n",
      "current iter: 2569000/24576000\n",
      "current iter: 2570000/24576000\n",
      "current iter: 2571000/24576000\n",
      "current iter: 2572000/24576000\n",
      "current iter: 2573000/24576000\n",
      "current iter: 2574000/24576000\n",
      "current iter: 2575000/24576000\n",
      "current iter: 2576000/24576000\n",
      "current iter: 2577000/24576000\n",
      "current iter: 2578000/24576000\n",
      "current iter: 2579000/24576000\n",
      "current iter: 2580000/24576000\n",
      "current iter: 2581000/24576000\n",
      "current iter: 2582000/24576000\n",
      "current iter: 2583000/24576000\n",
      "current iter: 2584000/24576000\n",
      "current iter: 2585000/24576000\n",
      "current iter: 2586000/24576000\n",
      "current iter: 2587000/24576000\n",
      "current iter: 2588000/24576000\n",
      "current iter: 2589000/24576000\n",
      "current iter: 2590000/24576000\n",
      "current iter: 2591000/24576000\n",
      "current iter: 2592000/24576000\n",
      "current iter: 2593000/24576000\n",
      "current iter: 2594000/24576000\n",
      "current iter: 2595000/24576000\n",
      "current iter: 2596000/24576000\n",
      "current iter: 2597000/24576000\n",
      "current iter: 2598000/24576000\n",
      "current iter: 2599000/24576000\n",
      "current iter: 2600000/24576000\n",
      "current iter: 2601000/24576000\n",
      "current iter: 2602000/24576000\n",
      "current iter: 2603000/24576000\n",
      "current iter: 2604000/24576000\n",
      "current iter: 2605000/24576000\n",
      "current iter: 2606000/24576000\n",
      "current iter: 2607000/24576000\n",
      "current iter: 2608000/24576000\n",
      "current iter: 2609000/24576000\n",
      "current iter: 2610000/24576000\n",
      "current iter: 2611000/24576000\n",
      "current iter: 2612000/24576000\n",
      "current iter: 2613000/24576000\n",
      "current iter: 2614000/24576000\n",
      "current iter: 2615000/24576000\n",
      "current iter: 2616000/24576000\n",
      "current iter: 2617000/24576000\n",
      "current iter: 2618000/24576000\n",
      "current iter: 2619000/24576000\n",
      "current iter: 2620000/24576000\n",
      "current iter: 2621000/24576000\n",
      "current iter: 2622000/24576000\n",
      "current iter: 2623000/24576000\n",
      "current iter: 2624000/24576000\n",
      "current iter: 2625000/24576000\n",
      "current iter: 2626000/24576000\n",
      "current iter: 2627000/24576000\n",
      "current iter: 2628000/24576000\n",
      "current iter: 2629000/24576000\n",
      "current iter: 2630000/24576000\n",
      "current iter: 2631000/24576000\n",
      "current iter: 2632000/24576000\n",
      "current iter: 2633000/24576000\n",
      "current iter: 2634000/24576000\n",
      "current iter: 2635000/24576000\n",
      "current iter: 2636000/24576000\n",
      "current iter: 2637000/24576000\n",
      "current iter: 2638000/24576000\n",
      "current iter: 2639000/24576000\n",
      "current iter: 2640000/24576000\n",
      "current iter: 2641000/24576000\n",
      "current iter: 2642000/24576000\n",
      "current iter: 2643000/24576000\n",
      "current iter: 2644000/24576000\n",
      "current iter: 2645000/24576000\n",
      "current iter: 2646000/24576000\n",
      "current iter: 2647000/24576000\n",
      "current iter: 2648000/24576000\n",
      "current iter: 2649000/24576000\n",
      "current iter: 2650000/24576000\n",
      "current iter: 2651000/24576000\n",
      "current iter: 2652000/24576000\n",
      "current iter: 2653000/24576000\n",
      "current iter: 2654000/24576000\n",
      "current iter: 2655000/24576000\n",
      "current iter: 2656000/24576000\n",
      "current iter: 2657000/24576000\n",
      "current iter: 2658000/24576000\n",
      "current iter: 2659000/24576000\n",
      "current iter: 2660000/24576000\n",
      "current iter: 2661000/24576000\n",
      "current iter: 2662000/24576000\n",
      "current iter: 2663000/24576000\n",
      "current iter: 2664000/24576000\n",
      "current iter: 2665000/24576000\n",
      "current iter: 2666000/24576000\n",
      "current iter: 2667000/24576000\n",
      "current iter: 2668000/24576000\n",
      "current iter: 2669000/24576000\n",
      "current iter: 2670000/24576000\n",
      "current iter: 2671000/24576000\n",
      "current iter: 2672000/24576000\n",
      "current iter: 2673000/24576000\n",
      "current iter: 2674000/24576000\n",
      "current iter: 2675000/24576000\n",
      "current iter: 2676000/24576000\n",
      "current iter: 2677000/24576000\n",
      "current iter: 2678000/24576000\n",
      "current iter: 2679000/24576000\n",
      "current iter: 2680000/24576000\n",
      "current iter: 2681000/24576000\n",
      "current iter: 2682000/24576000\n",
      "current iter: 2683000/24576000\n",
      "current iter: 2684000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 2685000/24576000\n",
      "current iter: 2686000/24576000\n",
      "current iter: 2687000/24576000\n",
      "current iter: 2688000/24576000\n",
      "current iter: 2689000/24576000\n",
      "current iter: 2690000/24576000\n",
      "current iter: 2691000/24576000\n",
      "current iter: 2692000/24576000\n",
      "current iter: 2693000/24576000\n",
      "current iter: 2694000/24576000\n",
      "current iter: 2695000/24576000\n",
      "current iter: 2696000/24576000\n",
      "current iter: 2697000/24576000\n",
      "current iter: 2698000/24576000\n",
      "current iter: 2699000/24576000\n",
      "current iter: 2700000/24576000\n",
      "current iter: 2701000/24576000\n",
      "current iter: 2702000/24576000\n",
      "current iter: 2703000/24576000\n",
      "current iter: 2704000/24576000\n",
      "current iter: 2705000/24576000\n",
      "current iter: 2706000/24576000\n",
      "current iter: 2707000/24576000\n",
      "current iter: 2708000/24576000\n",
      "current iter: 2709000/24576000\n",
      "current iter: 2710000/24576000\n",
      "current iter: 2711000/24576000\n",
      "current iter: 2712000/24576000\n",
      "current iter: 2713000/24576000\n",
      "current iter: 2714000/24576000\n",
      "current iter: 2715000/24576000\n",
      "current iter: 2716000/24576000\n",
      "current iter: 2717000/24576000\n",
      "current iter: 2718000/24576000\n",
      "current iter: 2719000/24576000\n",
      "current iter: 2720000/24576000\n",
      "current iter: 2721000/24576000\n",
      "current iter: 2722000/24576000\n",
      "current iter: 2723000/24576000\n",
      "current iter: 2724000/24576000\n",
      "current iter: 2725000/24576000\n",
      "current iter: 2726000/24576000\n",
      "current iter: 2727000/24576000\n",
      "current iter: 2728000/24576000\n",
      "current iter: 2729000/24576000\n",
      "current iter: 2730000/24576000\n",
      "current iter: 2731000/24576000\n",
      "current iter: 2732000/24576000\n",
      "current iter: 2733000/24576000\n",
      "current iter: 2734000/24576000\n",
      "current iter: 2735000/24576000\n",
      "current iter: 2736000/24576000\n",
      "current iter: 2737000/24576000\n",
      "current iter: 2738000/24576000\n",
      "current iter: 2739000/24576000\n",
      "current iter: 2740000/24576000\n",
      "current iter: 2741000/24576000\n",
      "current iter: 2742000/24576000\n",
      "current iter: 2743000/24576000\n",
      "current iter: 2744000/24576000\n",
      "current iter: 2745000/24576000\n",
      "current iter: 2746000/24576000\n",
      "current iter: 2747000/24576000\n",
      "current iter: 2748000/24576000\n",
      "current iter: 2749000/24576000\n",
      "current iter: 2750000/24576000\n",
      "current iter: 2751000/24576000\n",
      "current iter: 2752000/24576000\n",
      "current iter: 2753000/24576000\n",
      "current iter: 2754000/24576000\n",
      "current iter: 2755000/24576000\n",
      "current iter: 2756000/24576000\n",
      "current iter: 2757000/24576000\n",
      "current iter: 2758000/24576000\n",
      "current iter: 2759000/24576000\n",
      "current iter: 2760000/24576000\n",
      "current iter: 2761000/24576000\n",
      "current iter: 2762000/24576000\n",
      "current iter: 2763000/24576000\n",
      "current iter: 2764000/24576000\n",
      "current iter: 2765000/24576000\n",
      "current iter: 2766000/24576000\n",
      "current iter: 2767000/24576000\n",
      "current iter: 2768000/24576000\n",
      "current iter: 2769000/24576000\n",
      "current iter: 2770000/24576000\n",
      "current iter: 2771000/24576000\n",
      "current iter: 2772000/24576000\n",
      "current iter: 2773000/24576000\n",
      "current iter: 2774000/24576000\n",
      "current iter: 2775000/24576000\n",
      "current iter: 2776000/24576000\n",
      "current iter: 2777000/24576000\n",
      "current iter: 2778000/24576000\n",
      "current iter: 2779000/24576000\n",
      "current iter: 2780000/24576000\n",
      "current iter: 2781000/24576000\n",
      "current iter: 2782000/24576000\n",
      "current iter: 2783000/24576000\n",
      "current iter: 2784000/24576000\n",
      "current iter: 2785000/24576000\n",
      "current iter: 2786000/24576000\n",
      "current iter: 2787000/24576000\n",
      "current iter: 2788000/24576000\n",
      "current iter: 2789000/24576000\n",
      "current iter: 2790000/24576000\n",
      "current iter: 2791000/24576000\n",
      "current iter: 2792000/24576000\n",
      "current iter: 2793000/24576000\n",
      "current iter: 2794000/24576000\n",
      "current iter: 2795000/24576000\n",
      "current iter: 2796000/24576000\n",
      "current iter: 2797000/24576000\n",
      "current iter: 2798000/24576000\n",
      "current iter: 2799000/24576000\n",
      "current iter: 2800000/24576000\n",
      "current iter: 2801000/24576000\n",
      "current iter: 2802000/24576000\n",
      "current iter: 2803000/24576000\n",
      "current iter: 2804000/24576000\n",
      "current iter: 2805000/24576000\n",
      "current iter: 2806000/24576000\n",
      "current iter: 2807000/24576000\n",
      "current iter: 2808000/24576000\n",
      "current iter: 2809000/24576000\n",
      "current iter: 2810000/24576000\n",
      "current iter: 2811000/24576000\n",
      "current iter: 2812000/24576000\n",
      "current iter: 2813000/24576000\n",
      "current iter: 2814000/24576000\n",
      "current iter: 2815000/24576000\n",
      "current iter: 2816000/24576000\n",
      "current iter: 2817000/24576000\n",
      "current iter: 2818000/24576000\n",
      "current iter: 2819000/24576000\n",
      "current iter: 2820000/24576000\n",
      "current iter: 2821000/24576000\n",
      "current iter: 2822000/24576000\n",
      "current iter: 2823000/24576000\n",
      "current iter: 2824000/24576000\n",
      "current iter: 2825000/24576000\n",
      "current iter: 2826000/24576000\n",
      "current iter: 2827000/24576000\n",
      "current iter: 2828000/24576000\n",
      "current iter: 2829000/24576000\n",
      "current iter: 2830000/24576000\n",
      "current iter: 2831000/24576000\n",
      "current iter: 2832000/24576000\n",
      "current iter: 2833000/24576000\n",
      "current iter: 2834000/24576000\n",
      "current iter: 2835000/24576000\n",
      "current iter: 2836000/24576000\n",
      "current iter: 2837000/24576000\n",
      "current iter: 2838000/24576000\n",
      "current iter: 2839000/24576000\n",
      "current iter: 2840000/24576000\n",
      "current iter: 2841000/24576000\n",
      "current iter: 2842000/24576000\n",
      "current iter: 2843000/24576000\n",
      "current iter: 2844000/24576000\n",
      "current iter: 2845000/24576000\n",
      "current iter: 2846000/24576000\n",
      "current iter: 2847000/24576000\n",
      "current iter: 2848000/24576000\n",
      "current iter: 2849000/24576000\n",
      "current iter: 2850000/24576000\n",
      "current iter: 2851000/24576000\n",
      "current iter: 2852000/24576000\n",
      "current iter: 2853000/24576000\n",
      "current iter: 2854000/24576000\n",
      "current iter: 2855000/24576000\n",
      "current iter: 2856000/24576000\n",
      "current iter: 2857000/24576000\n",
      "current iter: 2858000/24576000\n",
      "current iter: 2859000/24576000\n",
      "current iter: 2860000/24576000\n",
      "current iter: 2861000/24576000\n",
      "current iter: 2862000/24576000\n",
      "current iter: 2863000/24576000\n",
      "current iter: 2864000/24576000\n",
      "current iter: 2865000/24576000\n",
      "current iter: 2866000/24576000\n",
      "current iter: 2867000/24576000\n",
      "current iter: 2868000/24576000\n",
      "current iter: 2869000/24576000\n",
      "current iter: 2870000/24576000\n",
      "current iter: 2871000/24576000\n",
      "current iter: 2872000/24576000\n",
      "current iter: 2873000/24576000\n",
      "current iter: 2874000/24576000\n",
      "current iter: 2875000/24576000\n",
      "current iter: 2876000/24576000\n",
      "current iter: 2877000/24576000\n",
      "current iter: 2878000/24576000\n",
      "current iter: 2879000/24576000\n",
      "current iter: 2880000/24576000\n",
      "current iter: 2881000/24576000\n",
      "current iter: 2882000/24576000\n",
      "current iter: 2883000/24576000\n",
      "current iter: 2884000/24576000\n",
      "current iter: 2885000/24576000\n",
      "current iter: 2886000/24576000\n",
      "current iter: 2887000/24576000\n",
      "current iter: 2888000/24576000\n",
      "current iter: 2889000/24576000\n",
      "current iter: 2890000/24576000\n",
      "current iter: 2891000/24576000\n",
      "current iter: 2892000/24576000\n",
      "current iter: 2893000/24576000\n",
      "current iter: 2894000/24576000\n",
      "current iter: 2895000/24576000\n",
      "current iter: 2896000/24576000\n",
      "current iter: 2897000/24576000\n",
      "current iter: 2898000/24576000\n",
      "current iter: 2899000/24576000\n",
      "current iter: 2900000/24576000\n",
      "current iter: 2901000/24576000\n",
      "current iter: 2902000/24576000\n",
      "current iter: 2903000/24576000\n",
      "current iter: 2904000/24576000\n",
      "current iter: 2905000/24576000\n",
      "current iter: 2906000/24576000\n",
      "current iter: 2907000/24576000\n",
      "current iter: 2908000/24576000\n",
      "current iter: 2909000/24576000\n",
      "current iter: 2910000/24576000\n",
      "current iter: 2911000/24576000\n",
      "current iter: 2912000/24576000\n",
      "current iter: 2913000/24576000\n",
      "current iter: 2914000/24576000\n",
      "current iter: 2915000/24576000\n",
      "current iter: 2916000/24576000\n",
      "current iter: 2917000/24576000\n",
      "current iter: 2918000/24576000\n",
      "current iter: 2919000/24576000\n",
      "current iter: 2920000/24576000\n",
      "current iter: 2921000/24576000\n",
      "current iter: 2922000/24576000\n",
      "current iter: 2923000/24576000\n",
      "current iter: 2924000/24576000\n",
      "current iter: 2925000/24576000\n",
      "current iter: 2926000/24576000\n",
      "current iter: 2927000/24576000\n",
      "current iter: 2928000/24576000\n",
      "current iter: 2929000/24576000\n",
      "current iter: 2930000/24576000\n",
      "current iter: 2931000/24576000\n",
      "current iter: 2932000/24576000\n",
      "current iter: 2933000/24576000\n",
      "current iter: 2934000/24576000\n",
      "current iter: 2935000/24576000\n",
      "current iter: 2936000/24576000\n",
      "current iter: 2937000/24576000\n",
      "current iter: 2938000/24576000\n",
      "current iter: 2939000/24576000\n",
      "current iter: 2940000/24576000\n",
      "current iter: 2941000/24576000\n",
      "current iter: 2942000/24576000\n",
      "current iter: 2943000/24576000\n",
      "current iter: 2944000/24576000\n",
      "current iter: 2945000/24576000\n",
      "current iter: 2946000/24576000\n",
      "current iter: 2947000/24576000\n",
      "current iter: 2948000/24576000\n",
      "current iter: 2949000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 2950000/24576000\n",
      "current iter: 2951000/24576000\n",
      "current iter: 2952000/24576000\n",
      "current iter: 2953000/24576000\n",
      "current iter: 2954000/24576000\n",
      "current iter: 2955000/24576000\n",
      "current iter: 2956000/24576000\n",
      "current iter: 2957000/24576000\n",
      "current iter: 2958000/24576000\n",
      "current iter: 2959000/24576000\n",
      "current iter: 2960000/24576000\n",
      "current iter: 2961000/24576000\n",
      "current iter: 2962000/24576000\n",
      "current iter: 2963000/24576000\n",
      "current iter: 2964000/24576000\n",
      "current iter: 2965000/24576000\n",
      "current iter: 2966000/24576000\n",
      "current iter: 2967000/24576000\n",
      "current iter: 2968000/24576000\n",
      "current iter: 2969000/24576000\n",
      "current iter: 2970000/24576000\n",
      "current iter: 2971000/24576000\n",
      "current iter: 2972000/24576000\n",
      "current iter: 2973000/24576000\n",
      "current iter: 2974000/24576000\n",
      "current iter: 2975000/24576000\n",
      "current iter: 2976000/24576000\n",
      "current iter: 2977000/24576000\n",
      "current iter: 2978000/24576000\n",
      "current iter: 2979000/24576000\n",
      "current iter: 2980000/24576000\n",
      "current iter: 2981000/24576000\n",
      "current iter: 2982000/24576000\n",
      "current iter: 2983000/24576000\n",
      "current iter: 2984000/24576000\n",
      "current iter: 2985000/24576000\n",
      "current iter: 2986000/24576000\n",
      "current iter: 2987000/24576000\n",
      "current iter: 2988000/24576000\n",
      "current iter: 2989000/24576000\n",
      "current iter: 2990000/24576000\n",
      "current iter: 2991000/24576000\n",
      "current iter: 2992000/24576000\n",
      "current iter: 2993000/24576000\n",
      "current iter: 2994000/24576000\n",
      "current iter: 2995000/24576000\n",
      "current iter: 2996000/24576000\n",
      "current iter: 2997000/24576000\n",
      "current iter: 2998000/24576000\n",
      "current iter: 2999000/24576000\n",
      "current iter: 3000000/24576000\n",
      "current iter: 3001000/24576000\n",
      "current iter: 3002000/24576000\n",
      "current iter: 3003000/24576000\n",
      "current iter: 3004000/24576000\n",
      "current iter: 3005000/24576000\n",
      "current iter: 3006000/24576000\n",
      "current iter: 3007000/24576000\n",
      "current iter: 3008000/24576000\n",
      "current iter: 3009000/24576000\n",
      "current iter: 3010000/24576000\n",
      "current iter: 3011000/24576000\n",
      "current iter: 3012000/24576000\n",
      "current iter: 3013000/24576000\n",
      "current iter: 3014000/24576000\n",
      "current iter: 3015000/24576000\n",
      "current iter: 3016000/24576000\n",
      "current iter: 3017000/24576000\n",
      "current iter: 3018000/24576000\n",
      "current iter: 3019000/24576000\n",
      "current iter: 3020000/24576000\n",
      "current iter: 3021000/24576000\n",
      "current iter: 3022000/24576000\n",
      "current iter: 3023000/24576000\n",
      "current iter: 3024000/24576000\n",
      "current iter: 3025000/24576000\n",
      "current iter: 3026000/24576000\n",
      "current iter: 3027000/24576000\n",
      "current iter: 3028000/24576000\n",
      "current iter: 3029000/24576000\n",
      "current iter: 3030000/24576000\n",
      "current iter: 3031000/24576000\n",
      "current iter: 3032000/24576000\n",
      "current iter: 3033000/24576000\n",
      "current iter: 3034000/24576000\n",
      "current iter: 3035000/24576000\n",
      "current iter: 3036000/24576000\n",
      "current iter: 3037000/24576000\n",
      "current iter: 3038000/24576000\n",
      "current iter: 3039000/24576000\n",
      "current iter: 3040000/24576000\n",
      "current iter: 3041000/24576000\n",
      "current iter: 3042000/24576000\n",
      "current iter: 3043000/24576000\n",
      "current iter: 3044000/24576000\n",
      "current iter: 3045000/24576000\n",
      "current iter: 3046000/24576000\n",
      "current iter: 3047000/24576000\n",
      "current iter: 3048000/24576000\n",
      "current iter: 3049000/24576000\n",
      "current iter: 3050000/24576000\n",
      "current iter: 3051000/24576000\n",
      "current iter: 3052000/24576000\n",
      "current iter: 3053000/24576000\n",
      "current iter: 3054000/24576000\n",
      "current iter: 3055000/24576000\n",
      "current iter: 3056000/24576000\n",
      "current iter: 3057000/24576000\n",
      "current iter: 3058000/24576000\n",
      "current iter: 3059000/24576000\n",
      "current iter: 3060000/24576000\n",
      "current iter: 3061000/24576000\n",
      "current iter: 3062000/24576000\n",
      "current iter: 3063000/24576000\n",
      "current iter: 3064000/24576000\n",
      "current iter: 3065000/24576000\n",
      "current iter: 3066000/24576000\n",
      "current iter: 3067000/24576000\n",
      "current iter: 3068000/24576000\n",
      "current iter: 3069000/24576000\n",
      "current iter: 3070000/24576000\n",
      "current iter: 3071000/24576000\n",
      "current iter: 3072000/24576000\n",
      "current iter: 3073000/24576000\n",
      "current iter: 3074000/24576000\n",
      "current iter: 3075000/24576000\n",
      "current iter: 3076000/24576000\n",
      "current iter: 3077000/24576000\n",
      "current iter: 3078000/24576000\n",
      "current iter: 3079000/24576000\n",
      "current iter: 3080000/24576000\n",
      "current iter: 3081000/24576000\n",
      "current iter: 3082000/24576000\n",
      "current iter: 3083000/24576000\n",
      "current iter: 3084000/24576000\n",
      "current iter: 3085000/24576000\n",
      "current iter: 3086000/24576000\n",
      "current iter: 3087000/24576000\n",
      "current iter: 3088000/24576000\n",
      "current iter: 3089000/24576000\n",
      "current iter: 3090000/24576000\n",
      "current iter: 3091000/24576000\n",
      "current iter: 3092000/24576000\n",
      "current iter: 3093000/24576000\n",
      "current iter: 3094000/24576000\n",
      "current iter: 3095000/24576000\n",
      "current iter: 3096000/24576000\n",
      "current iter: 3097000/24576000\n",
      "current iter: 3098000/24576000\n",
      "current iter: 3099000/24576000\n",
      "current iter: 3100000/24576000\n",
      "current iter: 3101000/24576000\n",
      "current iter: 3102000/24576000\n",
      "current iter: 3103000/24576000\n",
      "current iter: 3104000/24576000\n",
      "current iter: 3105000/24576000\n",
      "current iter: 3106000/24576000\n",
      "current iter: 3107000/24576000\n",
      "current iter: 3108000/24576000\n",
      "current iter: 3109000/24576000\n",
      "current iter: 3110000/24576000\n",
      "current iter: 3111000/24576000\n",
      "current iter: 3112000/24576000\n",
      "current iter: 3113000/24576000\n",
      "current iter: 3114000/24576000\n",
      "current iter: 3115000/24576000\n",
      "current iter: 3116000/24576000\n",
      "current iter: 3117000/24576000\n",
      "current iter: 3118000/24576000\n",
      "current iter: 3119000/24576000\n",
      "current iter: 3120000/24576000\n",
      "current iter: 3121000/24576000\n",
      "current iter: 3122000/24576000\n",
      "current iter: 3123000/24576000\n",
      "current iter: 3124000/24576000\n",
      "current iter: 3125000/24576000\n",
      "current iter: 3126000/24576000\n",
      "current iter: 3127000/24576000\n",
      "current iter: 3128000/24576000\n",
      "current iter: 3129000/24576000\n",
      "current iter: 3130000/24576000\n",
      "current iter: 3131000/24576000\n",
      "current iter: 3132000/24576000\n",
      "current iter: 3133000/24576000\n",
      "current iter: 3134000/24576000\n",
      "current iter: 3135000/24576000\n",
      "current iter: 3136000/24576000\n",
      "current iter: 3137000/24576000\n",
      "current iter: 3138000/24576000\n",
      "current iter: 3139000/24576000\n",
      "current iter: 3140000/24576000\n",
      "current iter: 3141000/24576000\n",
      "current iter: 3142000/24576000\n",
      "current iter: 3143000/24576000\n",
      "current iter: 3144000/24576000\n",
      "current iter: 3145000/24576000\n",
      "current iter: 3146000/24576000\n",
      "current iter: 3147000/24576000\n",
      "current iter: 3148000/24576000\n",
      "current iter: 3149000/24576000\n",
      "current iter: 3150000/24576000\n",
      "current iter: 3151000/24576000\n",
      "current iter: 3152000/24576000\n",
      "current iter: 3153000/24576000\n",
      "current iter: 3154000/24576000\n",
      "current iter: 3155000/24576000\n",
      "current iter: 3156000/24576000\n",
      "current iter: 3157000/24576000\n",
      "current iter: 3158000/24576000\n",
      "current iter: 3159000/24576000\n",
      "current iter: 3160000/24576000\n",
      "current iter: 3161000/24576000\n",
      "current iter: 3162000/24576000\n",
      "current iter: 3163000/24576000\n",
      "current iter: 3164000/24576000\n",
      "current iter: 3165000/24576000\n",
      "current iter: 3166000/24576000\n",
      "current iter: 3167000/24576000\n",
      "current iter: 3168000/24576000\n",
      "current iter: 3169000/24576000\n",
      "current iter: 3170000/24576000\n",
      "current iter: 3171000/24576000\n",
      "current iter: 3172000/24576000\n",
      "current iter: 3173000/24576000\n",
      "current iter: 3174000/24576000\n",
      "current iter: 3175000/24576000\n",
      "current iter: 3176000/24576000\n",
      "current iter: 3177000/24576000\n",
      "current iter: 3178000/24576000\n",
      "current iter: 3179000/24576000\n",
      "current iter: 3180000/24576000\n",
      "current iter: 3181000/24576000\n",
      "current iter: 3182000/24576000\n",
      "current iter: 3183000/24576000\n",
      "current iter: 3184000/24576000\n",
      "current iter: 3185000/24576000\n",
      "current iter: 3186000/24576000\n",
      "current iter: 3187000/24576000\n",
      "current iter: 3188000/24576000\n",
      "current iter: 3189000/24576000\n",
      "current iter: 3190000/24576000\n",
      "current iter: 3191000/24576000\n",
      "current iter: 3192000/24576000\n",
      "current iter: 3193000/24576000\n",
      "current iter: 3194000/24576000\n",
      "current iter: 3195000/24576000\n",
      "current iter: 3196000/24576000\n",
      "current iter: 3197000/24576000\n",
      "current iter: 3198000/24576000\n",
      "current iter: 3199000/24576000\n",
      "current iter: 3200000/24576000\n",
      "current iter: 3201000/24576000\n",
      "current iter: 3202000/24576000\n",
      "current iter: 3203000/24576000\n",
      "current iter: 3204000/24576000\n",
      "current iter: 3205000/24576000\n",
      "current iter: 3206000/24576000\n",
      "current iter: 3207000/24576000\n",
      "current iter: 3208000/24576000\n",
      "current iter: 3209000/24576000\n",
      "current iter: 3210000/24576000\n",
      "current iter: 3211000/24576000\n",
      "current iter: 3212000/24576000\n",
      "current iter: 3213000/24576000\n",
      "current iter: 3214000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 3215000/24576000\n",
      "current iter: 3216000/24576000\n",
      "current iter: 3217000/24576000\n",
      "current iter: 3218000/24576000\n",
      "current iter: 3219000/24576000\n",
      "current iter: 3220000/24576000\n",
      "current iter: 3221000/24576000\n",
      "current iter: 3222000/24576000\n",
      "current iter: 3223000/24576000\n",
      "current iter: 3224000/24576000\n",
      "current iter: 3225000/24576000\n",
      "current iter: 3226000/24576000\n",
      "current iter: 3227000/24576000\n",
      "current iter: 3228000/24576000\n",
      "current iter: 3229000/24576000\n",
      "current iter: 3230000/24576000\n",
      "current iter: 3231000/24576000\n",
      "current iter: 3232000/24576000\n",
      "current iter: 3233000/24576000\n",
      "current iter: 3234000/24576000\n",
      "current iter: 3235000/24576000\n",
      "current iter: 3236000/24576000\n",
      "current iter: 3237000/24576000\n",
      "current iter: 3238000/24576000\n",
      "current iter: 3239000/24576000\n",
      "current iter: 3240000/24576000\n",
      "current iter: 3241000/24576000\n",
      "current iter: 3242000/24576000\n",
      "current iter: 3243000/24576000\n",
      "current iter: 3244000/24576000\n",
      "current iter: 3245000/24576000\n",
      "current iter: 3246000/24576000\n",
      "current iter: 3247000/24576000\n",
      "current iter: 3248000/24576000\n",
      "current iter: 3249000/24576000\n",
      "current iter: 3250000/24576000\n",
      "current iter: 3251000/24576000\n",
      "current iter: 3252000/24576000\n",
      "current iter: 3253000/24576000\n",
      "current iter: 3254000/24576000\n",
      "current iter: 3255000/24576000\n",
      "current iter: 3256000/24576000\n",
      "current iter: 3257000/24576000\n",
      "current iter: 3258000/24576000\n",
      "current iter: 3259000/24576000\n",
      "current iter: 3260000/24576000\n",
      "current iter: 3261000/24576000\n",
      "current iter: 3262000/24576000\n",
      "current iter: 3263000/24576000\n",
      "current iter: 3264000/24576000\n",
      "current iter: 3265000/24576000\n",
      "current iter: 3266000/24576000\n",
      "current iter: 3267000/24576000\n",
      "current iter: 3268000/24576000\n",
      "current iter: 3269000/24576000\n",
      "current iter: 3270000/24576000\n",
      "current iter: 3271000/24576000\n",
      "current iter: 3272000/24576000\n",
      "current iter: 3273000/24576000\n",
      "current iter: 3274000/24576000\n",
      "current iter: 3275000/24576000\n",
      "current iter: 3276000/24576000\n",
      "current iter: 3277000/24576000\n",
      "current iter: 3278000/24576000\n",
      "current iter: 3279000/24576000\n",
      "current iter: 3280000/24576000\n",
      "current iter: 3281000/24576000\n",
      "current iter: 3282000/24576000\n",
      "current iter: 3283000/24576000\n",
      "current iter: 3284000/24576000\n",
      "current iter: 3285000/24576000\n",
      "current iter: 3286000/24576000\n",
      "current iter: 3287000/24576000\n",
      "current iter: 3288000/24576000\n",
      "current iter: 3289000/24576000\n",
      "current iter: 3290000/24576000\n",
      "current iter: 3291000/24576000\n",
      "current iter: 3292000/24576000\n",
      "current iter: 3293000/24576000\n",
      "current iter: 3294000/24576000\n",
      "current iter: 3295000/24576000\n",
      "current iter: 3296000/24576000\n",
      "current iter: 3297000/24576000\n",
      "current iter: 3298000/24576000\n",
      "current iter: 3299000/24576000\n",
      "current iter: 3300000/24576000\n",
      "current iter: 3301000/24576000\n",
      "current iter: 3302000/24576000\n",
      "current iter: 3303000/24576000\n",
      "current iter: 3304000/24576000\n",
      "current iter: 3305000/24576000\n",
      "current iter: 3306000/24576000\n",
      "current iter: 3307000/24576000\n",
      "current iter: 3308000/24576000\n",
      "current iter: 3309000/24576000\n",
      "current iter: 3310000/24576000\n",
      "current iter: 3311000/24576000\n",
      "current iter: 3312000/24576000\n",
      "current iter: 3313000/24576000\n",
      "current iter: 3314000/24576000\n",
      "current iter: 3315000/24576000\n",
      "current iter: 3316000/24576000\n",
      "current iter: 3317000/24576000\n",
      "current iter: 3318000/24576000\n",
      "current iter: 3319000/24576000\n",
      "current iter: 3320000/24576000\n",
      "current iter: 3321000/24576000\n",
      "current iter: 3322000/24576000\n",
      "current iter: 3323000/24576000\n",
      "current iter: 3324000/24576000\n",
      "current iter: 3325000/24576000\n",
      "current iter: 3326000/24576000\n",
      "current iter: 3327000/24576000\n",
      "current iter: 3328000/24576000\n",
      "current iter: 3329000/24576000\n",
      "current iter: 3330000/24576000\n",
      "current iter: 3331000/24576000\n",
      "current iter: 3332000/24576000\n",
      "current iter: 3333000/24576000\n",
      "current iter: 3334000/24576000\n",
      "current iter: 3335000/24576000\n",
      "current iter: 3336000/24576000\n",
      "current iter: 3337000/24576000\n",
      "current iter: 3338000/24576000\n",
      "current iter: 3339000/24576000\n",
      "current iter: 3340000/24576000\n",
      "current iter: 3341000/24576000\n",
      "current iter: 3342000/24576000\n",
      "current iter: 3343000/24576000\n",
      "current iter: 3344000/24576000\n",
      "current iter: 3345000/24576000\n",
      "current iter: 3346000/24576000\n",
      "current iter: 3347000/24576000\n",
      "current iter: 3348000/24576000\n",
      "current iter: 3349000/24576000\n",
      "current iter: 3350000/24576000\n",
      "current iter: 3351000/24576000\n",
      "current iter: 3352000/24576000\n",
      "current iter: 3353000/24576000\n",
      "current iter: 3354000/24576000\n",
      "current iter: 3355000/24576000\n",
      "current iter: 3356000/24576000\n",
      "current iter: 3357000/24576000\n",
      "current iter: 3358000/24576000\n",
      "current iter: 3359000/24576000\n",
      "current iter: 3360000/24576000\n",
      "current iter: 3361000/24576000\n",
      "current iter: 3362000/24576000\n",
      "current iter: 3363000/24576000\n",
      "current iter: 3364000/24576000\n",
      "current iter: 3365000/24576000\n",
      "current iter: 3366000/24576000\n",
      "current iter: 3367000/24576000\n",
      "current iter: 3368000/24576000\n",
      "current iter: 3369000/24576000\n",
      "current iter: 3370000/24576000\n",
      "current iter: 3371000/24576000\n",
      "current iter: 3372000/24576000\n",
      "current iter: 3373000/24576000\n",
      "current iter: 3374000/24576000\n",
      "current iter: 3375000/24576000\n",
      "current iter: 3376000/24576000\n",
      "current iter: 3377000/24576000\n",
      "current iter: 3378000/24576000\n",
      "current iter: 3379000/24576000\n",
      "current iter: 3380000/24576000\n",
      "current iter: 3381000/24576000\n",
      "current iter: 3382000/24576000\n",
      "current iter: 3383000/24576000\n",
      "current iter: 3384000/24576000\n",
      "current iter: 3385000/24576000\n",
      "current iter: 3386000/24576000\n",
      "current iter: 3387000/24576000\n",
      "current iter: 3388000/24576000\n",
      "current iter: 3389000/24576000\n",
      "current iter: 3390000/24576000\n",
      "current iter: 3391000/24576000\n",
      "current iter: 3392000/24576000\n",
      "current iter: 3393000/24576000\n",
      "current iter: 3394000/24576000\n",
      "current iter: 3395000/24576000\n",
      "current iter: 3396000/24576000\n",
      "current iter: 3397000/24576000\n",
      "current iter: 3398000/24576000\n",
      "current iter: 3399000/24576000\n",
      "current iter: 3400000/24576000\n",
      "current iter: 3401000/24576000\n",
      "current iter: 3402000/24576000\n",
      "current iter: 3403000/24576000\n",
      "current iter: 3404000/24576000\n",
      "current iter: 3405000/24576000\n",
      "current iter: 3406000/24576000\n",
      "current iter: 3407000/24576000\n",
      "current iter: 3408000/24576000\n",
      "current iter: 3409000/24576000\n",
      "current iter: 3410000/24576000\n",
      "current iter: 3411000/24576000\n",
      "current iter: 3412000/24576000\n",
      "current iter: 3413000/24576000\n",
      "current iter: 3414000/24576000\n",
      "current iter: 3415000/24576000\n",
      "current iter: 3416000/24576000\n",
      "current iter: 3417000/24576000\n",
      "current iter: 3418000/24576000\n",
      "current iter: 3419000/24576000\n",
      "current iter: 3420000/24576000\n",
      "current iter: 3421000/24576000\n",
      "current iter: 3422000/24576000\n",
      "current iter: 3423000/24576000\n",
      "current iter: 3424000/24576000\n",
      "current iter: 3425000/24576000\n",
      "current iter: 3426000/24576000\n",
      "current iter: 3427000/24576000\n",
      "current iter: 3428000/24576000\n",
      "current iter: 3429000/24576000\n",
      "current iter: 3430000/24576000\n",
      "current iter: 3431000/24576000\n",
      "current iter: 3432000/24576000\n",
      "current iter: 3433000/24576000\n",
      "current iter: 3434000/24576000\n",
      "current iter: 3435000/24576000\n",
      "current iter: 3436000/24576000\n",
      "current iter: 3437000/24576000\n",
      "current iter: 3438000/24576000\n",
      "current iter: 3439000/24576000\n",
      "current iter: 3440000/24576000\n",
      "current iter: 3441000/24576000\n",
      "current iter: 3442000/24576000\n",
      "current iter: 3443000/24576000\n",
      "current iter: 3444000/24576000\n",
      "current iter: 3445000/24576000\n",
      "current iter: 3446000/24576000\n",
      "current iter: 3447000/24576000\n",
      "current iter: 3448000/24576000\n",
      "current iter: 3449000/24576000\n",
      "current iter: 3450000/24576000\n",
      "current iter: 3451000/24576000\n",
      "current iter: 3452000/24576000\n",
      "current iter: 3453000/24576000\n",
      "current iter: 3454000/24576000\n",
      "current iter: 3455000/24576000\n",
      "current iter: 3456000/24576000\n",
      "current iter: 3457000/24576000\n",
      "current iter: 3458000/24576000\n",
      "current iter: 3459000/24576000\n",
      "current iter: 3460000/24576000\n",
      "current iter: 3461000/24576000\n",
      "current iter: 3462000/24576000\n",
      "current iter: 3463000/24576000\n",
      "current iter: 3464000/24576000\n",
      "current iter: 3465000/24576000\n",
      "current iter: 3466000/24576000\n",
      "current iter: 3467000/24576000\n",
      "current iter: 3468000/24576000\n",
      "current iter: 3469000/24576000\n",
      "current iter: 3470000/24576000\n",
      "current iter: 3471000/24576000\n",
      "current iter: 3472000/24576000\n",
      "current iter: 3473000/24576000\n",
      "current iter: 3474000/24576000\n",
      "current iter: 3475000/24576000\n",
      "current iter: 3476000/24576000\n",
      "current iter: 3477000/24576000\n",
      "current iter: 3478000/24576000\n",
      "current iter: 3479000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 3480000/24576000\n",
      "current iter: 3481000/24576000\n",
      "current iter: 3482000/24576000\n",
      "current iter: 3483000/24576000\n",
      "current iter: 3484000/24576000\n",
      "current iter: 3485000/24576000\n",
      "current iter: 3486000/24576000\n",
      "current iter: 3487000/24576000\n",
      "current iter: 3488000/24576000\n",
      "current iter: 3489000/24576000\n",
      "current iter: 3490000/24576000\n",
      "current iter: 3491000/24576000\n",
      "current iter: 3492000/24576000\n",
      "current iter: 3493000/24576000\n",
      "current iter: 3494000/24576000\n",
      "current iter: 3495000/24576000\n",
      "current iter: 3496000/24576000\n",
      "current iter: 3497000/24576000\n",
      "current iter: 3498000/24576000\n",
      "current iter: 3499000/24576000\n",
      "current iter: 3500000/24576000\n",
      "current iter: 3501000/24576000\n",
      "current iter: 3502000/24576000\n",
      "current iter: 3503000/24576000\n",
      "current iter: 3504000/24576000\n",
      "current iter: 3505000/24576000\n",
      "current iter: 3506000/24576000\n",
      "current iter: 3507000/24576000\n",
      "current iter: 3508000/24576000\n",
      "current iter: 3509000/24576000\n",
      "current iter: 3510000/24576000\n",
      "current iter: 3511000/24576000\n",
      "current iter: 3512000/24576000\n",
      "current iter: 3513000/24576000\n",
      "current iter: 3514000/24576000\n",
      "current iter: 3515000/24576000\n",
      "current iter: 3516000/24576000\n",
      "current iter: 3517000/24576000\n",
      "current iter: 3518000/24576000\n",
      "current iter: 3519000/24576000\n",
      "current iter: 3520000/24576000\n",
      "current iter: 3521000/24576000\n",
      "current iter: 3522000/24576000\n",
      "current iter: 3523000/24576000\n",
      "current iter: 3524000/24576000\n",
      "current iter: 3525000/24576000\n",
      "current iter: 3526000/24576000\n",
      "current iter: 3527000/24576000\n",
      "current iter: 3528000/24576000\n",
      "current iter: 3529000/24576000\n",
      "current iter: 3530000/24576000\n",
      "current iter: 3531000/24576000\n",
      "current iter: 3532000/24576000\n",
      "current iter: 3533000/24576000\n",
      "current iter: 3534000/24576000\n",
      "current iter: 3535000/24576000\n",
      "current iter: 3536000/24576000\n",
      "current iter: 3537000/24576000\n",
      "current iter: 3538000/24576000\n",
      "current iter: 3539000/24576000\n",
      "current iter: 3540000/24576000\n",
      "current iter: 3541000/24576000\n",
      "current iter: 3542000/24576000\n",
      "current iter: 3543000/24576000\n",
      "current iter: 3544000/24576000\n",
      "current iter: 3545000/24576000\n",
      "current iter: 3546000/24576000\n",
      "current iter: 3547000/24576000\n",
      "current iter: 3548000/24576000\n",
      "current iter: 3549000/24576000\n",
      "current iter: 3550000/24576000\n",
      "current iter: 3551000/24576000\n",
      "current iter: 3552000/24576000\n",
      "current iter: 3553000/24576000\n",
      "current iter: 3554000/24576000\n",
      "current iter: 3555000/24576000\n",
      "current iter: 3556000/24576000\n",
      "current iter: 3557000/24576000\n",
      "current iter: 3558000/24576000\n",
      "current iter: 3559000/24576000\n",
      "current iter: 3560000/24576000\n",
      "current iter: 3561000/24576000\n",
      "current iter: 3562000/24576000\n",
      "current iter: 3563000/24576000\n",
      "current iter: 3564000/24576000\n",
      "current iter: 3565000/24576000\n",
      "current iter: 3566000/24576000\n",
      "current iter: 3567000/24576000\n",
      "current iter: 3568000/24576000\n",
      "current iter: 3569000/24576000\n",
      "current iter: 3570000/24576000\n",
      "current iter: 3571000/24576000\n",
      "current iter: 3572000/24576000\n",
      "current iter: 3573000/24576000\n",
      "current iter: 3574000/24576000\n",
      "current iter: 3575000/24576000\n",
      "current iter: 3576000/24576000\n",
      "current iter: 3577000/24576000\n",
      "current iter: 3578000/24576000\n",
      "current iter: 3579000/24576000\n",
      "current iter: 3580000/24576000\n",
      "current iter: 3581000/24576000\n",
      "current iter: 3582000/24576000\n",
      "current iter: 3583000/24576000\n",
      "current iter: 3584000/24576000\n",
      "current iter: 3585000/24576000\n",
      "current iter: 3586000/24576000\n",
      "current iter: 3587000/24576000\n",
      "current iter: 3588000/24576000\n",
      "current iter: 3589000/24576000\n",
      "current iter: 3590000/24576000\n",
      "current iter: 3591000/24576000\n",
      "current iter: 3592000/24576000\n",
      "current iter: 3593000/24576000\n",
      "current iter: 3594000/24576000\n",
      "current iter: 3595000/24576000\n",
      "current iter: 3596000/24576000\n",
      "current iter: 3597000/24576000\n",
      "current iter: 3598000/24576000\n",
      "current iter: 3599000/24576000\n",
      "current iter: 3600000/24576000\n",
      "current iter: 3601000/24576000\n",
      "current iter: 3602000/24576000\n",
      "current iter: 3603000/24576000\n",
      "current iter: 3604000/24576000\n",
      "current iter: 3605000/24576000\n",
      "current iter: 3606000/24576000\n",
      "current iter: 3607000/24576000\n",
      "current iter: 3608000/24576000\n",
      "current iter: 3609000/24576000\n",
      "current iter: 3610000/24576000\n",
      "current iter: 3611000/24576000\n",
      "current iter: 3612000/24576000\n",
      "current iter: 3613000/24576000\n",
      "current iter: 3614000/24576000\n",
      "current iter: 3615000/24576000\n",
      "current iter: 3616000/24576000\n",
      "current iter: 3617000/24576000\n",
      "current iter: 3618000/24576000\n",
      "current iter: 3619000/24576000\n",
      "current iter: 3620000/24576000\n",
      "current iter: 3621000/24576000\n",
      "current iter: 3622000/24576000\n",
      "current iter: 3623000/24576000\n",
      "current iter: 3624000/24576000\n",
      "current iter: 3625000/24576000\n",
      "current iter: 3626000/24576000\n",
      "current iter: 3627000/24576000\n",
      "current iter: 3628000/24576000\n",
      "current iter: 3629000/24576000\n",
      "current iter: 3630000/24576000\n",
      "current iter: 3631000/24576000\n",
      "current iter: 3632000/24576000\n",
      "current iter: 3633000/24576000\n",
      "current iter: 3634000/24576000\n",
      "current iter: 3635000/24576000\n",
      "current iter: 3636000/24576000\n",
      "current iter: 3637000/24576000\n",
      "current iter: 3638000/24576000\n",
      "current iter: 3639000/24576000\n",
      "current iter: 3640000/24576000\n",
      "current iter: 3641000/24576000\n",
      "current iter: 3642000/24576000\n",
      "current iter: 3643000/24576000\n",
      "current iter: 3644000/24576000\n",
      "current iter: 3645000/24576000\n",
      "current iter: 3646000/24576000\n",
      "current iter: 3647000/24576000\n",
      "current iter: 3648000/24576000\n",
      "current iter: 3649000/24576000\n",
      "current iter: 3650000/24576000\n",
      "current iter: 3651000/24576000\n",
      "current iter: 3652000/24576000\n",
      "current iter: 3653000/24576000\n",
      "current iter: 3654000/24576000\n",
      "current iter: 3655000/24576000\n",
      "current iter: 3656000/24576000\n",
      "current iter: 3657000/24576000\n",
      "current iter: 3658000/24576000\n",
      "current iter: 3659000/24576000\n",
      "current iter: 3660000/24576000\n",
      "current iter: 3661000/24576000\n",
      "current iter: 3662000/24576000\n",
      "current iter: 3663000/24576000\n",
      "current iter: 3664000/24576000\n",
      "current iter: 3665000/24576000\n",
      "current iter: 3666000/24576000\n",
      "current iter: 3667000/24576000\n",
      "current iter: 3668000/24576000\n",
      "current iter: 3669000/24576000\n",
      "current iter: 3670000/24576000\n",
      "current iter: 3671000/24576000\n",
      "current iter: 3672000/24576000\n",
      "current iter: 3673000/24576000\n",
      "current iter: 3674000/24576000\n",
      "current iter: 3675000/24576000\n",
      "current iter: 3676000/24576000\n",
      "current iter: 3677000/24576000\n",
      "current iter: 3678000/24576000\n",
      "current iter: 3679000/24576000\n",
      "current iter: 3680000/24576000\n",
      "current iter: 3681000/24576000\n",
      "current iter: 3682000/24576000\n",
      "current iter: 3683000/24576000\n",
      "current iter: 3684000/24576000\n",
      "current iter: 3685000/24576000\n",
      "current iter: 3686000/24576000\n",
      "current iter: 3687000/24576000\n",
      "current iter: 3688000/24576000\n",
      "current iter: 3689000/24576000\n",
      "current iter: 3690000/24576000\n",
      "current iter: 3691000/24576000\n",
      "current iter: 3692000/24576000\n",
      "current iter: 3693000/24576000\n",
      "current iter: 3694000/24576000\n",
      "current iter: 3695000/24576000\n",
      "current iter: 3696000/24576000\n",
      "current iter: 3697000/24576000\n",
      "current iter: 3698000/24576000\n",
      "current iter: 3699000/24576000\n",
      "current iter: 3700000/24576000\n",
      "current iter: 3701000/24576000\n",
      "current iter: 3702000/24576000\n",
      "current iter: 3703000/24576000\n",
      "current iter: 3704000/24576000\n",
      "current iter: 3705000/24576000\n",
      "current iter: 3706000/24576000\n",
      "current iter: 3707000/24576000\n",
      "current iter: 3708000/24576000\n",
      "current iter: 3709000/24576000\n",
      "current iter: 3710000/24576000\n",
      "current iter: 3711000/24576000\n",
      "current iter: 3712000/24576000\n",
      "current iter: 3713000/24576000\n",
      "current iter: 3714000/24576000\n",
      "current iter: 3715000/24576000\n",
      "current iter: 3716000/24576000\n",
      "current iter: 3717000/24576000\n",
      "current iter: 3718000/24576000\n",
      "current iter: 3719000/24576000\n",
      "current iter: 3720000/24576000\n",
      "current iter: 3721000/24576000\n",
      "current iter: 3722000/24576000\n",
      "current iter: 3723000/24576000\n",
      "current iter: 3724000/24576000\n",
      "current iter: 3725000/24576000\n",
      "current iter: 3726000/24576000\n",
      "current iter: 3727000/24576000\n",
      "current iter: 3728000/24576000\n",
      "current iter: 3729000/24576000\n",
      "current iter: 3730000/24576000\n",
      "current iter: 3731000/24576000\n",
      "current iter: 3732000/24576000\n",
      "current iter: 3733000/24576000\n",
      "current iter: 3734000/24576000\n",
      "current iter: 3735000/24576000\n",
      "current iter: 3736000/24576000\n",
      "current iter: 3737000/24576000\n",
      "current iter: 3738000/24576000\n",
      "current iter: 3739000/24576000\n",
      "current iter: 3740000/24576000\n",
      "current iter: 3741000/24576000\n",
      "current iter: 3742000/24576000\n",
      "current iter: 3743000/24576000\n",
      "current iter: 3744000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 3745000/24576000\n",
      "current iter: 3746000/24576000\n",
      "current iter: 3747000/24576000\n",
      "current iter: 3748000/24576000\n",
      "current iter: 3749000/24576000\n",
      "current iter: 3750000/24576000\n",
      "current iter: 3751000/24576000\n",
      "current iter: 3752000/24576000\n",
      "current iter: 3753000/24576000\n",
      "current iter: 3754000/24576000\n",
      "current iter: 3755000/24576000\n",
      "current iter: 3756000/24576000\n",
      "current iter: 3757000/24576000\n",
      "current iter: 3758000/24576000\n",
      "current iter: 3759000/24576000\n",
      "current iter: 3760000/24576000\n",
      "current iter: 3761000/24576000\n",
      "current iter: 3762000/24576000\n",
      "current iter: 3763000/24576000\n",
      "current iter: 3764000/24576000\n",
      "current iter: 3765000/24576000\n",
      "current iter: 3766000/24576000\n",
      "current iter: 3767000/24576000\n",
      "current iter: 3768000/24576000\n",
      "current iter: 3769000/24576000\n",
      "current iter: 3770000/24576000\n",
      "current iter: 3771000/24576000\n",
      "current iter: 3772000/24576000\n",
      "current iter: 3773000/24576000\n",
      "current iter: 3774000/24576000\n",
      "current iter: 3775000/24576000\n",
      "current iter: 3776000/24576000\n",
      "current iter: 3777000/24576000\n",
      "current iter: 3778000/24576000\n",
      "current iter: 3779000/24576000\n",
      "current iter: 3780000/24576000\n",
      "current iter: 3781000/24576000\n",
      "current iter: 3782000/24576000\n",
      "current iter: 3783000/24576000\n",
      "current iter: 3784000/24576000\n",
      "current iter: 3785000/24576000\n",
      "current iter: 3786000/24576000\n",
      "current iter: 3787000/24576000\n",
      "current iter: 3788000/24576000\n",
      "current iter: 3789000/24576000\n",
      "current iter: 3790000/24576000\n",
      "current iter: 3791000/24576000\n",
      "current iter: 3792000/24576000\n",
      "current iter: 3793000/24576000\n",
      "current iter: 3794000/24576000\n",
      "current iter: 3795000/24576000\n",
      "current iter: 3796000/24576000\n",
      "current iter: 3797000/24576000\n",
      "current iter: 3798000/24576000\n",
      "current iter: 3799000/24576000\n",
      "current iter: 3800000/24576000\n",
      "current iter: 3801000/24576000\n",
      "current iter: 3802000/24576000\n",
      "current iter: 3803000/24576000\n",
      "current iter: 3804000/24576000\n",
      "current iter: 3805000/24576000\n",
      "current iter: 3806000/24576000\n",
      "current iter: 3807000/24576000\n",
      "current iter: 3808000/24576000\n",
      "current iter: 3809000/24576000\n",
      "current iter: 3810000/24576000\n",
      "current iter: 3811000/24576000\n",
      "current iter: 3812000/24576000\n",
      "current iter: 3813000/24576000\n",
      "current iter: 3814000/24576000\n",
      "current iter: 3815000/24576000\n",
      "current iter: 3816000/24576000\n",
      "current iter: 3817000/24576000\n",
      "current iter: 3818000/24576000\n",
      "current iter: 3819000/24576000\n",
      "current iter: 3820000/24576000\n",
      "current iter: 3821000/24576000\n",
      "current iter: 3822000/24576000\n",
      "current iter: 3823000/24576000\n",
      "current iter: 3824000/24576000\n",
      "current iter: 3825000/24576000\n",
      "current iter: 3826000/24576000\n",
      "current iter: 3827000/24576000\n",
      "current iter: 3828000/24576000\n",
      "current iter: 3829000/24576000\n",
      "current iter: 3830000/24576000\n",
      "current iter: 3831000/24576000\n",
      "current iter: 3832000/24576000\n",
      "current iter: 3833000/24576000\n",
      "current iter: 3834000/24576000\n",
      "current iter: 3835000/24576000\n",
      "current iter: 3836000/24576000\n",
      "current iter: 3837000/24576000\n",
      "current iter: 3838000/24576000\n",
      "current iter: 3839000/24576000\n",
      "current iter: 3840000/24576000\n",
      "current iter: 3841000/24576000\n",
      "current iter: 3842000/24576000\n",
      "current iter: 3843000/24576000\n",
      "current iter: 3844000/24576000\n",
      "current iter: 3845000/24576000\n",
      "current iter: 3846000/24576000\n",
      "current iter: 3847000/24576000\n",
      "current iter: 3848000/24576000\n",
      "current iter: 3849000/24576000\n",
      "current iter: 3850000/24576000\n",
      "current iter: 3851000/24576000\n",
      "current iter: 3852000/24576000\n",
      "current iter: 3853000/24576000\n",
      "current iter: 3854000/24576000\n",
      "current iter: 3855000/24576000\n",
      "current iter: 3856000/24576000\n",
      "current iter: 3857000/24576000\n",
      "current iter: 3858000/24576000\n",
      "current iter: 3859000/24576000\n",
      "current iter: 3860000/24576000\n",
      "current iter: 3861000/24576000\n",
      "current iter: 3862000/24576000\n",
      "current iter: 3863000/24576000\n",
      "current iter: 3864000/24576000\n",
      "current iter: 3865000/24576000\n",
      "current iter: 3866000/24576000\n",
      "current iter: 3867000/24576000\n",
      "current iter: 3868000/24576000\n",
      "current iter: 3869000/24576000\n",
      "current iter: 3870000/24576000\n",
      "current iter: 3871000/24576000\n",
      "current iter: 3872000/24576000\n",
      "current iter: 3873000/24576000\n",
      "current iter: 3874000/24576000\n",
      "current iter: 3875000/24576000\n",
      "current iter: 3876000/24576000\n",
      "current iter: 3877000/24576000\n",
      "current iter: 3878000/24576000\n",
      "current iter: 3879000/24576000\n",
      "current iter: 3880000/24576000\n",
      "current iter: 3881000/24576000\n",
      "current iter: 3882000/24576000\n",
      "current iter: 3883000/24576000\n",
      "current iter: 3884000/24576000\n",
      "current iter: 3885000/24576000\n",
      "current iter: 3886000/24576000\n",
      "current iter: 3887000/24576000\n",
      "current iter: 3888000/24576000\n",
      "current iter: 3889000/24576000\n",
      "current iter: 3890000/24576000\n",
      "current iter: 3891000/24576000\n",
      "current iter: 3892000/24576000\n",
      "current iter: 3893000/24576000\n",
      "current iter: 3894000/24576000\n",
      "current iter: 3895000/24576000\n",
      "current iter: 3896000/24576000\n",
      "current iter: 3897000/24576000\n",
      "current iter: 3898000/24576000\n",
      "current iter: 3899000/24576000\n",
      "current iter: 3900000/24576000\n",
      "current iter: 3901000/24576000\n",
      "current iter: 3902000/24576000\n",
      "current iter: 3903000/24576000\n",
      "current iter: 3904000/24576000\n",
      "current iter: 3905000/24576000\n",
      "current iter: 3906000/24576000\n",
      "current iter: 3907000/24576000\n",
      "current iter: 3908000/24576000\n",
      "current iter: 3909000/24576000\n",
      "current iter: 3910000/24576000\n",
      "current iter: 3911000/24576000\n",
      "current iter: 3912000/24576000\n",
      "current iter: 3913000/24576000\n",
      "current iter: 3914000/24576000\n",
      "current iter: 3915000/24576000\n",
      "current iter: 3916000/24576000\n",
      "current iter: 3917000/24576000\n",
      "current iter: 3918000/24576000\n",
      "current iter: 3919000/24576000\n",
      "current iter: 3920000/24576000\n",
      "current iter: 3921000/24576000\n",
      "current iter: 3922000/24576000\n",
      "current iter: 3923000/24576000\n",
      "current iter: 3924000/24576000\n",
      "current iter: 3925000/24576000\n",
      "current iter: 3926000/24576000\n",
      "current iter: 3927000/24576000\n",
      "current iter: 3928000/24576000\n",
      "current iter: 3929000/24576000\n",
      "current iter: 3930000/24576000\n",
      "current iter: 3931000/24576000\n",
      "current iter: 3932000/24576000\n",
      "current iter: 3933000/24576000\n",
      "current iter: 3934000/24576000\n",
      "current iter: 3935000/24576000\n",
      "current iter: 3936000/24576000\n",
      "current iter: 3937000/24576000\n",
      "current iter: 3938000/24576000\n",
      "current iter: 3939000/24576000\n",
      "current iter: 3940000/24576000\n",
      "current iter: 3941000/24576000\n",
      "current iter: 3942000/24576000\n",
      "current iter: 3943000/24576000\n",
      "current iter: 3944000/24576000\n",
      "current iter: 3945000/24576000\n",
      "current iter: 3946000/24576000\n",
      "current iter: 3947000/24576000\n",
      "current iter: 3948000/24576000\n",
      "current iter: 3949000/24576000\n",
      "current iter: 3950000/24576000\n",
      "current iter: 3951000/24576000\n",
      "current iter: 3952000/24576000\n",
      "current iter: 3953000/24576000\n",
      "current iter: 3954000/24576000\n",
      "current iter: 3955000/24576000\n",
      "current iter: 3956000/24576000\n",
      "current iter: 3957000/24576000\n",
      "current iter: 3958000/24576000\n",
      "current iter: 3959000/24576000\n",
      "current iter: 3960000/24576000\n",
      "current iter: 3961000/24576000\n",
      "current iter: 3962000/24576000\n",
      "current iter: 3963000/24576000\n",
      "current iter: 3964000/24576000\n",
      "current iter: 3965000/24576000\n",
      "current iter: 3966000/24576000\n",
      "current iter: 3967000/24576000\n",
      "current iter: 3968000/24576000\n",
      "current iter: 3969000/24576000\n",
      "current iter: 3970000/24576000\n",
      "current iter: 3971000/24576000\n",
      "current iter: 3972000/24576000\n",
      "current iter: 3973000/24576000\n",
      "current iter: 3974000/24576000\n",
      "current iter: 3975000/24576000\n",
      "current iter: 3976000/24576000\n",
      "current iter: 3977000/24576000\n",
      "current iter: 3978000/24576000\n",
      "current iter: 3979000/24576000\n",
      "current iter: 3980000/24576000\n",
      "current iter: 3981000/24576000\n",
      "current iter: 3982000/24576000\n",
      "current iter: 3983000/24576000\n",
      "current iter: 3984000/24576000\n",
      "current iter: 3985000/24576000\n",
      "current iter: 3986000/24576000\n",
      "current iter: 3987000/24576000\n",
      "current iter: 3988000/24576000\n",
      "current iter: 3989000/24576000\n",
      "current iter: 3990000/24576000\n",
      "current iter: 3991000/24576000\n",
      "current iter: 3992000/24576000\n",
      "current iter: 3993000/24576000\n",
      "current iter: 3994000/24576000\n",
      "current iter: 3995000/24576000\n",
      "current iter: 3996000/24576000\n",
      "current iter: 3997000/24576000\n",
      "current iter: 3998000/24576000\n",
      "current iter: 3999000/24576000\n",
      "current iter: 4000000/24576000\n",
      "current iter: 4001000/24576000\n",
      "current iter: 4002000/24576000\n",
      "current iter: 4003000/24576000\n",
      "current iter: 4004000/24576000\n",
      "current iter: 4005000/24576000\n",
      "current iter: 4006000/24576000\n",
      "current iter: 4007000/24576000\n",
      "current iter: 4008000/24576000\n",
      "current iter: 4009000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 4010000/24576000\n",
      "current iter: 4011000/24576000\n",
      "current iter: 4012000/24576000\n",
      "current iter: 4013000/24576000\n",
      "current iter: 4014000/24576000\n",
      "current iter: 4015000/24576000\n",
      "current iter: 4016000/24576000\n",
      "current iter: 4017000/24576000\n",
      "current iter: 4018000/24576000\n",
      "current iter: 4019000/24576000\n",
      "current iter: 4020000/24576000\n",
      "current iter: 4021000/24576000\n",
      "current iter: 4022000/24576000\n",
      "current iter: 4023000/24576000\n",
      "current iter: 4024000/24576000\n",
      "current iter: 4025000/24576000\n",
      "current iter: 4026000/24576000\n",
      "current iter: 4027000/24576000\n",
      "current iter: 4028000/24576000\n",
      "current iter: 4029000/24576000\n",
      "current iter: 4030000/24576000\n",
      "current iter: 4031000/24576000\n",
      "current iter: 4032000/24576000\n",
      "current iter: 4033000/24576000\n",
      "current iter: 4034000/24576000\n",
      "current iter: 4035000/24576000\n",
      "current iter: 4036000/24576000\n",
      "current iter: 4037000/24576000\n",
      "current iter: 4038000/24576000\n",
      "current iter: 4039000/24576000\n",
      "current iter: 4040000/24576000\n",
      "current iter: 4041000/24576000\n",
      "current iter: 4042000/24576000\n",
      "current iter: 4043000/24576000\n",
      "current iter: 4044000/24576000\n",
      "current iter: 4045000/24576000\n",
      "current iter: 4046000/24576000\n",
      "current iter: 4047000/24576000\n",
      "current iter: 4048000/24576000\n",
      "current iter: 4049000/24576000\n",
      "current iter: 4050000/24576000\n",
      "current iter: 4051000/24576000\n",
      "current iter: 4052000/24576000\n",
      "current iter: 4053000/24576000\n",
      "current iter: 4054000/24576000\n",
      "current iter: 4055000/24576000\n",
      "current iter: 4056000/24576000\n",
      "current iter: 4057000/24576000\n",
      "current iter: 4058000/24576000\n",
      "current iter: 4059000/24576000\n",
      "current iter: 4060000/24576000\n",
      "current iter: 4061000/24576000\n",
      "current iter: 4062000/24576000\n",
      "current iter: 4063000/24576000\n",
      "current iter: 4064000/24576000\n",
      "current iter: 4065000/24576000\n",
      "current iter: 4066000/24576000\n",
      "current iter: 4067000/24576000\n",
      "current iter: 4068000/24576000\n",
      "current iter: 4069000/24576000\n",
      "current iter: 4070000/24576000\n",
      "current iter: 4071000/24576000\n",
      "current iter: 4072000/24576000\n",
      "current iter: 4073000/24576000\n",
      "current iter: 4074000/24576000\n",
      "current iter: 4075000/24576000\n",
      "current iter: 4076000/24576000\n",
      "current iter: 4077000/24576000\n",
      "current iter: 4078000/24576000\n",
      "current iter: 4079000/24576000\n",
      "current iter: 4080000/24576000\n",
      "current iter: 4081000/24576000\n",
      "current iter: 4082000/24576000\n",
      "current iter: 4083000/24576000\n",
      "current iter: 4084000/24576000\n",
      "current iter: 4085000/24576000\n",
      "current iter: 4086000/24576000\n",
      "current iter: 4087000/24576000\n",
      "current iter: 4088000/24576000\n",
      "current iter: 4089000/24576000\n",
      "current iter: 4090000/24576000\n",
      "current iter: 4091000/24576000\n",
      "current iter: 4092000/24576000\n",
      "current iter: 4093000/24576000\n",
      "current iter: 4094000/24576000\n",
      "current iter: 4095000/24576000\n",
      "current iter: 4096000/24576000\n",
      "current iter: 4097000/24576000\n",
      "current iter: 4098000/24576000\n",
      "current iter: 4099000/24576000\n",
      "current iter: 4100000/24576000\n",
      "current iter: 4101000/24576000\n",
      "current iter: 4102000/24576000\n",
      "current iter: 4103000/24576000\n",
      "current iter: 4104000/24576000\n",
      "current iter: 4105000/24576000\n",
      "current iter: 4106000/24576000\n",
      "current iter: 4107000/24576000\n",
      "current iter: 4108000/24576000\n",
      "current iter: 4109000/24576000\n",
      "current iter: 4110000/24576000\n",
      "current iter: 4111000/24576000\n",
      "current iter: 4112000/24576000\n",
      "current iter: 4113000/24576000\n",
      "current iter: 4114000/24576000\n",
      "current iter: 4115000/24576000\n",
      "current iter: 4116000/24576000\n",
      "current iter: 4117000/24576000\n",
      "current iter: 4118000/24576000\n",
      "current iter: 4119000/24576000\n",
      "current iter: 4120000/24576000\n",
      "current iter: 4121000/24576000\n",
      "current iter: 4122000/24576000\n",
      "current iter: 4123000/24576000\n",
      "current iter: 4124000/24576000\n",
      "current iter: 4125000/24576000\n",
      "current iter: 4126000/24576000\n",
      "current iter: 4127000/24576000\n",
      "current iter: 4128000/24576000\n",
      "current iter: 4129000/24576000\n",
      "current iter: 4130000/24576000\n",
      "current iter: 4131000/24576000\n",
      "current iter: 4132000/24576000\n",
      "current iter: 4133000/24576000\n",
      "current iter: 4134000/24576000\n",
      "current iter: 4135000/24576000\n",
      "current iter: 4136000/24576000\n",
      "current iter: 4137000/24576000\n",
      "current iter: 4138000/24576000\n",
      "current iter: 4139000/24576000\n",
      "current iter: 4140000/24576000\n",
      "current iter: 4141000/24576000\n",
      "current iter: 4142000/24576000\n",
      "current iter: 4143000/24576000\n",
      "current iter: 4144000/24576000\n",
      "current iter: 4145000/24576000\n",
      "current iter: 4146000/24576000\n",
      "current iter: 4147000/24576000\n",
      "current iter: 4148000/24576000\n",
      "current iter: 4149000/24576000\n",
      "current iter: 4150000/24576000\n",
      "current iter: 4151000/24576000\n",
      "current iter: 4152000/24576000\n",
      "current iter: 4153000/24576000\n",
      "current iter: 4154000/24576000\n",
      "current iter: 4155000/24576000\n",
      "current iter: 4156000/24576000\n",
      "current iter: 4157000/24576000\n",
      "current iter: 4158000/24576000\n",
      "current iter: 4159000/24576000\n",
      "current iter: 4160000/24576000\n",
      "current iter: 4161000/24576000\n",
      "current iter: 4162000/24576000\n",
      "current iter: 4163000/24576000\n",
      "current iter: 4164000/24576000\n",
      "current iter: 4165000/24576000\n",
      "current iter: 4166000/24576000\n",
      "current iter: 4167000/24576000\n",
      "current iter: 4168000/24576000\n",
      "current iter: 4169000/24576000\n",
      "current iter: 4170000/24576000\n",
      "current iter: 4171000/24576000\n",
      "current iter: 4172000/24576000\n",
      "current iter: 4173000/24576000\n",
      "current iter: 4174000/24576000\n",
      "current iter: 4175000/24576000\n",
      "current iter: 4176000/24576000\n",
      "current iter: 4177000/24576000\n",
      "current iter: 4178000/24576000\n",
      "current iter: 4179000/24576000\n",
      "current iter: 4180000/24576000\n",
      "current iter: 4181000/24576000\n",
      "current iter: 4182000/24576000\n",
      "current iter: 4183000/24576000\n",
      "current iter: 4184000/24576000\n",
      "current iter: 4185000/24576000\n",
      "current iter: 4186000/24576000\n",
      "current iter: 4187000/24576000\n",
      "current iter: 4188000/24576000\n",
      "current iter: 4189000/24576000\n",
      "current iter: 4190000/24576000\n",
      "current iter: 4191000/24576000\n",
      "current iter: 4192000/24576000\n",
      "current iter: 4193000/24576000\n",
      "current iter: 4194000/24576000\n",
      "current iter: 4195000/24576000\n",
      "current iter: 4196000/24576000\n",
      "current iter: 4197000/24576000\n",
      "current iter: 4198000/24576000\n",
      "current iter: 4199000/24576000\n",
      "current iter: 4200000/24576000\n",
      "current iter: 4201000/24576000\n",
      "current iter: 4202000/24576000\n",
      "current iter: 4203000/24576000\n",
      "current iter: 4204000/24576000\n",
      "current iter: 4205000/24576000\n",
      "current iter: 4206000/24576000\n",
      "current iter: 4207000/24576000\n",
      "current iter: 4208000/24576000\n",
      "current iter: 4209000/24576000\n",
      "current iter: 4210000/24576000\n",
      "current iter: 4211000/24576000\n",
      "current iter: 4212000/24576000\n",
      "current iter: 4213000/24576000\n",
      "current iter: 4214000/24576000\n",
      "current iter: 4215000/24576000\n",
      "current iter: 4216000/24576000\n",
      "current iter: 4217000/24576000\n",
      "current iter: 4218000/24576000\n",
      "current iter: 4219000/24576000\n",
      "current iter: 4220000/24576000\n",
      "current iter: 4221000/24576000\n",
      "current iter: 4222000/24576000\n",
      "current iter: 4223000/24576000\n",
      "current iter: 4224000/24576000\n",
      "current iter: 4225000/24576000\n",
      "current iter: 4226000/24576000\n",
      "current iter: 4227000/24576000\n",
      "current iter: 4228000/24576000\n",
      "current iter: 4229000/24576000\n",
      "current iter: 4230000/24576000\n",
      "current iter: 4231000/24576000\n",
      "current iter: 4232000/24576000\n",
      "current iter: 4233000/24576000\n",
      "current iter: 4234000/24576000\n",
      "current iter: 4235000/24576000\n",
      "current iter: 4236000/24576000\n",
      "current iter: 4237000/24576000\n",
      "current iter: 4238000/24576000\n",
      "current iter: 4239000/24576000\n",
      "current iter: 4240000/24576000\n",
      "current iter: 4241000/24576000\n",
      "current iter: 4242000/24576000\n",
      "current iter: 4243000/24576000\n",
      "current iter: 4244000/24576000\n",
      "current iter: 4245000/24576000\n",
      "current iter: 4246000/24576000\n",
      "current iter: 4247000/24576000\n",
      "current iter: 4248000/24576000\n",
      "current iter: 4249000/24576000\n",
      "current iter: 4250000/24576000\n",
      "current iter: 4251000/24576000\n",
      "current iter: 4252000/24576000\n",
      "current iter: 4253000/24576000\n",
      "current iter: 4254000/24576000\n",
      "current iter: 4255000/24576000\n",
      "current iter: 4256000/24576000\n",
      "current iter: 4257000/24576000\n",
      "current iter: 4258000/24576000\n",
      "current iter: 4259000/24576000\n",
      "current iter: 4260000/24576000\n",
      "current iter: 4261000/24576000\n",
      "current iter: 4262000/24576000\n",
      "current iter: 4263000/24576000\n",
      "current iter: 4264000/24576000\n",
      "current iter: 4265000/24576000\n",
      "current iter: 4266000/24576000\n",
      "current iter: 4267000/24576000\n",
      "current iter: 4268000/24576000\n",
      "current iter: 4269000/24576000\n",
      "current iter: 4270000/24576000\n",
      "current iter: 4271000/24576000\n",
      "current iter: 4272000/24576000\n",
      "current iter: 4273000/24576000\n",
      "current iter: 4274000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 4275000/24576000\n",
      "current iter: 4276000/24576000\n",
      "current iter: 4277000/24576000\n",
      "current iter: 4278000/24576000\n",
      "current iter: 4279000/24576000\n",
      "current iter: 4280000/24576000\n",
      "current iter: 4281000/24576000\n",
      "current iter: 4282000/24576000\n",
      "current iter: 4283000/24576000\n",
      "current iter: 4284000/24576000\n",
      "current iter: 4285000/24576000\n",
      "current iter: 4286000/24576000\n",
      "current iter: 4287000/24576000\n",
      "current iter: 4288000/24576000\n",
      "current iter: 4289000/24576000\n",
      "current iter: 4290000/24576000\n",
      "current iter: 4291000/24576000\n",
      "current iter: 4292000/24576000\n",
      "current iter: 4293000/24576000\n",
      "current iter: 4294000/24576000\n",
      "current iter: 4295000/24576000\n",
      "current iter: 4296000/24576000\n",
      "current iter: 4297000/24576000\n",
      "current iter: 4298000/24576000\n",
      "current iter: 4299000/24576000\n",
      "current iter: 4300000/24576000\n",
      "current iter: 4301000/24576000\n",
      "current iter: 4302000/24576000\n",
      "current iter: 4303000/24576000\n",
      "current iter: 4304000/24576000\n",
      "current iter: 4305000/24576000\n",
      "current iter: 4306000/24576000\n",
      "current iter: 4307000/24576000\n",
      "current iter: 4308000/24576000\n",
      "current iter: 4309000/24576000\n",
      "current iter: 4310000/24576000\n",
      "current iter: 4311000/24576000\n",
      "current iter: 4312000/24576000\n",
      "current iter: 4313000/24576000\n",
      "current iter: 4314000/24576000\n",
      "current iter: 4315000/24576000\n",
      "current iter: 4316000/24576000\n",
      "current iter: 4317000/24576000\n",
      "current iter: 4318000/24576000\n",
      "current iter: 4319000/24576000\n",
      "current iter: 4320000/24576000\n",
      "current iter: 4321000/24576000\n",
      "current iter: 4322000/24576000\n",
      "current iter: 4323000/24576000\n",
      "current iter: 4324000/24576000\n",
      "current iter: 4325000/24576000\n",
      "current iter: 4326000/24576000\n",
      "current iter: 4327000/24576000\n",
      "current iter: 4328000/24576000\n",
      "current iter: 4329000/24576000\n",
      "current iter: 4330000/24576000\n",
      "current iter: 4331000/24576000\n",
      "current iter: 4332000/24576000\n",
      "current iter: 4333000/24576000\n",
      "current iter: 4334000/24576000\n",
      "current iter: 4335000/24576000\n",
      "current iter: 4336000/24576000\n",
      "current iter: 4337000/24576000\n",
      "current iter: 4338000/24576000\n",
      "current iter: 4339000/24576000\n",
      "current iter: 4340000/24576000\n",
      "current iter: 4341000/24576000\n",
      "current iter: 4342000/24576000\n",
      "current iter: 4343000/24576000\n",
      "current iter: 4344000/24576000\n",
      "current iter: 4345000/24576000\n",
      "current iter: 4346000/24576000\n",
      "current iter: 4347000/24576000\n",
      "current iter: 4348000/24576000\n",
      "current iter: 4349000/24576000\n",
      "current iter: 4350000/24576000\n",
      "current iter: 4351000/24576000\n",
      "current iter: 4352000/24576000\n",
      "current iter: 4353000/24576000\n",
      "current iter: 4354000/24576000\n",
      "current iter: 4355000/24576000\n",
      "current iter: 4356000/24576000\n",
      "current iter: 4357000/24576000\n",
      "current iter: 4358000/24576000\n",
      "current iter: 4359000/24576000\n",
      "current iter: 4360000/24576000\n",
      "current iter: 4361000/24576000\n",
      "current iter: 4362000/24576000\n",
      "current iter: 4363000/24576000\n",
      "current iter: 4364000/24576000\n",
      "current iter: 4365000/24576000\n",
      "current iter: 4366000/24576000\n",
      "current iter: 4367000/24576000\n",
      "current iter: 4368000/24576000\n",
      "current iter: 4369000/24576000\n",
      "current iter: 4370000/24576000\n",
      "current iter: 4371000/24576000\n",
      "current iter: 4372000/24576000\n",
      "current iter: 4373000/24576000\n",
      "current iter: 4374000/24576000\n",
      "current iter: 4375000/24576000\n",
      "current iter: 4376000/24576000\n",
      "current iter: 4377000/24576000\n",
      "current iter: 4378000/24576000\n",
      "current iter: 4379000/24576000\n",
      "current iter: 4380000/24576000\n",
      "current iter: 4381000/24576000\n",
      "current iter: 4382000/24576000\n",
      "current iter: 4383000/24576000\n",
      "current iter: 4384000/24576000\n",
      "current iter: 4385000/24576000\n",
      "current iter: 4386000/24576000\n",
      "current iter: 4387000/24576000\n",
      "current iter: 4388000/24576000\n",
      "current iter: 4389000/24576000\n",
      "current iter: 4390000/24576000\n",
      "current iter: 4391000/24576000\n",
      "current iter: 4392000/24576000\n",
      "current iter: 4393000/24576000\n",
      "current iter: 4394000/24576000\n",
      "current iter: 4395000/24576000\n",
      "current iter: 4396000/24576000\n",
      "current iter: 4397000/24576000\n",
      "current iter: 4398000/24576000\n",
      "current iter: 4399000/24576000\n",
      "current iter: 4400000/24576000\n",
      "current iter: 4401000/24576000\n",
      "current iter: 4402000/24576000\n",
      "current iter: 4403000/24576000\n",
      "current iter: 4404000/24576000\n",
      "current iter: 4405000/24576000\n",
      "current iter: 4406000/24576000\n",
      "current iter: 4407000/24576000\n",
      "current iter: 4408000/24576000\n",
      "current iter: 4409000/24576000\n",
      "current iter: 4410000/24576000\n",
      "current iter: 4411000/24576000\n",
      "current iter: 4412000/24576000\n",
      "current iter: 4413000/24576000\n",
      "current iter: 4414000/24576000\n",
      "current iter: 4415000/24576000\n",
      "current iter: 4416000/24576000\n",
      "current iter: 4417000/24576000\n",
      "current iter: 4418000/24576000\n",
      "current iter: 4419000/24576000\n",
      "current iter: 4420000/24576000\n",
      "current iter: 4421000/24576000\n",
      "current iter: 4422000/24576000\n",
      "current iter: 4423000/24576000\n",
      "current iter: 4424000/24576000\n",
      "current iter: 4425000/24576000\n",
      "current iter: 4426000/24576000\n",
      "current iter: 4427000/24576000\n",
      "current iter: 4428000/24576000\n",
      "current iter: 4429000/24576000\n",
      "current iter: 4430000/24576000\n",
      "current iter: 4431000/24576000\n",
      "current iter: 4432000/24576000\n",
      "current iter: 4433000/24576000\n",
      "current iter: 4434000/24576000\n",
      "current iter: 4435000/24576000\n",
      "current iter: 4436000/24576000\n",
      "current iter: 4437000/24576000\n",
      "current iter: 4438000/24576000\n",
      "current iter: 4439000/24576000\n",
      "current iter: 4440000/24576000\n",
      "current iter: 4441000/24576000\n",
      "current iter: 4442000/24576000\n",
      "current iter: 4443000/24576000\n",
      "current iter: 4444000/24576000\n",
      "current iter: 4445000/24576000\n",
      "current iter: 4446000/24576000\n",
      "current iter: 4447000/24576000\n",
      "current iter: 4448000/24576000\n",
      "current iter: 4449000/24576000\n",
      "current iter: 4450000/24576000\n",
      "current iter: 4451000/24576000\n",
      "current iter: 4452000/24576000\n",
      "current iter: 4453000/24576000\n",
      "current iter: 4454000/24576000\n",
      "current iter: 4455000/24576000\n",
      "current iter: 4456000/24576000\n",
      "current iter: 4457000/24576000\n",
      "current iter: 4458000/24576000\n",
      "current iter: 4459000/24576000\n",
      "current iter: 4460000/24576000\n",
      "current iter: 4461000/24576000\n",
      "current iter: 4462000/24576000\n",
      "current iter: 4463000/24576000\n",
      "current iter: 4464000/24576000\n",
      "current iter: 4465000/24576000\n",
      "current iter: 4466000/24576000\n",
      "current iter: 4467000/24576000\n",
      "current iter: 4468000/24576000\n",
      "current iter: 4469000/24576000\n",
      "current iter: 4470000/24576000\n",
      "current iter: 4471000/24576000\n",
      "current iter: 4472000/24576000\n",
      "current iter: 4473000/24576000\n",
      "current iter: 4474000/24576000\n",
      "current iter: 4475000/24576000\n",
      "current iter: 4476000/24576000\n",
      "current iter: 4477000/24576000\n",
      "current iter: 4478000/24576000\n",
      "current iter: 4479000/24576000\n",
      "current iter: 4480000/24576000\n",
      "current iter: 4481000/24576000\n",
      "current iter: 4482000/24576000\n",
      "current iter: 4483000/24576000\n",
      "current iter: 4484000/24576000\n",
      "current iter: 4485000/24576000\n",
      "current iter: 4486000/24576000\n",
      "current iter: 4487000/24576000\n",
      "current iter: 4488000/24576000\n",
      "current iter: 4489000/24576000\n",
      "current iter: 4490000/24576000\n",
      "current iter: 4491000/24576000\n",
      "current iter: 4492000/24576000\n",
      "current iter: 4493000/24576000\n",
      "current iter: 4494000/24576000\n",
      "current iter: 4495000/24576000\n",
      "current iter: 4496000/24576000\n",
      "current iter: 4497000/24576000\n",
      "current iter: 4498000/24576000\n",
      "current iter: 4499000/24576000\n",
      "current iter: 4500000/24576000\n",
      "current iter: 4501000/24576000\n",
      "current iter: 4502000/24576000\n",
      "current iter: 4503000/24576000\n",
      "current iter: 4504000/24576000\n",
      "current iter: 4505000/24576000\n",
      "current iter: 4506000/24576000\n",
      "current iter: 4507000/24576000\n",
      "current iter: 4508000/24576000\n",
      "current iter: 4509000/24576000\n",
      "current iter: 4510000/24576000\n",
      "current iter: 4511000/24576000\n",
      "current iter: 4512000/24576000\n",
      "current iter: 4513000/24576000\n",
      "current iter: 4514000/24576000\n",
      "current iter: 4515000/24576000\n",
      "current iter: 4516000/24576000\n",
      "current iter: 4517000/24576000\n",
      "current iter: 4518000/24576000\n",
      "current iter: 4519000/24576000\n",
      "current iter: 4520000/24576000\n",
      "current iter: 4521000/24576000\n",
      "current iter: 4522000/24576000\n",
      "current iter: 4523000/24576000\n",
      "current iter: 4524000/24576000\n",
      "current iter: 4525000/24576000\n",
      "current iter: 4526000/24576000\n",
      "current iter: 4527000/24576000\n",
      "current iter: 4528000/24576000\n",
      "current iter: 4529000/24576000\n",
      "current iter: 4530000/24576000\n",
      "current iter: 4531000/24576000\n",
      "current iter: 4532000/24576000\n",
      "current iter: 4533000/24576000\n",
      "current iter: 4534000/24576000\n",
      "current iter: 4535000/24576000\n",
      "current iter: 4536000/24576000\n",
      "current iter: 4537000/24576000\n",
      "current iter: 4538000/24576000\n",
      "current iter: 4539000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 4540000/24576000\n",
      "current iter: 4541000/24576000\n",
      "current iter: 4542000/24576000\n",
      "current iter: 4543000/24576000\n",
      "current iter: 4544000/24576000\n",
      "current iter: 4545000/24576000\n",
      "current iter: 4546000/24576000\n",
      "current iter: 4547000/24576000\n",
      "current iter: 4548000/24576000\n",
      "current iter: 4549000/24576000\n",
      "current iter: 4550000/24576000\n",
      "current iter: 4551000/24576000\n",
      "current iter: 4552000/24576000\n",
      "current iter: 4553000/24576000\n",
      "current iter: 4554000/24576000\n",
      "current iter: 4555000/24576000\n",
      "current iter: 4556000/24576000\n",
      "current iter: 4557000/24576000\n",
      "current iter: 4558000/24576000\n",
      "current iter: 4559000/24576000\n",
      "current iter: 4560000/24576000\n",
      "current iter: 4561000/24576000\n",
      "current iter: 4562000/24576000\n",
      "current iter: 4563000/24576000\n",
      "current iter: 4564000/24576000\n",
      "current iter: 4565000/24576000\n",
      "current iter: 4566000/24576000\n",
      "current iter: 4567000/24576000\n",
      "current iter: 4568000/24576000\n",
      "current iter: 4569000/24576000\n",
      "current iter: 4570000/24576000\n",
      "current iter: 4571000/24576000\n",
      "current iter: 4572000/24576000\n",
      "current iter: 4573000/24576000\n",
      "current iter: 4574000/24576000\n",
      "current iter: 4575000/24576000\n",
      "current iter: 4576000/24576000\n",
      "current iter: 4577000/24576000\n",
      "current iter: 4578000/24576000\n",
      "current iter: 4579000/24576000\n",
      "current iter: 4580000/24576000\n",
      "current iter: 4581000/24576000\n",
      "current iter: 4582000/24576000\n",
      "current iter: 4583000/24576000\n",
      "current iter: 4584000/24576000\n",
      "current iter: 4585000/24576000\n",
      "current iter: 4586000/24576000\n",
      "current iter: 4587000/24576000\n",
      "current iter: 4588000/24576000\n",
      "current iter: 4589000/24576000\n",
      "current iter: 4590000/24576000\n",
      "current iter: 4591000/24576000\n",
      "current iter: 4592000/24576000\n",
      "current iter: 4593000/24576000\n",
      "current iter: 4594000/24576000\n",
      "current iter: 4595000/24576000\n",
      "current iter: 4596000/24576000\n",
      "current iter: 4597000/24576000\n",
      "current iter: 4598000/24576000\n",
      "current iter: 4599000/24576000\n",
      "current iter: 4600000/24576000\n",
      "current iter: 4601000/24576000\n",
      "current iter: 4602000/24576000\n",
      "current iter: 4603000/24576000\n",
      "current iter: 4604000/24576000\n",
      "current iter: 4605000/24576000\n",
      "current iter: 4606000/24576000\n",
      "current iter: 4607000/24576000\n",
      "current iter: 4608000/24576000\n",
      "current iter: 4609000/24576000\n",
      "current iter: 4610000/24576000\n",
      "current iter: 4611000/24576000\n",
      "current iter: 4612000/24576000\n",
      "current iter: 4613000/24576000\n",
      "current iter: 4614000/24576000\n",
      "current iter: 4615000/24576000\n",
      "current iter: 4616000/24576000\n",
      "current iter: 4617000/24576000\n",
      "current iter: 4618000/24576000\n",
      "current iter: 4619000/24576000\n",
      "current iter: 4620000/24576000\n",
      "current iter: 4621000/24576000\n",
      "current iter: 4622000/24576000\n",
      "current iter: 4623000/24576000\n",
      "current iter: 4624000/24576000\n",
      "current iter: 4625000/24576000\n",
      "current iter: 4626000/24576000\n",
      "current iter: 4627000/24576000\n",
      "current iter: 4628000/24576000\n",
      "current iter: 4629000/24576000\n",
      "current iter: 4630000/24576000\n",
      "current iter: 4631000/24576000\n",
      "current iter: 4632000/24576000\n",
      "current iter: 4633000/24576000\n",
      "current iter: 4634000/24576000\n",
      "current iter: 4635000/24576000\n",
      "current iter: 4636000/24576000\n",
      "current iter: 4637000/24576000\n",
      "current iter: 4638000/24576000\n",
      "current iter: 4639000/24576000\n",
      "current iter: 4640000/24576000\n",
      "current iter: 4641000/24576000\n",
      "current iter: 4642000/24576000\n",
      "current iter: 4643000/24576000\n",
      "current iter: 4644000/24576000\n",
      "current iter: 4645000/24576000\n",
      "current iter: 4646000/24576000\n",
      "current iter: 4647000/24576000\n",
      "current iter: 4648000/24576000\n",
      "current iter: 4649000/24576000\n",
      "current iter: 4650000/24576000\n",
      "current iter: 4651000/24576000\n",
      "current iter: 4652000/24576000\n",
      "current iter: 4653000/24576000\n",
      "current iter: 4654000/24576000\n",
      "current iter: 4655000/24576000\n",
      "current iter: 4656000/24576000\n",
      "current iter: 4657000/24576000\n",
      "current iter: 4658000/24576000\n",
      "current iter: 4659000/24576000\n",
      "current iter: 4660000/24576000\n",
      "current iter: 4661000/24576000\n",
      "current iter: 4662000/24576000\n",
      "current iter: 4663000/24576000\n",
      "current iter: 4664000/24576000\n",
      "current iter: 4665000/24576000\n",
      "current iter: 4666000/24576000\n",
      "current iter: 4667000/24576000\n",
      "current iter: 4668000/24576000\n",
      "current iter: 4669000/24576000\n",
      "current iter: 4670000/24576000\n",
      "current iter: 4671000/24576000\n",
      "current iter: 4672000/24576000\n",
      "current iter: 4673000/24576000\n",
      "current iter: 4674000/24576000\n",
      "current iter: 4675000/24576000\n",
      "current iter: 4676000/24576000\n",
      "current iter: 4677000/24576000\n",
      "current iter: 4678000/24576000\n",
      "current iter: 4679000/24576000\n",
      "current iter: 4680000/24576000\n",
      "current iter: 4681000/24576000\n",
      "current iter: 4682000/24576000\n",
      "current iter: 4683000/24576000\n",
      "current iter: 4684000/24576000\n",
      "current iter: 4685000/24576000\n",
      "current iter: 4686000/24576000\n",
      "current iter: 4687000/24576000\n",
      "current iter: 4688000/24576000\n",
      "current iter: 4689000/24576000\n",
      "current iter: 4690000/24576000\n",
      "current iter: 4691000/24576000\n",
      "current iter: 4692000/24576000\n",
      "current iter: 4693000/24576000\n",
      "current iter: 4694000/24576000\n",
      "current iter: 4695000/24576000\n",
      "current iter: 4696000/24576000\n",
      "current iter: 4697000/24576000\n",
      "current iter: 4698000/24576000\n",
      "current iter: 4699000/24576000\n",
      "current iter: 4700000/24576000\n",
      "current iter: 4701000/24576000\n",
      "current iter: 4702000/24576000\n",
      "current iter: 4703000/24576000\n",
      "current iter: 4704000/24576000\n",
      "current iter: 4705000/24576000\n",
      "current iter: 4706000/24576000\n",
      "current iter: 4707000/24576000\n",
      "current iter: 4708000/24576000\n",
      "current iter: 4709000/24576000\n",
      "current iter: 4710000/24576000\n",
      "current iter: 4711000/24576000\n",
      "current iter: 4712000/24576000\n",
      "current iter: 4713000/24576000\n",
      "current iter: 4714000/24576000\n",
      "current iter: 4715000/24576000\n",
      "current iter: 4716000/24576000\n",
      "current iter: 4717000/24576000\n",
      "current iter: 4718000/24576000\n",
      "current iter: 4719000/24576000\n",
      "current iter: 4720000/24576000\n",
      "current iter: 4721000/24576000\n",
      "current iter: 4722000/24576000\n",
      "current iter: 4723000/24576000\n",
      "current iter: 4724000/24576000\n",
      "current iter: 4725000/24576000\n",
      "current iter: 4726000/24576000\n",
      "current iter: 4727000/24576000\n",
      "current iter: 4728000/24576000\n",
      "current iter: 4729000/24576000\n",
      "current iter: 4730000/24576000\n",
      "current iter: 4731000/24576000\n",
      "current iter: 4732000/24576000\n",
      "current iter: 4733000/24576000\n",
      "current iter: 4734000/24576000\n",
      "current iter: 4735000/24576000\n",
      "current iter: 4736000/24576000\n",
      "current iter: 4737000/24576000\n",
      "current iter: 4738000/24576000\n",
      "current iter: 4739000/24576000\n",
      "current iter: 4740000/24576000\n",
      "current iter: 4741000/24576000\n",
      "current iter: 4742000/24576000\n",
      "current iter: 4743000/24576000\n",
      "current iter: 4744000/24576000\n",
      "current iter: 4745000/24576000\n",
      "current iter: 4746000/24576000\n",
      "current iter: 4747000/24576000\n",
      "current iter: 4748000/24576000\n",
      "current iter: 4749000/24576000\n",
      "current iter: 4750000/24576000\n",
      "current iter: 4751000/24576000\n",
      "current iter: 4752000/24576000\n",
      "current iter: 4753000/24576000\n",
      "current iter: 4754000/24576000\n",
      "current iter: 4755000/24576000\n",
      "current iter: 4756000/24576000\n",
      "current iter: 4757000/24576000\n",
      "current iter: 4758000/24576000\n",
      "current iter: 4759000/24576000\n",
      "current iter: 4760000/24576000\n",
      "current iter: 4761000/24576000\n",
      "current iter: 4762000/24576000\n",
      "current iter: 4763000/24576000\n",
      "current iter: 4764000/24576000\n",
      "current iter: 4765000/24576000\n",
      "current iter: 4766000/24576000\n",
      "current iter: 4767000/24576000\n",
      "current iter: 4768000/24576000\n",
      "current iter: 4769000/24576000\n",
      "current iter: 4770000/24576000\n",
      "current iter: 4771000/24576000\n",
      "current iter: 4772000/24576000\n",
      "current iter: 4773000/24576000\n",
      "current iter: 4774000/24576000\n",
      "current iter: 4775000/24576000\n",
      "current iter: 4776000/24576000\n",
      "current iter: 4777000/24576000\n",
      "current iter: 4778000/24576000\n",
      "current iter: 4779000/24576000\n",
      "current iter: 4780000/24576000\n",
      "current iter: 4781000/24576000\n",
      "current iter: 4782000/24576000\n",
      "current iter: 4783000/24576000\n",
      "current iter: 4784000/24576000\n",
      "current iter: 4785000/24576000\n",
      "current iter: 4786000/24576000\n",
      "current iter: 4787000/24576000\n",
      "current iter: 4788000/24576000\n",
      "current iter: 4789000/24576000\n",
      "current iter: 4790000/24576000\n",
      "current iter: 4791000/24576000\n",
      "current iter: 4792000/24576000\n",
      "current iter: 4793000/24576000\n",
      "current iter: 4794000/24576000\n",
      "current iter: 4795000/24576000\n",
      "current iter: 4796000/24576000\n",
      "current iter: 4797000/24576000\n",
      "current iter: 4798000/24576000\n",
      "current iter: 4799000/24576000\n",
      "current iter: 4800000/24576000\n",
      "current iter: 4801000/24576000\n",
      "current iter: 4802000/24576000\n",
      "current iter: 4803000/24576000\n",
      "current iter: 4804000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 4805000/24576000\n",
      "current iter: 4806000/24576000\n",
      "current iter: 4807000/24576000\n",
      "current iter: 4808000/24576000\n",
      "current iter: 4809000/24576000\n",
      "current iter: 4810000/24576000\n",
      "current iter: 4811000/24576000\n",
      "current iter: 4812000/24576000\n",
      "current iter: 4813000/24576000\n",
      "current iter: 4814000/24576000\n",
      "current iter: 4815000/24576000\n",
      "current iter: 4816000/24576000\n",
      "current iter: 4817000/24576000\n",
      "current iter: 4818000/24576000\n",
      "current iter: 4819000/24576000\n",
      "current iter: 4820000/24576000\n",
      "current iter: 4821000/24576000\n",
      "current iter: 4822000/24576000\n",
      "current iter: 4823000/24576000\n",
      "current iter: 4824000/24576000\n",
      "current iter: 4825000/24576000\n",
      "current iter: 4826000/24576000\n",
      "current iter: 4827000/24576000\n",
      "current iter: 4828000/24576000\n",
      "current iter: 4829000/24576000\n",
      "current iter: 4830000/24576000\n",
      "current iter: 4831000/24576000\n",
      "current iter: 4832000/24576000\n",
      "current iter: 4833000/24576000\n",
      "current iter: 4834000/24576000\n",
      "current iter: 4835000/24576000\n",
      "current iter: 4836000/24576000\n",
      "current iter: 4837000/24576000\n",
      "current iter: 4838000/24576000\n",
      "current iter: 4839000/24576000\n",
      "current iter: 4840000/24576000\n",
      "current iter: 4841000/24576000\n",
      "current iter: 4842000/24576000\n",
      "current iter: 4843000/24576000\n",
      "current iter: 4844000/24576000\n",
      "current iter: 4845000/24576000\n",
      "current iter: 4846000/24576000\n",
      "current iter: 4847000/24576000\n",
      "current iter: 4848000/24576000\n",
      "current iter: 4849000/24576000\n",
      "current iter: 4850000/24576000\n",
      "current iter: 4851000/24576000\n",
      "current iter: 4852000/24576000\n",
      "current iter: 4853000/24576000\n",
      "current iter: 4854000/24576000\n",
      "current iter: 4855000/24576000\n",
      "current iter: 4856000/24576000\n",
      "current iter: 4857000/24576000\n",
      "current iter: 4858000/24576000\n",
      "current iter: 4859000/24576000\n",
      "current iter: 4860000/24576000\n",
      "current iter: 4861000/24576000\n",
      "current iter: 4862000/24576000\n",
      "current iter: 4863000/24576000\n",
      "current iter: 4864000/24576000\n",
      "current iter: 4865000/24576000\n",
      "current iter: 4866000/24576000\n",
      "current iter: 4867000/24576000\n",
      "current iter: 4868000/24576000\n",
      "current iter: 4869000/24576000\n",
      "current iter: 4870000/24576000\n",
      "current iter: 4871000/24576000\n",
      "current iter: 4872000/24576000\n",
      "current iter: 4873000/24576000\n",
      "current iter: 4874000/24576000\n",
      "current iter: 4875000/24576000\n",
      "current iter: 4876000/24576000\n",
      "current iter: 4877000/24576000\n",
      "current iter: 4878000/24576000\n",
      "current iter: 4879000/24576000\n",
      "current iter: 4880000/24576000\n",
      "current iter: 4881000/24576000\n",
      "current iter: 4882000/24576000\n",
      "current iter: 4883000/24576000\n",
      "current iter: 4884000/24576000\n",
      "current iter: 4885000/24576000\n",
      "current iter: 4886000/24576000\n",
      "current iter: 4887000/24576000\n",
      "current iter: 4888000/24576000\n",
      "current iter: 4889000/24576000\n",
      "current iter: 4890000/24576000\n",
      "current iter: 4891000/24576000\n",
      "current iter: 4892000/24576000\n",
      "current iter: 4893000/24576000\n",
      "current iter: 4894000/24576000\n",
      "current iter: 4895000/24576000\n",
      "current iter: 4896000/24576000\n",
      "current iter: 4897000/24576000\n",
      "current iter: 4898000/24576000\n",
      "current iter: 4899000/24576000\n",
      "current iter: 4900000/24576000\n",
      "current iter: 4901000/24576000\n",
      "current iter: 4902000/24576000\n",
      "current iter: 4903000/24576000\n",
      "current iter: 4904000/24576000\n",
      "current iter: 4905000/24576000\n",
      "current iter: 4906000/24576000\n",
      "current iter: 4907000/24576000\n",
      "current iter: 4908000/24576000\n",
      "current iter: 4909000/24576000\n",
      "current iter: 4910000/24576000\n",
      "current iter: 4911000/24576000\n",
      "current iter: 4912000/24576000\n",
      "current iter: 4913000/24576000\n",
      "current iter: 4914000/24576000\n",
      "current iter: 4915000/24576000\n",
      "current iter: 4916000/24576000\n",
      "current iter: 4917000/24576000\n",
      "current iter: 4918000/24576000\n",
      "current iter: 4919000/24576000\n",
      "current iter: 4920000/24576000\n",
      "current iter: 4921000/24576000\n",
      "current iter: 4922000/24576000\n",
      "current iter: 4923000/24576000\n",
      "current iter: 4924000/24576000\n",
      "current iter: 4925000/24576000\n",
      "current iter: 4926000/24576000\n",
      "current iter: 4927000/24576000\n",
      "current iter: 4928000/24576000\n",
      "current iter: 4929000/24576000\n",
      "current iter: 4930000/24576000\n",
      "current iter: 4931000/24576000\n",
      "current iter: 4932000/24576000\n",
      "current iter: 4933000/24576000\n",
      "current iter: 4934000/24576000\n",
      "current iter: 4935000/24576000\n",
      "current iter: 4936000/24576000\n",
      "current iter: 4937000/24576000\n",
      "current iter: 4938000/24576000\n",
      "current iter: 4939000/24576000\n",
      "current iter: 4940000/24576000\n",
      "current iter: 4941000/24576000\n",
      "current iter: 4942000/24576000\n",
      "current iter: 4943000/24576000\n",
      "current iter: 4944000/24576000\n",
      "current iter: 4945000/24576000\n",
      "current iter: 4946000/24576000\n",
      "current iter: 4947000/24576000\n",
      "current iter: 4948000/24576000\n",
      "current iter: 4949000/24576000\n",
      "current iter: 4950000/24576000\n",
      "current iter: 4951000/24576000\n",
      "current iter: 4952000/24576000\n",
      "current iter: 4953000/24576000\n",
      "current iter: 4954000/24576000\n",
      "current iter: 4955000/24576000\n",
      "current iter: 4956000/24576000\n",
      "current iter: 4957000/24576000\n",
      "current iter: 4958000/24576000\n",
      "current iter: 4959000/24576000\n",
      "current iter: 4960000/24576000\n",
      "current iter: 4961000/24576000\n",
      "current iter: 4962000/24576000\n",
      "current iter: 4963000/24576000\n",
      "current iter: 4964000/24576000\n",
      "current iter: 4965000/24576000\n",
      "current iter: 4966000/24576000\n",
      "current iter: 4967000/24576000\n",
      "current iter: 4968000/24576000\n",
      "current iter: 4969000/24576000\n",
      "current iter: 4970000/24576000\n",
      "current iter: 4971000/24576000\n",
      "current iter: 4972000/24576000\n",
      "current iter: 4973000/24576000\n",
      "current iter: 4974000/24576000\n",
      "current iter: 4975000/24576000\n",
      "current iter: 4976000/24576000\n",
      "current iter: 4977000/24576000\n",
      "current iter: 4978000/24576000\n",
      "current iter: 4979000/24576000\n",
      "current iter: 4980000/24576000\n",
      "current iter: 4981000/24576000\n",
      "current iter: 4982000/24576000\n",
      "current iter: 4983000/24576000\n",
      "current iter: 4984000/24576000\n",
      "current iter: 4985000/24576000\n",
      "current iter: 4986000/24576000\n",
      "current iter: 4987000/24576000\n",
      "current iter: 4988000/24576000\n",
      "current iter: 4989000/24576000\n",
      "current iter: 4990000/24576000\n",
      "current iter: 4991000/24576000\n",
      "current iter: 4992000/24576000\n",
      "current iter: 4993000/24576000\n",
      "current iter: 4994000/24576000\n",
      "current iter: 4995000/24576000\n",
      "current iter: 4996000/24576000\n",
      "current iter: 4997000/24576000\n",
      "current iter: 4998000/24576000\n",
      "current iter: 4999000/24576000\n",
      "current iter: 5000000/24576000\n",
      "current iter: 5001000/24576000\n",
      "current iter: 5002000/24576000\n",
      "current iter: 5003000/24576000\n",
      "current iter: 5004000/24576000\n",
      "current iter: 5005000/24576000\n",
      "current iter: 5006000/24576000\n",
      "current iter: 5007000/24576000\n",
      "current iter: 5008000/24576000\n",
      "current iter: 5009000/24576000\n",
      "current iter: 5010000/24576000\n",
      "current iter: 5011000/24576000\n",
      "current iter: 5012000/24576000\n",
      "current iter: 5013000/24576000\n",
      "current iter: 5014000/24576000\n",
      "current iter: 5015000/24576000\n",
      "current iter: 5016000/24576000\n",
      "current iter: 5017000/24576000\n",
      "current iter: 5018000/24576000\n",
      "current iter: 5019000/24576000\n",
      "current iter: 5020000/24576000\n",
      "current iter: 5021000/24576000\n",
      "current iter: 5022000/24576000\n",
      "current iter: 5023000/24576000\n",
      "current iter: 5024000/24576000\n",
      "current iter: 5025000/24576000\n",
      "current iter: 5026000/24576000\n",
      "current iter: 5027000/24576000\n",
      "current iter: 5028000/24576000\n",
      "current iter: 5029000/24576000\n",
      "current iter: 5030000/24576000\n",
      "current iter: 5031000/24576000\n",
      "current iter: 5032000/24576000\n",
      "current iter: 5033000/24576000\n",
      "current iter: 5034000/24576000\n",
      "current iter: 5035000/24576000\n",
      "current iter: 5036000/24576000\n",
      "current iter: 5037000/24576000\n",
      "current iter: 5038000/24576000\n",
      "current iter: 5039000/24576000\n",
      "current iter: 5040000/24576000\n",
      "current iter: 5041000/24576000\n",
      "current iter: 5042000/24576000\n",
      "current iter: 5043000/24576000\n",
      "current iter: 5044000/24576000\n",
      "current iter: 5045000/24576000\n",
      "current iter: 5046000/24576000\n",
      "current iter: 5047000/24576000\n",
      "current iter: 5048000/24576000\n",
      "current iter: 5049000/24576000\n",
      "current iter: 5050000/24576000\n",
      "current iter: 5051000/24576000\n",
      "current iter: 5052000/24576000\n",
      "current iter: 5053000/24576000\n",
      "current iter: 5054000/24576000\n",
      "current iter: 5055000/24576000\n",
      "current iter: 5056000/24576000\n",
      "current iter: 5057000/24576000\n",
      "current iter: 5058000/24576000\n",
      "current iter: 5059000/24576000\n",
      "current iter: 5060000/24576000\n",
      "current iter: 5061000/24576000\n",
      "current iter: 5062000/24576000\n",
      "current iter: 5063000/24576000\n",
      "current iter: 5064000/24576000\n",
      "current iter: 5065000/24576000\n",
      "current iter: 5066000/24576000\n",
      "current iter: 5067000/24576000\n",
      "current iter: 5068000/24576000\n",
      "current iter: 5069000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 5070000/24576000\n",
      "current iter: 5071000/24576000\n",
      "current iter: 5072000/24576000\n",
      "current iter: 5073000/24576000\n",
      "current iter: 5074000/24576000\n",
      "current iter: 5075000/24576000\n",
      "current iter: 5076000/24576000\n",
      "current iter: 5077000/24576000\n",
      "current iter: 5078000/24576000\n",
      "current iter: 5079000/24576000\n",
      "current iter: 5080000/24576000\n",
      "current iter: 5081000/24576000\n",
      "current iter: 5082000/24576000\n",
      "current iter: 5083000/24576000\n",
      "current iter: 5084000/24576000\n",
      "current iter: 5085000/24576000\n",
      "current iter: 5086000/24576000\n",
      "current iter: 5087000/24576000\n",
      "current iter: 5088000/24576000\n",
      "current iter: 5089000/24576000\n",
      "current iter: 5090000/24576000\n",
      "current iter: 5091000/24576000\n",
      "current iter: 5092000/24576000\n",
      "current iter: 5093000/24576000\n",
      "current iter: 5094000/24576000\n",
      "current iter: 5095000/24576000\n",
      "current iter: 5096000/24576000\n",
      "current iter: 5097000/24576000\n",
      "current iter: 5098000/24576000\n",
      "current iter: 5099000/24576000\n",
      "current iter: 5100000/24576000\n",
      "current iter: 5101000/24576000\n",
      "current iter: 5102000/24576000\n",
      "current iter: 5103000/24576000\n",
      "current iter: 5104000/24576000\n",
      "current iter: 5105000/24576000\n",
      "current iter: 5106000/24576000\n",
      "current iter: 5107000/24576000\n",
      "current iter: 5108000/24576000\n",
      "current iter: 5109000/24576000\n",
      "current iter: 5110000/24576000\n",
      "current iter: 5111000/24576000\n",
      "current iter: 5112000/24576000\n",
      "current iter: 5113000/24576000\n",
      "current iter: 5114000/24576000\n",
      "current iter: 5115000/24576000\n",
      "current iter: 5116000/24576000\n",
      "current iter: 5117000/24576000\n",
      "current iter: 5118000/24576000\n",
      "current iter: 5119000/24576000\n",
      "current iter: 5120000/24576000\n",
      "current iter: 5121000/24576000\n",
      "current iter: 5122000/24576000\n",
      "current iter: 5123000/24576000\n",
      "current iter: 5124000/24576000\n",
      "current iter: 5125000/24576000\n",
      "current iter: 5126000/24576000\n",
      "current iter: 5127000/24576000\n",
      "current iter: 5128000/24576000\n",
      "current iter: 5129000/24576000\n",
      "current iter: 5130000/24576000\n",
      "current iter: 5131000/24576000\n",
      "current iter: 5132000/24576000\n",
      "current iter: 5133000/24576000\n",
      "current iter: 5134000/24576000\n",
      "current iter: 5135000/24576000\n",
      "current iter: 5136000/24576000\n",
      "current iter: 5137000/24576000\n",
      "current iter: 5138000/24576000\n",
      "current iter: 5139000/24576000\n",
      "current iter: 5140000/24576000\n",
      "current iter: 5141000/24576000\n",
      "current iter: 5142000/24576000\n",
      "current iter: 5143000/24576000\n",
      "current iter: 5144000/24576000\n",
      "current iter: 5145000/24576000\n",
      "current iter: 5146000/24576000\n",
      "current iter: 5147000/24576000\n",
      "current iter: 5148000/24576000\n",
      "current iter: 5149000/24576000\n",
      "current iter: 5150000/24576000\n",
      "current iter: 5151000/24576000\n",
      "current iter: 5152000/24576000\n",
      "current iter: 5153000/24576000\n",
      "current iter: 5154000/24576000\n",
      "current iter: 5155000/24576000\n",
      "current iter: 5156000/24576000\n",
      "current iter: 5157000/24576000\n",
      "current iter: 5158000/24576000\n",
      "current iter: 5159000/24576000\n",
      "current iter: 5160000/24576000\n",
      "current iter: 5161000/24576000\n",
      "current iter: 5162000/24576000\n",
      "current iter: 5163000/24576000\n",
      "current iter: 5164000/24576000\n",
      "current iter: 5165000/24576000\n",
      "current iter: 5166000/24576000\n",
      "current iter: 5167000/24576000\n",
      "current iter: 5168000/24576000\n",
      "current iter: 5169000/24576000\n",
      "current iter: 5170000/24576000\n",
      "current iter: 5171000/24576000\n",
      "current iter: 5172000/24576000\n",
      "current iter: 5173000/24576000\n",
      "current iter: 5174000/24576000\n",
      "current iter: 5175000/24576000\n",
      "current iter: 5176000/24576000\n",
      "current iter: 5177000/24576000\n",
      "current iter: 5178000/24576000\n",
      "current iter: 5179000/24576000\n",
      "current iter: 5180000/24576000\n",
      "current iter: 5181000/24576000\n",
      "current iter: 5182000/24576000\n",
      "current iter: 5183000/24576000\n",
      "current iter: 5184000/24576000\n",
      "current iter: 5185000/24576000\n",
      "current iter: 5186000/24576000\n",
      "current iter: 5187000/24576000\n",
      "current iter: 5188000/24576000\n",
      "current iter: 5189000/24576000\n",
      "current iter: 5190000/24576000\n",
      "current iter: 5191000/24576000\n",
      "current iter: 5192000/24576000\n",
      "current iter: 5193000/24576000\n",
      "current iter: 5194000/24576000\n",
      "current iter: 5195000/24576000\n",
      "current iter: 5196000/24576000\n",
      "current iter: 5197000/24576000\n",
      "current iter: 5198000/24576000\n",
      "current iter: 5199000/24576000\n",
      "current iter: 5200000/24576000\n",
      "current iter: 5201000/24576000\n",
      "current iter: 5202000/24576000\n",
      "current iter: 5203000/24576000\n",
      "current iter: 5204000/24576000\n",
      "current iter: 5205000/24576000\n",
      "current iter: 5206000/24576000\n",
      "current iter: 5207000/24576000\n",
      "current iter: 5208000/24576000\n",
      "current iter: 5209000/24576000\n",
      "current iter: 5210000/24576000\n",
      "current iter: 5211000/24576000\n",
      "current iter: 5212000/24576000\n",
      "current iter: 5213000/24576000\n",
      "current iter: 5214000/24576000\n",
      "current iter: 5215000/24576000\n",
      "current iter: 5216000/24576000\n",
      "current iter: 5217000/24576000\n",
      "current iter: 5218000/24576000\n",
      "current iter: 5219000/24576000\n",
      "current iter: 5220000/24576000\n",
      "current iter: 5221000/24576000\n",
      "current iter: 5222000/24576000\n",
      "current iter: 5223000/24576000\n",
      "current iter: 5224000/24576000\n",
      "current iter: 5225000/24576000\n",
      "current iter: 5226000/24576000\n",
      "current iter: 5227000/24576000\n",
      "current iter: 5228000/24576000\n",
      "current iter: 5229000/24576000\n",
      "current iter: 5230000/24576000\n",
      "current iter: 5231000/24576000\n",
      "current iter: 5232000/24576000\n",
      "current iter: 5233000/24576000\n",
      "current iter: 5234000/24576000\n",
      "current iter: 5235000/24576000\n",
      "current iter: 5236000/24576000\n",
      "current iter: 5237000/24576000\n",
      "current iter: 5238000/24576000\n",
      "current iter: 5239000/24576000\n",
      "current iter: 5240000/24576000\n",
      "current iter: 5241000/24576000\n",
      "current iter: 5242000/24576000\n",
      "current iter: 5243000/24576000\n",
      "current iter: 5244000/24576000\n",
      "current iter: 5245000/24576000\n",
      "current iter: 5246000/24576000\n",
      "current iter: 5247000/24576000\n",
      "current iter: 5248000/24576000\n",
      "current iter: 5249000/24576000\n",
      "current iter: 5250000/24576000\n",
      "current iter: 5251000/24576000\n",
      "current iter: 5252000/24576000\n",
      "current iter: 5253000/24576000\n",
      "current iter: 5254000/24576000\n",
      "current iter: 5255000/24576000\n",
      "current iter: 5256000/24576000\n",
      "current iter: 5257000/24576000\n",
      "current iter: 5258000/24576000\n",
      "current iter: 5259000/24576000\n",
      "current iter: 5260000/24576000\n",
      "current iter: 5261000/24576000\n",
      "current iter: 5262000/24576000\n",
      "current iter: 5263000/24576000\n",
      "current iter: 5264000/24576000\n",
      "current iter: 5265000/24576000\n",
      "current iter: 5266000/24576000\n",
      "current iter: 5267000/24576000\n",
      "current iter: 5268000/24576000\n",
      "current iter: 5269000/24576000\n",
      "current iter: 5270000/24576000\n",
      "current iter: 5271000/24576000\n",
      "current iter: 5272000/24576000\n",
      "current iter: 5273000/24576000\n",
      "current iter: 5274000/24576000\n",
      "current iter: 5275000/24576000\n",
      "current iter: 5276000/24576000\n",
      "current iter: 5277000/24576000\n",
      "current iter: 5278000/24576000\n",
      "current iter: 5279000/24576000\n",
      "current iter: 5280000/24576000\n",
      "current iter: 5281000/24576000\n",
      "current iter: 5282000/24576000\n",
      "current iter: 5283000/24576000\n",
      "current iter: 5284000/24576000\n",
      "current iter: 5285000/24576000\n",
      "current iter: 5286000/24576000\n",
      "current iter: 5287000/24576000\n",
      "current iter: 5288000/24576000\n",
      "current iter: 5289000/24576000\n",
      "current iter: 5290000/24576000\n",
      "current iter: 5291000/24576000\n",
      "current iter: 5292000/24576000\n",
      "current iter: 5293000/24576000\n",
      "current iter: 5294000/24576000\n",
      "current iter: 5295000/24576000\n",
      "current iter: 5296000/24576000\n",
      "current iter: 5297000/24576000\n",
      "current iter: 5298000/24576000\n",
      "current iter: 5299000/24576000\n",
      "current iter: 5300000/24576000\n",
      "current iter: 5301000/24576000\n",
      "current iter: 5302000/24576000\n",
      "current iter: 5303000/24576000\n",
      "current iter: 5304000/24576000\n",
      "current iter: 5305000/24576000\n",
      "current iter: 5306000/24576000\n",
      "current iter: 5307000/24576000\n",
      "current iter: 5308000/24576000\n",
      "current iter: 5309000/24576000\n",
      "current iter: 5310000/24576000\n",
      "current iter: 5311000/24576000\n",
      "current iter: 5312000/24576000\n",
      "current iter: 5313000/24576000\n",
      "current iter: 5314000/24576000\n",
      "current iter: 5315000/24576000\n",
      "current iter: 5316000/24576000\n",
      "current iter: 5317000/24576000\n",
      "current iter: 5318000/24576000\n",
      "current iter: 5319000/24576000\n",
      "current iter: 5320000/24576000\n",
      "current iter: 5321000/24576000\n",
      "current iter: 5322000/24576000\n",
      "current iter: 5323000/24576000\n",
      "current iter: 5324000/24576000\n",
      "current iter: 5325000/24576000\n",
      "current iter: 5326000/24576000\n",
      "current iter: 5327000/24576000\n",
      "current iter: 5328000/24576000\n",
      "current iter: 5329000/24576000\n",
      "current iter: 5330000/24576000\n",
      "current iter: 5331000/24576000\n",
      "current iter: 5332000/24576000\n",
      "current iter: 5333000/24576000\n",
      "current iter: 5334000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 5335000/24576000\n",
      "current iter: 5336000/24576000\n",
      "current iter: 5337000/24576000\n",
      "current iter: 5338000/24576000\n",
      "current iter: 5339000/24576000\n",
      "current iter: 5340000/24576000\n",
      "current iter: 5341000/24576000\n",
      "current iter: 5342000/24576000\n",
      "current iter: 5343000/24576000\n",
      "current iter: 5344000/24576000\n",
      "current iter: 5345000/24576000\n",
      "current iter: 5346000/24576000\n",
      "current iter: 5347000/24576000\n",
      "current iter: 5348000/24576000\n",
      "current iter: 5349000/24576000\n",
      "current iter: 5350000/24576000\n",
      "current iter: 5351000/24576000\n",
      "current iter: 5352000/24576000\n",
      "current iter: 5353000/24576000\n",
      "current iter: 5354000/24576000\n",
      "current iter: 5355000/24576000\n",
      "current iter: 5356000/24576000\n",
      "current iter: 5357000/24576000\n",
      "current iter: 5358000/24576000\n",
      "current iter: 5359000/24576000\n",
      "current iter: 5360000/24576000\n",
      "current iter: 5361000/24576000\n",
      "current iter: 5362000/24576000\n",
      "current iter: 5363000/24576000\n",
      "current iter: 5364000/24576000\n",
      "current iter: 5365000/24576000\n",
      "current iter: 5366000/24576000\n",
      "current iter: 5367000/24576000\n",
      "current iter: 5368000/24576000\n",
      "current iter: 5369000/24576000\n",
      "current iter: 5370000/24576000\n",
      "current iter: 5371000/24576000\n",
      "current iter: 5372000/24576000\n",
      "current iter: 5373000/24576000\n",
      "current iter: 5374000/24576000\n",
      "current iter: 5375000/24576000\n",
      "current iter: 5376000/24576000\n",
      "current iter: 5377000/24576000\n",
      "current iter: 5378000/24576000\n",
      "current iter: 5379000/24576000\n",
      "current iter: 5380000/24576000\n",
      "current iter: 5381000/24576000\n",
      "current iter: 5382000/24576000\n",
      "current iter: 5383000/24576000\n",
      "current iter: 5384000/24576000\n",
      "current iter: 5385000/24576000\n",
      "current iter: 5386000/24576000\n",
      "current iter: 5387000/24576000\n",
      "current iter: 5388000/24576000\n",
      "current iter: 5389000/24576000\n",
      "current iter: 5390000/24576000\n",
      "current iter: 5391000/24576000\n",
      "current iter: 5392000/24576000\n",
      "current iter: 5393000/24576000\n",
      "current iter: 5394000/24576000\n",
      "current iter: 5395000/24576000\n",
      "current iter: 5396000/24576000\n",
      "current iter: 5397000/24576000\n",
      "current iter: 5398000/24576000\n",
      "current iter: 5399000/24576000\n",
      "current iter: 5400000/24576000\n",
      "current iter: 5401000/24576000\n",
      "current iter: 5402000/24576000\n",
      "current iter: 5403000/24576000\n",
      "current iter: 5404000/24576000\n",
      "current iter: 5405000/24576000\n",
      "current iter: 5406000/24576000\n",
      "current iter: 5407000/24576000\n",
      "current iter: 5408000/24576000\n",
      "current iter: 5409000/24576000\n",
      "current iter: 5410000/24576000\n",
      "current iter: 5411000/24576000\n",
      "current iter: 5412000/24576000\n",
      "current iter: 5413000/24576000\n",
      "current iter: 5414000/24576000\n",
      "current iter: 5415000/24576000\n",
      "current iter: 5416000/24576000\n",
      "current iter: 5417000/24576000\n",
      "current iter: 5418000/24576000\n",
      "current iter: 5419000/24576000\n",
      "current iter: 5420000/24576000\n",
      "current iter: 5421000/24576000\n",
      "current iter: 5422000/24576000\n",
      "current iter: 5423000/24576000\n",
      "current iter: 5424000/24576000\n",
      "current iter: 5425000/24576000\n",
      "current iter: 5426000/24576000\n",
      "current iter: 5427000/24576000\n",
      "current iter: 5428000/24576000\n",
      "current iter: 5429000/24576000\n",
      "current iter: 5430000/24576000\n",
      "current iter: 5431000/24576000\n",
      "current iter: 5432000/24576000\n",
      "current iter: 5433000/24576000\n",
      "current iter: 5434000/24576000\n",
      "current iter: 5435000/24576000\n",
      "current iter: 5436000/24576000\n",
      "current iter: 5437000/24576000\n",
      "current iter: 5438000/24576000\n",
      "current iter: 5439000/24576000\n",
      "current iter: 5440000/24576000\n",
      "current iter: 5441000/24576000\n",
      "current iter: 5442000/24576000\n",
      "current iter: 5443000/24576000\n",
      "current iter: 5444000/24576000\n",
      "current iter: 5445000/24576000\n",
      "current iter: 5446000/24576000\n",
      "current iter: 5447000/24576000\n",
      "current iter: 5448000/24576000\n",
      "current iter: 5449000/24576000\n",
      "current iter: 5450000/24576000\n",
      "current iter: 5451000/24576000\n",
      "current iter: 5452000/24576000\n",
      "current iter: 5453000/24576000\n",
      "current iter: 5454000/24576000\n",
      "current iter: 5455000/24576000\n",
      "current iter: 5456000/24576000\n",
      "current iter: 5457000/24576000\n",
      "current iter: 5458000/24576000\n",
      "current iter: 5459000/24576000\n",
      "current iter: 5460000/24576000\n",
      "current iter: 5461000/24576000\n",
      "current iter: 5462000/24576000\n",
      "current iter: 5463000/24576000\n",
      "current iter: 5464000/24576000\n",
      "current iter: 5465000/24576000\n",
      "current iter: 5466000/24576000\n",
      "current iter: 5467000/24576000\n",
      "current iter: 5468000/24576000\n",
      "current iter: 5469000/24576000\n",
      "current iter: 5470000/24576000\n",
      "current iter: 5471000/24576000\n",
      "current iter: 5472000/24576000\n",
      "current iter: 5473000/24576000\n",
      "current iter: 5474000/24576000\n",
      "current iter: 5475000/24576000\n",
      "current iter: 5476000/24576000\n",
      "current iter: 5477000/24576000\n",
      "current iter: 5478000/24576000\n",
      "current iter: 5479000/24576000\n",
      "current iter: 5480000/24576000\n",
      "current iter: 5481000/24576000\n",
      "current iter: 5482000/24576000\n",
      "current iter: 5483000/24576000\n",
      "current iter: 5484000/24576000\n",
      "current iter: 5485000/24576000\n",
      "current iter: 5486000/24576000\n",
      "current iter: 5487000/24576000\n",
      "current iter: 5488000/24576000\n",
      "current iter: 5489000/24576000\n",
      "current iter: 5490000/24576000\n",
      "current iter: 5491000/24576000\n",
      "current iter: 5492000/24576000\n",
      "current iter: 5493000/24576000\n",
      "current iter: 5494000/24576000\n",
      "current iter: 5495000/24576000\n",
      "current iter: 5496000/24576000\n",
      "current iter: 5497000/24576000\n",
      "current iter: 5498000/24576000\n",
      "current iter: 5499000/24576000\n",
      "current iter: 5500000/24576000\n",
      "current iter: 5501000/24576000\n",
      "current iter: 5502000/24576000\n",
      "current iter: 5503000/24576000\n",
      "current iter: 5504000/24576000\n",
      "current iter: 5505000/24576000\n",
      "current iter: 5506000/24576000\n",
      "current iter: 5507000/24576000\n",
      "current iter: 5508000/24576000\n",
      "current iter: 5509000/24576000\n",
      "current iter: 5510000/24576000\n",
      "current iter: 5511000/24576000\n",
      "current iter: 5512000/24576000\n",
      "current iter: 5513000/24576000\n",
      "current iter: 5514000/24576000\n",
      "current iter: 5515000/24576000\n",
      "current iter: 5516000/24576000\n",
      "current iter: 5517000/24576000\n",
      "current iter: 5518000/24576000\n",
      "current iter: 5519000/24576000\n",
      "current iter: 5520000/24576000\n",
      "current iter: 5521000/24576000\n",
      "current iter: 5522000/24576000\n",
      "current iter: 5523000/24576000\n",
      "current iter: 5524000/24576000\n",
      "current iter: 5525000/24576000\n",
      "current iter: 5526000/24576000\n",
      "current iter: 5527000/24576000\n",
      "current iter: 5528000/24576000\n",
      "current iter: 5529000/24576000\n",
      "current iter: 5530000/24576000\n",
      "current iter: 5531000/24576000\n",
      "current iter: 5532000/24576000\n",
      "current iter: 5533000/24576000\n",
      "current iter: 5534000/24576000\n",
      "current iter: 5535000/24576000\n",
      "current iter: 5536000/24576000\n",
      "current iter: 5537000/24576000\n",
      "current iter: 5538000/24576000\n",
      "current iter: 5539000/24576000\n",
      "current iter: 5540000/24576000\n",
      "current iter: 5541000/24576000\n",
      "current iter: 5542000/24576000\n",
      "current iter: 5543000/24576000\n",
      "current iter: 5544000/24576000\n",
      "current iter: 5545000/24576000\n",
      "current iter: 5546000/24576000\n",
      "current iter: 5547000/24576000\n",
      "current iter: 5548000/24576000\n",
      "current iter: 5549000/24576000\n",
      "current iter: 5550000/24576000\n",
      "current iter: 5551000/24576000\n",
      "current iter: 5552000/24576000\n",
      "current iter: 5553000/24576000\n",
      "current iter: 5554000/24576000\n",
      "current iter: 5555000/24576000\n",
      "current iter: 5556000/24576000\n",
      "current iter: 5557000/24576000\n",
      "current iter: 5558000/24576000\n",
      "current iter: 5559000/24576000\n",
      "current iter: 5560000/24576000\n",
      "current iter: 5561000/24576000\n",
      "current iter: 5562000/24576000\n",
      "current iter: 5563000/24576000\n",
      "current iter: 5564000/24576000\n",
      "current iter: 5565000/24576000\n",
      "current iter: 5566000/24576000\n",
      "current iter: 5567000/24576000\n",
      "current iter: 5568000/24576000\n",
      "current iter: 5569000/24576000\n",
      "current iter: 5570000/24576000\n",
      "current iter: 5571000/24576000\n",
      "current iter: 5572000/24576000\n",
      "current iter: 5573000/24576000\n",
      "current iter: 5574000/24576000\n",
      "current iter: 5575000/24576000\n",
      "current iter: 5576000/24576000\n",
      "current iter: 5577000/24576000\n",
      "current iter: 5578000/24576000\n",
      "current iter: 5579000/24576000\n",
      "current iter: 5580000/24576000\n",
      "current iter: 5581000/24576000\n",
      "current iter: 5582000/24576000\n",
      "current iter: 5583000/24576000\n",
      "current iter: 5584000/24576000\n",
      "current iter: 5585000/24576000\n",
      "current iter: 5586000/24576000\n",
      "current iter: 5587000/24576000\n",
      "current iter: 5588000/24576000\n",
      "current iter: 5589000/24576000\n",
      "current iter: 5590000/24576000\n",
      "current iter: 5591000/24576000\n",
      "current iter: 5592000/24576000\n",
      "current iter: 5593000/24576000\n",
      "current iter: 5594000/24576000\n",
      "current iter: 5595000/24576000\n",
      "current iter: 5596000/24576000\n",
      "current iter: 5597000/24576000\n",
      "current iter: 5598000/24576000\n",
      "current iter: 5599000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 5600000/24576000\n",
      "current iter: 5601000/24576000\n",
      "current iter: 5602000/24576000\n",
      "current iter: 5603000/24576000\n",
      "current iter: 5604000/24576000\n",
      "current iter: 5605000/24576000\n",
      "current iter: 5606000/24576000\n",
      "current iter: 5607000/24576000\n",
      "current iter: 5608000/24576000\n",
      "current iter: 5609000/24576000\n",
      "current iter: 5610000/24576000\n",
      "current iter: 5611000/24576000\n",
      "current iter: 5612000/24576000\n",
      "current iter: 5613000/24576000\n",
      "current iter: 5614000/24576000\n",
      "current iter: 5615000/24576000\n",
      "current iter: 5616000/24576000\n",
      "current iter: 5617000/24576000\n",
      "current iter: 5618000/24576000\n",
      "current iter: 5619000/24576000\n",
      "current iter: 5620000/24576000\n",
      "current iter: 5621000/24576000\n",
      "current iter: 5622000/24576000\n",
      "current iter: 5623000/24576000\n",
      "current iter: 5624000/24576000\n",
      "current iter: 5625000/24576000\n",
      "current iter: 5626000/24576000\n",
      "current iter: 5627000/24576000\n",
      "current iter: 5628000/24576000\n",
      "current iter: 5629000/24576000\n",
      "current iter: 5630000/24576000\n",
      "current iter: 5631000/24576000\n",
      "current iter: 5632000/24576000\n",
      "current iter: 5633000/24576000\n",
      "current iter: 5634000/24576000\n",
      "current iter: 5635000/24576000\n",
      "current iter: 5636000/24576000\n",
      "current iter: 5637000/24576000\n",
      "current iter: 5638000/24576000\n",
      "current iter: 5639000/24576000\n",
      "current iter: 5640000/24576000\n",
      "current iter: 5641000/24576000\n",
      "current iter: 5642000/24576000\n",
      "current iter: 5643000/24576000\n",
      "current iter: 5644000/24576000\n",
      "current iter: 5645000/24576000\n",
      "current iter: 5646000/24576000\n",
      "current iter: 5647000/24576000\n",
      "current iter: 5648000/24576000\n",
      "current iter: 5649000/24576000\n",
      "current iter: 5650000/24576000\n",
      "current iter: 5651000/24576000\n",
      "current iter: 5652000/24576000\n",
      "current iter: 5653000/24576000\n",
      "current iter: 5654000/24576000\n",
      "current iter: 5655000/24576000\n",
      "current iter: 5656000/24576000\n",
      "current iter: 5657000/24576000\n",
      "current iter: 5658000/24576000\n",
      "current iter: 5659000/24576000\n",
      "current iter: 5660000/24576000\n",
      "current iter: 5661000/24576000\n",
      "current iter: 5662000/24576000\n",
      "current iter: 5663000/24576000\n",
      "current iter: 5664000/24576000\n",
      "current iter: 5665000/24576000\n",
      "current iter: 5666000/24576000\n",
      "current iter: 5667000/24576000\n",
      "current iter: 5668000/24576000\n",
      "current iter: 5669000/24576000\n",
      "current iter: 5670000/24576000\n",
      "current iter: 5671000/24576000\n",
      "current iter: 5672000/24576000\n",
      "current iter: 5673000/24576000\n",
      "current iter: 5674000/24576000\n",
      "current iter: 5675000/24576000\n",
      "current iter: 5676000/24576000\n",
      "current iter: 5677000/24576000\n",
      "current iter: 5678000/24576000\n",
      "current iter: 5679000/24576000\n",
      "current iter: 5680000/24576000\n",
      "current iter: 5681000/24576000\n",
      "current iter: 5682000/24576000\n",
      "current iter: 5683000/24576000\n",
      "current iter: 5684000/24576000\n",
      "current iter: 5685000/24576000\n",
      "current iter: 5686000/24576000\n",
      "current iter: 5687000/24576000\n",
      "current iter: 5688000/24576000\n",
      "current iter: 5689000/24576000\n",
      "current iter: 5690000/24576000\n",
      "current iter: 5691000/24576000\n",
      "current iter: 5692000/24576000\n",
      "current iter: 5693000/24576000\n",
      "current iter: 5694000/24576000\n",
      "current iter: 5695000/24576000\n",
      "current iter: 5696000/24576000\n",
      "current iter: 5697000/24576000\n",
      "current iter: 5698000/24576000\n",
      "current iter: 5699000/24576000\n",
      "current iter: 5700000/24576000\n",
      "current iter: 5701000/24576000\n",
      "current iter: 5702000/24576000\n",
      "current iter: 5703000/24576000\n",
      "current iter: 5704000/24576000\n",
      "current iter: 5705000/24576000\n",
      "current iter: 5706000/24576000\n",
      "current iter: 5707000/24576000\n",
      "current iter: 5708000/24576000\n",
      "current iter: 5709000/24576000\n",
      "current iter: 5710000/24576000\n",
      "current iter: 5711000/24576000\n",
      "current iter: 5712000/24576000\n",
      "current iter: 5713000/24576000\n",
      "current iter: 5714000/24576000\n",
      "current iter: 5715000/24576000\n",
      "current iter: 5716000/24576000\n",
      "current iter: 5717000/24576000\n",
      "current iter: 5718000/24576000\n",
      "current iter: 5719000/24576000\n",
      "current iter: 5720000/24576000\n",
      "current iter: 5721000/24576000\n",
      "current iter: 5722000/24576000\n",
      "current iter: 5723000/24576000\n",
      "current iter: 5724000/24576000\n",
      "current iter: 5725000/24576000\n",
      "current iter: 5726000/24576000\n",
      "current iter: 5727000/24576000\n",
      "current iter: 5728000/24576000\n",
      "current iter: 5729000/24576000\n",
      "current iter: 5730000/24576000\n",
      "current iter: 5731000/24576000\n",
      "current iter: 5732000/24576000\n",
      "current iter: 5733000/24576000\n",
      "current iter: 5734000/24576000\n",
      "current iter: 5735000/24576000\n",
      "current iter: 5736000/24576000\n",
      "current iter: 5737000/24576000\n",
      "current iter: 5738000/24576000\n",
      "current iter: 5739000/24576000\n",
      "current iter: 5740000/24576000\n",
      "current iter: 5741000/24576000\n",
      "current iter: 5742000/24576000\n",
      "current iter: 5743000/24576000\n",
      "current iter: 5744000/24576000\n",
      "current iter: 5745000/24576000\n",
      "current iter: 5746000/24576000\n",
      "current iter: 5747000/24576000\n",
      "current iter: 5748000/24576000\n",
      "current iter: 5749000/24576000\n",
      "current iter: 5750000/24576000\n",
      "current iter: 5751000/24576000\n",
      "current iter: 5752000/24576000\n",
      "current iter: 5753000/24576000\n",
      "current iter: 5754000/24576000\n",
      "current iter: 5755000/24576000\n",
      "current iter: 5756000/24576000\n",
      "current iter: 5757000/24576000\n",
      "current iter: 5758000/24576000\n",
      "current iter: 5759000/24576000\n",
      "current iter: 5760000/24576000\n",
      "current iter: 5761000/24576000\n",
      "current iter: 5762000/24576000\n",
      "current iter: 5763000/24576000\n",
      "current iter: 5764000/24576000\n",
      "current iter: 5765000/24576000\n",
      "current iter: 5766000/24576000\n",
      "current iter: 5767000/24576000\n",
      "current iter: 5768000/24576000\n",
      "current iter: 5769000/24576000\n",
      "current iter: 5770000/24576000\n",
      "current iter: 5771000/24576000\n",
      "current iter: 5772000/24576000\n",
      "current iter: 5773000/24576000\n",
      "current iter: 5774000/24576000\n",
      "current iter: 5775000/24576000\n",
      "current iter: 5776000/24576000\n",
      "current iter: 5777000/24576000\n",
      "current iter: 5778000/24576000\n",
      "current iter: 5779000/24576000\n",
      "current iter: 5780000/24576000\n",
      "current iter: 5781000/24576000\n",
      "current iter: 5782000/24576000\n",
      "current iter: 5783000/24576000\n",
      "current iter: 5784000/24576000\n",
      "current iter: 5785000/24576000\n",
      "current iter: 5786000/24576000\n",
      "current iter: 5787000/24576000\n",
      "current iter: 5788000/24576000\n",
      "current iter: 5789000/24576000\n",
      "current iter: 5790000/24576000\n",
      "current iter: 5791000/24576000\n",
      "current iter: 5792000/24576000\n",
      "current iter: 5793000/24576000\n",
      "current iter: 5794000/24576000\n",
      "current iter: 5795000/24576000\n",
      "current iter: 5796000/24576000\n",
      "current iter: 5797000/24576000\n",
      "current iter: 5798000/24576000\n",
      "current iter: 5799000/24576000\n",
      "current iter: 5800000/24576000\n",
      "current iter: 5801000/24576000\n",
      "current iter: 5802000/24576000\n",
      "current iter: 5803000/24576000\n",
      "current iter: 5804000/24576000\n",
      "current iter: 5805000/24576000\n",
      "current iter: 5806000/24576000\n",
      "current iter: 5807000/24576000\n",
      "current iter: 5808000/24576000\n",
      "current iter: 5809000/24576000\n",
      "current iter: 5810000/24576000\n",
      "current iter: 5811000/24576000\n",
      "current iter: 5812000/24576000\n",
      "current iter: 5813000/24576000\n",
      "current iter: 5814000/24576000\n",
      "current iter: 5815000/24576000\n",
      "current iter: 5816000/24576000\n",
      "current iter: 5817000/24576000\n",
      "current iter: 5818000/24576000\n",
      "current iter: 5819000/24576000\n",
      "current iter: 5820000/24576000\n",
      "current iter: 5821000/24576000\n",
      "current iter: 5822000/24576000\n",
      "current iter: 5823000/24576000\n",
      "current iter: 5824000/24576000\n",
      "current iter: 5825000/24576000\n",
      "current iter: 5826000/24576000\n",
      "current iter: 5827000/24576000\n",
      "current iter: 5828000/24576000\n",
      "current iter: 5829000/24576000\n",
      "current iter: 5830000/24576000\n",
      "current iter: 5831000/24576000\n",
      "current iter: 5832000/24576000\n",
      "current iter: 5833000/24576000\n",
      "current iter: 5834000/24576000\n",
      "current iter: 5835000/24576000\n",
      "current iter: 5836000/24576000\n",
      "current iter: 5837000/24576000\n",
      "current iter: 5838000/24576000\n",
      "current iter: 5839000/24576000\n",
      "current iter: 5840000/24576000\n",
      "current iter: 5841000/24576000\n",
      "current iter: 5842000/24576000\n",
      "current iter: 5843000/24576000\n",
      "current iter: 5844000/24576000\n",
      "current iter: 5845000/24576000\n",
      "current iter: 5846000/24576000\n",
      "current iter: 5847000/24576000\n",
      "current iter: 5848000/24576000\n",
      "current iter: 5849000/24576000\n",
      "current iter: 5850000/24576000\n",
      "current iter: 5851000/24576000\n",
      "current iter: 5852000/24576000\n",
      "current iter: 5853000/24576000\n",
      "current iter: 5854000/24576000\n",
      "current iter: 5855000/24576000\n",
      "current iter: 5856000/24576000\n",
      "current iter: 5857000/24576000\n",
      "current iter: 5858000/24576000\n",
      "current iter: 5859000/24576000\n",
      "current iter: 5860000/24576000\n",
      "current iter: 5861000/24576000\n",
      "current iter: 5862000/24576000\n",
      "current iter: 5863000/24576000\n",
      "current iter: 5864000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 5865000/24576000\n",
      "current iter: 5866000/24576000\n",
      "current iter: 5867000/24576000\n",
      "current iter: 5868000/24576000\n",
      "current iter: 5869000/24576000\n",
      "current iter: 5870000/24576000\n",
      "current iter: 5871000/24576000\n",
      "current iter: 5872000/24576000\n",
      "current iter: 5873000/24576000\n",
      "current iter: 5874000/24576000\n",
      "current iter: 5875000/24576000\n",
      "current iter: 5876000/24576000\n",
      "current iter: 5877000/24576000\n",
      "current iter: 5878000/24576000\n",
      "current iter: 5879000/24576000\n",
      "current iter: 5880000/24576000\n",
      "current iter: 5881000/24576000\n",
      "current iter: 5882000/24576000\n",
      "current iter: 5883000/24576000\n",
      "current iter: 5884000/24576000\n",
      "current iter: 5885000/24576000\n",
      "current iter: 5886000/24576000\n",
      "current iter: 5887000/24576000\n",
      "current iter: 5888000/24576000\n",
      "current iter: 5889000/24576000\n",
      "current iter: 5890000/24576000\n",
      "current iter: 5891000/24576000\n",
      "current iter: 5892000/24576000\n",
      "current iter: 5893000/24576000\n",
      "current iter: 5894000/24576000\n",
      "current iter: 5895000/24576000\n",
      "current iter: 5896000/24576000\n",
      "current iter: 5897000/24576000\n",
      "current iter: 5898000/24576000\n",
      "current iter: 5899000/24576000\n",
      "current iter: 5900000/24576000\n",
      "current iter: 5901000/24576000\n",
      "current iter: 5902000/24576000\n",
      "current iter: 5903000/24576000\n",
      "current iter: 5904000/24576000\n",
      "current iter: 5905000/24576000\n",
      "current iter: 5906000/24576000\n",
      "current iter: 5907000/24576000\n",
      "current iter: 5908000/24576000\n",
      "current iter: 5909000/24576000\n",
      "current iter: 5910000/24576000\n",
      "current iter: 5911000/24576000\n",
      "current iter: 5912000/24576000\n",
      "current iter: 5913000/24576000\n",
      "current iter: 5914000/24576000\n",
      "current iter: 5915000/24576000\n",
      "current iter: 5916000/24576000\n",
      "current iter: 5917000/24576000\n",
      "current iter: 5918000/24576000\n",
      "current iter: 5919000/24576000\n",
      "current iter: 5920000/24576000\n",
      "current iter: 5921000/24576000\n",
      "current iter: 5922000/24576000\n",
      "current iter: 5923000/24576000\n",
      "current iter: 5924000/24576000\n",
      "current iter: 5925000/24576000\n",
      "current iter: 5926000/24576000\n",
      "current iter: 5927000/24576000\n",
      "current iter: 5928000/24576000\n",
      "current iter: 5929000/24576000\n",
      "current iter: 5930000/24576000\n",
      "current iter: 5931000/24576000\n",
      "current iter: 5932000/24576000\n",
      "current iter: 5933000/24576000\n",
      "current iter: 5934000/24576000\n",
      "current iter: 5935000/24576000\n",
      "current iter: 5936000/24576000\n",
      "current iter: 5937000/24576000\n",
      "current iter: 5938000/24576000\n",
      "current iter: 5939000/24576000\n",
      "current iter: 5940000/24576000\n",
      "current iter: 5941000/24576000\n",
      "current iter: 5942000/24576000\n",
      "current iter: 5943000/24576000\n",
      "current iter: 5944000/24576000\n",
      "current iter: 5945000/24576000\n",
      "current iter: 5946000/24576000\n",
      "current iter: 5947000/24576000\n",
      "current iter: 5948000/24576000\n",
      "current iter: 5949000/24576000\n",
      "current iter: 5950000/24576000\n",
      "current iter: 5951000/24576000\n",
      "current iter: 5952000/24576000\n",
      "current iter: 5953000/24576000\n",
      "current iter: 5954000/24576000\n",
      "current iter: 5955000/24576000\n",
      "current iter: 5956000/24576000\n",
      "current iter: 5957000/24576000\n",
      "current iter: 5958000/24576000\n",
      "current iter: 5959000/24576000\n",
      "current iter: 5960000/24576000\n",
      "current iter: 5961000/24576000\n",
      "current iter: 5962000/24576000\n",
      "current iter: 5963000/24576000\n",
      "current iter: 5964000/24576000\n",
      "current iter: 5965000/24576000\n",
      "current iter: 5966000/24576000\n",
      "current iter: 5967000/24576000\n",
      "current iter: 5968000/24576000\n",
      "current iter: 5969000/24576000\n",
      "current iter: 5970000/24576000\n",
      "current iter: 5971000/24576000\n",
      "current iter: 5972000/24576000\n",
      "current iter: 5973000/24576000\n",
      "current iter: 5974000/24576000\n",
      "current iter: 5975000/24576000\n",
      "current iter: 5976000/24576000\n",
      "current iter: 5977000/24576000\n",
      "current iter: 5978000/24576000\n",
      "current iter: 5979000/24576000\n",
      "current iter: 5980000/24576000\n",
      "current iter: 5981000/24576000\n",
      "current iter: 5982000/24576000\n",
      "current iter: 5983000/24576000\n",
      "current iter: 5984000/24576000\n",
      "current iter: 5985000/24576000\n",
      "current iter: 5986000/24576000\n",
      "current iter: 5987000/24576000\n",
      "current iter: 5988000/24576000\n",
      "current iter: 5989000/24576000\n",
      "current iter: 5990000/24576000\n",
      "current iter: 5991000/24576000\n",
      "current iter: 5992000/24576000\n",
      "current iter: 5993000/24576000\n",
      "current iter: 5994000/24576000\n",
      "current iter: 5995000/24576000\n",
      "current iter: 5996000/24576000\n",
      "current iter: 5997000/24576000\n",
      "current iter: 5998000/24576000\n",
      "current iter: 5999000/24576000\n",
      "current iter: 6000000/24576000\n",
      "current iter: 6001000/24576000\n",
      "current iter: 6002000/24576000\n",
      "current iter: 6003000/24576000\n",
      "current iter: 6004000/24576000\n",
      "current iter: 6005000/24576000\n",
      "current iter: 6006000/24576000\n",
      "current iter: 6007000/24576000\n",
      "current iter: 6008000/24576000\n",
      "current iter: 6009000/24576000\n",
      "current iter: 6010000/24576000\n",
      "current iter: 6011000/24576000\n",
      "current iter: 6012000/24576000\n",
      "current iter: 6013000/24576000\n",
      "current iter: 6014000/24576000\n",
      "current iter: 6015000/24576000\n",
      "current iter: 6016000/24576000\n",
      "current iter: 6017000/24576000\n",
      "current iter: 6018000/24576000\n",
      "current iter: 6019000/24576000\n",
      "current iter: 6020000/24576000\n",
      "current iter: 6021000/24576000\n",
      "current iter: 6022000/24576000\n",
      "current iter: 6023000/24576000\n",
      "current iter: 6024000/24576000\n",
      "current iter: 6025000/24576000\n",
      "current iter: 6026000/24576000\n",
      "current iter: 6027000/24576000\n",
      "current iter: 6028000/24576000\n",
      "current iter: 6029000/24576000\n",
      "current iter: 6030000/24576000\n",
      "current iter: 6031000/24576000\n",
      "current iter: 6032000/24576000\n",
      "current iter: 6033000/24576000\n",
      "current iter: 6034000/24576000\n",
      "current iter: 6035000/24576000\n",
      "current iter: 6036000/24576000\n",
      "current iter: 6037000/24576000\n",
      "current iter: 6038000/24576000\n",
      "current iter: 6039000/24576000\n",
      "current iter: 6040000/24576000\n",
      "current iter: 6041000/24576000\n",
      "current iter: 6042000/24576000\n",
      "current iter: 6043000/24576000\n",
      "current iter: 6044000/24576000\n",
      "current iter: 6045000/24576000\n",
      "current iter: 6046000/24576000\n",
      "current iter: 6047000/24576000\n",
      "current iter: 6048000/24576000\n",
      "current iter: 6049000/24576000\n",
      "current iter: 6050000/24576000\n",
      "current iter: 6051000/24576000\n",
      "current iter: 6052000/24576000\n",
      "current iter: 6053000/24576000\n",
      "current iter: 6054000/24576000\n",
      "current iter: 6055000/24576000\n",
      "current iter: 6056000/24576000\n",
      "current iter: 6057000/24576000\n",
      "current iter: 6058000/24576000\n",
      "current iter: 6059000/24576000\n",
      "current iter: 6060000/24576000\n",
      "current iter: 6061000/24576000\n",
      "current iter: 6062000/24576000\n",
      "current iter: 6063000/24576000\n",
      "current iter: 6064000/24576000\n",
      "current iter: 6065000/24576000\n",
      "current iter: 6066000/24576000\n",
      "current iter: 6067000/24576000\n",
      "current iter: 6068000/24576000\n",
      "current iter: 6069000/24576000\n",
      "current iter: 6070000/24576000\n",
      "current iter: 6071000/24576000\n",
      "current iter: 6072000/24576000\n",
      "current iter: 6073000/24576000\n",
      "current iter: 6074000/24576000\n",
      "current iter: 6075000/24576000\n",
      "current iter: 6076000/24576000\n",
      "current iter: 6077000/24576000\n",
      "current iter: 6078000/24576000\n",
      "current iter: 6079000/24576000\n",
      "current iter: 6080000/24576000\n",
      "current iter: 6081000/24576000\n",
      "current iter: 6082000/24576000\n",
      "current iter: 6083000/24576000\n",
      "current iter: 6084000/24576000\n",
      "current iter: 6085000/24576000\n",
      "current iter: 6086000/24576000\n",
      "current iter: 6087000/24576000\n",
      "current iter: 6088000/24576000\n",
      "current iter: 6089000/24576000\n",
      "current iter: 6090000/24576000\n",
      "current iter: 6091000/24576000\n",
      "current iter: 6092000/24576000\n",
      "current iter: 6093000/24576000\n",
      "current iter: 6094000/24576000\n",
      "current iter: 6095000/24576000\n",
      "current iter: 6096000/24576000\n",
      "current iter: 6097000/24576000\n",
      "current iter: 6098000/24576000\n",
      "current iter: 6099000/24576000\n",
      "current iter: 6100000/24576000\n",
      "current iter: 6101000/24576000\n",
      "current iter: 6102000/24576000\n",
      "current iter: 6103000/24576000\n",
      "current iter: 6104000/24576000\n",
      "current iter: 6105000/24576000\n",
      "current iter: 6106000/24576000\n",
      "current iter: 6107000/24576000\n",
      "current iter: 6108000/24576000\n",
      "current iter: 6109000/24576000\n",
      "current iter: 6110000/24576000\n",
      "current iter: 6111000/24576000\n",
      "current iter: 6112000/24576000\n",
      "current iter: 6113000/24576000\n",
      "current iter: 6114000/24576000\n",
      "current iter: 6115000/24576000\n",
      "current iter: 6116000/24576000\n",
      "current iter: 6117000/24576000\n",
      "current iter: 6118000/24576000\n",
      "current iter: 6119000/24576000\n",
      "current iter: 6120000/24576000\n",
      "current iter: 6121000/24576000\n",
      "current iter: 6122000/24576000\n",
      "current iter: 6123000/24576000\n",
      "current iter: 6124000/24576000\n",
      "current iter: 6125000/24576000\n",
      "current iter: 6126000/24576000\n",
      "current iter: 6127000/24576000\n",
      "current iter: 6128000/24576000\n",
      "current iter: 6129000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 6130000/24576000\n",
      "current iter: 6131000/24576000\n",
      "current iter: 6132000/24576000\n",
      "current iter: 6133000/24576000\n",
      "current iter: 6134000/24576000\n",
      "current iter: 6135000/24576000\n",
      "current iter: 6136000/24576000\n",
      "current iter: 6137000/24576000\n",
      "current iter: 6138000/24576000\n",
      "current iter: 6139000/24576000\n",
      "current iter: 6140000/24576000\n",
      "current iter: 6141000/24576000\n",
      "current iter: 6142000/24576000\n",
      "current iter: 6143000/24576000\n",
      "current iter: 6144000/24576000\n",
      "current iter: 6145000/24576000\n",
      "current iter: 6146000/24576000\n",
      "current iter: 6147000/24576000\n",
      "current iter: 6148000/24576000\n",
      "current iter: 6149000/24576000\n",
      "current iter: 6150000/24576000\n",
      "current iter: 6151000/24576000\n",
      "current iter: 6152000/24576000\n",
      "current iter: 6153000/24576000\n",
      "current iter: 6154000/24576000\n",
      "current iter: 6155000/24576000\n",
      "current iter: 6156000/24576000\n",
      "current iter: 6157000/24576000\n",
      "current iter: 6158000/24576000\n",
      "current iter: 6159000/24576000\n",
      "current iter: 6160000/24576000\n",
      "current iter: 6161000/24576000\n",
      "current iter: 6162000/24576000\n",
      "current iter: 6163000/24576000\n",
      "current iter: 6164000/24576000\n",
      "current iter: 6165000/24576000\n",
      "current iter: 6166000/24576000\n",
      "current iter: 6167000/24576000\n",
      "current iter: 6168000/24576000\n",
      "current iter: 6169000/24576000\n",
      "current iter: 6170000/24576000\n",
      "current iter: 6171000/24576000\n",
      "current iter: 6172000/24576000\n",
      "current iter: 6173000/24576000\n",
      "current iter: 6174000/24576000\n",
      "current iter: 6175000/24576000\n",
      "current iter: 6176000/24576000\n",
      "current iter: 6177000/24576000\n",
      "current iter: 6178000/24576000\n",
      "current iter: 6179000/24576000\n",
      "current iter: 6180000/24576000\n",
      "current iter: 6181000/24576000\n",
      "current iter: 6182000/24576000\n",
      "current iter: 6183000/24576000\n",
      "current iter: 6184000/24576000\n",
      "current iter: 6185000/24576000\n",
      "current iter: 6186000/24576000\n",
      "current iter: 6187000/24576000\n",
      "current iter: 6188000/24576000\n",
      "current iter: 6189000/24576000\n",
      "current iter: 6190000/24576000\n",
      "current iter: 6191000/24576000\n",
      "current iter: 6192000/24576000\n",
      "current iter: 6193000/24576000\n",
      "current iter: 6194000/24576000\n",
      "current iter: 6195000/24576000\n",
      "current iter: 6196000/24576000\n",
      "current iter: 6197000/24576000\n",
      "current iter: 6198000/24576000\n",
      "current iter: 6199000/24576000\n",
      "current iter: 6200000/24576000\n",
      "current iter: 6201000/24576000\n",
      "current iter: 6202000/24576000\n",
      "current iter: 6203000/24576000\n",
      "current iter: 6204000/24576000\n",
      "current iter: 6205000/24576000\n",
      "current iter: 6206000/24576000\n",
      "current iter: 6207000/24576000\n",
      "current iter: 6208000/24576000\n",
      "current iter: 6209000/24576000\n",
      "current iter: 6210000/24576000\n",
      "current iter: 6211000/24576000\n",
      "current iter: 6212000/24576000\n",
      "current iter: 6213000/24576000\n",
      "current iter: 6214000/24576000\n",
      "current iter: 6215000/24576000\n",
      "current iter: 6216000/24576000\n",
      "current iter: 6217000/24576000\n",
      "current iter: 6218000/24576000\n",
      "current iter: 6219000/24576000\n",
      "current iter: 6220000/24576000\n",
      "current iter: 6221000/24576000\n",
      "current iter: 6222000/24576000\n",
      "current iter: 6223000/24576000\n",
      "current iter: 6224000/24576000\n",
      "current iter: 6225000/24576000\n",
      "current iter: 6226000/24576000\n",
      "current iter: 6227000/24576000\n",
      "current iter: 6228000/24576000\n",
      "current iter: 6229000/24576000\n",
      "current iter: 6230000/24576000\n",
      "current iter: 6231000/24576000\n",
      "current iter: 6232000/24576000\n",
      "current iter: 6233000/24576000\n",
      "current iter: 6234000/24576000\n",
      "current iter: 6235000/24576000\n",
      "current iter: 6236000/24576000\n",
      "current iter: 6237000/24576000\n",
      "current iter: 6238000/24576000\n",
      "current iter: 6239000/24576000\n",
      "current iter: 6240000/24576000\n",
      "current iter: 6241000/24576000\n",
      "current iter: 6242000/24576000\n",
      "current iter: 6243000/24576000\n",
      "current iter: 6244000/24576000\n",
      "current iter: 6245000/24576000\n",
      "current iter: 6246000/24576000\n",
      "current iter: 6247000/24576000\n",
      "current iter: 6248000/24576000\n",
      "current iter: 6249000/24576000\n",
      "current iter: 6250000/24576000\n",
      "current iter: 6251000/24576000\n",
      "current iter: 6252000/24576000\n",
      "current iter: 6253000/24576000\n",
      "current iter: 6254000/24576000\n",
      "current iter: 6255000/24576000\n",
      "current iter: 6256000/24576000\n",
      "current iter: 6257000/24576000\n",
      "current iter: 6258000/24576000\n",
      "current iter: 6259000/24576000\n",
      "current iter: 6260000/24576000\n",
      "current iter: 6261000/24576000\n",
      "current iter: 6262000/24576000\n",
      "current iter: 6263000/24576000\n",
      "current iter: 6264000/24576000\n",
      "current iter: 6265000/24576000\n",
      "current iter: 6266000/24576000\n",
      "current iter: 6267000/24576000\n",
      "current iter: 6268000/24576000\n",
      "current iter: 6269000/24576000\n",
      "current iter: 6270000/24576000\n",
      "current iter: 6271000/24576000\n",
      "current iter: 6272000/24576000\n",
      "current iter: 6273000/24576000\n",
      "current iter: 6274000/24576000\n",
      "current iter: 6275000/24576000\n",
      "current iter: 6276000/24576000\n",
      "current iter: 6277000/24576000\n",
      "current iter: 6278000/24576000\n",
      "current iter: 6279000/24576000\n",
      "current iter: 6280000/24576000\n",
      "current iter: 6281000/24576000\n",
      "current iter: 6282000/24576000\n",
      "current iter: 6283000/24576000\n",
      "current iter: 6284000/24576000\n",
      "current iter: 6285000/24576000\n",
      "current iter: 6286000/24576000\n",
      "current iter: 6287000/24576000\n",
      "current iter: 6288000/24576000\n",
      "current iter: 6289000/24576000\n",
      "current iter: 6290000/24576000\n",
      "current iter: 6291000/24576000\n",
      "current iter: 6292000/24576000\n",
      "current iter: 6293000/24576000\n",
      "current iter: 6294000/24576000\n",
      "current iter: 6295000/24576000\n",
      "current iter: 6296000/24576000\n",
      "current iter: 6297000/24576000\n",
      "current iter: 6298000/24576000\n",
      "current iter: 6299000/24576000\n",
      "current iter: 6300000/24576000\n",
      "current iter: 6301000/24576000\n",
      "current iter: 6302000/24576000\n",
      "current iter: 6303000/24576000\n",
      "current iter: 6304000/24576000\n",
      "current iter: 6305000/24576000\n",
      "current iter: 6306000/24576000\n",
      "current iter: 6307000/24576000\n",
      "current iter: 6308000/24576000\n",
      "current iter: 6309000/24576000\n",
      "current iter: 6310000/24576000\n",
      "current iter: 6311000/24576000\n",
      "current iter: 6312000/24576000\n",
      "current iter: 6313000/24576000\n",
      "current iter: 6314000/24576000\n",
      "current iter: 6315000/24576000\n",
      "current iter: 6316000/24576000\n",
      "current iter: 6317000/24576000\n",
      "current iter: 6318000/24576000\n",
      "current iter: 6319000/24576000\n",
      "current iter: 6320000/24576000\n",
      "current iter: 6321000/24576000\n",
      "current iter: 6322000/24576000\n",
      "current iter: 6323000/24576000\n",
      "current iter: 6324000/24576000\n",
      "current iter: 6325000/24576000\n",
      "current iter: 6326000/24576000\n",
      "current iter: 6327000/24576000\n",
      "current iter: 6328000/24576000\n",
      "current iter: 6329000/24576000\n",
      "current iter: 6330000/24576000\n",
      "current iter: 6331000/24576000\n",
      "current iter: 6332000/24576000\n",
      "current iter: 6333000/24576000\n",
      "current iter: 6334000/24576000\n",
      "current iter: 6335000/24576000\n",
      "current iter: 6336000/24576000\n",
      "current iter: 6337000/24576000\n",
      "current iter: 6338000/24576000\n",
      "current iter: 6339000/24576000\n",
      "current iter: 6340000/24576000\n",
      "current iter: 6341000/24576000\n",
      "current iter: 6342000/24576000\n",
      "current iter: 6343000/24576000\n",
      "current iter: 6344000/24576000\n",
      "current iter: 6345000/24576000\n",
      "current iter: 6346000/24576000\n",
      "current iter: 6347000/24576000\n",
      "current iter: 6348000/24576000\n",
      "current iter: 6349000/24576000\n",
      "current iter: 6350000/24576000\n",
      "current iter: 6351000/24576000\n",
      "current iter: 6352000/24576000\n",
      "current iter: 6353000/24576000\n",
      "current iter: 6354000/24576000\n",
      "current iter: 6355000/24576000\n",
      "current iter: 6356000/24576000\n",
      "current iter: 6357000/24576000\n",
      "current iter: 6358000/24576000\n",
      "current iter: 6359000/24576000\n",
      "current iter: 6360000/24576000\n",
      "current iter: 6361000/24576000\n",
      "current iter: 6362000/24576000\n",
      "current iter: 6363000/24576000\n",
      "current iter: 6364000/24576000\n",
      "current iter: 6365000/24576000\n",
      "current iter: 6366000/24576000\n",
      "current iter: 6367000/24576000\n",
      "current iter: 6368000/24576000\n",
      "current iter: 6369000/24576000\n",
      "current iter: 6370000/24576000\n",
      "current iter: 6371000/24576000\n",
      "current iter: 6372000/24576000\n",
      "current iter: 6373000/24576000\n",
      "current iter: 6374000/24576000\n",
      "current iter: 6375000/24576000\n",
      "current iter: 6376000/24576000\n",
      "current iter: 6377000/24576000\n",
      "current iter: 6378000/24576000\n",
      "current iter: 6379000/24576000\n",
      "current iter: 6380000/24576000\n",
      "current iter: 6381000/24576000\n",
      "current iter: 6382000/24576000\n",
      "current iter: 6383000/24576000\n",
      "current iter: 6384000/24576000\n",
      "current iter: 6385000/24576000\n",
      "current iter: 6386000/24576000\n",
      "current iter: 6387000/24576000\n",
      "current iter: 6388000/24576000\n",
      "current iter: 6389000/24576000\n",
      "current iter: 6390000/24576000\n",
      "current iter: 6391000/24576000\n",
      "current iter: 6392000/24576000\n",
      "current iter: 6393000/24576000\n",
      "current iter: 6394000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 6395000/24576000\n",
      "current iter: 6396000/24576000\n",
      "current iter: 6397000/24576000\n",
      "current iter: 6398000/24576000\n",
      "current iter: 6399000/24576000\n",
      "current iter: 6400000/24576000\n",
      "current iter: 6401000/24576000\n",
      "current iter: 6402000/24576000\n",
      "current iter: 6403000/24576000\n",
      "current iter: 6404000/24576000\n",
      "current iter: 6405000/24576000\n",
      "current iter: 6406000/24576000\n",
      "current iter: 6407000/24576000\n",
      "current iter: 6408000/24576000\n",
      "current iter: 6409000/24576000\n",
      "current iter: 6410000/24576000\n",
      "current iter: 6411000/24576000\n",
      "current iter: 6412000/24576000\n",
      "current iter: 6413000/24576000\n",
      "current iter: 6414000/24576000\n",
      "current iter: 6415000/24576000\n",
      "current iter: 6416000/24576000\n",
      "current iter: 6417000/24576000\n",
      "current iter: 6418000/24576000\n",
      "current iter: 6419000/24576000\n",
      "current iter: 6420000/24576000\n",
      "current iter: 6421000/24576000\n",
      "current iter: 6422000/24576000\n",
      "current iter: 6423000/24576000\n",
      "current iter: 6424000/24576000\n",
      "current iter: 6425000/24576000\n",
      "current iter: 6426000/24576000\n",
      "current iter: 6427000/24576000\n",
      "current iter: 6428000/24576000\n",
      "current iter: 6429000/24576000\n",
      "current iter: 6430000/24576000\n",
      "current iter: 6431000/24576000\n",
      "current iter: 6432000/24576000\n",
      "current iter: 6433000/24576000\n",
      "current iter: 6434000/24576000\n",
      "current iter: 6435000/24576000\n",
      "current iter: 6436000/24576000\n",
      "current iter: 6437000/24576000\n",
      "current iter: 6438000/24576000\n",
      "current iter: 6439000/24576000\n",
      "current iter: 6440000/24576000\n",
      "current iter: 6441000/24576000\n",
      "current iter: 6442000/24576000\n",
      "current iter: 6443000/24576000\n",
      "current iter: 6444000/24576000\n",
      "current iter: 6445000/24576000\n",
      "current iter: 6446000/24576000\n",
      "current iter: 6447000/24576000\n",
      "current iter: 6448000/24576000\n",
      "current iter: 6449000/24576000\n",
      "current iter: 6450000/24576000\n",
      "current iter: 6451000/24576000\n",
      "current iter: 6452000/24576000\n",
      "current iter: 6453000/24576000\n",
      "current iter: 6454000/24576000\n",
      "current iter: 6455000/24576000\n",
      "current iter: 6456000/24576000\n",
      "current iter: 6457000/24576000\n",
      "current iter: 6458000/24576000\n",
      "current iter: 6459000/24576000\n",
      "current iter: 6460000/24576000\n",
      "current iter: 6461000/24576000\n",
      "current iter: 6462000/24576000\n",
      "current iter: 6463000/24576000\n",
      "current iter: 6464000/24576000\n",
      "current iter: 6465000/24576000\n",
      "current iter: 6466000/24576000\n",
      "current iter: 6467000/24576000\n",
      "current iter: 6468000/24576000\n",
      "current iter: 6469000/24576000\n",
      "current iter: 6470000/24576000\n",
      "current iter: 6471000/24576000\n",
      "current iter: 6472000/24576000\n",
      "current iter: 6473000/24576000\n",
      "current iter: 6474000/24576000\n",
      "current iter: 6475000/24576000\n",
      "current iter: 6476000/24576000\n",
      "current iter: 6477000/24576000\n",
      "current iter: 6478000/24576000\n",
      "current iter: 6479000/24576000\n",
      "current iter: 6480000/24576000\n",
      "current iter: 6481000/24576000\n",
      "current iter: 6482000/24576000\n",
      "current iter: 6483000/24576000\n",
      "current iter: 6484000/24576000\n",
      "current iter: 6485000/24576000\n",
      "current iter: 6486000/24576000\n",
      "current iter: 6487000/24576000\n",
      "current iter: 6488000/24576000\n",
      "current iter: 6489000/24576000\n",
      "current iter: 6490000/24576000\n",
      "current iter: 6491000/24576000\n",
      "current iter: 6492000/24576000\n",
      "current iter: 6493000/24576000\n",
      "current iter: 6494000/24576000\n",
      "current iter: 6495000/24576000\n",
      "current iter: 6496000/24576000\n",
      "current iter: 6497000/24576000\n",
      "current iter: 6498000/24576000\n",
      "current iter: 6499000/24576000\n",
      "current iter: 6500000/24576000\n",
      "current iter: 6501000/24576000\n",
      "current iter: 6502000/24576000\n",
      "current iter: 6503000/24576000\n",
      "current iter: 6504000/24576000\n",
      "current iter: 6505000/24576000\n",
      "current iter: 6506000/24576000\n",
      "current iter: 6507000/24576000\n",
      "current iter: 6508000/24576000\n",
      "current iter: 6509000/24576000\n",
      "current iter: 6510000/24576000\n",
      "current iter: 6511000/24576000\n",
      "current iter: 6512000/24576000\n",
      "current iter: 6513000/24576000\n",
      "current iter: 6514000/24576000\n",
      "current iter: 6515000/24576000\n",
      "current iter: 6516000/24576000\n",
      "current iter: 6517000/24576000\n",
      "current iter: 6518000/24576000\n",
      "current iter: 6519000/24576000\n",
      "current iter: 6520000/24576000\n",
      "current iter: 6521000/24576000\n",
      "current iter: 6522000/24576000\n",
      "current iter: 6523000/24576000\n",
      "current iter: 6524000/24576000\n",
      "current iter: 6525000/24576000\n",
      "current iter: 6526000/24576000\n",
      "current iter: 6527000/24576000\n",
      "current iter: 6528000/24576000\n",
      "current iter: 6529000/24576000\n",
      "current iter: 6530000/24576000\n",
      "current iter: 6531000/24576000\n",
      "current iter: 6532000/24576000\n",
      "current iter: 6533000/24576000\n",
      "current iter: 6534000/24576000\n",
      "current iter: 6535000/24576000\n",
      "current iter: 6536000/24576000\n",
      "current iter: 6537000/24576000\n",
      "current iter: 6538000/24576000\n",
      "current iter: 6539000/24576000\n",
      "current iter: 6540000/24576000\n",
      "current iter: 6541000/24576000\n",
      "current iter: 6542000/24576000\n",
      "current iter: 6543000/24576000\n",
      "current iter: 6544000/24576000\n",
      "current iter: 6545000/24576000\n",
      "current iter: 6546000/24576000\n",
      "current iter: 6547000/24576000\n",
      "current iter: 6548000/24576000\n",
      "current iter: 6549000/24576000\n",
      "current iter: 6550000/24576000\n",
      "current iter: 6551000/24576000\n",
      "current iter: 6552000/24576000\n",
      "current iter: 6553000/24576000\n",
      "current iter: 6554000/24576000\n",
      "current iter: 6555000/24576000\n",
      "current iter: 6556000/24576000\n",
      "current iter: 6557000/24576000\n",
      "current iter: 6558000/24576000\n",
      "current iter: 6559000/24576000\n",
      "current iter: 6560000/24576000\n",
      "current iter: 6561000/24576000\n",
      "current iter: 6562000/24576000\n",
      "current iter: 6563000/24576000\n",
      "current iter: 6564000/24576000\n",
      "current iter: 6565000/24576000\n",
      "current iter: 6566000/24576000\n",
      "current iter: 6567000/24576000\n",
      "current iter: 6568000/24576000\n",
      "current iter: 6569000/24576000\n",
      "current iter: 6570000/24576000\n",
      "current iter: 6571000/24576000\n",
      "current iter: 6572000/24576000\n",
      "current iter: 6573000/24576000\n",
      "current iter: 6574000/24576000\n",
      "current iter: 6575000/24576000\n",
      "current iter: 6576000/24576000\n",
      "current iter: 6577000/24576000\n",
      "current iter: 6578000/24576000\n",
      "current iter: 6579000/24576000\n",
      "current iter: 6580000/24576000\n",
      "current iter: 6581000/24576000\n",
      "current iter: 6582000/24576000\n",
      "current iter: 6583000/24576000\n",
      "current iter: 6584000/24576000\n",
      "current iter: 6585000/24576000\n",
      "current iter: 6586000/24576000\n",
      "current iter: 6587000/24576000\n",
      "current iter: 6588000/24576000\n",
      "current iter: 6589000/24576000\n",
      "current iter: 6590000/24576000\n",
      "current iter: 6591000/24576000\n",
      "current iter: 6592000/24576000\n",
      "current iter: 6593000/24576000\n",
      "current iter: 6594000/24576000\n",
      "current iter: 6595000/24576000\n",
      "current iter: 6596000/24576000\n",
      "current iter: 6597000/24576000\n",
      "current iter: 6598000/24576000\n",
      "current iter: 6599000/24576000\n",
      "current iter: 6600000/24576000\n",
      "current iter: 6601000/24576000\n",
      "current iter: 6602000/24576000\n",
      "current iter: 6603000/24576000\n",
      "current iter: 6604000/24576000\n",
      "current iter: 6605000/24576000\n",
      "current iter: 6606000/24576000\n",
      "current iter: 6607000/24576000\n",
      "current iter: 6608000/24576000\n",
      "current iter: 6609000/24576000\n",
      "current iter: 6610000/24576000\n",
      "current iter: 6611000/24576000\n",
      "current iter: 6612000/24576000\n",
      "current iter: 6613000/24576000\n",
      "current iter: 6614000/24576000\n",
      "current iter: 6615000/24576000\n",
      "current iter: 6616000/24576000\n",
      "current iter: 6617000/24576000\n",
      "current iter: 6618000/24576000\n",
      "current iter: 6619000/24576000\n",
      "current iter: 6620000/24576000\n",
      "current iter: 6621000/24576000\n",
      "current iter: 6622000/24576000\n",
      "current iter: 6623000/24576000\n",
      "current iter: 6624000/24576000\n",
      "current iter: 6625000/24576000\n",
      "current iter: 6626000/24576000\n",
      "current iter: 6627000/24576000\n",
      "current iter: 6628000/24576000\n",
      "current iter: 6629000/24576000\n",
      "current iter: 6630000/24576000\n",
      "current iter: 6631000/24576000\n",
      "current iter: 6632000/24576000\n",
      "current iter: 6633000/24576000\n",
      "current iter: 6634000/24576000\n",
      "current iter: 6635000/24576000\n",
      "current iter: 6636000/24576000\n",
      "current iter: 6637000/24576000\n",
      "current iter: 6638000/24576000\n",
      "current iter: 6639000/24576000\n",
      "current iter: 6640000/24576000\n",
      "current iter: 6641000/24576000\n",
      "current iter: 6642000/24576000\n",
      "current iter: 6643000/24576000\n",
      "current iter: 6644000/24576000\n",
      "current iter: 6645000/24576000\n",
      "current iter: 6646000/24576000\n",
      "current iter: 6647000/24576000\n",
      "current iter: 6648000/24576000\n",
      "current iter: 6649000/24576000\n",
      "current iter: 6650000/24576000\n",
      "current iter: 6651000/24576000\n",
      "current iter: 6652000/24576000\n",
      "current iter: 6653000/24576000\n",
      "current iter: 6654000/24576000\n",
      "current iter: 6655000/24576000\n",
      "current iter: 6656000/24576000\n",
      "current iter: 6657000/24576000\n",
      "current iter: 6658000/24576000\n",
      "current iter: 6659000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 6660000/24576000\n",
      "current iter: 6661000/24576000\n",
      "current iter: 6662000/24576000\n",
      "current iter: 6663000/24576000\n",
      "current iter: 6664000/24576000\n",
      "current iter: 6665000/24576000\n",
      "current iter: 6666000/24576000\n",
      "current iter: 6667000/24576000\n",
      "current iter: 6668000/24576000\n",
      "current iter: 6669000/24576000\n",
      "current iter: 6670000/24576000\n",
      "current iter: 6671000/24576000\n",
      "current iter: 6672000/24576000\n",
      "current iter: 6673000/24576000\n",
      "current iter: 6674000/24576000\n",
      "current iter: 6675000/24576000\n",
      "current iter: 6676000/24576000\n",
      "current iter: 6677000/24576000\n",
      "current iter: 6678000/24576000\n",
      "current iter: 6679000/24576000\n",
      "current iter: 6680000/24576000\n",
      "current iter: 6681000/24576000\n",
      "current iter: 6682000/24576000\n",
      "current iter: 6683000/24576000\n",
      "current iter: 6684000/24576000\n",
      "current iter: 6685000/24576000\n",
      "current iter: 6686000/24576000\n",
      "current iter: 6687000/24576000\n",
      "current iter: 6688000/24576000\n",
      "current iter: 6689000/24576000\n",
      "current iter: 6690000/24576000\n",
      "current iter: 6691000/24576000\n",
      "current iter: 6692000/24576000\n",
      "current iter: 6693000/24576000\n",
      "current iter: 6694000/24576000\n",
      "current iter: 6695000/24576000\n",
      "current iter: 6696000/24576000\n",
      "current iter: 6697000/24576000\n",
      "current iter: 6698000/24576000\n",
      "current iter: 6699000/24576000\n",
      "current iter: 6700000/24576000\n",
      "current iter: 6701000/24576000\n",
      "current iter: 6702000/24576000\n",
      "current iter: 6703000/24576000\n",
      "current iter: 6704000/24576000\n",
      "current iter: 6705000/24576000\n",
      "current iter: 6706000/24576000\n",
      "current iter: 6707000/24576000\n",
      "current iter: 6708000/24576000\n",
      "current iter: 6709000/24576000\n",
      "current iter: 6710000/24576000\n",
      "current iter: 6711000/24576000\n",
      "current iter: 6712000/24576000\n",
      "current iter: 6713000/24576000\n",
      "current iter: 6714000/24576000\n",
      "current iter: 6715000/24576000\n",
      "current iter: 6716000/24576000\n",
      "current iter: 6717000/24576000\n",
      "current iter: 6718000/24576000\n",
      "current iter: 6719000/24576000\n",
      "current iter: 6720000/24576000\n",
      "current iter: 6721000/24576000\n",
      "current iter: 6722000/24576000\n",
      "current iter: 6723000/24576000\n",
      "current iter: 6724000/24576000\n",
      "current iter: 6725000/24576000\n",
      "current iter: 6726000/24576000\n",
      "current iter: 6727000/24576000\n",
      "current iter: 6728000/24576000\n",
      "current iter: 6729000/24576000\n",
      "current iter: 6730000/24576000\n",
      "current iter: 6731000/24576000\n",
      "current iter: 6732000/24576000\n",
      "current iter: 6733000/24576000\n",
      "current iter: 6734000/24576000\n",
      "current iter: 6735000/24576000\n",
      "current iter: 6736000/24576000\n",
      "current iter: 6737000/24576000\n",
      "current iter: 6738000/24576000\n",
      "current iter: 6739000/24576000\n",
      "current iter: 6740000/24576000\n",
      "current iter: 6741000/24576000\n",
      "current iter: 6742000/24576000\n",
      "current iter: 6743000/24576000\n",
      "current iter: 6744000/24576000\n",
      "current iter: 6745000/24576000\n",
      "current iter: 6746000/24576000\n",
      "current iter: 6747000/24576000\n",
      "current iter: 6748000/24576000\n",
      "current iter: 6749000/24576000\n",
      "current iter: 6750000/24576000\n",
      "current iter: 6751000/24576000\n",
      "current iter: 6752000/24576000\n",
      "current iter: 6753000/24576000\n",
      "current iter: 6754000/24576000\n",
      "current iter: 6755000/24576000\n",
      "current iter: 6756000/24576000\n",
      "current iter: 6757000/24576000\n",
      "current iter: 6758000/24576000\n",
      "current iter: 6759000/24576000\n",
      "current iter: 6760000/24576000\n",
      "current iter: 6761000/24576000\n",
      "current iter: 6762000/24576000\n",
      "current iter: 6763000/24576000\n",
      "current iter: 6764000/24576000\n",
      "current iter: 6765000/24576000\n",
      "current iter: 6766000/24576000\n",
      "current iter: 6767000/24576000\n",
      "current iter: 6768000/24576000\n",
      "current iter: 6769000/24576000\n",
      "current iter: 6770000/24576000\n",
      "current iter: 6771000/24576000\n",
      "current iter: 6772000/24576000\n",
      "current iter: 6773000/24576000\n",
      "current iter: 6774000/24576000\n",
      "current iter: 6775000/24576000\n",
      "current iter: 6776000/24576000\n",
      "current iter: 6777000/24576000\n",
      "current iter: 6778000/24576000\n",
      "current iter: 6779000/24576000\n",
      "current iter: 6780000/24576000\n",
      "current iter: 6781000/24576000\n",
      "current iter: 6782000/24576000\n",
      "current iter: 6783000/24576000\n",
      "current iter: 6784000/24576000\n",
      "current iter: 6785000/24576000\n",
      "current iter: 6786000/24576000\n",
      "current iter: 6787000/24576000\n",
      "current iter: 6788000/24576000\n",
      "current iter: 6789000/24576000\n",
      "current iter: 6790000/24576000\n",
      "current iter: 6791000/24576000\n",
      "current iter: 6792000/24576000\n",
      "current iter: 6793000/24576000\n",
      "current iter: 6794000/24576000\n",
      "current iter: 6795000/24576000\n",
      "current iter: 6796000/24576000\n",
      "current iter: 6797000/24576000\n",
      "current iter: 6798000/24576000\n",
      "current iter: 6799000/24576000\n",
      "current iter: 6800000/24576000\n",
      "current iter: 6801000/24576000\n",
      "current iter: 6802000/24576000\n",
      "current iter: 6803000/24576000\n",
      "current iter: 6804000/24576000\n",
      "current iter: 6805000/24576000\n",
      "current iter: 6806000/24576000\n",
      "current iter: 6807000/24576000\n",
      "current iter: 6808000/24576000\n",
      "current iter: 6809000/24576000\n",
      "current iter: 6810000/24576000\n",
      "current iter: 6811000/24576000\n",
      "current iter: 6812000/24576000\n",
      "current iter: 6813000/24576000\n",
      "current iter: 6814000/24576000\n",
      "current iter: 6815000/24576000\n",
      "current iter: 6816000/24576000\n",
      "current iter: 6817000/24576000\n",
      "current iter: 6818000/24576000\n",
      "current iter: 6819000/24576000\n",
      "current iter: 6820000/24576000\n",
      "current iter: 6821000/24576000\n",
      "current iter: 6822000/24576000\n",
      "current iter: 6823000/24576000\n",
      "current iter: 6824000/24576000\n",
      "current iter: 6825000/24576000\n",
      "current iter: 6826000/24576000\n",
      "current iter: 6827000/24576000\n",
      "current iter: 6828000/24576000\n",
      "current iter: 6829000/24576000\n",
      "current iter: 6830000/24576000\n",
      "current iter: 6831000/24576000\n",
      "current iter: 6832000/24576000\n",
      "current iter: 6833000/24576000\n",
      "current iter: 6834000/24576000\n",
      "current iter: 6835000/24576000\n",
      "current iter: 6836000/24576000\n",
      "current iter: 6837000/24576000\n",
      "current iter: 6838000/24576000\n",
      "current iter: 6839000/24576000\n",
      "current iter: 6840000/24576000\n",
      "current iter: 6841000/24576000\n",
      "current iter: 6842000/24576000\n",
      "current iter: 6843000/24576000\n",
      "current iter: 6844000/24576000\n",
      "current iter: 6845000/24576000\n",
      "current iter: 6846000/24576000\n",
      "current iter: 6847000/24576000\n",
      "current iter: 6848000/24576000\n",
      "current iter: 6849000/24576000\n",
      "current iter: 6850000/24576000\n",
      "current iter: 6851000/24576000\n",
      "current iter: 6852000/24576000\n",
      "current iter: 6853000/24576000\n",
      "current iter: 6854000/24576000\n",
      "current iter: 6855000/24576000\n",
      "current iter: 6856000/24576000\n",
      "current iter: 6857000/24576000\n",
      "current iter: 6858000/24576000\n",
      "current iter: 6859000/24576000\n",
      "current iter: 6860000/24576000\n",
      "current iter: 6861000/24576000\n",
      "current iter: 6862000/24576000\n",
      "current iter: 6863000/24576000\n",
      "current iter: 6864000/24576000\n",
      "current iter: 6865000/24576000\n",
      "current iter: 6866000/24576000\n",
      "current iter: 6867000/24576000\n",
      "current iter: 6868000/24576000\n",
      "current iter: 6869000/24576000\n",
      "current iter: 6870000/24576000\n",
      "current iter: 6871000/24576000\n",
      "current iter: 6872000/24576000\n",
      "current iter: 6873000/24576000\n",
      "current iter: 6874000/24576000\n",
      "current iter: 6875000/24576000\n",
      "current iter: 6876000/24576000\n",
      "current iter: 6877000/24576000\n",
      "current iter: 6878000/24576000\n",
      "current iter: 6879000/24576000\n",
      "current iter: 6880000/24576000\n",
      "current iter: 6881000/24576000\n",
      "current iter: 6882000/24576000\n",
      "current iter: 6883000/24576000\n",
      "current iter: 6884000/24576000\n",
      "current iter: 6885000/24576000\n",
      "current iter: 6886000/24576000\n",
      "current iter: 6887000/24576000\n",
      "current iter: 6888000/24576000\n",
      "current iter: 6889000/24576000\n",
      "current iter: 6890000/24576000\n",
      "current iter: 6891000/24576000\n",
      "current iter: 6892000/24576000\n",
      "current iter: 6893000/24576000\n",
      "current iter: 6894000/24576000\n",
      "current iter: 6895000/24576000\n",
      "current iter: 6896000/24576000\n",
      "current iter: 6897000/24576000\n",
      "current iter: 6898000/24576000\n",
      "current iter: 6899000/24576000\n",
      "current iter: 6900000/24576000\n",
      "current iter: 6901000/24576000\n",
      "current iter: 6902000/24576000\n",
      "current iter: 6903000/24576000\n",
      "current iter: 6904000/24576000\n",
      "current iter: 6905000/24576000\n",
      "current iter: 6906000/24576000\n",
      "current iter: 6907000/24576000\n",
      "current iter: 6908000/24576000\n",
      "current iter: 6909000/24576000\n",
      "current iter: 6910000/24576000\n",
      "current iter: 6911000/24576000\n",
      "current iter: 6912000/24576000\n",
      "current iter: 6913000/24576000\n",
      "current iter: 6914000/24576000\n",
      "current iter: 6915000/24576000\n",
      "current iter: 6916000/24576000\n",
      "current iter: 6917000/24576000\n",
      "current iter: 6918000/24576000\n",
      "current iter: 6919000/24576000\n",
      "current iter: 6920000/24576000\n",
      "current iter: 6921000/24576000\n",
      "current iter: 6922000/24576000\n",
      "current iter: 6923000/24576000\n",
      "current iter: 6924000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 6925000/24576000\n",
      "current iter: 6926000/24576000\n",
      "current iter: 6927000/24576000\n",
      "current iter: 6928000/24576000\n",
      "current iter: 6929000/24576000\n",
      "current iter: 6930000/24576000\n",
      "current iter: 6931000/24576000\n",
      "current iter: 6932000/24576000\n",
      "current iter: 6933000/24576000\n",
      "current iter: 6934000/24576000\n",
      "current iter: 6935000/24576000\n",
      "current iter: 6936000/24576000\n",
      "current iter: 6937000/24576000\n",
      "current iter: 6938000/24576000\n",
      "current iter: 6939000/24576000\n",
      "current iter: 6940000/24576000\n",
      "current iter: 6941000/24576000\n",
      "current iter: 6942000/24576000\n",
      "current iter: 6943000/24576000\n",
      "current iter: 6944000/24576000\n",
      "current iter: 6945000/24576000\n",
      "current iter: 6946000/24576000\n",
      "current iter: 6947000/24576000\n",
      "current iter: 6948000/24576000\n",
      "current iter: 6949000/24576000\n",
      "current iter: 6950000/24576000\n",
      "current iter: 6951000/24576000\n",
      "current iter: 6952000/24576000\n",
      "current iter: 6953000/24576000\n",
      "current iter: 6954000/24576000\n",
      "current iter: 6955000/24576000\n",
      "current iter: 6956000/24576000\n",
      "current iter: 6957000/24576000\n",
      "current iter: 6958000/24576000\n",
      "current iter: 6959000/24576000\n",
      "current iter: 6960000/24576000\n",
      "current iter: 6961000/24576000\n",
      "current iter: 6962000/24576000\n",
      "current iter: 6963000/24576000\n",
      "current iter: 6964000/24576000\n",
      "current iter: 6965000/24576000\n",
      "current iter: 6966000/24576000\n",
      "current iter: 6967000/24576000\n",
      "current iter: 6968000/24576000\n",
      "current iter: 6969000/24576000\n",
      "current iter: 6970000/24576000\n",
      "current iter: 6971000/24576000\n",
      "current iter: 6972000/24576000\n",
      "current iter: 6973000/24576000\n",
      "current iter: 6974000/24576000\n",
      "current iter: 6975000/24576000\n",
      "current iter: 6976000/24576000\n",
      "current iter: 6977000/24576000\n",
      "current iter: 6978000/24576000\n",
      "current iter: 6979000/24576000\n",
      "current iter: 6980000/24576000\n",
      "current iter: 6981000/24576000\n",
      "current iter: 6982000/24576000\n",
      "current iter: 6983000/24576000\n",
      "current iter: 6984000/24576000\n",
      "current iter: 6985000/24576000\n",
      "current iter: 6986000/24576000\n",
      "current iter: 6987000/24576000\n",
      "current iter: 6988000/24576000\n",
      "current iter: 6989000/24576000\n",
      "current iter: 6990000/24576000\n",
      "current iter: 6991000/24576000\n",
      "current iter: 6992000/24576000\n",
      "current iter: 6993000/24576000\n",
      "current iter: 6994000/24576000\n",
      "current iter: 6995000/24576000\n",
      "current iter: 6996000/24576000\n",
      "current iter: 6997000/24576000\n",
      "current iter: 6998000/24576000\n",
      "current iter: 6999000/24576000\n",
      "current iter: 7000000/24576000\n",
      "current iter: 7001000/24576000\n",
      "current iter: 7002000/24576000\n",
      "current iter: 7003000/24576000\n",
      "current iter: 7004000/24576000\n",
      "current iter: 7005000/24576000\n",
      "current iter: 7006000/24576000\n",
      "current iter: 7007000/24576000\n",
      "current iter: 7008000/24576000\n",
      "current iter: 7009000/24576000\n",
      "current iter: 7010000/24576000\n",
      "current iter: 7011000/24576000\n",
      "current iter: 7012000/24576000\n",
      "current iter: 7013000/24576000\n",
      "current iter: 7014000/24576000\n",
      "current iter: 7015000/24576000\n",
      "current iter: 7016000/24576000\n",
      "current iter: 7017000/24576000\n",
      "current iter: 7018000/24576000\n",
      "current iter: 7019000/24576000\n",
      "current iter: 7020000/24576000\n",
      "current iter: 7021000/24576000\n",
      "current iter: 7022000/24576000\n",
      "current iter: 7023000/24576000\n",
      "current iter: 7024000/24576000\n",
      "current iter: 7025000/24576000\n",
      "current iter: 7026000/24576000\n",
      "current iter: 7027000/24576000\n",
      "current iter: 7028000/24576000\n",
      "current iter: 7029000/24576000\n",
      "current iter: 7030000/24576000\n",
      "current iter: 7031000/24576000\n",
      "current iter: 7032000/24576000\n",
      "current iter: 7033000/24576000\n",
      "current iter: 7034000/24576000\n",
      "current iter: 7035000/24576000\n",
      "current iter: 7036000/24576000\n",
      "current iter: 7037000/24576000\n",
      "current iter: 7038000/24576000\n",
      "current iter: 7039000/24576000\n",
      "current iter: 7040000/24576000\n",
      "current iter: 7041000/24576000\n",
      "current iter: 7042000/24576000\n",
      "current iter: 7043000/24576000\n",
      "current iter: 7044000/24576000\n",
      "current iter: 7045000/24576000\n",
      "current iter: 7046000/24576000\n",
      "current iter: 7047000/24576000\n",
      "current iter: 7048000/24576000\n",
      "current iter: 7049000/24576000\n",
      "current iter: 7050000/24576000\n",
      "current iter: 7051000/24576000\n",
      "current iter: 7052000/24576000\n",
      "current iter: 7053000/24576000\n",
      "current iter: 7054000/24576000\n",
      "current iter: 7055000/24576000\n",
      "current iter: 7056000/24576000\n",
      "current iter: 7057000/24576000\n",
      "current iter: 7058000/24576000\n",
      "current iter: 7059000/24576000\n",
      "current iter: 7060000/24576000\n",
      "current iter: 7061000/24576000\n",
      "current iter: 7062000/24576000\n",
      "current iter: 7063000/24576000\n",
      "current iter: 7064000/24576000\n",
      "current iter: 7065000/24576000\n",
      "current iter: 7066000/24576000\n",
      "current iter: 7067000/24576000\n",
      "current iter: 7068000/24576000\n",
      "current iter: 7069000/24576000\n",
      "current iter: 7070000/24576000\n",
      "current iter: 7071000/24576000\n",
      "current iter: 7072000/24576000\n",
      "current iter: 7073000/24576000\n",
      "current iter: 7074000/24576000\n",
      "current iter: 7075000/24576000\n",
      "current iter: 7076000/24576000\n",
      "current iter: 7077000/24576000\n",
      "current iter: 7078000/24576000\n",
      "current iter: 7079000/24576000\n",
      "current iter: 7080000/24576000\n",
      "current iter: 7081000/24576000\n",
      "current iter: 7082000/24576000\n",
      "current iter: 7083000/24576000\n",
      "current iter: 7084000/24576000\n",
      "current iter: 7085000/24576000\n",
      "current iter: 7086000/24576000\n",
      "current iter: 7087000/24576000\n",
      "current iter: 7088000/24576000\n",
      "current iter: 7089000/24576000\n",
      "current iter: 7090000/24576000\n",
      "current iter: 7091000/24576000\n",
      "current iter: 7092000/24576000\n",
      "current iter: 7093000/24576000\n",
      "current iter: 7094000/24576000\n",
      "current iter: 7095000/24576000\n",
      "current iter: 7096000/24576000\n",
      "current iter: 7097000/24576000\n",
      "current iter: 7098000/24576000\n",
      "current iter: 7099000/24576000\n",
      "current iter: 7100000/24576000\n",
      "current iter: 7101000/24576000\n",
      "current iter: 7102000/24576000\n",
      "current iter: 7103000/24576000\n",
      "current iter: 7104000/24576000\n",
      "current iter: 7105000/24576000\n",
      "current iter: 7106000/24576000\n",
      "current iter: 7107000/24576000\n",
      "current iter: 7108000/24576000\n",
      "current iter: 7109000/24576000\n",
      "current iter: 7110000/24576000\n",
      "current iter: 7111000/24576000\n",
      "current iter: 7112000/24576000\n",
      "current iter: 7113000/24576000\n",
      "current iter: 7114000/24576000\n",
      "current iter: 7115000/24576000\n",
      "current iter: 7116000/24576000\n",
      "current iter: 7117000/24576000\n",
      "current iter: 7118000/24576000\n",
      "current iter: 7119000/24576000\n",
      "current iter: 7120000/24576000\n",
      "current iter: 7121000/24576000\n",
      "current iter: 7122000/24576000\n",
      "current iter: 7123000/24576000\n",
      "current iter: 7124000/24576000\n",
      "current iter: 7125000/24576000\n",
      "current iter: 7126000/24576000\n",
      "current iter: 7127000/24576000\n",
      "current iter: 7128000/24576000\n",
      "current iter: 7129000/24576000\n",
      "current iter: 7130000/24576000\n",
      "current iter: 7131000/24576000\n",
      "current iter: 7132000/24576000\n",
      "current iter: 7133000/24576000\n",
      "current iter: 7134000/24576000\n",
      "current iter: 7135000/24576000\n",
      "current iter: 7136000/24576000\n",
      "current iter: 7137000/24576000\n",
      "current iter: 7138000/24576000\n",
      "current iter: 7139000/24576000\n",
      "current iter: 7140000/24576000\n",
      "current iter: 7141000/24576000\n",
      "current iter: 7142000/24576000\n",
      "current iter: 7143000/24576000\n",
      "current iter: 7144000/24576000\n",
      "current iter: 7145000/24576000\n",
      "current iter: 7146000/24576000\n",
      "current iter: 7147000/24576000\n",
      "current iter: 7148000/24576000\n",
      "current iter: 7149000/24576000\n",
      "current iter: 7150000/24576000\n",
      "current iter: 7151000/24576000\n",
      "current iter: 7152000/24576000\n",
      "current iter: 7153000/24576000\n",
      "current iter: 7154000/24576000\n",
      "current iter: 7155000/24576000\n",
      "current iter: 7156000/24576000\n",
      "current iter: 7157000/24576000\n",
      "current iter: 7158000/24576000\n",
      "current iter: 7159000/24576000\n",
      "current iter: 7160000/24576000\n",
      "current iter: 7161000/24576000\n",
      "current iter: 7162000/24576000\n",
      "current iter: 7163000/24576000\n",
      "current iter: 7164000/24576000\n",
      "current iter: 7165000/24576000\n",
      "current iter: 7166000/24576000\n",
      "current iter: 7167000/24576000\n",
      "current iter: 7168000/24576000\n",
      "current iter: 7169000/24576000\n",
      "current iter: 7170000/24576000\n",
      "current iter: 7171000/24576000\n",
      "current iter: 7172000/24576000\n",
      "current iter: 7173000/24576000\n",
      "current iter: 7174000/24576000\n",
      "current iter: 7175000/24576000\n",
      "current iter: 7176000/24576000\n",
      "current iter: 7177000/24576000\n",
      "current iter: 7178000/24576000\n",
      "current iter: 7179000/24576000\n",
      "current iter: 7180000/24576000\n",
      "current iter: 7181000/24576000\n",
      "current iter: 7182000/24576000\n",
      "current iter: 7183000/24576000\n",
      "current iter: 7184000/24576000\n",
      "current iter: 7185000/24576000\n",
      "current iter: 7186000/24576000\n",
      "current iter: 7187000/24576000\n",
      "current iter: 7188000/24576000\n",
      "current iter: 7189000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 7190000/24576000\n",
      "current iter: 7191000/24576000\n",
      "current iter: 7192000/24576000\n",
      "current iter: 7193000/24576000\n",
      "current iter: 7194000/24576000\n",
      "current iter: 7195000/24576000\n",
      "current iter: 7196000/24576000\n",
      "current iter: 7197000/24576000\n",
      "current iter: 7198000/24576000\n",
      "current iter: 7199000/24576000\n",
      "current iter: 7200000/24576000\n",
      "current iter: 7201000/24576000\n",
      "current iter: 7202000/24576000\n",
      "current iter: 7203000/24576000\n",
      "current iter: 7204000/24576000\n",
      "current iter: 7205000/24576000\n",
      "current iter: 7206000/24576000\n",
      "current iter: 7207000/24576000\n",
      "current iter: 7208000/24576000\n",
      "current iter: 7209000/24576000\n",
      "current iter: 7210000/24576000\n",
      "current iter: 7211000/24576000\n",
      "current iter: 7212000/24576000\n",
      "current iter: 7213000/24576000\n",
      "current iter: 7214000/24576000\n",
      "current iter: 7215000/24576000\n",
      "current iter: 7216000/24576000\n",
      "current iter: 7217000/24576000\n",
      "current iter: 7218000/24576000\n",
      "current iter: 7219000/24576000\n",
      "current iter: 7220000/24576000\n",
      "current iter: 7221000/24576000\n",
      "current iter: 7222000/24576000\n",
      "current iter: 7223000/24576000\n",
      "current iter: 7224000/24576000\n",
      "current iter: 7225000/24576000\n",
      "current iter: 7226000/24576000\n",
      "current iter: 7227000/24576000\n",
      "current iter: 7228000/24576000\n",
      "current iter: 7229000/24576000\n",
      "current iter: 7230000/24576000\n",
      "current iter: 7231000/24576000\n",
      "current iter: 7232000/24576000\n",
      "current iter: 7233000/24576000\n",
      "current iter: 7234000/24576000\n",
      "current iter: 7235000/24576000\n",
      "current iter: 7236000/24576000\n",
      "current iter: 7237000/24576000\n",
      "current iter: 7238000/24576000\n",
      "current iter: 7239000/24576000\n",
      "current iter: 7240000/24576000\n",
      "current iter: 7241000/24576000\n",
      "current iter: 7242000/24576000\n",
      "current iter: 7243000/24576000\n",
      "current iter: 7244000/24576000\n",
      "current iter: 7245000/24576000\n",
      "current iter: 7246000/24576000\n",
      "current iter: 7247000/24576000\n",
      "current iter: 7248000/24576000\n",
      "current iter: 7249000/24576000\n",
      "current iter: 7250000/24576000\n",
      "current iter: 7251000/24576000\n",
      "current iter: 7252000/24576000\n",
      "current iter: 7253000/24576000\n",
      "current iter: 7254000/24576000\n",
      "current iter: 7255000/24576000\n",
      "current iter: 7256000/24576000\n",
      "current iter: 7257000/24576000\n",
      "current iter: 7258000/24576000\n",
      "current iter: 7259000/24576000\n",
      "current iter: 7260000/24576000\n",
      "current iter: 7261000/24576000\n",
      "current iter: 7262000/24576000\n",
      "current iter: 7263000/24576000\n",
      "current iter: 7264000/24576000\n",
      "current iter: 7265000/24576000\n",
      "current iter: 7266000/24576000\n",
      "current iter: 7267000/24576000\n",
      "current iter: 7268000/24576000\n",
      "current iter: 7269000/24576000\n",
      "current iter: 7270000/24576000\n",
      "current iter: 7271000/24576000\n",
      "current iter: 7272000/24576000\n",
      "current iter: 7273000/24576000\n",
      "current iter: 7274000/24576000\n",
      "current iter: 7275000/24576000\n",
      "current iter: 7276000/24576000\n",
      "current iter: 7277000/24576000\n",
      "current iter: 7278000/24576000\n",
      "current iter: 7279000/24576000\n",
      "current iter: 7280000/24576000\n",
      "current iter: 7281000/24576000\n",
      "current iter: 7282000/24576000\n",
      "current iter: 7283000/24576000\n",
      "current iter: 7284000/24576000\n",
      "current iter: 7285000/24576000\n",
      "current iter: 7286000/24576000\n",
      "current iter: 7287000/24576000\n",
      "current iter: 7288000/24576000\n",
      "current iter: 7289000/24576000\n",
      "current iter: 7290000/24576000\n",
      "current iter: 7291000/24576000\n",
      "current iter: 7292000/24576000\n",
      "current iter: 7293000/24576000\n",
      "current iter: 7294000/24576000\n",
      "current iter: 7295000/24576000\n",
      "current iter: 7296000/24576000\n",
      "current iter: 7297000/24576000\n",
      "current iter: 7298000/24576000\n",
      "current iter: 7299000/24576000\n",
      "current iter: 7300000/24576000\n",
      "current iter: 7301000/24576000\n",
      "current iter: 7302000/24576000\n",
      "current iter: 7303000/24576000\n",
      "current iter: 7304000/24576000\n",
      "current iter: 7305000/24576000\n",
      "current iter: 7306000/24576000\n",
      "current iter: 7307000/24576000\n",
      "current iter: 7308000/24576000\n",
      "current iter: 7309000/24576000\n",
      "current iter: 7310000/24576000\n",
      "current iter: 7311000/24576000\n",
      "current iter: 7312000/24576000\n",
      "current iter: 7313000/24576000\n",
      "current iter: 7314000/24576000\n",
      "current iter: 7315000/24576000\n",
      "current iter: 7316000/24576000\n",
      "current iter: 7317000/24576000\n",
      "current iter: 7318000/24576000\n",
      "current iter: 7319000/24576000\n",
      "current iter: 7320000/24576000\n",
      "current iter: 7321000/24576000\n",
      "current iter: 7322000/24576000\n",
      "current iter: 7323000/24576000\n",
      "current iter: 7324000/24576000\n",
      "current iter: 7325000/24576000\n",
      "current iter: 7326000/24576000\n",
      "current iter: 7327000/24576000\n",
      "current iter: 7328000/24576000\n",
      "current iter: 7329000/24576000\n",
      "current iter: 7330000/24576000\n",
      "current iter: 7331000/24576000\n",
      "current iter: 7332000/24576000\n",
      "current iter: 7333000/24576000\n",
      "current iter: 7334000/24576000\n",
      "current iter: 7335000/24576000\n",
      "current iter: 7336000/24576000\n",
      "current iter: 7337000/24576000\n",
      "current iter: 7338000/24576000\n",
      "current iter: 7339000/24576000\n",
      "current iter: 7340000/24576000\n",
      "current iter: 7341000/24576000\n",
      "current iter: 7342000/24576000\n",
      "current iter: 7343000/24576000\n",
      "current iter: 7344000/24576000\n",
      "current iter: 7345000/24576000\n",
      "current iter: 7346000/24576000\n",
      "current iter: 7347000/24576000\n",
      "current iter: 7348000/24576000\n",
      "current iter: 7349000/24576000\n",
      "current iter: 7350000/24576000\n",
      "current iter: 7351000/24576000\n",
      "current iter: 7352000/24576000\n",
      "current iter: 7353000/24576000\n",
      "current iter: 7354000/24576000\n",
      "current iter: 7355000/24576000\n",
      "current iter: 7356000/24576000\n",
      "current iter: 7357000/24576000\n",
      "current iter: 7358000/24576000\n",
      "current iter: 7359000/24576000\n",
      "current iter: 7360000/24576000\n",
      "current iter: 7361000/24576000\n",
      "current iter: 7362000/24576000\n",
      "current iter: 7363000/24576000\n",
      "current iter: 7364000/24576000\n",
      "current iter: 7365000/24576000\n",
      "current iter: 7366000/24576000\n",
      "current iter: 7367000/24576000\n",
      "current iter: 7368000/24576000\n",
      "current iter: 7369000/24576000\n",
      "current iter: 7370000/24576000\n",
      "current iter: 7371000/24576000\n",
      "current iter: 7372000/24576000\n",
      "current iter: 7373000/24576000\n",
      "current iter: 7374000/24576000\n",
      "current iter: 7375000/24576000\n",
      "current iter: 7376000/24576000\n",
      "current iter: 7377000/24576000\n",
      "current iter: 7378000/24576000\n",
      "current iter: 7379000/24576000\n",
      "current iter: 7380000/24576000\n",
      "current iter: 7381000/24576000\n",
      "current iter: 7382000/24576000\n",
      "current iter: 7383000/24576000\n",
      "current iter: 7384000/24576000\n",
      "current iter: 7385000/24576000\n",
      "current iter: 7386000/24576000\n",
      "current iter: 7387000/24576000\n",
      "current iter: 7388000/24576000\n",
      "current iter: 7389000/24576000\n",
      "current iter: 7390000/24576000\n",
      "current iter: 7391000/24576000\n",
      "current iter: 7392000/24576000\n",
      "current iter: 7393000/24576000\n",
      "current iter: 7394000/24576000\n",
      "current iter: 7395000/24576000\n",
      "current iter: 7396000/24576000\n",
      "current iter: 7397000/24576000\n",
      "current iter: 7398000/24576000\n",
      "current iter: 7399000/24576000\n",
      "current iter: 7400000/24576000\n",
      "current iter: 7401000/24576000\n",
      "current iter: 7402000/24576000\n",
      "current iter: 7403000/24576000\n",
      "current iter: 7404000/24576000\n",
      "current iter: 7405000/24576000\n",
      "current iter: 7406000/24576000\n",
      "current iter: 7407000/24576000\n",
      "current iter: 7408000/24576000\n",
      "current iter: 7409000/24576000\n",
      "current iter: 7410000/24576000\n",
      "current iter: 7411000/24576000\n",
      "current iter: 7412000/24576000\n",
      "current iter: 7413000/24576000\n",
      "current iter: 7414000/24576000\n",
      "current iter: 7415000/24576000\n",
      "current iter: 7416000/24576000\n",
      "current iter: 7417000/24576000\n",
      "current iter: 7418000/24576000\n",
      "current iter: 7419000/24576000\n",
      "current iter: 7420000/24576000\n",
      "current iter: 7421000/24576000\n",
      "current iter: 7422000/24576000\n",
      "current iter: 7423000/24576000\n",
      "current iter: 7424000/24576000\n",
      "current iter: 7425000/24576000\n",
      "current iter: 7426000/24576000\n",
      "current iter: 7427000/24576000\n",
      "current iter: 7428000/24576000\n",
      "current iter: 7429000/24576000\n",
      "current iter: 7430000/24576000\n",
      "current iter: 7431000/24576000\n",
      "current iter: 7432000/24576000\n",
      "current iter: 7433000/24576000\n",
      "current iter: 7434000/24576000\n",
      "current iter: 7435000/24576000\n",
      "current iter: 7436000/24576000\n",
      "current iter: 7437000/24576000\n",
      "current iter: 7438000/24576000\n",
      "current iter: 7439000/24576000\n",
      "current iter: 7440000/24576000\n",
      "current iter: 7441000/24576000\n",
      "current iter: 7442000/24576000\n",
      "current iter: 7443000/24576000\n",
      "current iter: 7444000/24576000\n",
      "current iter: 7445000/24576000\n",
      "current iter: 7446000/24576000\n",
      "current iter: 7447000/24576000\n",
      "current iter: 7448000/24576000\n",
      "current iter: 7449000/24576000\n",
      "current iter: 7450000/24576000\n",
      "current iter: 7451000/24576000\n",
      "current iter: 7452000/24576000\n",
      "current iter: 7453000/24576000\n",
      "current iter: 7454000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 7455000/24576000\n",
      "current iter: 7456000/24576000\n",
      "current iter: 7457000/24576000\n",
      "current iter: 7458000/24576000\n",
      "current iter: 7459000/24576000\n",
      "current iter: 7460000/24576000\n",
      "current iter: 7461000/24576000\n",
      "current iter: 7462000/24576000\n",
      "current iter: 7463000/24576000\n",
      "current iter: 7464000/24576000\n",
      "current iter: 7465000/24576000\n",
      "current iter: 7466000/24576000\n",
      "current iter: 7467000/24576000\n",
      "current iter: 7468000/24576000\n",
      "current iter: 7469000/24576000\n",
      "current iter: 7470000/24576000\n",
      "current iter: 7471000/24576000\n",
      "current iter: 7472000/24576000\n",
      "current iter: 7473000/24576000\n",
      "current iter: 7474000/24576000\n",
      "current iter: 7475000/24576000\n",
      "current iter: 7476000/24576000\n",
      "current iter: 7477000/24576000\n",
      "current iter: 7478000/24576000\n",
      "current iter: 7479000/24576000\n",
      "current iter: 7480000/24576000\n",
      "current iter: 7481000/24576000\n",
      "current iter: 7482000/24576000\n",
      "current iter: 7483000/24576000\n",
      "current iter: 7484000/24576000\n",
      "current iter: 7485000/24576000\n",
      "current iter: 7486000/24576000\n",
      "current iter: 7487000/24576000\n",
      "current iter: 7488000/24576000\n",
      "current iter: 7489000/24576000\n",
      "current iter: 7490000/24576000\n",
      "current iter: 7491000/24576000\n",
      "current iter: 7492000/24576000\n",
      "current iter: 7493000/24576000\n",
      "current iter: 7494000/24576000\n",
      "current iter: 7495000/24576000\n",
      "current iter: 7496000/24576000\n",
      "current iter: 7497000/24576000\n",
      "current iter: 7498000/24576000\n",
      "current iter: 7499000/24576000\n",
      "current iter: 7500000/24576000\n",
      "current iter: 7501000/24576000\n",
      "current iter: 7502000/24576000\n",
      "current iter: 7503000/24576000\n",
      "current iter: 7504000/24576000\n",
      "current iter: 7505000/24576000\n",
      "current iter: 7506000/24576000\n",
      "current iter: 7507000/24576000\n",
      "current iter: 7508000/24576000\n",
      "current iter: 7509000/24576000\n",
      "current iter: 7510000/24576000\n",
      "current iter: 7511000/24576000\n",
      "current iter: 7512000/24576000\n",
      "current iter: 7513000/24576000\n",
      "current iter: 7514000/24576000\n",
      "current iter: 7515000/24576000\n",
      "current iter: 7516000/24576000\n",
      "current iter: 7517000/24576000\n",
      "current iter: 7518000/24576000\n",
      "current iter: 7519000/24576000\n",
      "current iter: 7520000/24576000\n",
      "current iter: 7521000/24576000\n",
      "current iter: 7522000/24576000\n",
      "current iter: 7523000/24576000\n",
      "current iter: 7524000/24576000\n",
      "current iter: 7525000/24576000\n",
      "current iter: 7526000/24576000\n",
      "current iter: 7527000/24576000\n",
      "current iter: 7528000/24576000\n",
      "current iter: 7529000/24576000\n",
      "current iter: 7530000/24576000\n",
      "current iter: 7531000/24576000\n",
      "current iter: 7532000/24576000\n",
      "current iter: 7533000/24576000\n",
      "current iter: 7534000/24576000\n",
      "current iter: 7535000/24576000\n",
      "current iter: 7536000/24576000\n",
      "current iter: 7537000/24576000\n",
      "current iter: 7538000/24576000\n",
      "current iter: 7539000/24576000\n",
      "current iter: 7540000/24576000\n",
      "current iter: 7541000/24576000\n",
      "current iter: 7542000/24576000\n",
      "current iter: 7543000/24576000\n",
      "current iter: 7544000/24576000\n",
      "current iter: 7545000/24576000\n",
      "current iter: 7546000/24576000\n",
      "current iter: 7547000/24576000\n",
      "current iter: 7548000/24576000\n",
      "current iter: 7549000/24576000\n",
      "current iter: 7550000/24576000\n",
      "current iter: 7551000/24576000\n",
      "current iter: 7552000/24576000\n",
      "current iter: 7553000/24576000\n",
      "current iter: 7554000/24576000\n",
      "current iter: 7555000/24576000\n",
      "current iter: 7556000/24576000\n",
      "current iter: 7557000/24576000\n",
      "current iter: 7558000/24576000\n",
      "current iter: 7559000/24576000\n",
      "current iter: 7560000/24576000\n",
      "current iter: 7561000/24576000\n",
      "current iter: 7562000/24576000\n",
      "current iter: 7563000/24576000\n",
      "current iter: 7564000/24576000\n",
      "current iter: 7565000/24576000\n",
      "current iter: 7566000/24576000\n",
      "current iter: 7567000/24576000\n",
      "current iter: 7568000/24576000\n",
      "current iter: 7569000/24576000\n",
      "current iter: 7570000/24576000\n",
      "current iter: 7571000/24576000\n",
      "current iter: 7572000/24576000\n",
      "current iter: 7573000/24576000\n",
      "current iter: 7574000/24576000\n",
      "current iter: 7575000/24576000\n",
      "current iter: 7576000/24576000\n",
      "current iter: 7577000/24576000\n",
      "current iter: 7578000/24576000\n",
      "current iter: 7579000/24576000\n",
      "current iter: 7580000/24576000\n",
      "current iter: 7581000/24576000\n",
      "current iter: 7582000/24576000\n",
      "current iter: 7583000/24576000\n",
      "current iter: 7584000/24576000\n",
      "current iter: 7585000/24576000\n",
      "current iter: 7586000/24576000\n",
      "current iter: 7587000/24576000\n",
      "current iter: 7588000/24576000\n",
      "current iter: 7589000/24576000\n",
      "current iter: 7590000/24576000\n",
      "current iter: 7591000/24576000\n",
      "current iter: 7592000/24576000\n",
      "current iter: 7593000/24576000\n",
      "current iter: 7594000/24576000\n",
      "current iter: 7595000/24576000\n",
      "current iter: 7596000/24576000\n",
      "current iter: 7597000/24576000\n",
      "current iter: 7598000/24576000\n",
      "current iter: 7599000/24576000\n",
      "current iter: 7600000/24576000\n",
      "current iter: 7601000/24576000\n",
      "current iter: 7602000/24576000\n",
      "current iter: 7603000/24576000\n",
      "current iter: 7604000/24576000\n",
      "current iter: 7605000/24576000\n",
      "current iter: 7606000/24576000\n",
      "current iter: 7607000/24576000\n",
      "current iter: 7608000/24576000\n",
      "current iter: 7609000/24576000\n",
      "current iter: 7610000/24576000\n",
      "current iter: 7611000/24576000\n",
      "current iter: 7612000/24576000\n",
      "current iter: 7613000/24576000\n",
      "current iter: 7614000/24576000\n",
      "current iter: 7615000/24576000\n",
      "current iter: 7616000/24576000\n",
      "current iter: 7617000/24576000\n",
      "current iter: 7618000/24576000\n",
      "current iter: 7619000/24576000\n",
      "current iter: 7620000/24576000\n",
      "current iter: 7621000/24576000\n",
      "current iter: 7622000/24576000\n",
      "current iter: 7623000/24576000\n",
      "current iter: 7624000/24576000\n",
      "current iter: 7625000/24576000\n",
      "current iter: 7626000/24576000\n",
      "current iter: 7627000/24576000\n",
      "current iter: 7628000/24576000\n",
      "current iter: 7629000/24576000\n",
      "current iter: 7630000/24576000\n",
      "current iter: 7631000/24576000\n",
      "current iter: 7632000/24576000\n",
      "current iter: 7633000/24576000\n",
      "current iter: 7634000/24576000\n",
      "current iter: 7635000/24576000\n",
      "current iter: 7636000/24576000\n",
      "current iter: 7637000/24576000\n",
      "current iter: 7638000/24576000\n",
      "current iter: 7639000/24576000\n",
      "current iter: 7640000/24576000\n",
      "current iter: 7641000/24576000\n",
      "current iter: 7642000/24576000\n",
      "current iter: 7643000/24576000\n",
      "current iter: 7644000/24576000\n",
      "current iter: 7645000/24576000\n",
      "current iter: 7646000/24576000\n",
      "current iter: 7647000/24576000\n",
      "current iter: 7648000/24576000\n",
      "current iter: 7649000/24576000\n",
      "current iter: 7650000/24576000\n",
      "current iter: 7651000/24576000\n",
      "current iter: 7652000/24576000\n",
      "current iter: 7653000/24576000\n",
      "current iter: 7654000/24576000\n",
      "current iter: 7655000/24576000\n",
      "current iter: 7656000/24576000\n",
      "current iter: 7657000/24576000\n",
      "current iter: 7658000/24576000\n",
      "current iter: 7659000/24576000\n",
      "current iter: 7660000/24576000\n",
      "current iter: 7661000/24576000\n",
      "current iter: 7662000/24576000\n",
      "current iter: 7663000/24576000\n",
      "current iter: 7664000/24576000\n",
      "current iter: 7665000/24576000\n",
      "current iter: 7666000/24576000\n",
      "current iter: 7667000/24576000\n",
      "current iter: 7668000/24576000\n",
      "current iter: 7669000/24576000\n",
      "current iter: 7670000/24576000\n",
      "current iter: 7671000/24576000\n",
      "current iter: 7672000/24576000\n",
      "current iter: 7673000/24576000\n",
      "current iter: 7674000/24576000\n",
      "current iter: 7675000/24576000\n",
      "current iter: 7676000/24576000\n",
      "current iter: 7677000/24576000\n",
      "current iter: 7678000/24576000\n",
      "current iter: 7679000/24576000\n",
      "current iter: 7680000/24576000\n",
      "current iter: 7681000/24576000\n",
      "current iter: 7682000/24576000\n",
      "current iter: 7683000/24576000\n",
      "current iter: 7684000/24576000\n",
      "current iter: 7685000/24576000\n",
      "current iter: 7686000/24576000\n",
      "current iter: 7687000/24576000\n",
      "current iter: 7688000/24576000\n",
      "current iter: 7689000/24576000\n",
      "current iter: 7690000/24576000\n",
      "current iter: 7691000/24576000\n",
      "current iter: 7692000/24576000\n",
      "current iter: 7693000/24576000\n",
      "current iter: 7694000/24576000\n",
      "current iter: 7695000/24576000\n",
      "current iter: 7696000/24576000\n",
      "current iter: 7697000/24576000\n",
      "current iter: 7698000/24576000\n",
      "current iter: 7699000/24576000\n",
      "current iter: 7700000/24576000\n",
      "current iter: 7701000/24576000\n",
      "current iter: 7702000/24576000\n",
      "current iter: 7703000/24576000\n",
      "current iter: 7704000/24576000\n",
      "current iter: 7705000/24576000\n",
      "current iter: 7706000/24576000\n",
      "current iter: 7707000/24576000\n",
      "current iter: 7708000/24576000\n",
      "current iter: 7709000/24576000\n",
      "current iter: 7710000/24576000\n",
      "current iter: 7711000/24576000\n",
      "current iter: 7712000/24576000\n",
      "current iter: 7713000/24576000\n",
      "current iter: 7714000/24576000\n",
      "current iter: 7715000/24576000\n",
      "current iter: 7716000/24576000\n",
      "current iter: 7717000/24576000\n",
      "current iter: 7718000/24576000\n",
      "current iter: 7719000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 7720000/24576000\n",
      "current iter: 7721000/24576000\n",
      "current iter: 7722000/24576000\n",
      "current iter: 7723000/24576000\n",
      "current iter: 7724000/24576000\n",
      "current iter: 7725000/24576000\n",
      "current iter: 7726000/24576000\n",
      "current iter: 7727000/24576000\n",
      "current iter: 7728000/24576000\n",
      "current iter: 7729000/24576000\n",
      "current iter: 7730000/24576000\n",
      "current iter: 7731000/24576000\n",
      "current iter: 7732000/24576000\n",
      "current iter: 7733000/24576000\n",
      "current iter: 7734000/24576000\n",
      "current iter: 7735000/24576000\n",
      "current iter: 7736000/24576000\n",
      "current iter: 7737000/24576000\n",
      "current iter: 7738000/24576000\n",
      "current iter: 7739000/24576000\n",
      "current iter: 7740000/24576000\n",
      "current iter: 7741000/24576000\n",
      "current iter: 7742000/24576000\n",
      "current iter: 7743000/24576000\n",
      "current iter: 7744000/24576000\n",
      "current iter: 7745000/24576000\n",
      "current iter: 7746000/24576000\n",
      "current iter: 7747000/24576000\n",
      "current iter: 7748000/24576000\n",
      "current iter: 7749000/24576000\n",
      "current iter: 7750000/24576000\n",
      "current iter: 7751000/24576000\n",
      "current iter: 7752000/24576000\n",
      "current iter: 7753000/24576000\n",
      "current iter: 7754000/24576000\n",
      "current iter: 7755000/24576000\n",
      "current iter: 7756000/24576000\n",
      "current iter: 7757000/24576000\n",
      "current iter: 7758000/24576000\n",
      "current iter: 7759000/24576000\n",
      "current iter: 7760000/24576000\n",
      "current iter: 7761000/24576000\n",
      "current iter: 7762000/24576000\n",
      "current iter: 7763000/24576000\n",
      "current iter: 7764000/24576000\n",
      "current iter: 7765000/24576000\n",
      "current iter: 7766000/24576000\n",
      "current iter: 7767000/24576000\n",
      "current iter: 7768000/24576000\n",
      "current iter: 7769000/24576000\n",
      "current iter: 7770000/24576000\n",
      "current iter: 7771000/24576000\n",
      "current iter: 7772000/24576000\n",
      "current iter: 7773000/24576000\n",
      "current iter: 7774000/24576000\n",
      "current iter: 7775000/24576000\n",
      "current iter: 7776000/24576000\n",
      "current iter: 7777000/24576000\n",
      "current iter: 7778000/24576000\n",
      "current iter: 7779000/24576000\n",
      "current iter: 7780000/24576000\n",
      "current iter: 7781000/24576000\n",
      "current iter: 7782000/24576000\n",
      "current iter: 7783000/24576000\n",
      "current iter: 7784000/24576000\n",
      "current iter: 7785000/24576000\n",
      "current iter: 7786000/24576000\n",
      "current iter: 7787000/24576000\n",
      "current iter: 7788000/24576000\n",
      "current iter: 7789000/24576000\n",
      "current iter: 7790000/24576000\n",
      "current iter: 7791000/24576000\n",
      "current iter: 7792000/24576000\n",
      "current iter: 7793000/24576000\n",
      "current iter: 7794000/24576000\n",
      "current iter: 7795000/24576000\n",
      "current iter: 7796000/24576000\n",
      "current iter: 7797000/24576000\n",
      "current iter: 7798000/24576000\n",
      "current iter: 7799000/24576000\n",
      "current iter: 7800000/24576000\n",
      "current iter: 7801000/24576000\n",
      "current iter: 7802000/24576000\n",
      "current iter: 7803000/24576000\n",
      "current iter: 7804000/24576000\n",
      "current iter: 7805000/24576000\n",
      "current iter: 7806000/24576000\n",
      "current iter: 7807000/24576000\n",
      "current iter: 7808000/24576000\n",
      "current iter: 7809000/24576000\n",
      "current iter: 7810000/24576000\n",
      "current iter: 7811000/24576000\n",
      "current iter: 7812000/24576000\n",
      "current iter: 7813000/24576000\n",
      "current iter: 7814000/24576000\n",
      "current iter: 7815000/24576000\n",
      "current iter: 7816000/24576000\n",
      "current iter: 7817000/24576000\n",
      "current iter: 7818000/24576000\n",
      "current iter: 7819000/24576000\n",
      "current iter: 7820000/24576000\n",
      "current iter: 7821000/24576000\n",
      "current iter: 7822000/24576000\n",
      "current iter: 7823000/24576000\n",
      "current iter: 7824000/24576000\n",
      "current iter: 7825000/24576000\n",
      "current iter: 7826000/24576000\n",
      "current iter: 7827000/24576000\n",
      "current iter: 7828000/24576000\n",
      "current iter: 7829000/24576000\n",
      "current iter: 7830000/24576000\n",
      "current iter: 7831000/24576000\n",
      "current iter: 7832000/24576000\n",
      "current iter: 7833000/24576000\n",
      "current iter: 7834000/24576000\n",
      "current iter: 7835000/24576000\n",
      "current iter: 7836000/24576000\n",
      "current iter: 7837000/24576000\n",
      "current iter: 7838000/24576000\n",
      "current iter: 7839000/24576000\n",
      "current iter: 7840000/24576000\n",
      "current iter: 7841000/24576000\n",
      "current iter: 7842000/24576000\n",
      "current iter: 7843000/24576000\n",
      "current iter: 7844000/24576000\n",
      "current iter: 7845000/24576000\n",
      "current iter: 7846000/24576000\n",
      "current iter: 7847000/24576000\n",
      "current iter: 7848000/24576000\n",
      "current iter: 7849000/24576000\n",
      "current iter: 7850000/24576000\n",
      "current iter: 7851000/24576000\n",
      "current iter: 7852000/24576000\n",
      "current iter: 7853000/24576000\n",
      "current iter: 7854000/24576000\n",
      "current iter: 7855000/24576000\n",
      "current iter: 7856000/24576000\n",
      "current iter: 7857000/24576000\n",
      "current iter: 7858000/24576000\n",
      "current iter: 7859000/24576000\n",
      "current iter: 7860000/24576000\n",
      "current iter: 7861000/24576000\n",
      "current iter: 7862000/24576000\n",
      "current iter: 7863000/24576000\n",
      "current iter: 7864000/24576000\n",
      "current iter: 7865000/24576000\n",
      "current iter: 7866000/24576000\n",
      "current iter: 7867000/24576000\n",
      "current iter: 7868000/24576000\n",
      "current iter: 7869000/24576000\n",
      "current iter: 7870000/24576000\n",
      "current iter: 7871000/24576000\n",
      "current iter: 7872000/24576000\n",
      "current iter: 7873000/24576000\n",
      "current iter: 7874000/24576000\n",
      "current iter: 7875000/24576000\n",
      "current iter: 7876000/24576000\n",
      "current iter: 7877000/24576000\n",
      "current iter: 7878000/24576000\n",
      "current iter: 7879000/24576000\n",
      "current iter: 7880000/24576000\n",
      "current iter: 7881000/24576000\n",
      "current iter: 7882000/24576000\n",
      "current iter: 7883000/24576000\n",
      "current iter: 7884000/24576000\n",
      "current iter: 7885000/24576000\n",
      "current iter: 7886000/24576000\n",
      "current iter: 7887000/24576000\n",
      "current iter: 7888000/24576000\n",
      "current iter: 7889000/24576000\n",
      "current iter: 7890000/24576000\n",
      "current iter: 7891000/24576000\n",
      "current iter: 7892000/24576000\n",
      "current iter: 7893000/24576000\n",
      "current iter: 7894000/24576000\n",
      "current iter: 7895000/24576000\n",
      "current iter: 7896000/24576000\n",
      "current iter: 7897000/24576000\n",
      "current iter: 7898000/24576000\n",
      "current iter: 7899000/24576000\n",
      "current iter: 7900000/24576000\n",
      "current iter: 7901000/24576000\n",
      "current iter: 7902000/24576000\n",
      "current iter: 7903000/24576000\n",
      "current iter: 7904000/24576000\n",
      "current iter: 7905000/24576000\n",
      "current iter: 7906000/24576000\n",
      "current iter: 7907000/24576000\n",
      "current iter: 7908000/24576000\n",
      "current iter: 7909000/24576000\n",
      "current iter: 7910000/24576000\n",
      "current iter: 7911000/24576000\n",
      "current iter: 7912000/24576000\n",
      "current iter: 7913000/24576000\n",
      "current iter: 7914000/24576000\n",
      "current iter: 7915000/24576000\n",
      "current iter: 7916000/24576000\n",
      "current iter: 7917000/24576000\n",
      "current iter: 7918000/24576000\n",
      "current iter: 7919000/24576000\n",
      "current iter: 7920000/24576000\n",
      "current iter: 7921000/24576000\n",
      "current iter: 7922000/24576000\n",
      "current iter: 7923000/24576000\n",
      "current iter: 7924000/24576000\n",
      "current iter: 7925000/24576000\n",
      "current iter: 7926000/24576000\n",
      "current iter: 7927000/24576000\n",
      "current iter: 7928000/24576000\n",
      "current iter: 7929000/24576000\n",
      "current iter: 7930000/24576000\n",
      "current iter: 7931000/24576000\n",
      "current iter: 7932000/24576000\n",
      "current iter: 7933000/24576000\n",
      "current iter: 7934000/24576000\n",
      "current iter: 7935000/24576000\n",
      "current iter: 7936000/24576000\n",
      "current iter: 7937000/24576000\n",
      "current iter: 7938000/24576000\n",
      "current iter: 7939000/24576000\n",
      "current iter: 7940000/24576000\n",
      "current iter: 7941000/24576000\n",
      "current iter: 7942000/24576000\n",
      "current iter: 7943000/24576000\n",
      "current iter: 7944000/24576000\n",
      "current iter: 7945000/24576000\n",
      "current iter: 7946000/24576000\n",
      "current iter: 7947000/24576000\n",
      "current iter: 7948000/24576000\n",
      "current iter: 7949000/24576000\n",
      "current iter: 7950000/24576000\n",
      "current iter: 7951000/24576000\n",
      "current iter: 7952000/24576000\n",
      "current iter: 7953000/24576000\n",
      "current iter: 7954000/24576000\n",
      "current iter: 7955000/24576000\n",
      "current iter: 7956000/24576000\n",
      "current iter: 7957000/24576000\n",
      "current iter: 7958000/24576000\n",
      "current iter: 7959000/24576000\n",
      "current iter: 7960000/24576000\n",
      "current iter: 7961000/24576000\n",
      "current iter: 7962000/24576000\n",
      "current iter: 7963000/24576000\n",
      "current iter: 7964000/24576000\n",
      "current iter: 7965000/24576000\n",
      "current iter: 7966000/24576000\n",
      "current iter: 7967000/24576000\n",
      "current iter: 7968000/24576000\n",
      "current iter: 7969000/24576000\n",
      "current iter: 7970000/24576000\n",
      "current iter: 7971000/24576000\n",
      "current iter: 7972000/24576000\n",
      "current iter: 7973000/24576000\n",
      "current iter: 7974000/24576000\n",
      "current iter: 7975000/24576000\n",
      "current iter: 7976000/24576000\n",
      "current iter: 7977000/24576000\n",
      "current iter: 7978000/24576000\n",
      "current iter: 7979000/24576000\n",
      "current iter: 7980000/24576000\n",
      "current iter: 7981000/24576000\n",
      "current iter: 7982000/24576000\n",
      "current iter: 7983000/24576000\n",
      "current iter: 7984000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 7985000/24576000\n",
      "current iter: 7986000/24576000\n",
      "current iter: 7987000/24576000\n",
      "current iter: 7988000/24576000\n",
      "current iter: 7989000/24576000\n",
      "current iter: 7990000/24576000\n",
      "current iter: 7991000/24576000\n",
      "current iter: 7992000/24576000\n",
      "current iter: 7993000/24576000\n",
      "current iter: 7994000/24576000\n",
      "current iter: 7995000/24576000\n",
      "current iter: 7996000/24576000\n",
      "current iter: 7997000/24576000\n",
      "current iter: 7998000/24576000\n",
      "current iter: 7999000/24576000\n",
      "current iter: 8000000/24576000\n",
      "current iter: 8001000/24576000\n",
      "current iter: 8002000/24576000\n",
      "current iter: 8003000/24576000\n",
      "current iter: 8004000/24576000\n",
      "current iter: 8005000/24576000\n",
      "current iter: 8006000/24576000\n",
      "current iter: 8007000/24576000\n",
      "current iter: 8008000/24576000\n",
      "current iter: 8009000/24576000\n",
      "current iter: 8010000/24576000\n",
      "current iter: 8011000/24576000\n",
      "current iter: 8012000/24576000\n",
      "current iter: 8013000/24576000\n",
      "current iter: 8014000/24576000\n",
      "current iter: 8015000/24576000\n",
      "current iter: 8016000/24576000\n",
      "current iter: 8017000/24576000\n",
      "current iter: 8018000/24576000\n",
      "current iter: 8019000/24576000\n",
      "current iter: 8020000/24576000\n",
      "current iter: 8021000/24576000\n",
      "current iter: 8022000/24576000\n",
      "current iter: 8023000/24576000\n",
      "current iter: 8024000/24576000\n",
      "current iter: 8025000/24576000\n",
      "current iter: 8026000/24576000\n",
      "current iter: 8027000/24576000\n",
      "current iter: 8028000/24576000\n",
      "current iter: 8029000/24576000\n",
      "current iter: 8030000/24576000\n",
      "current iter: 8031000/24576000\n",
      "current iter: 8032000/24576000\n",
      "current iter: 8033000/24576000\n",
      "current iter: 8034000/24576000\n",
      "current iter: 8035000/24576000\n",
      "current iter: 8036000/24576000\n",
      "current iter: 8037000/24576000\n",
      "current iter: 8038000/24576000\n",
      "current iter: 8039000/24576000\n",
      "current iter: 8040000/24576000\n",
      "current iter: 8041000/24576000\n",
      "current iter: 8042000/24576000\n",
      "current iter: 8043000/24576000\n",
      "current iter: 8044000/24576000\n",
      "current iter: 8045000/24576000\n",
      "current iter: 8046000/24576000\n",
      "current iter: 8047000/24576000\n",
      "current iter: 8048000/24576000\n",
      "current iter: 8049000/24576000\n",
      "current iter: 8050000/24576000\n",
      "current iter: 8051000/24576000\n",
      "current iter: 8052000/24576000\n",
      "current iter: 8053000/24576000\n",
      "current iter: 8054000/24576000\n",
      "current iter: 8055000/24576000\n",
      "current iter: 8056000/24576000\n",
      "current iter: 8057000/24576000\n",
      "current iter: 8058000/24576000\n",
      "current iter: 8059000/24576000\n",
      "current iter: 8060000/24576000\n",
      "current iter: 8061000/24576000\n",
      "current iter: 8062000/24576000\n",
      "current iter: 8063000/24576000\n",
      "current iter: 8064000/24576000\n",
      "current iter: 8065000/24576000\n",
      "current iter: 8066000/24576000\n",
      "current iter: 8067000/24576000\n",
      "current iter: 8068000/24576000\n",
      "current iter: 8069000/24576000\n",
      "current iter: 8070000/24576000\n",
      "current iter: 8071000/24576000\n",
      "current iter: 8072000/24576000\n",
      "current iter: 8073000/24576000\n",
      "current iter: 8074000/24576000\n",
      "current iter: 8075000/24576000\n",
      "current iter: 8076000/24576000\n",
      "current iter: 8077000/24576000\n",
      "current iter: 8078000/24576000\n",
      "current iter: 8079000/24576000\n",
      "current iter: 8080000/24576000\n",
      "current iter: 8081000/24576000\n",
      "current iter: 8082000/24576000\n",
      "current iter: 8083000/24576000\n",
      "current iter: 8084000/24576000\n",
      "current iter: 8085000/24576000\n",
      "current iter: 8086000/24576000\n",
      "current iter: 8087000/24576000\n",
      "current iter: 8088000/24576000\n",
      "current iter: 8089000/24576000\n",
      "current iter: 8090000/24576000\n",
      "current iter: 8091000/24576000\n",
      "current iter: 8092000/24576000\n",
      "current iter: 8093000/24576000\n",
      "current iter: 8094000/24576000\n",
      "current iter: 8095000/24576000\n",
      "current iter: 8096000/24576000\n",
      "current iter: 8097000/24576000\n",
      "current iter: 8098000/24576000\n",
      "current iter: 8099000/24576000\n",
      "current iter: 8100000/24576000\n",
      "current iter: 8101000/24576000\n",
      "current iter: 8102000/24576000\n",
      "current iter: 8103000/24576000\n",
      "current iter: 8104000/24576000\n",
      "current iter: 8105000/24576000\n",
      "current iter: 8106000/24576000\n",
      "current iter: 8107000/24576000\n",
      "current iter: 8108000/24576000\n",
      "current iter: 8109000/24576000\n",
      "current iter: 8110000/24576000\n",
      "current iter: 8111000/24576000\n",
      "current iter: 8112000/24576000\n",
      "current iter: 8113000/24576000\n",
      "current iter: 8114000/24576000\n",
      "current iter: 8115000/24576000\n",
      "current iter: 8116000/24576000\n",
      "current iter: 8117000/24576000\n",
      "current iter: 8118000/24576000\n",
      "current iter: 8119000/24576000\n",
      "current iter: 8120000/24576000\n",
      "current iter: 8121000/24576000\n",
      "current iter: 8122000/24576000\n",
      "current iter: 8123000/24576000\n",
      "current iter: 8124000/24576000\n",
      "current iter: 8125000/24576000\n",
      "current iter: 8126000/24576000\n",
      "current iter: 8127000/24576000\n",
      "current iter: 8128000/24576000\n",
      "current iter: 8129000/24576000\n",
      "current iter: 8130000/24576000\n",
      "current iter: 8131000/24576000\n",
      "current iter: 8132000/24576000\n",
      "current iter: 8133000/24576000\n",
      "current iter: 8134000/24576000\n",
      "current iter: 8135000/24576000\n",
      "current iter: 8136000/24576000\n",
      "current iter: 8137000/24576000\n",
      "current iter: 8138000/24576000\n",
      "current iter: 8139000/24576000\n",
      "current iter: 8140000/24576000\n",
      "current iter: 8141000/24576000\n",
      "current iter: 8142000/24576000\n",
      "current iter: 8143000/24576000\n",
      "current iter: 8144000/24576000\n",
      "current iter: 8145000/24576000\n",
      "current iter: 8146000/24576000\n",
      "current iter: 8147000/24576000\n",
      "current iter: 8148000/24576000\n",
      "current iter: 8149000/24576000\n",
      "current iter: 8150000/24576000\n",
      "current iter: 8151000/24576000\n",
      "current iter: 8152000/24576000\n",
      "current iter: 8153000/24576000\n",
      "current iter: 8154000/24576000\n",
      "current iter: 8155000/24576000\n",
      "current iter: 8156000/24576000\n",
      "current iter: 8157000/24576000\n",
      "current iter: 8158000/24576000\n",
      "current iter: 8159000/24576000\n",
      "current iter: 8160000/24576000\n",
      "current iter: 8161000/24576000\n",
      "current iter: 8162000/24576000\n",
      "current iter: 8163000/24576000\n",
      "current iter: 8164000/24576000\n",
      "current iter: 8165000/24576000\n",
      "current iter: 8166000/24576000\n",
      "current iter: 8167000/24576000\n",
      "current iter: 8168000/24576000\n",
      "current iter: 8169000/24576000\n",
      "current iter: 8170000/24576000\n",
      "current iter: 8171000/24576000\n",
      "current iter: 8172000/24576000\n",
      "current iter: 8173000/24576000\n",
      "current iter: 8174000/24576000\n",
      "current iter: 8175000/24576000\n",
      "current iter: 8176000/24576000\n",
      "current iter: 8177000/24576000\n",
      "current iter: 8178000/24576000\n",
      "current iter: 8179000/24576000\n",
      "current iter: 8180000/24576000\n",
      "current iter: 8181000/24576000\n",
      "current iter: 8182000/24576000\n",
      "current iter: 8183000/24576000\n",
      "current iter: 8184000/24576000\n",
      "current iter: 8185000/24576000\n",
      "current iter: 8186000/24576000\n",
      "current iter: 8187000/24576000\n",
      "current iter: 8188000/24576000\n",
      "current iter: 8189000/24576000\n",
      "current iter: 8190000/24576000\n",
      "current iter: 8191000/24576000\n",
      "current iter: 8192000/24576000\n",
      "current iter: 8193000/24576000\n",
      "current iter: 8194000/24576000\n",
      "current iter: 8195000/24576000\n",
      "current iter: 8196000/24576000\n",
      "current iter: 8197000/24576000\n",
      "current iter: 8198000/24576000\n",
      "current iter: 8199000/24576000\n",
      "current iter: 8200000/24576000\n",
      "current iter: 8201000/24576000\n",
      "current iter: 8202000/24576000\n",
      "current iter: 8203000/24576000\n",
      "current iter: 8204000/24576000\n",
      "current iter: 8205000/24576000\n",
      "current iter: 8206000/24576000\n",
      "current iter: 8207000/24576000\n",
      "current iter: 8208000/24576000\n",
      "current iter: 8209000/24576000\n",
      "current iter: 8210000/24576000\n",
      "current iter: 8211000/24576000\n",
      "current iter: 8212000/24576000\n",
      "current iter: 8213000/24576000\n",
      "current iter: 8214000/24576000\n",
      "current iter: 8215000/24576000\n",
      "current iter: 8216000/24576000\n",
      "current iter: 8217000/24576000\n",
      "current iter: 8218000/24576000\n",
      "current iter: 8219000/24576000\n",
      "current iter: 8220000/24576000\n",
      "current iter: 8221000/24576000\n",
      "current iter: 8222000/24576000\n",
      "current iter: 8223000/24576000\n",
      "current iter: 8224000/24576000\n",
      "current iter: 8225000/24576000\n",
      "current iter: 8226000/24576000\n",
      "current iter: 8227000/24576000\n",
      "current iter: 8228000/24576000\n",
      "current iter: 8229000/24576000\n",
      "current iter: 8230000/24576000\n",
      "current iter: 8231000/24576000\n",
      "current iter: 8232000/24576000\n",
      "current iter: 8233000/24576000\n",
      "current iter: 8234000/24576000\n",
      "current iter: 8235000/24576000\n",
      "current iter: 8236000/24576000\n",
      "current iter: 8237000/24576000\n",
      "current iter: 8238000/24576000\n",
      "current iter: 8239000/24576000\n",
      "current iter: 8240000/24576000\n",
      "current iter: 8241000/24576000\n",
      "current iter: 8242000/24576000\n",
      "current iter: 8243000/24576000\n",
      "current iter: 8244000/24576000\n",
      "current iter: 8245000/24576000\n",
      "current iter: 8246000/24576000\n",
      "current iter: 8247000/24576000\n",
      "current iter: 8248000/24576000\n",
      "current iter: 8249000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 8250000/24576000\n",
      "current iter: 8251000/24576000\n",
      "current iter: 8252000/24576000\n",
      "current iter: 8253000/24576000\n",
      "current iter: 8254000/24576000\n",
      "current iter: 8255000/24576000\n",
      "current iter: 8256000/24576000\n",
      "current iter: 8257000/24576000\n",
      "current iter: 8258000/24576000\n",
      "current iter: 8259000/24576000\n",
      "current iter: 8260000/24576000\n",
      "current iter: 8261000/24576000\n",
      "current iter: 8262000/24576000\n",
      "current iter: 8263000/24576000\n",
      "current iter: 8264000/24576000\n",
      "current iter: 8265000/24576000\n",
      "current iter: 8266000/24576000\n",
      "current iter: 8267000/24576000\n",
      "current iter: 8268000/24576000\n",
      "current iter: 8269000/24576000\n",
      "current iter: 8270000/24576000\n",
      "current iter: 8271000/24576000\n",
      "current iter: 8272000/24576000\n",
      "current iter: 8273000/24576000\n",
      "current iter: 8274000/24576000\n",
      "current iter: 8275000/24576000\n",
      "current iter: 8276000/24576000\n",
      "current iter: 8277000/24576000\n",
      "current iter: 8278000/24576000\n",
      "current iter: 8279000/24576000\n",
      "current iter: 8280000/24576000\n",
      "current iter: 8281000/24576000\n",
      "current iter: 8282000/24576000\n",
      "current iter: 8283000/24576000\n",
      "current iter: 8284000/24576000\n",
      "current iter: 8285000/24576000\n",
      "current iter: 8286000/24576000\n",
      "current iter: 8287000/24576000\n",
      "current iter: 8288000/24576000\n",
      "current iter: 8289000/24576000\n",
      "current iter: 8290000/24576000\n",
      "current iter: 8291000/24576000\n",
      "current iter: 8292000/24576000\n",
      "current iter: 8293000/24576000\n",
      "current iter: 8294000/24576000\n",
      "current iter: 8295000/24576000\n",
      "current iter: 8296000/24576000\n",
      "current iter: 8297000/24576000\n",
      "current iter: 8298000/24576000\n",
      "current iter: 8299000/24576000\n",
      "current iter: 8300000/24576000\n",
      "current iter: 8301000/24576000\n",
      "current iter: 8302000/24576000\n",
      "current iter: 8303000/24576000\n",
      "current iter: 8304000/24576000\n",
      "current iter: 8305000/24576000\n",
      "current iter: 8306000/24576000\n",
      "current iter: 8307000/24576000\n",
      "current iter: 8308000/24576000\n",
      "current iter: 8309000/24576000\n",
      "current iter: 8310000/24576000\n",
      "current iter: 8311000/24576000\n",
      "current iter: 8312000/24576000\n",
      "current iter: 8313000/24576000\n",
      "current iter: 8314000/24576000\n",
      "current iter: 8315000/24576000\n",
      "current iter: 8316000/24576000\n",
      "current iter: 8317000/24576000\n",
      "current iter: 8318000/24576000\n",
      "current iter: 8319000/24576000\n",
      "current iter: 8320000/24576000\n",
      "current iter: 8321000/24576000\n",
      "current iter: 8322000/24576000\n",
      "current iter: 8323000/24576000\n",
      "current iter: 8324000/24576000\n",
      "current iter: 8325000/24576000\n",
      "current iter: 8326000/24576000\n",
      "current iter: 8327000/24576000\n",
      "current iter: 8328000/24576000\n",
      "current iter: 8329000/24576000\n",
      "current iter: 8330000/24576000\n",
      "current iter: 8331000/24576000\n",
      "current iter: 8332000/24576000\n",
      "current iter: 8333000/24576000\n",
      "current iter: 8334000/24576000\n",
      "current iter: 8335000/24576000\n",
      "current iter: 8336000/24576000\n",
      "current iter: 8337000/24576000\n",
      "current iter: 8338000/24576000\n",
      "current iter: 8339000/24576000\n",
      "current iter: 8340000/24576000\n",
      "current iter: 8341000/24576000\n",
      "current iter: 8342000/24576000\n",
      "current iter: 8343000/24576000\n",
      "current iter: 8344000/24576000\n",
      "current iter: 8345000/24576000\n",
      "current iter: 8346000/24576000\n",
      "current iter: 8347000/24576000\n",
      "current iter: 8348000/24576000\n",
      "current iter: 8349000/24576000\n",
      "current iter: 8350000/24576000\n",
      "current iter: 8351000/24576000\n",
      "current iter: 8352000/24576000\n",
      "current iter: 8353000/24576000\n",
      "current iter: 8354000/24576000\n",
      "current iter: 8355000/24576000\n",
      "current iter: 8356000/24576000\n",
      "current iter: 8357000/24576000\n",
      "current iter: 8358000/24576000\n",
      "current iter: 8359000/24576000\n",
      "current iter: 8360000/24576000\n",
      "current iter: 8361000/24576000\n",
      "current iter: 8362000/24576000\n",
      "current iter: 8363000/24576000\n",
      "current iter: 8364000/24576000\n",
      "current iter: 8365000/24576000\n",
      "current iter: 8366000/24576000\n",
      "current iter: 8367000/24576000\n",
      "current iter: 8368000/24576000\n",
      "current iter: 8369000/24576000\n",
      "current iter: 8370000/24576000\n",
      "current iter: 8371000/24576000\n",
      "current iter: 8372000/24576000\n",
      "current iter: 8373000/24576000\n",
      "current iter: 8374000/24576000\n",
      "current iter: 8375000/24576000\n",
      "current iter: 8376000/24576000\n",
      "current iter: 8377000/24576000\n",
      "current iter: 8378000/24576000\n",
      "current iter: 8379000/24576000\n",
      "current iter: 8380000/24576000\n",
      "current iter: 8381000/24576000\n",
      "current iter: 8382000/24576000\n",
      "current iter: 8383000/24576000\n",
      "current iter: 8384000/24576000\n",
      "current iter: 8385000/24576000\n",
      "current iter: 8386000/24576000\n",
      "current iter: 8387000/24576000\n",
      "current iter: 8388000/24576000\n",
      "current iter: 8389000/24576000\n",
      "current iter: 8390000/24576000\n",
      "current iter: 8391000/24576000\n",
      "current iter: 8392000/24576000\n",
      "current iter: 8393000/24576000\n",
      "current iter: 8394000/24576000\n",
      "current iter: 8395000/24576000\n",
      "current iter: 8396000/24576000\n",
      "current iter: 8397000/24576000\n",
      "current iter: 8398000/24576000\n",
      "current iter: 8399000/24576000\n",
      "current iter: 8400000/24576000\n",
      "current iter: 8401000/24576000\n",
      "current iter: 8402000/24576000\n",
      "current iter: 8403000/24576000\n",
      "current iter: 8404000/24576000\n",
      "current iter: 8405000/24576000\n",
      "current iter: 8406000/24576000\n",
      "current iter: 8407000/24576000\n",
      "current iter: 8408000/24576000\n",
      "current iter: 8409000/24576000\n",
      "current iter: 8410000/24576000\n",
      "current iter: 8411000/24576000\n",
      "current iter: 8412000/24576000\n",
      "current iter: 8413000/24576000\n",
      "current iter: 8414000/24576000\n",
      "current iter: 8415000/24576000\n",
      "current iter: 8416000/24576000\n",
      "current iter: 8417000/24576000\n",
      "current iter: 8418000/24576000\n",
      "current iter: 8419000/24576000\n",
      "current iter: 8420000/24576000\n",
      "current iter: 8421000/24576000\n",
      "current iter: 8422000/24576000\n",
      "current iter: 8423000/24576000\n",
      "current iter: 8424000/24576000\n",
      "current iter: 8425000/24576000\n",
      "current iter: 8426000/24576000\n",
      "current iter: 8427000/24576000\n",
      "current iter: 8428000/24576000\n",
      "current iter: 8429000/24576000\n",
      "current iter: 8430000/24576000\n",
      "current iter: 8431000/24576000\n",
      "current iter: 8432000/24576000\n",
      "current iter: 8433000/24576000\n",
      "current iter: 8434000/24576000\n",
      "current iter: 8435000/24576000\n",
      "current iter: 8436000/24576000\n",
      "current iter: 8437000/24576000\n",
      "current iter: 8438000/24576000\n",
      "current iter: 8439000/24576000\n",
      "current iter: 8440000/24576000\n",
      "current iter: 8441000/24576000\n",
      "current iter: 8442000/24576000\n",
      "current iter: 8443000/24576000\n",
      "current iter: 8444000/24576000\n",
      "current iter: 8445000/24576000\n",
      "current iter: 8446000/24576000\n",
      "current iter: 8447000/24576000\n",
      "current iter: 8448000/24576000\n",
      "current iter: 8449000/24576000\n",
      "current iter: 8450000/24576000\n",
      "current iter: 8451000/24576000\n",
      "current iter: 8452000/24576000\n",
      "current iter: 8453000/24576000\n",
      "current iter: 8454000/24576000\n",
      "current iter: 8455000/24576000\n",
      "current iter: 8456000/24576000\n",
      "current iter: 8457000/24576000\n",
      "current iter: 8458000/24576000\n",
      "current iter: 8459000/24576000\n",
      "current iter: 8460000/24576000\n",
      "current iter: 8461000/24576000\n",
      "current iter: 8462000/24576000\n",
      "current iter: 8463000/24576000\n",
      "current iter: 8464000/24576000\n",
      "current iter: 8465000/24576000\n",
      "current iter: 8466000/24576000\n",
      "current iter: 8467000/24576000\n",
      "current iter: 8468000/24576000\n",
      "current iter: 8469000/24576000\n",
      "current iter: 8470000/24576000\n",
      "current iter: 8471000/24576000\n",
      "current iter: 8472000/24576000\n",
      "current iter: 8473000/24576000\n",
      "current iter: 8474000/24576000\n",
      "current iter: 8475000/24576000\n",
      "current iter: 8476000/24576000\n",
      "current iter: 8477000/24576000\n",
      "current iter: 8478000/24576000\n",
      "current iter: 8479000/24576000\n",
      "current iter: 8480000/24576000\n",
      "current iter: 8481000/24576000\n",
      "current iter: 8482000/24576000\n",
      "current iter: 8483000/24576000\n",
      "current iter: 8484000/24576000\n",
      "current iter: 8485000/24576000\n",
      "current iter: 8486000/24576000\n",
      "current iter: 8487000/24576000\n",
      "current iter: 8488000/24576000\n",
      "current iter: 8489000/24576000\n",
      "current iter: 8490000/24576000\n",
      "current iter: 8491000/24576000\n",
      "current iter: 8492000/24576000\n",
      "current iter: 8493000/24576000\n",
      "current iter: 8494000/24576000\n",
      "current iter: 8495000/24576000\n",
      "current iter: 8496000/24576000\n",
      "current iter: 8497000/24576000\n",
      "current iter: 8498000/24576000\n",
      "current iter: 8499000/24576000\n",
      "current iter: 8500000/24576000\n",
      "current iter: 8501000/24576000\n",
      "current iter: 8502000/24576000\n",
      "current iter: 8503000/24576000\n",
      "current iter: 8504000/24576000\n",
      "current iter: 8505000/24576000\n",
      "current iter: 8506000/24576000\n",
      "current iter: 8507000/24576000\n",
      "current iter: 8508000/24576000\n",
      "current iter: 8509000/24576000\n",
      "current iter: 8510000/24576000\n",
      "current iter: 8511000/24576000\n",
      "current iter: 8512000/24576000\n",
      "current iter: 8513000/24576000\n",
      "current iter: 8514000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 8515000/24576000\n",
      "current iter: 8516000/24576000\n",
      "current iter: 8517000/24576000\n",
      "current iter: 8518000/24576000\n",
      "current iter: 8519000/24576000\n",
      "current iter: 8520000/24576000\n",
      "current iter: 8521000/24576000\n",
      "current iter: 8522000/24576000\n",
      "current iter: 8523000/24576000\n",
      "current iter: 8524000/24576000\n",
      "current iter: 8525000/24576000\n",
      "current iter: 8526000/24576000\n",
      "current iter: 8527000/24576000\n",
      "current iter: 8528000/24576000\n",
      "current iter: 8529000/24576000\n",
      "current iter: 8530000/24576000\n",
      "current iter: 8531000/24576000\n",
      "current iter: 8532000/24576000\n",
      "current iter: 8533000/24576000\n",
      "current iter: 8534000/24576000\n",
      "current iter: 8535000/24576000\n",
      "current iter: 8536000/24576000\n",
      "current iter: 8537000/24576000\n",
      "current iter: 8538000/24576000\n",
      "current iter: 8539000/24576000\n",
      "current iter: 8540000/24576000\n",
      "current iter: 8541000/24576000\n",
      "current iter: 8542000/24576000\n",
      "current iter: 8543000/24576000\n",
      "current iter: 8544000/24576000\n",
      "current iter: 8545000/24576000\n",
      "current iter: 8546000/24576000\n",
      "current iter: 8547000/24576000\n",
      "current iter: 8548000/24576000\n",
      "current iter: 8549000/24576000\n",
      "current iter: 8550000/24576000\n",
      "current iter: 8551000/24576000\n",
      "current iter: 8552000/24576000\n",
      "current iter: 8553000/24576000\n",
      "current iter: 8554000/24576000\n",
      "current iter: 8555000/24576000\n",
      "current iter: 8556000/24576000\n",
      "current iter: 8557000/24576000\n",
      "current iter: 8558000/24576000\n",
      "current iter: 8559000/24576000\n",
      "current iter: 8560000/24576000\n",
      "current iter: 8561000/24576000\n",
      "current iter: 8562000/24576000\n",
      "current iter: 8563000/24576000\n",
      "current iter: 8564000/24576000\n",
      "current iter: 8565000/24576000\n",
      "current iter: 8566000/24576000\n",
      "current iter: 8567000/24576000\n",
      "current iter: 8568000/24576000\n",
      "current iter: 8569000/24576000\n",
      "current iter: 8570000/24576000\n",
      "current iter: 8571000/24576000\n",
      "current iter: 8572000/24576000\n",
      "current iter: 8573000/24576000\n",
      "current iter: 8574000/24576000\n",
      "current iter: 8575000/24576000\n",
      "current iter: 8576000/24576000\n",
      "current iter: 8577000/24576000\n",
      "current iter: 8578000/24576000\n",
      "current iter: 8579000/24576000\n",
      "current iter: 8580000/24576000\n",
      "current iter: 8581000/24576000\n",
      "current iter: 8582000/24576000\n",
      "current iter: 8583000/24576000\n",
      "current iter: 8584000/24576000\n",
      "current iter: 8585000/24576000\n",
      "current iter: 8586000/24576000\n",
      "current iter: 8587000/24576000\n",
      "current iter: 8588000/24576000\n",
      "current iter: 8589000/24576000\n",
      "current iter: 8590000/24576000\n",
      "current iter: 8591000/24576000\n",
      "current iter: 8592000/24576000\n",
      "current iter: 8593000/24576000\n",
      "current iter: 8594000/24576000\n",
      "current iter: 8595000/24576000\n",
      "current iter: 8596000/24576000\n",
      "current iter: 8597000/24576000\n",
      "current iter: 8598000/24576000\n",
      "current iter: 8599000/24576000\n",
      "current iter: 8600000/24576000\n",
      "current iter: 8601000/24576000\n",
      "current iter: 8602000/24576000\n",
      "current iter: 8603000/24576000\n",
      "current iter: 8604000/24576000\n",
      "current iter: 8605000/24576000\n",
      "current iter: 8606000/24576000\n",
      "current iter: 8607000/24576000\n",
      "current iter: 8608000/24576000\n",
      "current iter: 8609000/24576000\n",
      "current iter: 8610000/24576000\n",
      "current iter: 8611000/24576000\n",
      "current iter: 8612000/24576000\n",
      "current iter: 8613000/24576000\n",
      "current iter: 8614000/24576000\n",
      "current iter: 8615000/24576000\n",
      "current iter: 8616000/24576000\n",
      "current iter: 8617000/24576000\n",
      "current iter: 8618000/24576000\n",
      "current iter: 8619000/24576000\n",
      "current iter: 8620000/24576000\n",
      "current iter: 8621000/24576000\n",
      "current iter: 8622000/24576000\n",
      "current iter: 8623000/24576000\n",
      "current iter: 8624000/24576000\n",
      "current iter: 8625000/24576000\n",
      "current iter: 8626000/24576000\n",
      "current iter: 8627000/24576000\n",
      "current iter: 8628000/24576000\n",
      "current iter: 8629000/24576000\n",
      "current iter: 8630000/24576000\n",
      "current iter: 8631000/24576000\n",
      "current iter: 8632000/24576000\n",
      "current iter: 8633000/24576000\n",
      "current iter: 8634000/24576000\n",
      "current iter: 8635000/24576000\n",
      "current iter: 8636000/24576000\n",
      "current iter: 8637000/24576000\n",
      "current iter: 8638000/24576000\n",
      "current iter: 8639000/24576000\n",
      "current iter: 8640000/24576000\n",
      "current iter: 8641000/24576000\n",
      "current iter: 8642000/24576000\n",
      "current iter: 8643000/24576000\n",
      "current iter: 8644000/24576000\n",
      "current iter: 8645000/24576000\n",
      "current iter: 8646000/24576000\n",
      "current iter: 8647000/24576000\n",
      "current iter: 8648000/24576000\n",
      "current iter: 8649000/24576000\n",
      "current iter: 8650000/24576000\n",
      "current iter: 8651000/24576000\n",
      "current iter: 8652000/24576000\n",
      "current iter: 8653000/24576000\n",
      "current iter: 8654000/24576000\n",
      "current iter: 8655000/24576000\n",
      "current iter: 8656000/24576000\n",
      "current iter: 8657000/24576000\n",
      "current iter: 8658000/24576000\n",
      "current iter: 8659000/24576000\n",
      "current iter: 8660000/24576000\n",
      "current iter: 8661000/24576000\n",
      "current iter: 8662000/24576000\n",
      "current iter: 8663000/24576000\n",
      "current iter: 8664000/24576000\n",
      "current iter: 8665000/24576000\n",
      "current iter: 8666000/24576000\n",
      "current iter: 8667000/24576000\n",
      "current iter: 8668000/24576000\n",
      "current iter: 8669000/24576000\n",
      "current iter: 8670000/24576000\n",
      "current iter: 8671000/24576000\n",
      "current iter: 8672000/24576000\n",
      "current iter: 8673000/24576000\n",
      "current iter: 8674000/24576000\n",
      "current iter: 8675000/24576000\n",
      "current iter: 8676000/24576000\n",
      "current iter: 8677000/24576000\n",
      "current iter: 8678000/24576000\n",
      "current iter: 8679000/24576000\n",
      "current iter: 8680000/24576000\n",
      "current iter: 8681000/24576000\n",
      "current iter: 8682000/24576000\n",
      "current iter: 8683000/24576000\n",
      "current iter: 8684000/24576000\n",
      "current iter: 8685000/24576000\n",
      "current iter: 8686000/24576000\n",
      "current iter: 8687000/24576000\n",
      "current iter: 8688000/24576000\n",
      "current iter: 8689000/24576000\n",
      "current iter: 8690000/24576000\n",
      "current iter: 8691000/24576000\n",
      "current iter: 8692000/24576000\n",
      "current iter: 8693000/24576000\n",
      "current iter: 8694000/24576000\n",
      "current iter: 8695000/24576000\n",
      "current iter: 8696000/24576000\n",
      "current iter: 8697000/24576000\n",
      "current iter: 8698000/24576000\n",
      "current iter: 8699000/24576000\n",
      "current iter: 8700000/24576000\n",
      "current iter: 8701000/24576000\n",
      "current iter: 8702000/24576000\n",
      "current iter: 8703000/24576000\n",
      "current iter: 8704000/24576000\n",
      "current iter: 8705000/24576000\n",
      "current iter: 8706000/24576000\n",
      "current iter: 8707000/24576000\n",
      "current iter: 8708000/24576000\n",
      "current iter: 8709000/24576000\n",
      "current iter: 8710000/24576000\n",
      "current iter: 8711000/24576000\n",
      "current iter: 8712000/24576000\n",
      "current iter: 8713000/24576000\n",
      "current iter: 8714000/24576000\n",
      "current iter: 8715000/24576000\n",
      "current iter: 8716000/24576000\n",
      "current iter: 8717000/24576000\n",
      "current iter: 8718000/24576000\n",
      "current iter: 8719000/24576000\n",
      "current iter: 8720000/24576000\n",
      "current iter: 8721000/24576000\n",
      "current iter: 8722000/24576000\n",
      "current iter: 8723000/24576000\n",
      "current iter: 8724000/24576000\n",
      "current iter: 8725000/24576000\n",
      "current iter: 8726000/24576000\n",
      "current iter: 8727000/24576000\n",
      "current iter: 8728000/24576000\n",
      "current iter: 8729000/24576000\n",
      "current iter: 8730000/24576000\n",
      "current iter: 8731000/24576000\n",
      "current iter: 8732000/24576000\n",
      "current iter: 8733000/24576000\n",
      "current iter: 8734000/24576000\n",
      "current iter: 8735000/24576000\n",
      "current iter: 8736000/24576000\n",
      "current iter: 8737000/24576000\n",
      "current iter: 8738000/24576000\n",
      "current iter: 8739000/24576000\n",
      "current iter: 8740000/24576000\n",
      "current iter: 8741000/24576000\n",
      "current iter: 8742000/24576000\n",
      "current iter: 8743000/24576000\n",
      "current iter: 8744000/24576000\n",
      "current iter: 8745000/24576000\n",
      "current iter: 8746000/24576000\n",
      "current iter: 8747000/24576000\n",
      "current iter: 8748000/24576000\n",
      "current iter: 8749000/24576000\n",
      "current iter: 8750000/24576000\n",
      "current iter: 8751000/24576000\n",
      "current iter: 8752000/24576000\n",
      "current iter: 8753000/24576000\n",
      "current iter: 8754000/24576000\n",
      "current iter: 8755000/24576000\n",
      "current iter: 8756000/24576000\n",
      "current iter: 8757000/24576000\n",
      "current iter: 8758000/24576000\n",
      "current iter: 8759000/24576000\n",
      "current iter: 8760000/24576000\n",
      "current iter: 8761000/24576000\n",
      "current iter: 8762000/24576000\n",
      "current iter: 8763000/24576000\n",
      "current iter: 8764000/24576000\n",
      "current iter: 8765000/24576000\n",
      "current iter: 8766000/24576000\n",
      "current iter: 8767000/24576000\n",
      "current iter: 8768000/24576000\n",
      "current iter: 8769000/24576000\n",
      "current iter: 8770000/24576000\n",
      "current iter: 8771000/24576000\n",
      "current iter: 8772000/24576000\n",
      "current iter: 8773000/24576000\n",
      "current iter: 8774000/24576000\n",
      "current iter: 8775000/24576000\n",
      "current iter: 8776000/24576000\n",
      "current iter: 8777000/24576000\n",
      "current iter: 8778000/24576000\n",
      "current iter: 8779000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 8780000/24576000\n",
      "current iter: 8781000/24576000\n",
      "current iter: 8782000/24576000\n",
      "current iter: 8783000/24576000\n",
      "current iter: 8784000/24576000\n",
      "current iter: 8785000/24576000\n",
      "current iter: 8786000/24576000\n",
      "current iter: 8787000/24576000\n",
      "current iter: 8788000/24576000\n",
      "current iter: 8789000/24576000\n",
      "current iter: 8790000/24576000\n",
      "current iter: 8791000/24576000\n",
      "current iter: 8792000/24576000\n",
      "current iter: 8793000/24576000\n",
      "current iter: 8794000/24576000\n",
      "current iter: 8795000/24576000\n",
      "current iter: 8796000/24576000\n",
      "current iter: 8797000/24576000\n",
      "current iter: 8798000/24576000\n",
      "current iter: 8799000/24576000\n",
      "current iter: 8800000/24576000\n",
      "current iter: 8801000/24576000\n",
      "current iter: 8802000/24576000\n",
      "current iter: 8803000/24576000\n",
      "current iter: 8804000/24576000\n",
      "current iter: 8805000/24576000\n",
      "current iter: 8806000/24576000\n",
      "current iter: 8807000/24576000\n",
      "current iter: 8808000/24576000\n",
      "current iter: 8809000/24576000\n",
      "current iter: 8810000/24576000\n",
      "current iter: 8811000/24576000\n",
      "current iter: 8812000/24576000\n",
      "current iter: 8813000/24576000\n",
      "current iter: 8814000/24576000\n",
      "current iter: 8815000/24576000\n",
      "current iter: 8816000/24576000\n",
      "current iter: 8817000/24576000\n",
      "current iter: 8818000/24576000\n",
      "current iter: 8819000/24576000\n",
      "current iter: 8820000/24576000\n",
      "current iter: 8821000/24576000\n",
      "current iter: 8822000/24576000\n",
      "current iter: 8823000/24576000\n",
      "current iter: 8824000/24576000\n",
      "current iter: 8825000/24576000\n",
      "current iter: 8826000/24576000\n",
      "current iter: 8827000/24576000\n",
      "current iter: 8828000/24576000\n",
      "current iter: 8829000/24576000\n",
      "current iter: 8830000/24576000\n",
      "current iter: 8831000/24576000\n",
      "current iter: 8832000/24576000\n",
      "current iter: 8833000/24576000\n",
      "current iter: 8834000/24576000\n",
      "current iter: 8835000/24576000\n",
      "current iter: 8836000/24576000\n",
      "current iter: 8837000/24576000\n",
      "current iter: 8838000/24576000\n",
      "current iter: 8839000/24576000\n",
      "current iter: 8840000/24576000\n",
      "current iter: 8841000/24576000\n",
      "current iter: 8842000/24576000\n",
      "current iter: 8843000/24576000\n",
      "current iter: 8844000/24576000\n",
      "current iter: 8845000/24576000\n",
      "current iter: 8846000/24576000\n",
      "current iter: 8847000/24576000\n",
      "current iter: 8848000/24576000\n",
      "current iter: 8849000/24576000\n",
      "current iter: 8850000/24576000\n",
      "current iter: 8851000/24576000\n",
      "current iter: 8852000/24576000\n",
      "current iter: 8853000/24576000\n",
      "current iter: 8854000/24576000\n",
      "current iter: 8855000/24576000\n",
      "current iter: 8856000/24576000\n",
      "current iter: 8857000/24576000\n",
      "current iter: 8858000/24576000\n",
      "current iter: 8859000/24576000\n",
      "current iter: 8860000/24576000\n",
      "current iter: 8861000/24576000\n",
      "current iter: 8862000/24576000\n",
      "current iter: 8863000/24576000\n",
      "current iter: 8864000/24576000\n",
      "current iter: 8865000/24576000\n",
      "current iter: 8866000/24576000\n",
      "current iter: 8867000/24576000\n",
      "current iter: 8868000/24576000\n",
      "current iter: 8869000/24576000\n",
      "current iter: 8870000/24576000\n",
      "current iter: 8871000/24576000\n",
      "current iter: 8872000/24576000\n",
      "current iter: 8873000/24576000\n",
      "current iter: 8874000/24576000\n",
      "current iter: 8875000/24576000\n",
      "current iter: 8876000/24576000\n",
      "current iter: 8877000/24576000\n",
      "current iter: 8878000/24576000\n",
      "current iter: 8879000/24576000\n",
      "current iter: 8880000/24576000\n",
      "current iter: 8881000/24576000\n",
      "current iter: 8882000/24576000\n",
      "current iter: 8883000/24576000\n",
      "current iter: 8884000/24576000\n",
      "current iter: 8885000/24576000\n",
      "current iter: 8886000/24576000\n",
      "current iter: 8887000/24576000\n",
      "current iter: 8888000/24576000\n",
      "current iter: 8889000/24576000\n",
      "current iter: 8890000/24576000\n",
      "current iter: 8891000/24576000\n",
      "current iter: 8892000/24576000\n",
      "current iter: 8893000/24576000\n",
      "current iter: 8894000/24576000\n",
      "current iter: 8895000/24576000\n",
      "current iter: 8896000/24576000\n",
      "current iter: 8897000/24576000\n",
      "current iter: 8898000/24576000\n",
      "current iter: 8899000/24576000\n",
      "current iter: 8900000/24576000\n",
      "current iter: 8901000/24576000\n",
      "current iter: 8902000/24576000\n",
      "current iter: 8903000/24576000\n",
      "current iter: 8904000/24576000\n",
      "current iter: 8905000/24576000\n",
      "current iter: 8906000/24576000\n",
      "current iter: 8907000/24576000\n",
      "current iter: 8908000/24576000\n",
      "current iter: 8909000/24576000\n",
      "current iter: 8910000/24576000\n",
      "current iter: 8911000/24576000\n",
      "current iter: 8912000/24576000\n",
      "current iter: 8913000/24576000\n",
      "current iter: 8914000/24576000\n",
      "current iter: 8915000/24576000\n",
      "current iter: 8916000/24576000\n",
      "current iter: 8917000/24576000\n",
      "current iter: 8918000/24576000\n",
      "current iter: 8919000/24576000\n",
      "current iter: 8920000/24576000\n",
      "current iter: 8921000/24576000\n",
      "current iter: 8922000/24576000\n",
      "current iter: 8923000/24576000\n",
      "current iter: 8924000/24576000\n",
      "current iter: 8925000/24576000\n",
      "current iter: 8926000/24576000\n",
      "current iter: 8927000/24576000\n",
      "current iter: 8928000/24576000\n",
      "current iter: 8929000/24576000\n",
      "current iter: 8930000/24576000\n",
      "current iter: 8931000/24576000\n",
      "current iter: 8932000/24576000\n",
      "current iter: 8933000/24576000\n",
      "current iter: 8934000/24576000\n",
      "current iter: 8935000/24576000\n",
      "current iter: 8936000/24576000\n",
      "current iter: 8937000/24576000\n",
      "current iter: 8938000/24576000\n",
      "current iter: 8939000/24576000\n",
      "current iter: 8940000/24576000\n",
      "current iter: 8941000/24576000\n",
      "current iter: 8942000/24576000\n",
      "current iter: 8943000/24576000\n",
      "current iter: 8944000/24576000\n",
      "current iter: 8945000/24576000\n",
      "current iter: 8946000/24576000\n",
      "current iter: 8947000/24576000\n",
      "current iter: 8948000/24576000\n",
      "current iter: 8949000/24576000\n",
      "current iter: 8950000/24576000\n",
      "current iter: 8951000/24576000\n",
      "current iter: 8952000/24576000\n",
      "current iter: 8953000/24576000\n",
      "current iter: 8954000/24576000\n",
      "current iter: 8955000/24576000\n",
      "current iter: 8956000/24576000\n",
      "current iter: 8957000/24576000\n",
      "current iter: 8958000/24576000\n",
      "current iter: 8959000/24576000\n",
      "current iter: 8960000/24576000\n",
      "current iter: 8961000/24576000\n",
      "current iter: 8962000/24576000\n",
      "current iter: 8963000/24576000\n",
      "current iter: 8964000/24576000\n",
      "current iter: 8965000/24576000\n",
      "current iter: 8966000/24576000\n",
      "current iter: 8967000/24576000\n",
      "current iter: 8968000/24576000\n",
      "current iter: 8969000/24576000\n",
      "current iter: 8970000/24576000\n",
      "current iter: 8971000/24576000\n",
      "current iter: 8972000/24576000\n",
      "current iter: 8973000/24576000\n",
      "current iter: 8974000/24576000\n",
      "current iter: 8975000/24576000\n",
      "current iter: 8976000/24576000\n",
      "current iter: 8977000/24576000\n",
      "current iter: 8978000/24576000\n",
      "current iter: 8979000/24576000\n",
      "current iter: 8980000/24576000\n",
      "current iter: 8981000/24576000\n",
      "current iter: 8982000/24576000\n",
      "current iter: 8983000/24576000\n",
      "current iter: 8984000/24576000\n",
      "current iter: 8985000/24576000\n",
      "current iter: 8986000/24576000\n",
      "current iter: 8987000/24576000\n",
      "current iter: 8988000/24576000\n",
      "current iter: 8989000/24576000\n",
      "current iter: 8990000/24576000\n",
      "current iter: 8991000/24576000\n",
      "current iter: 8992000/24576000\n",
      "current iter: 8993000/24576000\n",
      "current iter: 8994000/24576000\n",
      "current iter: 8995000/24576000\n",
      "current iter: 8996000/24576000\n",
      "current iter: 8997000/24576000\n",
      "current iter: 8998000/24576000\n",
      "current iter: 8999000/24576000\n",
      "current iter: 9000000/24576000\n",
      "current iter: 9001000/24576000\n",
      "current iter: 9002000/24576000\n",
      "current iter: 9003000/24576000\n",
      "current iter: 9004000/24576000\n",
      "current iter: 9005000/24576000\n",
      "current iter: 9006000/24576000\n",
      "current iter: 9007000/24576000\n",
      "current iter: 9008000/24576000\n",
      "current iter: 9009000/24576000\n",
      "current iter: 9010000/24576000\n",
      "current iter: 9011000/24576000\n",
      "current iter: 9012000/24576000\n",
      "current iter: 9013000/24576000\n",
      "current iter: 9014000/24576000\n",
      "current iter: 9015000/24576000\n",
      "current iter: 9016000/24576000\n",
      "current iter: 9017000/24576000\n",
      "current iter: 9018000/24576000\n",
      "current iter: 9019000/24576000\n",
      "current iter: 9020000/24576000\n",
      "current iter: 9021000/24576000\n",
      "current iter: 9022000/24576000\n",
      "current iter: 9023000/24576000\n",
      "current iter: 9024000/24576000\n",
      "current iter: 9025000/24576000\n",
      "current iter: 9026000/24576000\n",
      "current iter: 9027000/24576000\n",
      "current iter: 9028000/24576000\n",
      "current iter: 9029000/24576000\n",
      "current iter: 9030000/24576000\n",
      "current iter: 9031000/24576000\n",
      "current iter: 9032000/24576000\n",
      "current iter: 9033000/24576000\n",
      "current iter: 9034000/24576000\n",
      "current iter: 9035000/24576000\n",
      "current iter: 9036000/24576000\n",
      "current iter: 9037000/24576000\n",
      "current iter: 9038000/24576000\n",
      "current iter: 9039000/24576000\n",
      "current iter: 9040000/24576000\n",
      "current iter: 9041000/24576000\n",
      "current iter: 9042000/24576000\n",
      "current iter: 9043000/24576000\n",
      "current iter: 9044000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 9045000/24576000\n",
      "current iter: 9046000/24576000\n",
      "current iter: 9047000/24576000\n",
      "current iter: 9048000/24576000\n",
      "current iter: 9049000/24576000\n",
      "current iter: 9050000/24576000\n",
      "current iter: 9051000/24576000\n",
      "current iter: 9052000/24576000\n",
      "current iter: 9053000/24576000\n",
      "current iter: 9054000/24576000\n",
      "current iter: 9055000/24576000\n",
      "current iter: 9056000/24576000\n",
      "current iter: 9057000/24576000\n",
      "current iter: 9058000/24576000\n",
      "current iter: 9059000/24576000\n",
      "current iter: 9060000/24576000\n",
      "current iter: 9061000/24576000\n",
      "current iter: 9062000/24576000\n",
      "current iter: 9063000/24576000\n",
      "current iter: 9064000/24576000\n",
      "current iter: 9065000/24576000\n",
      "current iter: 9066000/24576000\n",
      "current iter: 9067000/24576000\n",
      "current iter: 9068000/24576000\n",
      "current iter: 9069000/24576000\n",
      "current iter: 9070000/24576000\n",
      "current iter: 9071000/24576000\n",
      "current iter: 9072000/24576000\n",
      "current iter: 9073000/24576000\n",
      "current iter: 9074000/24576000\n",
      "current iter: 9075000/24576000\n",
      "current iter: 9076000/24576000\n",
      "current iter: 9077000/24576000\n",
      "current iter: 9078000/24576000\n",
      "current iter: 9079000/24576000\n",
      "current iter: 9080000/24576000\n",
      "current iter: 9081000/24576000\n",
      "current iter: 9082000/24576000\n",
      "current iter: 9083000/24576000\n",
      "current iter: 9084000/24576000\n",
      "current iter: 9085000/24576000\n",
      "current iter: 9086000/24576000\n",
      "current iter: 9087000/24576000\n",
      "current iter: 9088000/24576000\n",
      "current iter: 9089000/24576000\n",
      "current iter: 9090000/24576000\n",
      "current iter: 9091000/24576000\n",
      "current iter: 9092000/24576000\n",
      "current iter: 9093000/24576000\n",
      "current iter: 9094000/24576000\n",
      "current iter: 9095000/24576000\n",
      "current iter: 9096000/24576000\n",
      "current iter: 9097000/24576000\n",
      "current iter: 9098000/24576000\n",
      "current iter: 9099000/24576000\n",
      "current iter: 9100000/24576000\n",
      "current iter: 9101000/24576000\n",
      "current iter: 9102000/24576000\n",
      "current iter: 9103000/24576000\n",
      "current iter: 9104000/24576000\n",
      "current iter: 9105000/24576000\n",
      "current iter: 9106000/24576000\n",
      "current iter: 9107000/24576000\n",
      "current iter: 9108000/24576000\n",
      "current iter: 9109000/24576000\n",
      "current iter: 9110000/24576000\n",
      "current iter: 9111000/24576000\n",
      "current iter: 9112000/24576000\n",
      "current iter: 9113000/24576000\n",
      "current iter: 9114000/24576000\n",
      "current iter: 9115000/24576000\n",
      "current iter: 9116000/24576000\n",
      "current iter: 9117000/24576000\n",
      "current iter: 9118000/24576000\n",
      "current iter: 9119000/24576000\n",
      "current iter: 9120000/24576000\n",
      "current iter: 9121000/24576000\n",
      "current iter: 9122000/24576000\n",
      "current iter: 9123000/24576000\n",
      "current iter: 9124000/24576000\n",
      "current iter: 9125000/24576000\n",
      "current iter: 9126000/24576000\n",
      "current iter: 9127000/24576000\n",
      "current iter: 9128000/24576000\n",
      "current iter: 9129000/24576000\n",
      "current iter: 9130000/24576000\n",
      "current iter: 9131000/24576000\n",
      "current iter: 9132000/24576000\n",
      "current iter: 9133000/24576000\n",
      "current iter: 9134000/24576000\n",
      "current iter: 9135000/24576000\n",
      "current iter: 9136000/24576000\n",
      "current iter: 9137000/24576000\n",
      "current iter: 9138000/24576000\n",
      "current iter: 9139000/24576000\n",
      "current iter: 9140000/24576000\n",
      "current iter: 9141000/24576000\n",
      "current iter: 9142000/24576000\n",
      "current iter: 9143000/24576000\n",
      "current iter: 9144000/24576000\n",
      "current iter: 9145000/24576000\n",
      "current iter: 9146000/24576000\n",
      "current iter: 9147000/24576000\n",
      "current iter: 9148000/24576000\n",
      "current iter: 9149000/24576000\n",
      "current iter: 9150000/24576000\n",
      "current iter: 9151000/24576000\n",
      "current iter: 9152000/24576000\n",
      "current iter: 9153000/24576000\n",
      "current iter: 9154000/24576000\n",
      "current iter: 9155000/24576000\n",
      "current iter: 9156000/24576000\n",
      "current iter: 9157000/24576000\n",
      "current iter: 9158000/24576000\n",
      "current iter: 9159000/24576000\n",
      "current iter: 9160000/24576000\n",
      "current iter: 9161000/24576000\n",
      "current iter: 9162000/24576000\n",
      "current iter: 9163000/24576000\n",
      "current iter: 9164000/24576000\n",
      "current iter: 9165000/24576000\n",
      "current iter: 9166000/24576000\n",
      "current iter: 9167000/24576000\n",
      "current iter: 9168000/24576000\n",
      "current iter: 9169000/24576000\n",
      "current iter: 9170000/24576000\n",
      "current iter: 9171000/24576000\n",
      "current iter: 9172000/24576000\n",
      "current iter: 9173000/24576000\n",
      "current iter: 9174000/24576000\n",
      "current iter: 9175000/24576000\n",
      "current iter: 9176000/24576000\n",
      "current iter: 9177000/24576000\n",
      "current iter: 9178000/24576000\n",
      "current iter: 9179000/24576000\n",
      "current iter: 9180000/24576000\n",
      "current iter: 9181000/24576000\n",
      "current iter: 9182000/24576000\n",
      "current iter: 9183000/24576000\n",
      "current iter: 9184000/24576000\n",
      "current iter: 9185000/24576000\n",
      "current iter: 9186000/24576000\n",
      "current iter: 9187000/24576000\n",
      "current iter: 9188000/24576000\n",
      "current iter: 9189000/24576000\n",
      "current iter: 9190000/24576000\n",
      "current iter: 9191000/24576000\n",
      "current iter: 9192000/24576000\n",
      "current iter: 9193000/24576000\n",
      "current iter: 9194000/24576000\n",
      "current iter: 9195000/24576000\n",
      "current iter: 9196000/24576000\n",
      "current iter: 9197000/24576000\n",
      "current iter: 9198000/24576000\n",
      "current iter: 9199000/24576000\n",
      "current iter: 9200000/24576000\n",
      "current iter: 9201000/24576000\n",
      "current iter: 9202000/24576000\n",
      "current iter: 9203000/24576000\n",
      "current iter: 9204000/24576000\n",
      "current iter: 9205000/24576000\n",
      "current iter: 9206000/24576000\n",
      "current iter: 9207000/24576000\n",
      "current iter: 9208000/24576000\n",
      "current iter: 9209000/24576000\n",
      "current iter: 9210000/24576000\n",
      "current iter: 9211000/24576000\n",
      "current iter: 9212000/24576000\n",
      "current iter: 9213000/24576000\n",
      "current iter: 9214000/24576000\n",
      "current iter: 9215000/24576000\n",
      "current iter: 9216000/24576000\n",
      "current iter: 9217000/24576000\n",
      "current iter: 9218000/24576000\n",
      "current iter: 9219000/24576000\n",
      "current iter: 9220000/24576000\n",
      "current iter: 9221000/24576000\n",
      "current iter: 9222000/24576000\n",
      "current iter: 9223000/24576000\n",
      "current iter: 9224000/24576000\n",
      "current iter: 9225000/24576000\n",
      "current iter: 9226000/24576000\n",
      "current iter: 9227000/24576000\n",
      "current iter: 9228000/24576000\n",
      "current iter: 9229000/24576000\n",
      "current iter: 9230000/24576000\n",
      "current iter: 9231000/24576000\n",
      "current iter: 9232000/24576000\n",
      "current iter: 9233000/24576000\n",
      "current iter: 9234000/24576000\n",
      "current iter: 9235000/24576000\n",
      "current iter: 9236000/24576000\n",
      "current iter: 9237000/24576000\n",
      "current iter: 9238000/24576000\n",
      "current iter: 9239000/24576000\n",
      "current iter: 9240000/24576000\n",
      "current iter: 9241000/24576000\n",
      "current iter: 9242000/24576000\n",
      "current iter: 9243000/24576000\n",
      "current iter: 9244000/24576000\n",
      "current iter: 9245000/24576000\n",
      "current iter: 9246000/24576000\n",
      "current iter: 9247000/24576000\n",
      "current iter: 9248000/24576000\n",
      "current iter: 9249000/24576000\n",
      "current iter: 9250000/24576000\n",
      "current iter: 9251000/24576000\n",
      "current iter: 9252000/24576000\n",
      "current iter: 9253000/24576000\n",
      "current iter: 9254000/24576000\n",
      "current iter: 9255000/24576000\n",
      "current iter: 9256000/24576000\n",
      "current iter: 9257000/24576000\n",
      "current iter: 9258000/24576000\n",
      "current iter: 9259000/24576000\n",
      "current iter: 9260000/24576000\n",
      "current iter: 9261000/24576000\n",
      "current iter: 9262000/24576000\n",
      "current iter: 9263000/24576000\n",
      "current iter: 9264000/24576000\n",
      "current iter: 9265000/24576000\n",
      "current iter: 9266000/24576000\n",
      "current iter: 9267000/24576000\n",
      "current iter: 9268000/24576000\n",
      "current iter: 9269000/24576000\n",
      "current iter: 9270000/24576000\n",
      "current iter: 9271000/24576000\n",
      "current iter: 9272000/24576000\n",
      "current iter: 9273000/24576000\n",
      "current iter: 9274000/24576000\n",
      "current iter: 9275000/24576000\n",
      "current iter: 9276000/24576000\n",
      "current iter: 9277000/24576000\n",
      "current iter: 9278000/24576000\n",
      "current iter: 9279000/24576000\n",
      "current iter: 9280000/24576000\n",
      "current iter: 9281000/24576000\n",
      "current iter: 9282000/24576000\n",
      "current iter: 9283000/24576000\n",
      "current iter: 9284000/24576000\n",
      "current iter: 9285000/24576000\n",
      "current iter: 9286000/24576000\n",
      "current iter: 9287000/24576000\n",
      "current iter: 9288000/24576000\n",
      "current iter: 9289000/24576000\n",
      "current iter: 9290000/24576000\n",
      "current iter: 9291000/24576000\n",
      "current iter: 9292000/24576000\n",
      "current iter: 9293000/24576000\n",
      "current iter: 9294000/24576000\n",
      "current iter: 9295000/24576000\n",
      "current iter: 9296000/24576000\n",
      "current iter: 9297000/24576000\n",
      "current iter: 9298000/24576000\n",
      "current iter: 9299000/24576000\n",
      "current iter: 9300000/24576000\n",
      "current iter: 9301000/24576000\n",
      "current iter: 9302000/24576000\n",
      "current iter: 9303000/24576000\n",
      "current iter: 9304000/24576000\n",
      "current iter: 9305000/24576000\n",
      "current iter: 9306000/24576000\n",
      "current iter: 9307000/24576000\n",
      "current iter: 9308000/24576000\n",
      "current iter: 9309000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 9310000/24576000\n",
      "current iter: 9311000/24576000\n",
      "current iter: 9312000/24576000\n",
      "current iter: 9313000/24576000\n",
      "current iter: 9314000/24576000\n",
      "current iter: 9315000/24576000\n",
      "current iter: 9316000/24576000\n",
      "current iter: 9317000/24576000\n",
      "current iter: 9318000/24576000\n",
      "current iter: 9319000/24576000\n",
      "current iter: 9320000/24576000\n",
      "current iter: 9321000/24576000\n",
      "current iter: 9322000/24576000\n",
      "current iter: 9323000/24576000\n",
      "current iter: 9324000/24576000\n",
      "current iter: 9325000/24576000\n",
      "current iter: 9326000/24576000\n",
      "current iter: 9327000/24576000\n",
      "current iter: 9328000/24576000\n",
      "current iter: 9329000/24576000\n",
      "current iter: 9330000/24576000\n",
      "current iter: 9331000/24576000\n",
      "current iter: 9332000/24576000\n",
      "current iter: 9333000/24576000\n",
      "current iter: 9334000/24576000\n",
      "current iter: 9335000/24576000\n",
      "current iter: 9336000/24576000\n",
      "current iter: 9337000/24576000\n",
      "current iter: 9338000/24576000\n",
      "current iter: 9339000/24576000\n",
      "current iter: 9340000/24576000\n",
      "current iter: 9341000/24576000\n",
      "current iter: 9342000/24576000\n",
      "current iter: 9343000/24576000\n",
      "current iter: 9344000/24576000\n",
      "current iter: 9345000/24576000\n",
      "current iter: 9346000/24576000\n",
      "current iter: 9347000/24576000\n",
      "current iter: 9348000/24576000\n",
      "current iter: 9349000/24576000\n",
      "current iter: 9350000/24576000\n",
      "current iter: 9351000/24576000\n",
      "current iter: 9352000/24576000\n",
      "current iter: 9353000/24576000\n",
      "current iter: 9354000/24576000\n",
      "current iter: 9355000/24576000\n",
      "current iter: 9356000/24576000\n",
      "current iter: 9357000/24576000\n",
      "current iter: 9358000/24576000\n",
      "current iter: 9359000/24576000\n",
      "current iter: 9360000/24576000\n",
      "current iter: 9361000/24576000\n",
      "current iter: 9362000/24576000\n",
      "current iter: 9363000/24576000\n",
      "current iter: 9364000/24576000\n",
      "current iter: 9365000/24576000\n",
      "current iter: 9366000/24576000\n",
      "current iter: 9367000/24576000\n",
      "current iter: 9368000/24576000\n",
      "current iter: 9369000/24576000\n",
      "current iter: 9370000/24576000\n",
      "current iter: 9371000/24576000\n",
      "current iter: 9372000/24576000\n",
      "current iter: 9373000/24576000\n",
      "current iter: 9374000/24576000\n",
      "current iter: 9375000/24576000\n",
      "current iter: 9376000/24576000\n",
      "current iter: 9377000/24576000\n",
      "current iter: 9378000/24576000\n",
      "current iter: 9379000/24576000\n",
      "current iter: 9380000/24576000\n",
      "current iter: 9381000/24576000\n",
      "current iter: 9382000/24576000\n",
      "current iter: 9383000/24576000\n",
      "current iter: 9384000/24576000\n",
      "current iter: 9385000/24576000\n",
      "current iter: 9386000/24576000\n",
      "current iter: 9387000/24576000\n",
      "current iter: 9388000/24576000\n",
      "current iter: 9389000/24576000\n",
      "current iter: 9390000/24576000\n",
      "current iter: 9391000/24576000\n",
      "current iter: 9392000/24576000\n",
      "current iter: 9393000/24576000\n",
      "current iter: 9394000/24576000\n",
      "current iter: 9395000/24576000\n",
      "current iter: 9396000/24576000\n",
      "current iter: 9397000/24576000\n",
      "current iter: 9398000/24576000\n",
      "current iter: 9399000/24576000\n",
      "current iter: 9400000/24576000\n",
      "current iter: 9401000/24576000\n",
      "current iter: 9402000/24576000\n",
      "current iter: 9403000/24576000\n",
      "current iter: 9404000/24576000\n",
      "current iter: 9405000/24576000\n",
      "current iter: 9406000/24576000\n",
      "current iter: 9407000/24576000\n",
      "current iter: 9408000/24576000\n",
      "current iter: 9409000/24576000\n",
      "current iter: 9410000/24576000\n",
      "current iter: 9411000/24576000\n",
      "current iter: 9412000/24576000\n",
      "current iter: 9413000/24576000\n",
      "current iter: 9414000/24576000\n",
      "current iter: 9415000/24576000\n",
      "current iter: 9416000/24576000\n",
      "current iter: 9417000/24576000\n",
      "current iter: 9418000/24576000\n",
      "current iter: 9419000/24576000\n",
      "current iter: 9420000/24576000\n",
      "current iter: 9421000/24576000\n",
      "current iter: 9422000/24576000\n",
      "current iter: 9423000/24576000\n",
      "current iter: 9424000/24576000\n",
      "current iter: 9425000/24576000\n",
      "current iter: 9426000/24576000\n",
      "current iter: 9427000/24576000\n",
      "current iter: 9428000/24576000\n",
      "current iter: 9429000/24576000\n",
      "current iter: 9430000/24576000\n",
      "current iter: 9431000/24576000\n",
      "current iter: 9432000/24576000\n",
      "current iter: 9433000/24576000\n",
      "current iter: 9434000/24576000\n",
      "current iter: 9435000/24576000\n",
      "current iter: 9436000/24576000\n",
      "current iter: 9437000/24576000\n",
      "current iter: 9438000/24576000\n",
      "current iter: 9439000/24576000\n",
      "current iter: 9440000/24576000\n",
      "current iter: 9441000/24576000\n",
      "current iter: 9442000/24576000\n",
      "current iter: 9443000/24576000\n",
      "current iter: 9444000/24576000\n",
      "current iter: 9445000/24576000\n",
      "current iter: 9446000/24576000\n",
      "current iter: 9447000/24576000\n",
      "current iter: 9448000/24576000\n",
      "current iter: 9449000/24576000\n",
      "current iter: 9450000/24576000\n",
      "current iter: 9451000/24576000\n",
      "current iter: 9452000/24576000\n",
      "current iter: 9453000/24576000\n",
      "current iter: 9454000/24576000\n",
      "current iter: 9455000/24576000\n",
      "current iter: 9456000/24576000\n",
      "current iter: 9457000/24576000\n",
      "current iter: 9458000/24576000\n",
      "current iter: 9459000/24576000\n",
      "current iter: 9460000/24576000\n",
      "current iter: 9461000/24576000\n",
      "current iter: 9462000/24576000\n",
      "current iter: 9463000/24576000\n",
      "current iter: 9464000/24576000\n",
      "current iter: 9465000/24576000\n",
      "current iter: 9466000/24576000\n",
      "current iter: 9467000/24576000\n",
      "current iter: 9468000/24576000\n",
      "current iter: 9469000/24576000\n",
      "current iter: 9470000/24576000\n",
      "current iter: 9471000/24576000\n",
      "current iter: 9472000/24576000\n",
      "current iter: 9473000/24576000\n",
      "current iter: 9474000/24576000\n",
      "current iter: 9475000/24576000\n",
      "current iter: 9476000/24576000\n",
      "current iter: 9477000/24576000\n",
      "current iter: 9478000/24576000\n",
      "current iter: 9479000/24576000\n",
      "current iter: 9480000/24576000\n",
      "current iter: 9481000/24576000\n",
      "current iter: 9482000/24576000\n",
      "current iter: 9483000/24576000\n",
      "current iter: 9484000/24576000\n",
      "current iter: 9485000/24576000\n",
      "current iter: 9486000/24576000\n",
      "current iter: 9487000/24576000\n",
      "current iter: 9488000/24576000\n",
      "current iter: 9489000/24576000\n",
      "current iter: 9490000/24576000\n",
      "current iter: 9491000/24576000\n",
      "current iter: 9492000/24576000\n",
      "current iter: 9493000/24576000\n",
      "current iter: 9494000/24576000\n",
      "current iter: 9495000/24576000\n",
      "current iter: 9496000/24576000\n",
      "current iter: 9497000/24576000\n",
      "current iter: 9498000/24576000\n",
      "current iter: 9499000/24576000\n",
      "current iter: 9500000/24576000\n",
      "current iter: 9501000/24576000\n",
      "current iter: 9502000/24576000\n",
      "current iter: 9503000/24576000\n",
      "current iter: 9504000/24576000\n",
      "current iter: 9505000/24576000\n",
      "current iter: 9506000/24576000\n",
      "current iter: 9507000/24576000\n",
      "current iter: 9508000/24576000\n",
      "current iter: 9509000/24576000\n",
      "current iter: 9510000/24576000\n",
      "current iter: 9511000/24576000\n",
      "current iter: 9512000/24576000\n",
      "current iter: 9513000/24576000\n",
      "current iter: 9514000/24576000\n",
      "current iter: 9515000/24576000\n",
      "current iter: 9516000/24576000\n",
      "current iter: 9517000/24576000\n",
      "current iter: 9518000/24576000\n",
      "current iter: 9519000/24576000\n",
      "current iter: 9520000/24576000\n",
      "current iter: 9521000/24576000\n",
      "current iter: 9522000/24576000\n",
      "current iter: 9523000/24576000\n",
      "current iter: 9524000/24576000\n",
      "current iter: 9525000/24576000\n",
      "current iter: 9526000/24576000\n",
      "current iter: 9527000/24576000\n",
      "current iter: 9528000/24576000\n",
      "current iter: 9529000/24576000\n",
      "current iter: 9530000/24576000\n",
      "current iter: 9531000/24576000\n",
      "current iter: 9532000/24576000\n",
      "current iter: 9533000/24576000\n",
      "current iter: 9534000/24576000\n",
      "current iter: 9535000/24576000\n",
      "current iter: 9536000/24576000\n",
      "current iter: 9537000/24576000\n",
      "current iter: 9538000/24576000\n",
      "current iter: 9539000/24576000\n",
      "current iter: 9540000/24576000\n",
      "current iter: 9541000/24576000\n",
      "current iter: 9542000/24576000\n",
      "current iter: 9543000/24576000\n",
      "current iter: 9544000/24576000\n",
      "current iter: 9545000/24576000\n",
      "current iter: 9546000/24576000\n",
      "current iter: 9547000/24576000\n",
      "current iter: 9548000/24576000\n",
      "current iter: 9549000/24576000\n",
      "current iter: 9550000/24576000\n",
      "current iter: 9551000/24576000\n",
      "current iter: 9552000/24576000\n",
      "current iter: 9553000/24576000\n",
      "current iter: 9554000/24576000\n",
      "current iter: 9555000/24576000\n",
      "current iter: 9556000/24576000\n",
      "current iter: 9557000/24576000\n",
      "current iter: 9558000/24576000\n",
      "current iter: 9559000/24576000\n",
      "current iter: 9560000/24576000\n",
      "current iter: 9561000/24576000\n",
      "current iter: 9562000/24576000\n",
      "current iter: 9563000/24576000\n",
      "current iter: 9564000/24576000\n",
      "current iter: 9565000/24576000\n",
      "current iter: 9566000/24576000\n",
      "current iter: 9567000/24576000\n",
      "current iter: 9568000/24576000\n",
      "current iter: 9569000/24576000\n",
      "current iter: 9570000/24576000\n",
      "current iter: 9571000/24576000\n",
      "current iter: 9572000/24576000\n",
      "current iter: 9573000/24576000\n",
      "current iter: 9574000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 9575000/24576000\n",
      "current iter: 9576000/24576000\n",
      "current iter: 9577000/24576000\n",
      "current iter: 9578000/24576000\n",
      "current iter: 9579000/24576000\n",
      "current iter: 9580000/24576000\n",
      "current iter: 9581000/24576000\n",
      "current iter: 9582000/24576000\n",
      "current iter: 9583000/24576000\n",
      "current iter: 9584000/24576000\n",
      "current iter: 9585000/24576000\n",
      "current iter: 9586000/24576000\n",
      "current iter: 9587000/24576000\n",
      "current iter: 9588000/24576000\n",
      "current iter: 9589000/24576000\n",
      "current iter: 9590000/24576000\n",
      "current iter: 9591000/24576000\n",
      "current iter: 9592000/24576000\n",
      "current iter: 9593000/24576000\n",
      "current iter: 9594000/24576000\n",
      "current iter: 9595000/24576000\n",
      "current iter: 9596000/24576000\n",
      "current iter: 9597000/24576000\n",
      "current iter: 9598000/24576000\n",
      "current iter: 9599000/24576000\n",
      "current iter: 9600000/24576000\n",
      "current iter: 9601000/24576000\n",
      "current iter: 9602000/24576000\n",
      "current iter: 9603000/24576000\n",
      "current iter: 9604000/24576000\n",
      "current iter: 9605000/24576000\n",
      "current iter: 9606000/24576000\n",
      "current iter: 9607000/24576000\n",
      "current iter: 9608000/24576000\n",
      "current iter: 9609000/24576000\n",
      "current iter: 9610000/24576000\n",
      "current iter: 9611000/24576000\n",
      "current iter: 9612000/24576000\n",
      "current iter: 9613000/24576000\n",
      "current iter: 9614000/24576000\n",
      "current iter: 9615000/24576000\n",
      "current iter: 9616000/24576000\n",
      "current iter: 9617000/24576000\n",
      "current iter: 9618000/24576000\n",
      "current iter: 9619000/24576000\n",
      "current iter: 9620000/24576000\n",
      "current iter: 9621000/24576000\n",
      "current iter: 9622000/24576000\n",
      "current iter: 9623000/24576000\n",
      "current iter: 9624000/24576000\n",
      "current iter: 9625000/24576000\n",
      "current iter: 9626000/24576000\n",
      "current iter: 9627000/24576000\n",
      "current iter: 9628000/24576000\n",
      "current iter: 9629000/24576000\n",
      "current iter: 9630000/24576000\n",
      "current iter: 9631000/24576000\n",
      "current iter: 9632000/24576000\n",
      "current iter: 9633000/24576000\n",
      "current iter: 9634000/24576000\n",
      "current iter: 9635000/24576000\n",
      "current iter: 9636000/24576000\n",
      "current iter: 9637000/24576000\n",
      "current iter: 9638000/24576000\n",
      "current iter: 9639000/24576000\n",
      "current iter: 9640000/24576000\n",
      "current iter: 9641000/24576000\n",
      "current iter: 9642000/24576000\n",
      "current iter: 9643000/24576000\n",
      "current iter: 9644000/24576000\n",
      "current iter: 9645000/24576000\n",
      "current iter: 9646000/24576000\n",
      "current iter: 9647000/24576000\n",
      "current iter: 9648000/24576000\n",
      "current iter: 9649000/24576000\n",
      "current iter: 9650000/24576000\n",
      "current iter: 9651000/24576000\n",
      "current iter: 9652000/24576000\n",
      "current iter: 9653000/24576000\n",
      "current iter: 9654000/24576000\n",
      "current iter: 9655000/24576000\n",
      "current iter: 9656000/24576000\n",
      "current iter: 9657000/24576000\n",
      "current iter: 9658000/24576000\n",
      "current iter: 9659000/24576000\n",
      "current iter: 9660000/24576000\n",
      "current iter: 9661000/24576000\n",
      "current iter: 9662000/24576000\n",
      "current iter: 9663000/24576000\n",
      "current iter: 9664000/24576000\n",
      "current iter: 9665000/24576000\n",
      "current iter: 9666000/24576000\n",
      "current iter: 9667000/24576000\n",
      "current iter: 9668000/24576000\n",
      "current iter: 9669000/24576000\n",
      "current iter: 9670000/24576000\n",
      "current iter: 9671000/24576000\n",
      "current iter: 9672000/24576000\n",
      "current iter: 9673000/24576000\n",
      "current iter: 9674000/24576000\n",
      "current iter: 9675000/24576000\n",
      "current iter: 9676000/24576000\n",
      "current iter: 9677000/24576000\n",
      "current iter: 9678000/24576000\n",
      "current iter: 9679000/24576000\n",
      "current iter: 9680000/24576000\n",
      "current iter: 9681000/24576000\n",
      "current iter: 9682000/24576000\n",
      "current iter: 9683000/24576000\n",
      "current iter: 9684000/24576000\n",
      "current iter: 9685000/24576000\n",
      "current iter: 9686000/24576000\n",
      "current iter: 9687000/24576000\n",
      "current iter: 9688000/24576000\n",
      "current iter: 9689000/24576000\n",
      "current iter: 9690000/24576000\n",
      "current iter: 9691000/24576000\n",
      "current iter: 9692000/24576000\n",
      "current iter: 9693000/24576000\n",
      "current iter: 9694000/24576000\n",
      "current iter: 9695000/24576000\n",
      "current iter: 9696000/24576000\n",
      "current iter: 9697000/24576000\n",
      "current iter: 9698000/24576000\n",
      "current iter: 9699000/24576000\n",
      "current iter: 9700000/24576000\n",
      "current iter: 9701000/24576000\n",
      "current iter: 9702000/24576000\n",
      "current iter: 9703000/24576000\n",
      "current iter: 9704000/24576000\n",
      "current iter: 9705000/24576000\n",
      "current iter: 9706000/24576000\n",
      "current iter: 9707000/24576000\n",
      "current iter: 9708000/24576000\n",
      "current iter: 9709000/24576000\n",
      "current iter: 9710000/24576000\n",
      "current iter: 9711000/24576000\n",
      "current iter: 9712000/24576000\n",
      "current iter: 9713000/24576000\n",
      "current iter: 9714000/24576000\n",
      "current iter: 9715000/24576000\n",
      "current iter: 9716000/24576000\n",
      "current iter: 9717000/24576000\n",
      "current iter: 9718000/24576000\n",
      "current iter: 9719000/24576000\n",
      "current iter: 9720000/24576000\n",
      "current iter: 9721000/24576000\n",
      "current iter: 9722000/24576000\n",
      "current iter: 9723000/24576000\n",
      "current iter: 9724000/24576000\n",
      "current iter: 9725000/24576000\n",
      "current iter: 9726000/24576000\n",
      "current iter: 9727000/24576000\n",
      "current iter: 9728000/24576000\n",
      "current iter: 9729000/24576000\n",
      "current iter: 9730000/24576000\n",
      "current iter: 9731000/24576000\n",
      "current iter: 9732000/24576000\n",
      "current iter: 9733000/24576000\n",
      "current iter: 9734000/24576000\n",
      "current iter: 9735000/24576000\n",
      "current iter: 9736000/24576000\n",
      "current iter: 9737000/24576000\n",
      "current iter: 9738000/24576000\n",
      "current iter: 9739000/24576000\n",
      "current iter: 9740000/24576000\n",
      "current iter: 9741000/24576000\n",
      "current iter: 9742000/24576000\n",
      "current iter: 9743000/24576000\n",
      "current iter: 9744000/24576000\n",
      "current iter: 9745000/24576000\n",
      "current iter: 9746000/24576000\n",
      "current iter: 9747000/24576000\n",
      "current iter: 9748000/24576000\n",
      "current iter: 9749000/24576000\n",
      "current iter: 9750000/24576000\n",
      "current iter: 9751000/24576000\n",
      "current iter: 9752000/24576000\n",
      "current iter: 9753000/24576000\n",
      "current iter: 9754000/24576000\n",
      "current iter: 9755000/24576000\n",
      "current iter: 9756000/24576000\n",
      "current iter: 9757000/24576000\n",
      "current iter: 9758000/24576000\n",
      "current iter: 9759000/24576000\n",
      "current iter: 9760000/24576000\n",
      "current iter: 9761000/24576000\n",
      "current iter: 9762000/24576000\n",
      "current iter: 9763000/24576000\n",
      "current iter: 9764000/24576000\n",
      "current iter: 9765000/24576000\n",
      "current iter: 9766000/24576000\n",
      "current iter: 9767000/24576000\n",
      "current iter: 9768000/24576000\n",
      "current iter: 9769000/24576000\n",
      "current iter: 9770000/24576000\n",
      "current iter: 9771000/24576000\n",
      "current iter: 9772000/24576000\n",
      "current iter: 9773000/24576000\n",
      "current iter: 9774000/24576000\n",
      "current iter: 9775000/24576000\n",
      "current iter: 9776000/24576000\n",
      "current iter: 9777000/24576000\n",
      "current iter: 9778000/24576000\n",
      "current iter: 9779000/24576000\n",
      "current iter: 9780000/24576000\n",
      "current iter: 9781000/24576000\n",
      "current iter: 9782000/24576000\n",
      "current iter: 9783000/24576000\n",
      "current iter: 9784000/24576000\n",
      "current iter: 9785000/24576000\n",
      "current iter: 9786000/24576000\n",
      "current iter: 9787000/24576000\n",
      "current iter: 9788000/24576000\n",
      "current iter: 9789000/24576000\n",
      "current iter: 9790000/24576000\n",
      "current iter: 9791000/24576000\n",
      "current iter: 9792000/24576000\n",
      "current iter: 9793000/24576000\n",
      "current iter: 9794000/24576000\n",
      "current iter: 9795000/24576000\n",
      "current iter: 9796000/24576000\n",
      "current iter: 9797000/24576000\n",
      "current iter: 9798000/24576000\n",
      "current iter: 9799000/24576000\n",
      "current iter: 9800000/24576000\n",
      "current iter: 9801000/24576000\n",
      "current iter: 9802000/24576000\n",
      "current iter: 9803000/24576000\n",
      "current iter: 9804000/24576000\n",
      "current iter: 9805000/24576000\n",
      "current iter: 9806000/24576000\n",
      "current iter: 9807000/24576000\n",
      "current iter: 9808000/24576000\n",
      "current iter: 9809000/24576000\n",
      "current iter: 9810000/24576000\n",
      "current iter: 9811000/24576000\n",
      "current iter: 9812000/24576000\n",
      "current iter: 9813000/24576000\n",
      "current iter: 9814000/24576000\n",
      "current iter: 9815000/24576000\n",
      "current iter: 9816000/24576000\n",
      "current iter: 9817000/24576000\n",
      "current iter: 9818000/24576000\n",
      "current iter: 9819000/24576000\n",
      "current iter: 9820000/24576000\n",
      "current iter: 9821000/24576000\n",
      "current iter: 9822000/24576000\n",
      "current iter: 9823000/24576000\n",
      "current iter: 9824000/24576000\n",
      "current iter: 9825000/24576000\n",
      "current iter: 9826000/24576000\n",
      "current iter: 9827000/24576000\n",
      "current iter: 9828000/24576000\n",
      "current iter: 9829000/24576000\n",
      "current iter: 9830000/24576000\n",
      "current iter: 9831000/24576000\n",
      "current iter: 9832000/24576000\n",
      "current iter: 9833000/24576000\n",
      "current iter: 9834000/24576000\n",
      "current iter: 9835000/24576000\n",
      "current iter: 9836000/24576000\n",
      "current iter: 9837000/24576000\n",
      "current iter: 9838000/24576000\n",
      "current iter: 9839000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 9840000/24576000\n",
      "current iter: 9841000/24576000\n",
      "current iter: 9842000/24576000\n",
      "current iter: 9843000/24576000\n",
      "current iter: 9844000/24576000\n",
      "current iter: 9845000/24576000\n",
      "current iter: 9846000/24576000\n",
      "current iter: 9847000/24576000\n",
      "current iter: 9848000/24576000\n",
      "current iter: 9849000/24576000\n",
      "current iter: 9850000/24576000\n",
      "current iter: 9851000/24576000\n",
      "current iter: 9852000/24576000\n",
      "current iter: 9853000/24576000\n",
      "current iter: 9854000/24576000\n",
      "current iter: 9855000/24576000\n",
      "current iter: 9856000/24576000\n",
      "current iter: 9857000/24576000\n",
      "current iter: 9858000/24576000\n",
      "current iter: 9859000/24576000\n",
      "current iter: 9860000/24576000\n",
      "current iter: 9861000/24576000\n",
      "current iter: 9862000/24576000\n",
      "current iter: 9863000/24576000\n",
      "current iter: 9864000/24576000\n",
      "current iter: 9865000/24576000\n",
      "current iter: 9866000/24576000\n",
      "current iter: 9867000/24576000\n",
      "current iter: 9868000/24576000\n",
      "current iter: 9869000/24576000\n",
      "current iter: 9870000/24576000\n",
      "current iter: 9871000/24576000\n",
      "current iter: 9872000/24576000\n",
      "current iter: 9873000/24576000\n",
      "current iter: 9874000/24576000\n",
      "current iter: 9875000/24576000\n",
      "current iter: 9876000/24576000\n",
      "current iter: 9877000/24576000\n",
      "current iter: 9878000/24576000\n",
      "current iter: 9879000/24576000\n",
      "current iter: 9880000/24576000\n",
      "current iter: 9881000/24576000\n",
      "current iter: 9882000/24576000\n",
      "current iter: 9883000/24576000\n",
      "current iter: 9884000/24576000\n",
      "current iter: 9885000/24576000\n",
      "current iter: 9886000/24576000\n",
      "current iter: 9887000/24576000\n",
      "current iter: 9888000/24576000\n",
      "current iter: 9889000/24576000\n",
      "current iter: 9890000/24576000\n",
      "current iter: 9891000/24576000\n",
      "current iter: 9892000/24576000\n",
      "current iter: 9893000/24576000\n",
      "current iter: 9894000/24576000\n",
      "current iter: 9895000/24576000\n",
      "current iter: 9896000/24576000\n",
      "current iter: 9897000/24576000\n",
      "current iter: 9898000/24576000\n",
      "current iter: 9899000/24576000\n",
      "current iter: 9900000/24576000\n",
      "current iter: 9901000/24576000\n",
      "current iter: 9902000/24576000\n",
      "current iter: 9903000/24576000\n",
      "current iter: 9904000/24576000\n",
      "current iter: 9905000/24576000\n",
      "current iter: 9906000/24576000\n",
      "current iter: 9907000/24576000\n",
      "current iter: 9908000/24576000\n",
      "current iter: 9909000/24576000\n",
      "current iter: 9910000/24576000\n",
      "current iter: 9911000/24576000\n",
      "current iter: 9912000/24576000\n",
      "current iter: 9913000/24576000\n",
      "current iter: 9914000/24576000\n",
      "current iter: 9915000/24576000\n",
      "current iter: 9916000/24576000\n",
      "current iter: 9917000/24576000\n",
      "current iter: 9918000/24576000\n",
      "current iter: 9919000/24576000\n",
      "current iter: 9920000/24576000\n",
      "current iter: 9921000/24576000\n",
      "current iter: 9922000/24576000\n",
      "current iter: 9923000/24576000\n",
      "current iter: 9924000/24576000\n",
      "current iter: 9925000/24576000\n",
      "current iter: 9926000/24576000\n",
      "current iter: 9927000/24576000\n",
      "current iter: 9928000/24576000\n",
      "current iter: 9929000/24576000\n",
      "current iter: 9930000/24576000\n",
      "current iter: 9931000/24576000\n",
      "current iter: 9932000/24576000\n",
      "current iter: 9933000/24576000\n",
      "current iter: 9934000/24576000\n",
      "current iter: 9935000/24576000\n",
      "current iter: 9936000/24576000\n",
      "current iter: 9937000/24576000\n",
      "current iter: 9938000/24576000\n",
      "current iter: 9939000/24576000\n",
      "current iter: 9940000/24576000\n",
      "current iter: 9941000/24576000\n",
      "current iter: 9942000/24576000\n",
      "current iter: 9943000/24576000\n",
      "current iter: 9944000/24576000\n",
      "current iter: 9945000/24576000\n",
      "current iter: 9946000/24576000\n",
      "current iter: 9947000/24576000\n",
      "current iter: 9948000/24576000\n",
      "current iter: 9949000/24576000\n",
      "current iter: 9950000/24576000\n",
      "current iter: 9951000/24576000\n",
      "current iter: 9952000/24576000\n",
      "current iter: 9953000/24576000\n",
      "current iter: 9954000/24576000\n",
      "current iter: 9955000/24576000\n",
      "current iter: 9956000/24576000\n",
      "current iter: 9957000/24576000\n",
      "current iter: 9958000/24576000\n",
      "current iter: 9959000/24576000\n",
      "current iter: 9960000/24576000\n",
      "current iter: 9961000/24576000\n",
      "current iter: 9962000/24576000\n",
      "current iter: 9963000/24576000\n",
      "current iter: 9964000/24576000\n",
      "current iter: 9965000/24576000\n",
      "current iter: 9966000/24576000\n",
      "current iter: 9967000/24576000\n",
      "current iter: 9968000/24576000\n",
      "current iter: 9969000/24576000\n",
      "current iter: 9970000/24576000\n",
      "current iter: 9971000/24576000\n",
      "current iter: 9972000/24576000\n",
      "current iter: 9973000/24576000\n",
      "current iter: 9974000/24576000\n",
      "current iter: 9975000/24576000\n",
      "current iter: 9976000/24576000\n",
      "current iter: 9977000/24576000\n",
      "current iter: 9978000/24576000\n",
      "current iter: 9979000/24576000\n",
      "current iter: 9980000/24576000\n",
      "current iter: 9981000/24576000\n",
      "current iter: 9982000/24576000\n",
      "current iter: 9983000/24576000\n",
      "current iter: 9984000/24576000\n",
      "current iter: 9985000/24576000\n",
      "current iter: 9986000/24576000\n",
      "current iter: 9987000/24576000\n",
      "current iter: 9988000/24576000\n",
      "current iter: 9989000/24576000\n",
      "current iter: 9990000/24576000\n",
      "current iter: 9991000/24576000\n",
      "current iter: 9992000/24576000\n",
      "current iter: 9993000/24576000\n",
      "current iter: 9994000/24576000\n",
      "current iter: 9995000/24576000\n",
      "current iter: 9996000/24576000\n",
      "current iter: 9997000/24576000\n",
      "current iter: 9998000/24576000\n",
      "current iter: 9999000/24576000\n",
      "current iter: 10000000/24576000\n",
      "current iter: 10001000/24576000\n",
      "current iter: 10002000/24576000\n",
      "current iter: 10003000/24576000\n",
      "current iter: 10004000/24576000\n",
      "current iter: 10005000/24576000\n",
      "current iter: 10006000/24576000\n",
      "current iter: 10007000/24576000\n",
      "current iter: 10008000/24576000\n",
      "current iter: 10009000/24576000\n",
      "current iter: 10010000/24576000\n",
      "current iter: 10011000/24576000\n",
      "current iter: 10012000/24576000\n",
      "current iter: 10013000/24576000\n",
      "current iter: 10014000/24576000\n",
      "current iter: 10015000/24576000\n",
      "current iter: 10016000/24576000\n",
      "current iter: 10017000/24576000\n",
      "current iter: 10018000/24576000\n",
      "current iter: 10019000/24576000\n",
      "current iter: 10020000/24576000\n",
      "current iter: 10021000/24576000\n",
      "current iter: 10022000/24576000\n",
      "current iter: 10023000/24576000\n",
      "current iter: 10024000/24576000\n",
      "current iter: 10025000/24576000\n",
      "current iter: 10026000/24576000\n",
      "current iter: 10027000/24576000\n",
      "current iter: 10028000/24576000\n",
      "current iter: 10029000/24576000\n",
      "current iter: 10030000/24576000\n",
      "current iter: 10031000/24576000\n",
      "current iter: 10032000/24576000\n",
      "current iter: 10033000/24576000\n",
      "current iter: 10034000/24576000\n",
      "current iter: 10035000/24576000\n",
      "current iter: 10036000/24576000\n",
      "current iter: 10037000/24576000\n",
      "current iter: 10038000/24576000\n",
      "current iter: 10039000/24576000\n",
      "current iter: 10040000/24576000\n",
      "current iter: 10041000/24576000\n",
      "current iter: 10042000/24576000\n",
      "current iter: 10043000/24576000\n",
      "current iter: 10044000/24576000\n",
      "current iter: 10045000/24576000\n",
      "current iter: 10046000/24576000\n",
      "current iter: 10047000/24576000\n",
      "current iter: 10048000/24576000\n",
      "current iter: 10049000/24576000\n",
      "current iter: 10050000/24576000\n",
      "current iter: 10051000/24576000\n",
      "current iter: 10052000/24576000\n",
      "current iter: 10053000/24576000\n",
      "current iter: 10054000/24576000\n",
      "current iter: 10055000/24576000\n",
      "current iter: 10056000/24576000\n",
      "current iter: 10057000/24576000\n",
      "current iter: 10058000/24576000\n",
      "current iter: 10059000/24576000\n",
      "current iter: 10060000/24576000\n",
      "current iter: 10061000/24576000\n",
      "current iter: 10062000/24576000\n",
      "current iter: 10063000/24576000\n",
      "current iter: 10064000/24576000\n",
      "current iter: 10065000/24576000\n",
      "current iter: 10066000/24576000\n",
      "current iter: 10067000/24576000\n",
      "current iter: 10068000/24576000\n",
      "current iter: 10069000/24576000\n",
      "current iter: 10070000/24576000\n",
      "current iter: 10071000/24576000\n",
      "current iter: 10072000/24576000\n",
      "current iter: 10073000/24576000\n",
      "current iter: 10074000/24576000\n",
      "current iter: 10075000/24576000\n",
      "current iter: 10076000/24576000\n",
      "current iter: 10077000/24576000\n",
      "current iter: 10078000/24576000\n",
      "current iter: 10079000/24576000\n",
      "current iter: 10080000/24576000\n",
      "current iter: 10081000/24576000\n",
      "current iter: 10082000/24576000\n",
      "current iter: 10083000/24576000\n",
      "current iter: 10084000/24576000\n",
      "current iter: 10085000/24576000\n",
      "current iter: 10086000/24576000\n",
      "current iter: 10087000/24576000\n",
      "current iter: 10088000/24576000\n",
      "current iter: 10089000/24576000\n",
      "current iter: 10090000/24576000\n",
      "current iter: 10091000/24576000\n",
      "current iter: 10092000/24576000\n",
      "current iter: 10093000/24576000\n",
      "current iter: 10094000/24576000\n",
      "current iter: 10095000/24576000\n",
      "current iter: 10096000/24576000\n",
      "current iter: 10097000/24576000\n",
      "current iter: 10098000/24576000\n",
      "current iter: 10099000/24576000\n",
      "current iter: 10100000/24576000\n",
      "current iter: 10101000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 10102000/24576000\n",
      "current iter: 10103000/24576000\n",
      "current iter: 10104000/24576000\n",
      "current iter: 10105000/24576000\n",
      "current iter: 10106000/24576000\n",
      "current iter: 10107000/24576000\n",
      "current iter: 10108000/24576000\n",
      "current iter: 10109000/24576000\n",
      "current iter: 10110000/24576000\n",
      "current iter: 10111000/24576000\n",
      "current iter: 10112000/24576000\n",
      "current iter: 10113000/24576000\n",
      "current iter: 10114000/24576000\n",
      "current iter: 10115000/24576000\n",
      "current iter: 10116000/24576000\n",
      "current iter: 10117000/24576000\n",
      "current iter: 10118000/24576000\n",
      "current iter: 10119000/24576000\n",
      "current iter: 10120000/24576000\n",
      "current iter: 10121000/24576000\n",
      "current iter: 10122000/24576000\n",
      "current iter: 10123000/24576000\n",
      "current iter: 10124000/24576000\n",
      "current iter: 10125000/24576000\n",
      "current iter: 10126000/24576000\n",
      "current iter: 10127000/24576000\n",
      "current iter: 10128000/24576000\n",
      "current iter: 10129000/24576000\n",
      "current iter: 10130000/24576000\n",
      "current iter: 10131000/24576000\n",
      "current iter: 10132000/24576000\n",
      "current iter: 10133000/24576000\n",
      "current iter: 10134000/24576000\n",
      "current iter: 10135000/24576000\n",
      "current iter: 10136000/24576000\n",
      "current iter: 10137000/24576000\n",
      "current iter: 10138000/24576000\n",
      "current iter: 10139000/24576000\n",
      "current iter: 10140000/24576000\n",
      "current iter: 10141000/24576000\n",
      "current iter: 10142000/24576000\n",
      "current iter: 10143000/24576000\n",
      "current iter: 10144000/24576000\n",
      "current iter: 10145000/24576000\n",
      "current iter: 10146000/24576000\n",
      "current iter: 10147000/24576000\n",
      "current iter: 10148000/24576000\n",
      "current iter: 10149000/24576000\n",
      "current iter: 10150000/24576000\n",
      "current iter: 10151000/24576000\n",
      "current iter: 10152000/24576000\n",
      "current iter: 10153000/24576000\n",
      "current iter: 10154000/24576000\n",
      "current iter: 10155000/24576000\n",
      "current iter: 10156000/24576000\n",
      "current iter: 10157000/24576000\n",
      "current iter: 10158000/24576000\n",
      "current iter: 10159000/24576000\n",
      "current iter: 10160000/24576000\n",
      "current iter: 10161000/24576000\n",
      "current iter: 10162000/24576000\n",
      "current iter: 10163000/24576000\n",
      "current iter: 10164000/24576000\n",
      "current iter: 10165000/24576000\n",
      "current iter: 10166000/24576000\n",
      "current iter: 10167000/24576000\n",
      "current iter: 10168000/24576000\n",
      "current iter: 10169000/24576000\n",
      "current iter: 10170000/24576000\n",
      "current iter: 10171000/24576000\n",
      "current iter: 10172000/24576000\n",
      "current iter: 10173000/24576000\n",
      "current iter: 10174000/24576000\n",
      "current iter: 10175000/24576000\n",
      "current iter: 10176000/24576000\n",
      "current iter: 10177000/24576000\n",
      "current iter: 10178000/24576000\n",
      "current iter: 10179000/24576000\n",
      "current iter: 10180000/24576000\n",
      "current iter: 10181000/24576000\n",
      "current iter: 10182000/24576000\n",
      "current iter: 10183000/24576000\n",
      "current iter: 10184000/24576000\n",
      "current iter: 10185000/24576000\n",
      "current iter: 10186000/24576000\n",
      "current iter: 10187000/24576000\n",
      "current iter: 10188000/24576000\n",
      "current iter: 10189000/24576000\n",
      "current iter: 10190000/24576000\n",
      "current iter: 10191000/24576000\n",
      "current iter: 10192000/24576000\n",
      "current iter: 10193000/24576000\n",
      "current iter: 10194000/24576000\n",
      "current iter: 10195000/24576000\n",
      "current iter: 10196000/24576000\n",
      "current iter: 10197000/24576000\n",
      "current iter: 10198000/24576000\n",
      "current iter: 10199000/24576000\n",
      "current iter: 10200000/24576000\n",
      "current iter: 10201000/24576000\n",
      "current iter: 10202000/24576000\n",
      "current iter: 10203000/24576000\n",
      "current iter: 10204000/24576000\n",
      "current iter: 10205000/24576000\n",
      "current iter: 10206000/24576000\n",
      "current iter: 10207000/24576000\n",
      "current iter: 10208000/24576000\n",
      "current iter: 10209000/24576000\n",
      "current iter: 10210000/24576000\n",
      "current iter: 10211000/24576000\n",
      "current iter: 10212000/24576000\n",
      "current iter: 10213000/24576000\n",
      "current iter: 10214000/24576000\n",
      "current iter: 10215000/24576000\n",
      "current iter: 10216000/24576000\n",
      "current iter: 10217000/24576000\n",
      "current iter: 10218000/24576000\n",
      "current iter: 10219000/24576000\n",
      "current iter: 10220000/24576000\n",
      "current iter: 10221000/24576000\n",
      "current iter: 10222000/24576000\n",
      "current iter: 10223000/24576000\n",
      "current iter: 10224000/24576000\n",
      "current iter: 10225000/24576000\n",
      "current iter: 10226000/24576000\n",
      "current iter: 10227000/24576000\n",
      "current iter: 10228000/24576000\n",
      "current iter: 10229000/24576000\n",
      "current iter: 10230000/24576000\n",
      "current iter: 10231000/24576000\n",
      "current iter: 10232000/24576000\n",
      "current iter: 10233000/24576000\n",
      "current iter: 10234000/24576000\n",
      "current iter: 10235000/24576000\n",
      "current iter: 10236000/24576000\n",
      "current iter: 10237000/24576000\n",
      "current iter: 10238000/24576000\n",
      "current iter: 10239000/24576000\n",
      "current iter: 10240000/24576000\n",
      "current iter: 10241000/24576000\n",
      "current iter: 10242000/24576000\n",
      "current iter: 10243000/24576000\n",
      "current iter: 10244000/24576000\n",
      "current iter: 10245000/24576000\n",
      "current iter: 10246000/24576000\n",
      "current iter: 10247000/24576000\n",
      "current iter: 10248000/24576000\n",
      "current iter: 10249000/24576000\n",
      "current iter: 10250000/24576000\n",
      "current iter: 10251000/24576000\n",
      "current iter: 10252000/24576000\n",
      "current iter: 10253000/24576000\n",
      "current iter: 10254000/24576000\n",
      "current iter: 10255000/24576000\n",
      "current iter: 10256000/24576000\n",
      "current iter: 10257000/24576000\n",
      "current iter: 10258000/24576000\n",
      "current iter: 10259000/24576000\n",
      "current iter: 10260000/24576000\n",
      "current iter: 10261000/24576000\n",
      "current iter: 10262000/24576000\n",
      "current iter: 10263000/24576000\n",
      "current iter: 10264000/24576000\n",
      "current iter: 10265000/24576000\n",
      "current iter: 10266000/24576000\n",
      "current iter: 10267000/24576000\n",
      "current iter: 10268000/24576000\n",
      "current iter: 10269000/24576000\n",
      "current iter: 10270000/24576000\n",
      "current iter: 10271000/24576000\n",
      "current iter: 10272000/24576000\n",
      "current iter: 10273000/24576000\n",
      "current iter: 10274000/24576000\n",
      "current iter: 10275000/24576000\n",
      "current iter: 10276000/24576000\n",
      "current iter: 10277000/24576000\n",
      "current iter: 10278000/24576000\n",
      "current iter: 10279000/24576000\n",
      "current iter: 10280000/24576000\n",
      "current iter: 10281000/24576000\n",
      "current iter: 10282000/24576000\n",
      "current iter: 10283000/24576000\n",
      "current iter: 10284000/24576000\n",
      "current iter: 10285000/24576000\n",
      "current iter: 10286000/24576000\n",
      "current iter: 10287000/24576000\n",
      "current iter: 10288000/24576000\n",
      "current iter: 10289000/24576000\n",
      "current iter: 10290000/24576000\n",
      "current iter: 10291000/24576000\n",
      "current iter: 10292000/24576000\n",
      "current iter: 10293000/24576000\n",
      "current iter: 10294000/24576000\n",
      "current iter: 10295000/24576000\n",
      "current iter: 10296000/24576000\n",
      "current iter: 10297000/24576000\n",
      "current iter: 10298000/24576000\n",
      "current iter: 10299000/24576000\n",
      "current iter: 10300000/24576000\n",
      "current iter: 10301000/24576000\n",
      "current iter: 10302000/24576000\n",
      "current iter: 10303000/24576000\n",
      "current iter: 10304000/24576000\n",
      "current iter: 10305000/24576000\n",
      "current iter: 10306000/24576000\n",
      "current iter: 10307000/24576000\n",
      "current iter: 10308000/24576000\n",
      "current iter: 10309000/24576000\n",
      "current iter: 10310000/24576000\n",
      "current iter: 10311000/24576000\n",
      "current iter: 10312000/24576000\n",
      "current iter: 10313000/24576000\n",
      "current iter: 10314000/24576000\n",
      "current iter: 10315000/24576000\n",
      "current iter: 10316000/24576000\n",
      "current iter: 10317000/24576000\n",
      "current iter: 10318000/24576000\n",
      "current iter: 10319000/24576000\n",
      "current iter: 10320000/24576000\n",
      "current iter: 10321000/24576000\n",
      "current iter: 10322000/24576000\n",
      "current iter: 10323000/24576000\n",
      "current iter: 10324000/24576000\n",
      "current iter: 10325000/24576000\n",
      "current iter: 10326000/24576000\n",
      "current iter: 10327000/24576000\n",
      "current iter: 10328000/24576000\n",
      "current iter: 10329000/24576000\n",
      "current iter: 10330000/24576000\n",
      "current iter: 10331000/24576000\n",
      "current iter: 10332000/24576000\n",
      "current iter: 10333000/24576000\n",
      "current iter: 10334000/24576000\n",
      "current iter: 10335000/24576000\n",
      "current iter: 10336000/24576000\n",
      "current iter: 10337000/24576000\n",
      "current iter: 10338000/24576000\n",
      "current iter: 10339000/24576000\n",
      "current iter: 10340000/24576000\n",
      "current iter: 10341000/24576000\n",
      "current iter: 10342000/24576000\n",
      "current iter: 10343000/24576000\n",
      "current iter: 10344000/24576000\n",
      "current iter: 10345000/24576000\n",
      "current iter: 10346000/24576000\n",
      "current iter: 10347000/24576000\n",
      "current iter: 10348000/24576000\n",
      "current iter: 10349000/24576000\n",
      "current iter: 10350000/24576000\n",
      "current iter: 10351000/24576000\n",
      "current iter: 10352000/24576000\n",
      "current iter: 10353000/24576000\n",
      "current iter: 10354000/24576000\n",
      "current iter: 10355000/24576000\n",
      "current iter: 10356000/24576000\n",
      "current iter: 10357000/24576000\n",
      "current iter: 10358000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 10359000/24576000\n",
      "current iter: 10360000/24576000\n",
      "current iter: 10361000/24576000\n",
      "current iter: 10362000/24576000\n",
      "current iter: 10363000/24576000\n",
      "current iter: 10364000/24576000\n",
      "current iter: 10365000/24576000\n",
      "current iter: 10366000/24576000\n",
      "current iter: 10367000/24576000\n",
      "current iter: 10368000/24576000\n",
      "current iter: 10369000/24576000\n",
      "current iter: 10370000/24576000\n",
      "current iter: 10371000/24576000\n",
      "current iter: 10372000/24576000\n",
      "current iter: 10373000/24576000\n",
      "current iter: 10374000/24576000\n",
      "current iter: 10375000/24576000\n",
      "current iter: 10376000/24576000\n",
      "current iter: 10377000/24576000\n",
      "current iter: 10378000/24576000\n",
      "current iter: 10379000/24576000\n",
      "current iter: 10380000/24576000\n",
      "current iter: 10381000/24576000\n",
      "current iter: 10382000/24576000\n",
      "current iter: 10383000/24576000\n",
      "current iter: 10384000/24576000\n",
      "current iter: 10385000/24576000\n",
      "current iter: 10386000/24576000\n",
      "current iter: 10387000/24576000\n",
      "current iter: 10388000/24576000\n",
      "current iter: 10389000/24576000\n",
      "current iter: 10390000/24576000\n",
      "current iter: 10391000/24576000\n",
      "current iter: 10392000/24576000\n",
      "current iter: 10393000/24576000\n",
      "current iter: 10394000/24576000\n",
      "current iter: 10395000/24576000\n",
      "current iter: 10396000/24576000\n",
      "current iter: 10397000/24576000\n",
      "current iter: 10398000/24576000\n",
      "current iter: 10399000/24576000\n",
      "current iter: 10400000/24576000\n",
      "current iter: 10401000/24576000\n",
      "current iter: 10402000/24576000\n",
      "current iter: 10403000/24576000\n",
      "current iter: 10404000/24576000\n",
      "current iter: 10405000/24576000\n",
      "current iter: 10406000/24576000\n",
      "current iter: 10407000/24576000\n",
      "current iter: 10408000/24576000\n",
      "current iter: 10409000/24576000\n",
      "current iter: 10410000/24576000\n",
      "current iter: 10411000/24576000\n",
      "current iter: 10412000/24576000\n",
      "current iter: 10413000/24576000\n",
      "current iter: 10414000/24576000\n",
      "current iter: 10415000/24576000\n",
      "current iter: 10416000/24576000\n",
      "current iter: 10417000/24576000\n",
      "current iter: 10418000/24576000\n",
      "current iter: 10419000/24576000\n",
      "current iter: 10420000/24576000\n",
      "current iter: 10421000/24576000\n",
      "current iter: 10422000/24576000\n",
      "current iter: 10423000/24576000\n",
      "current iter: 10424000/24576000\n",
      "current iter: 10425000/24576000\n",
      "current iter: 10426000/24576000\n",
      "current iter: 10427000/24576000\n",
      "current iter: 10428000/24576000\n",
      "current iter: 10429000/24576000\n",
      "current iter: 10430000/24576000\n",
      "current iter: 10431000/24576000\n",
      "current iter: 10432000/24576000\n",
      "current iter: 10433000/24576000\n",
      "current iter: 10434000/24576000\n",
      "current iter: 10435000/24576000\n",
      "current iter: 10436000/24576000\n",
      "current iter: 10437000/24576000\n",
      "current iter: 10438000/24576000\n",
      "current iter: 10439000/24576000\n",
      "current iter: 10440000/24576000\n",
      "current iter: 10441000/24576000\n",
      "current iter: 10442000/24576000\n",
      "current iter: 10443000/24576000\n",
      "current iter: 10444000/24576000\n",
      "current iter: 10445000/24576000\n",
      "current iter: 10446000/24576000\n",
      "current iter: 10447000/24576000\n",
      "current iter: 10448000/24576000\n",
      "current iter: 10449000/24576000\n",
      "current iter: 10450000/24576000\n",
      "current iter: 10451000/24576000\n",
      "current iter: 10452000/24576000\n",
      "current iter: 10453000/24576000\n",
      "current iter: 10454000/24576000\n",
      "current iter: 10455000/24576000\n",
      "current iter: 10456000/24576000\n",
      "current iter: 10457000/24576000\n",
      "current iter: 10458000/24576000\n",
      "current iter: 10459000/24576000\n",
      "current iter: 10460000/24576000\n",
      "current iter: 10461000/24576000\n",
      "current iter: 10462000/24576000\n",
      "current iter: 10463000/24576000\n",
      "current iter: 10464000/24576000\n",
      "current iter: 10465000/24576000\n",
      "current iter: 10466000/24576000\n",
      "current iter: 10467000/24576000\n",
      "current iter: 10468000/24576000\n",
      "current iter: 10469000/24576000\n",
      "current iter: 10470000/24576000\n",
      "current iter: 10471000/24576000\n",
      "current iter: 10472000/24576000\n",
      "current iter: 10473000/24576000\n",
      "current iter: 10474000/24576000\n",
      "current iter: 10475000/24576000\n",
      "current iter: 10476000/24576000\n",
      "current iter: 10477000/24576000\n",
      "current iter: 10478000/24576000\n",
      "current iter: 10479000/24576000\n",
      "current iter: 10480000/24576000\n",
      "current iter: 10481000/24576000\n",
      "current iter: 10482000/24576000\n",
      "current iter: 10483000/24576000\n",
      "current iter: 10484000/24576000\n",
      "current iter: 10485000/24576000\n",
      "current iter: 10486000/24576000\n",
      "current iter: 10487000/24576000\n",
      "current iter: 10488000/24576000\n",
      "current iter: 10489000/24576000\n",
      "current iter: 10490000/24576000\n",
      "current iter: 10491000/24576000\n",
      "current iter: 10492000/24576000\n",
      "current iter: 10493000/24576000\n",
      "current iter: 10494000/24576000\n",
      "current iter: 10495000/24576000\n",
      "current iter: 10496000/24576000\n",
      "current iter: 10497000/24576000\n",
      "current iter: 10498000/24576000\n",
      "current iter: 10499000/24576000\n",
      "current iter: 10500000/24576000\n",
      "current iter: 10501000/24576000\n",
      "current iter: 10502000/24576000\n",
      "current iter: 10503000/24576000\n",
      "current iter: 10504000/24576000\n",
      "current iter: 10505000/24576000\n",
      "current iter: 10506000/24576000\n",
      "current iter: 10507000/24576000\n",
      "current iter: 10508000/24576000\n",
      "current iter: 10509000/24576000\n",
      "current iter: 10510000/24576000\n",
      "current iter: 10511000/24576000\n",
      "current iter: 10512000/24576000\n",
      "current iter: 10513000/24576000\n",
      "current iter: 10514000/24576000\n",
      "current iter: 10515000/24576000\n",
      "current iter: 10516000/24576000\n",
      "current iter: 10517000/24576000\n",
      "current iter: 10518000/24576000\n",
      "current iter: 10519000/24576000\n",
      "current iter: 10520000/24576000\n",
      "current iter: 10521000/24576000\n",
      "current iter: 10522000/24576000\n",
      "current iter: 10523000/24576000\n",
      "current iter: 10524000/24576000\n",
      "current iter: 10525000/24576000\n",
      "current iter: 10526000/24576000\n",
      "current iter: 10527000/24576000\n",
      "current iter: 10528000/24576000\n",
      "current iter: 10529000/24576000\n",
      "current iter: 10530000/24576000\n",
      "current iter: 10531000/24576000\n",
      "current iter: 10532000/24576000\n",
      "current iter: 10533000/24576000\n",
      "current iter: 10534000/24576000\n",
      "current iter: 10535000/24576000\n",
      "current iter: 10536000/24576000\n",
      "current iter: 10537000/24576000\n",
      "current iter: 10538000/24576000\n",
      "current iter: 10539000/24576000\n",
      "current iter: 10540000/24576000\n",
      "current iter: 10541000/24576000\n",
      "current iter: 10542000/24576000\n",
      "current iter: 10543000/24576000\n",
      "current iter: 10544000/24576000\n",
      "current iter: 10545000/24576000\n",
      "current iter: 10546000/24576000\n",
      "current iter: 10547000/24576000\n",
      "current iter: 10548000/24576000\n",
      "current iter: 10549000/24576000\n",
      "current iter: 10550000/24576000\n",
      "current iter: 10551000/24576000\n",
      "current iter: 10552000/24576000\n",
      "current iter: 10553000/24576000\n",
      "current iter: 10554000/24576000\n",
      "current iter: 10555000/24576000\n",
      "current iter: 10556000/24576000\n",
      "current iter: 10557000/24576000\n",
      "current iter: 10558000/24576000\n",
      "current iter: 10559000/24576000\n",
      "current iter: 10560000/24576000\n",
      "current iter: 10561000/24576000\n",
      "current iter: 10562000/24576000\n",
      "current iter: 10563000/24576000\n",
      "current iter: 10564000/24576000\n",
      "current iter: 10565000/24576000\n",
      "current iter: 10566000/24576000\n",
      "current iter: 10567000/24576000\n",
      "current iter: 10568000/24576000\n",
      "current iter: 10569000/24576000\n",
      "current iter: 10570000/24576000\n",
      "current iter: 10571000/24576000\n",
      "current iter: 10572000/24576000\n",
      "current iter: 10573000/24576000\n",
      "current iter: 10574000/24576000\n",
      "current iter: 10575000/24576000\n",
      "current iter: 10576000/24576000\n",
      "current iter: 10577000/24576000\n",
      "current iter: 10578000/24576000\n",
      "current iter: 10579000/24576000\n",
      "current iter: 10580000/24576000\n",
      "current iter: 10581000/24576000\n",
      "current iter: 10582000/24576000\n",
      "current iter: 10583000/24576000\n",
      "current iter: 10584000/24576000\n",
      "current iter: 10585000/24576000\n",
      "current iter: 10586000/24576000\n",
      "current iter: 10587000/24576000\n",
      "current iter: 10588000/24576000\n",
      "current iter: 10589000/24576000\n",
      "current iter: 10590000/24576000\n",
      "current iter: 10591000/24576000\n",
      "current iter: 10592000/24576000\n",
      "current iter: 10593000/24576000\n",
      "current iter: 10594000/24576000\n",
      "current iter: 10595000/24576000\n",
      "current iter: 10596000/24576000\n",
      "current iter: 10597000/24576000\n",
      "current iter: 10598000/24576000\n",
      "current iter: 10599000/24576000\n",
      "current iter: 10600000/24576000\n",
      "current iter: 10601000/24576000\n",
      "current iter: 10602000/24576000\n",
      "current iter: 10603000/24576000\n",
      "current iter: 10604000/24576000\n",
      "current iter: 10605000/24576000\n",
      "current iter: 10606000/24576000\n",
      "current iter: 10607000/24576000\n",
      "current iter: 10608000/24576000\n",
      "current iter: 10609000/24576000\n",
      "current iter: 10610000/24576000\n",
      "current iter: 10611000/24576000\n",
      "current iter: 10612000/24576000\n",
      "current iter: 10613000/24576000\n",
      "current iter: 10614000/24576000\n",
      "current iter: 10615000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 10616000/24576000\n",
      "current iter: 10617000/24576000\n",
      "current iter: 10618000/24576000\n",
      "current iter: 10619000/24576000\n",
      "current iter: 10620000/24576000\n",
      "current iter: 10621000/24576000\n",
      "current iter: 10622000/24576000\n",
      "current iter: 10623000/24576000\n",
      "current iter: 10624000/24576000\n",
      "current iter: 10625000/24576000\n",
      "current iter: 10626000/24576000\n",
      "current iter: 10627000/24576000\n",
      "current iter: 10628000/24576000\n",
      "current iter: 10629000/24576000\n",
      "current iter: 10630000/24576000\n",
      "current iter: 10631000/24576000\n",
      "current iter: 10632000/24576000\n",
      "current iter: 10633000/24576000\n",
      "current iter: 10634000/24576000\n",
      "current iter: 10635000/24576000\n",
      "current iter: 10636000/24576000\n",
      "current iter: 10637000/24576000\n",
      "current iter: 10638000/24576000\n",
      "current iter: 10639000/24576000\n",
      "current iter: 10640000/24576000\n",
      "current iter: 10641000/24576000\n",
      "current iter: 10642000/24576000\n",
      "current iter: 10643000/24576000\n",
      "current iter: 10644000/24576000\n",
      "current iter: 10645000/24576000\n",
      "current iter: 10646000/24576000\n",
      "current iter: 10647000/24576000\n",
      "current iter: 10648000/24576000\n",
      "current iter: 10649000/24576000\n",
      "current iter: 10650000/24576000\n",
      "current iter: 10651000/24576000\n",
      "current iter: 10652000/24576000\n",
      "current iter: 10653000/24576000\n",
      "current iter: 10654000/24576000\n",
      "current iter: 10655000/24576000\n",
      "current iter: 10656000/24576000\n",
      "current iter: 10657000/24576000\n",
      "current iter: 10658000/24576000\n",
      "current iter: 10659000/24576000\n",
      "current iter: 10660000/24576000\n",
      "current iter: 10661000/24576000\n",
      "current iter: 10662000/24576000\n",
      "current iter: 10663000/24576000\n",
      "current iter: 10664000/24576000\n",
      "current iter: 10665000/24576000\n",
      "current iter: 10666000/24576000\n",
      "current iter: 10667000/24576000\n",
      "current iter: 10668000/24576000\n",
      "current iter: 10669000/24576000\n",
      "current iter: 10670000/24576000\n",
      "current iter: 10671000/24576000\n",
      "current iter: 10672000/24576000\n",
      "current iter: 10673000/24576000\n",
      "current iter: 10674000/24576000\n",
      "current iter: 10675000/24576000\n",
      "current iter: 10676000/24576000\n",
      "current iter: 10677000/24576000\n",
      "current iter: 10678000/24576000\n",
      "current iter: 10679000/24576000\n",
      "current iter: 10680000/24576000\n",
      "current iter: 10681000/24576000\n",
      "current iter: 10682000/24576000\n",
      "current iter: 10683000/24576000\n",
      "current iter: 10684000/24576000\n",
      "current iter: 10685000/24576000\n",
      "current iter: 10686000/24576000\n",
      "current iter: 10687000/24576000\n",
      "current iter: 10688000/24576000\n",
      "current iter: 10689000/24576000\n",
      "current iter: 10690000/24576000\n",
      "current iter: 10691000/24576000\n",
      "current iter: 10692000/24576000\n",
      "current iter: 10693000/24576000\n",
      "current iter: 10694000/24576000\n",
      "current iter: 10695000/24576000\n",
      "current iter: 10696000/24576000\n",
      "current iter: 10697000/24576000\n",
      "current iter: 10698000/24576000\n",
      "current iter: 10699000/24576000\n",
      "current iter: 10700000/24576000\n",
      "current iter: 10701000/24576000\n",
      "current iter: 10702000/24576000\n",
      "current iter: 10703000/24576000\n",
      "current iter: 10704000/24576000\n",
      "current iter: 10705000/24576000\n",
      "current iter: 10706000/24576000\n",
      "current iter: 10707000/24576000\n",
      "current iter: 10708000/24576000\n",
      "current iter: 10709000/24576000\n",
      "current iter: 10710000/24576000\n",
      "current iter: 10711000/24576000\n",
      "current iter: 10712000/24576000\n",
      "current iter: 10713000/24576000\n",
      "current iter: 10714000/24576000\n",
      "current iter: 10715000/24576000\n",
      "current iter: 10716000/24576000\n",
      "current iter: 10717000/24576000\n",
      "current iter: 10718000/24576000\n",
      "current iter: 10719000/24576000\n",
      "current iter: 10720000/24576000\n",
      "current iter: 10721000/24576000\n",
      "current iter: 10722000/24576000\n",
      "current iter: 10723000/24576000\n",
      "current iter: 10724000/24576000\n",
      "current iter: 10725000/24576000\n",
      "current iter: 10726000/24576000\n",
      "current iter: 10727000/24576000\n",
      "current iter: 10728000/24576000\n",
      "current iter: 10729000/24576000\n",
      "current iter: 10730000/24576000\n",
      "current iter: 10731000/24576000\n",
      "current iter: 10732000/24576000\n",
      "current iter: 10733000/24576000\n",
      "current iter: 10734000/24576000\n",
      "current iter: 10735000/24576000\n",
      "current iter: 10736000/24576000\n",
      "current iter: 10737000/24576000\n",
      "current iter: 10738000/24576000\n",
      "current iter: 10739000/24576000\n",
      "current iter: 10740000/24576000\n",
      "current iter: 10741000/24576000\n",
      "current iter: 10742000/24576000\n",
      "current iter: 10743000/24576000\n",
      "current iter: 10744000/24576000\n",
      "current iter: 10745000/24576000\n",
      "current iter: 10746000/24576000\n",
      "current iter: 10747000/24576000\n",
      "current iter: 10748000/24576000\n",
      "current iter: 10749000/24576000\n",
      "current iter: 10750000/24576000\n",
      "current iter: 10751000/24576000\n",
      "current iter: 10752000/24576000\n",
      "current iter: 10753000/24576000\n",
      "current iter: 10754000/24576000\n",
      "current iter: 10755000/24576000\n",
      "current iter: 10756000/24576000\n",
      "current iter: 10757000/24576000\n",
      "current iter: 10758000/24576000\n",
      "current iter: 10759000/24576000\n",
      "current iter: 10760000/24576000\n",
      "current iter: 10761000/24576000\n",
      "current iter: 10762000/24576000\n",
      "current iter: 10763000/24576000\n",
      "current iter: 10764000/24576000\n",
      "current iter: 10765000/24576000\n",
      "current iter: 10766000/24576000\n",
      "current iter: 10767000/24576000\n",
      "current iter: 10768000/24576000\n",
      "current iter: 10769000/24576000\n",
      "current iter: 10770000/24576000\n",
      "current iter: 10771000/24576000\n",
      "current iter: 10772000/24576000\n",
      "current iter: 10773000/24576000\n",
      "current iter: 10774000/24576000\n",
      "current iter: 10775000/24576000\n",
      "current iter: 10776000/24576000\n",
      "current iter: 10777000/24576000\n",
      "current iter: 10778000/24576000\n",
      "current iter: 10779000/24576000\n",
      "current iter: 10780000/24576000\n",
      "current iter: 10781000/24576000\n",
      "current iter: 10782000/24576000\n",
      "current iter: 10783000/24576000\n",
      "current iter: 10784000/24576000\n",
      "current iter: 10785000/24576000\n",
      "current iter: 10786000/24576000\n",
      "current iter: 10787000/24576000\n",
      "current iter: 10788000/24576000\n",
      "current iter: 10789000/24576000\n",
      "current iter: 10790000/24576000\n",
      "current iter: 10791000/24576000\n",
      "current iter: 10792000/24576000\n",
      "current iter: 10793000/24576000\n",
      "current iter: 10794000/24576000\n",
      "current iter: 10795000/24576000\n",
      "current iter: 10796000/24576000\n",
      "current iter: 10797000/24576000\n",
      "current iter: 10798000/24576000\n",
      "current iter: 10799000/24576000\n",
      "current iter: 10800000/24576000\n",
      "current iter: 10801000/24576000\n",
      "current iter: 10802000/24576000\n",
      "current iter: 10803000/24576000\n",
      "current iter: 10804000/24576000\n",
      "current iter: 10805000/24576000\n",
      "current iter: 10806000/24576000\n",
      "current iter: 10807000/24576000\n",
      "current iter: 10808000/24576000\n",
      "current iter: 10809000/24576000\n",
      "current iter: 10810000/24576000\n",
      "current iter: 10811000/24576000\n",
      "current iter: 10812000/24576000\n",
      "current iter: 10813000/24576000\n",
      "current iter: 10814000/24576000\n",
      "current iter: 10815000/24576000\n",
      "current iter: 10816000/24576000\n",
      "current iter: 10817000/24576000\n",
      "current iter: 10818000/24576000\n",
      "current iter: 10819000/24576000\n",
      "current iter: 10820000/24576000\n",
      "current iter: 10821000/24576000\n",
      "current iter: 10822000/24576000\n",
      "current iter: 10823000/24576000\n",
      "current iter: 10824000/24576000\n",
      "current iter: 10825000/24576000\n",
      "current iter: 10826000/24576000\n",
      "current iter: 10827000/24576000\n",
      "current iter: 10828000/24576000\n",
      "current iter: 10829000/24576000\n",
      "current iter: 10830000/24576000\n",
      "current iter: 10831000/24576000\n",
      "current iter: 10832000/24576000\n",
      "current iter: 10833000/24576000\n",
      "current iter: 10834000/24576000\n",
      "current iter: 10835000/24576000\n",
      "current iter: 10836000/24576000\n",
      "current iter: 10837000/24576000\n",
      "current iter: 10838000/24576000\n",
      "current iter: 10839000/24576000\n",
      "current iter: 10840000/24576000\n",
      "current iter: 10841000/24576000\n",
      "current iter: 10842000/24576000\n",
      "current iter: 10843000/24576000\n",
      "current iter: 10844000/24576000\n",
      "current iter: 10845000/24576000\n",
      "current iter: 10846000/24576000\n",
      "current iter: 10847000/24576000\n",
      "current iter: 10848000/24576000\n",
      "current iter: 10849000/24576000\n",
      "current iter: 10850000/24576000\n",
      "current iter: 10851000/24576000\n",
      "current iter: 10852000/24576000\n",
      "current iter: 10853000/24576000\n",
      "current iter: 10854000/24576000\n",
      "current iter: 10855000/24576000\n",
      "current iter: 10856000/24576000\n",
      "current iter: 10857000/24576000\n",
      "current iter: 10858000/24576000\n",
      "current iter: 10859000/24576000\n",
      "current iter: 10860000/24576000\n",
      "current iter: 10861000/24576000\n",
      "current iter: 10862000/24576000\n",
      "current iter: 10863000/24576000\n",
      "current iter: 10864000/24576000\n",
      "current iter: 10865000/24576000\n",
      "current iter: 10866000/24576000\n",
      "current iter: 10867000/24576000\n",
      "current iter: 10868000/24576000\n",
      "current iter: 10869000/24576000\n",
      "current iter: 10870000/24576000\n",
      "current iter: 10871000/24576000\n",
      "current iter: 10872000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 10873000/24576000\n",
      "current iter: 10874000/24576000\n",
      "current iter: 10875000/24576000\n",
      "current iter: 10876000/24576000\n",
      "current iter: 10877000/24576000\n",
      "current iter: 10878000/24576000\n",
      "current iter: 10879000/24576000\n",
      "current iter: 10880000/24576000\n",
      "current iter: 10881000/24576000\n",
      "current iter: 10882000/24576000\n",
      "current iter: 10883000/24576000\n",
      "current iter: 10884000/24576000\n",
      "current iter: 10885000/24576000\n",
      "current iter: 10886000/24576000\n",
      "current iter: 10887000/24576000\n",
      "current iter: 10888000/24576000\n",
      "current iter: 10889000/24576000\n",
      "current iter: 10890000/24576000\n",
      "current iter: 10891000/24576000\n",
      "current iter: 10892000/24576000\n",
      "current iter: 10893000/24576000\n",
      "current iter: 10894000/24576000\n",
      "current iter: 10895000/24576000\n",
      "current iter: 10896000/24576000\n",
      "current iter: 10897000/24576000\n",
      "current iter: 10898000/24576000\n",
      "current iter: 10899000/24576000\n",
      "current iter: 10900000/24576000\n",
      "current iter: 10901000/24576000\n",
      "current iter: 10902000/24576000\n",
      "current iter: 10903000/24576000\n",
      "current iter: 10904000/24576000\n",
      "current iter: 10905000/24576000\n",
      "current iter: 10906000/24576000\n",
      "current iter: 10907000/24576000\n",
      "current iter: 10908000/24576000\n",
      "current iter: 10909000/24576000\n",
      "current iter: 10910000/24576000\n",
      "current iter: 10911000/24576000\n",
      "current iter: 10912000/24576000\n",
      "current iter: 10913000/24576000\n",
      "current iter: 10914000/24576000\n",
      "current iter: 10915000/24576000\n",
      "current iter: 10916000/24576000\n",
      "current iter: 10917000/24576000\n",
      "current iter: 10918000/24576000\n",
      "current iter: 10919000/24576000\n",
      "current iter: 10920000/24576000\n",
      "current iter: 10921000/24576000\n",
      "current iter: 10922000/24576000\n",
      "current iter: 10923000/24576000\n",
      "current iter: 10924000/24576000\n",
      "current iter: 10925000/24576000\n",
      "current iter: 10926000/24576000\n",
      "current iter: 10927000/24576000\n",
      "current iter: 10928000/24576000\n",
      "current iter: 10929000/24576000\n",
      "current iter: 10930000/24576000\n",
      "current iter: 10931000/24576000\n",
      "current iter: 10932000/24576000\n",
      "current iter: 10933000/24576000\n",
      "current iter: 10934000/24576000\n",
      "current iter: 10935000/24576000\n",
      "current iter: 10936000/24576000\n",
      "current iter: 10937000/24576000\n",
      "current iter: 10938000/24576000\n",
      "current iter: 10939000/24576000\n",
      "current iter: 10940000/24576000\n",
      "current iter: 10941000/24576000\n",
      "current iter: 10942000/24576000\n",
      "current iter: 10943000/24576000\n",
      "current iter: 10944000/24576000\n",
      "current iter: 10945000/24576000\n",
      "current iter: 10946000/24576000\n",
      "current iter: 10947000/24576000\n",
      "current iter: 10948000/24576000\n",
      "current iter: 10949000/24576000\n",
      "current iter: 10950000/24576000\n",
      "current iter: 10951000/24576000\n",
      "current iter: 10952000/24576000\n",
      "current iter: 10953000/24576000\n",
      "current iter: 10954000/24576000\n",
      "current iter: 10955000/24576000\n",
      "current iter: 10956000/24576000\n",
      "current iter: 10957000/24576000\n",
      "current iter: 10958000/24576000\n",
      "current iter: 10959000/24576000\n",
      "current iter: 10960000/24576000\n",
      "current iter: 10961000/24576000\n",
      "current iter: 10962000/24576000\n",
      "current iter: 10963000/24576000\n",
      "current iter: 10964000/24576000\n",
      "current iter: 10965000/24576000\n",
      "current iter: 10966000/24576000\n",
      "current iter: 10967000/24576000\n",
      "current iter: 10968000/24576000\n",
      "current iter: 10969000/24576000\n",
      "current iter: 10970000/24576000\n",
      "current iter: 10971000/24576000\n",
      "current iter: 10972000/24576000\n",
      "current iter: 10973000/24576000\n",
      "current iter: 10974000/24576000\n",
      "current iter: 10975000/24576000\n",
      "current iter: 10976000/24576000\n",
      "current iter: 10977000/24576000\n",
      "current iter: 10978000/24576000\n",
      "current iter: 10979000/24576000\n",
      "current iter: 10980000/24576000\n",
      "current iter: 10981000/24576000\n",
      "current iter: 10982000/24576000\n",
      "current iter: 10983000/24576000\n",
      "current iter: 10984000/24576000\n",
      "current iter: 10985000/24576000\n",
      "current iter: 10986000/24576000\n",
      "current iter: 10987000/24576000\n",
      "current iter: 10988000/24576000\n",
      "current iter: 10989000/24576000\n",
      "current iter: 10990000/24576000\n",
      "current iter: 10991000/24576000\n",
      "current iter: 10992000/24576000\n",
      "current iter: 10993000/24576000\n",
      "current iter: 10994000/24576000\n",
      "current iter: 10995000/24576000\n",
      "current iter: 10996000/24576000\n",
      "current iter: 10997000/24576000\n",
      "current iter: 10998000/24576000\n",
      "current iter: 10999000/24576000\n",
      "current iter: 11000000/24576000\n",
      "current iter: 11001000/24576000\n",
      "current iter: 11002000/24576000\n",
      "current iter: 11003000/24576000\n",
      "current iter: 11004000/24576000\n",
      "current iter: 11005000/24576000\n",
      "current iter: 11006000/24576000\n",
      "current iter: 11007000/24576000\n",
      "current iter: 11008000/24576000\n",
      "current iter: 11009000/24576000\n",
      "current iter: 11010000/24576000\n",
      "current iter: 11011000/24576000\n",
      "current iter: 11012000/24576000\n",
      "current iter: 11013000/24576000\n",
      "current iter: 11014000/24576000\n",
      "current iter: 11015000/24576000\n",
      "current iter: 11016000/24576000\n",
      "current iter: 11017000/24576000\n",
      "current iter: 11018000/24576000\n",
      "current iter: 11019000/24576000\n",
      "current iter: 11020000/24576000\n",
      "current iter: 11021000/24576000\n",
      "current iter: 11022000/24576000\n",
      "current iter: 11023000/24576000\n",
      "current iter: 11024000/24576000\n",
      "current iter: 11025000/24576000\n",
      "current iter: 11026000/24576000\n",
      "current iter: 11027000/24576000\n",
      "current iter: 11028000/24576000\n",
      "current iter: 11029000/24576000\n",
      "current iter: 11030000/24576000\n",
      "current iter: 11031000/24576000\n",
      "current iter: 11032000/24576000\n",
      "current iter: 11033000/24576000\n",
      "current iter: 11034000/24576000\n",
      "current iter: 11035000/24576000\n",
      "current iter: 11036000/24576000\n",
      "current iter: 11037000/24576000\n",
      "current iter: 11038000/24576000\n",
      "current iter: 11039000/24576000\n",
      "current iter: 11040000/24576000\n",
      "current iter: 11041000/24576000\n",
      "current iter: 11042000/24576000\n",
      "current iter: 11043000/24576000\n",
      "current iter: 11044000/24576000\n",
      "current iter: 11045000/24576000\n",
      "current iter: 11046000/24576000\n",
      "current iter: 11047000/24576000\n",
      "current iter: 11048000/24576000\n",
      "current iter: 11049000/24576000\n",
      "current iter: 11050000/24576000\n",
      "current iter: 11051000/24576000\n",
      "current iter: 11052000/24576000\n",
      "current iter: 11053000/24576000\n",
      "current iter: 11054000/24576000\n",
      "current iter: 11055000/24576000\n",
      "current iter: 11056000/24576000\n",
      "current iter: 11057000/24576000\n",
      "current iter: 11058000/24576000\n",
      "current iter: 11059000/24576000\n",
      "current iter: 11060000/24576000\n",
      "current iter: 11061000/24576000\n",
      "current iter: 11062000/24576000\n",
      "current iter: 11063000/24576000\n",
      "current iter: 11064000/24576000\n",
      "current iter: 11065000/24576000\n",
      "current iter: 11066000/24576000\n",
      "current iter: 11067000/24576000\n",
      "current iter: 11068000/24576000\n",
      "current iter: 11069000/24576000\n",
      "current iter: 11070000/24576000\n",
      "current iter: 11071000/24576000\n",
      "current iter: 11072000/24576000\n",
      "current iter: 11073000/24576000\n",
      "current iter: 11074000/24576000\n",
      "current iter: 11075000/24576000\n",
      "current iter: 11076000/24576000\n",
      "current iter: 11077000/24576000\n",
      "current iter: 11078000/24576000\n",
      "current iter: 11079000/24576000\n",
      "current iter: 11080000/24576000\n",
      "current iter: 11081000/24576000\n",
      "current iter: 11082000/24576000\n",
      "current iter: 11083000/24576000\n",
      "current iter: 11084000/24576000\n",
      "current iter: 11085000/24576000\n",
      "current iter: 11086000/24576000\n",
      "current iter: 11087000/24576000\n",
      "current iter: 11088000/24576000\n",
      "current iter: 11089000/24576000\n",
      "current iter: 11090000/24576000\n",
      "current iter: 11091000/24576000\n",
      "current iter: 11092000/24576000\n",
      "current iter: 11093000/24576000\n",
      "current iter: 11094000/24576000\n",
      "current iter: 11095000/24576000\n",
      "current iter: 11096000/24576000\n",
      "current iter: 11097000/24576000\n",
      "current iter: 11098000/24576000\n",
      "current iter: 11099000/24576000\n",
      "current iter: 11100000/24576000\n",
      "current iter: 11101000/24576000\n",
      "current iter: 11102000/24576000\n",
      "current iter: 11103000/24576000\n",
      "current iter: 11104000/24576000\n",
      "current iter: 11105000/24576000\n",
      "current iter: 11106000/24576000\n",
      "current iter: 11107000/24576000\n",
      "current iter: 11108000/24576000\n",
      "current iter: 11109000/24576000\n",
      "current iter: 11110000/24576000\n",
      "current iter: 11111000/24576000\n",
      "current iter: 11112000/24576000\n",
      "current iter: 11113000/24576000\n",
      "current iter: 11114000/24576000\n",
      "current iter: 11115000/24576000\n",
      "current iter: 11116000/24576000\n",
      "current iter: 11117000/24576000\n",
      "current iter: 11118000/24576000\n",
      "current iter: 11119000/24576000\n",
      "current iter: 11120000/24576000\n",
      "current iter: 11121000/24576000\n",
      "current iter: 11122000/24576000\n",
      "current iter: 11123000/24576000\n",
      "current iter: 11124000/24576000\n",
      "current iter: 11125000/24576000\n",
      "current iter: 11126000/24576000\n",
      "current iter: 11127000/24576000\n",
      "current iter: 11128000/24576000\n",
      "current iter: 11129000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 11130000/24576000\n",
      "current iter: 11131000/24576000\n",
      "current iter: 11132000/24576000\n",
      "current iter: 11133000/24576000\n",
      "current iter: 11134000/24576000\n",
      "current iter: 11135000/24576000\n",
      "current iter: 11136000/24576000\n",
      "current iter: 11137000/24576000\n",
      "current iter: 11138000/24576000\n",
      "current iter: 11139000/24576000\n",
      "current iter: 11140000/24576000\n",
      "current iter: 11141000/24576000\n",
      "current iter: 11142000/24576000\n",
      "current iter: 11143000/24576000\n",
      "current iter: 11144000/24576000\n",
      "current iter: 11145000/24576000\n",
      "current iter: 11146000/24576000\n",
      "current iter: 11147000/24576000\n",
      "current iter: 11148000/24576000\n",
      "current iter: 11149000/24576000\n",
      "current iter: 11150000/24576000\n",
      "current iter: 11151000/24576000\n",
      "current iter: 11152000/24576000\n",
      "current iter: 11153000/24576000\n",
      "current iter: 11154000/24576000\n",
      "current iter: 11155000/24576000\n",
      "current iter: 11156000/24576000\n",
      "current iter: 11157000/24576000\n",
      "current iter: 11158000/24576000\n",
      "current iter: 11159000/24576000\n",
      "current iter: 11160000/24576000\n",
      "current iter: 11161000/24576000\n",
      "current iter: 11162000/24576000\n",
      "current iter: 11163000/24576000\n",
      "current iter: 11164000/24576000\n",
      "current iter: 11165000/24576000\n",
      "current iter: 11166000/24576000\n",
      "current iter: 11167000/24576000\n",
      "current iter: 11168000/24576000\n",
      "current iter: 11169000/24576000\n",
      "current iter: 11170000/24576000\n",
      "current iter: 11171000/24576000\n",
      "current iter: 11172000/24576000\n",
      "current iter: 11173000/24576000\n",
      "current iter: 11174000/24576000\n",
      "current iter: 11175000/24576000\n",
      "current iter: 11176000/24576000\n",
      "current iter: 11177000/24576000\n",
      "current iter: 11178000/24576000\n",
      "current iter: 11179000/24576000\n",
      "current iter: 11180000/24576000\n",
      "current iter: 11181000/24576000\n",
      "current iter: 11182000/24576000\n",
      "current iter: 11183000/24576000\n",
      "current iter: 11184000/24576000\n",
      "current iter: 11185000/24576000\n",
      "current iter: 11186000/24576000\n",
      "current iter: 11187000/24576000\n",
      "current iter: 11188000/24576000\n",
      "current iter: 11189000/24576000\n",
      "current iter: 11190000/24576000\n",
      "current iter: 11191000/24576000\n",
      "current iter: 11192000/24576000\n",
      "current iter: 11193000/24576000\n",
      "current iter: 11194000/24576000\n",
      "current iter: 11195000/24576000\n",
      "current iter: 11196000/24576000\n",
      "current iter: 11197000/24576000\n",
      "current iter: 11198000/24576000\n",
      "current iter: 11199000/24576000\n",
      "current iter: 11200000/24576000\n",
      "current iter: 11201000/24576000\n",
      "current iter: 11202000/24576000\n",
      "current iter: 11203000/24576000\n",
      "current iter: 11204000/24576000\n",
      "current iter: 11205000/24576000\n",
      "current iter: 11206000/24576000\n",
      "current iter: 11207000/24576000\n",
      "current iter: 11208000/24576000\n",
      "current iter: 11209000/24576000\n",
      "current iter: 11210000/24576000\n",
      "current iter: 11211000/24576000\n",
      "current iter: 11212000/24576000\n",
      "current iter: 11213000/24576000\n",
      "current iter: 11214000/24576000\n",
      "current iter: 11215000/24576000\n",
      "current iter: 11216000/24576000\n",
      "current iter: 11217000/24576000\n",
      "current iter: 11218000/24576000\n",
      "current iter: 11219000/24576000\n",
      "current iter: 11220000/24576000\n",
      "current iter: 11221000/24576000\n",
      "current iter: 11222000/24576000\n",
      "current iter: 11223000/24576000\n",
      "current iter: 11224000/24576000\n",
      "current iter: 11225000/24576000\n",
      "current iter: 11226000/24576000\n",
      "current iter: 11227000/24576000\n",
      "current iter: 11228000/24576000\n",
      "current iter: 11229000/24576000\n",
      "current iter: 11230000/24576000\n",
      "current iter: 11231000/24576000\n",
      "current iter: 11232000/24576000\n",
      "current iter: 11233000/24576000\n",
      "current iter: 11234000/24576000\n",
      "current iter: 11235000/24576000\n",
      "current iter: 11236000/24576000\n",
      "current iter: 11237000/24576000\n",
      "current iter: 11238000/24576000\n",
      "current iter: 11239000/24576000\n",
      "current iter: 11240000/24576000\n",
      "current iter: 11241000/24576000\n",
      "current iter: 11242000/24576000\n",
      "current iter: 11243000/24576000\n",
      "current iter: 11244000/24576000\n",
      "current iter: 11245000/24576000\n",
      "current iter: 11246000/24576000\n",
      "current iter: 11247000/24576000\n",
      "current iter: 11248000/24576000\n",
      "current iter: 11249000/24576000\n",
      "current iter: 11250000/24576000\n",
      "current iter: 11251000/24576000\n",
      "current iter: 11252000/24576000\n",
      "current iter: 11253000/24576000\n",
      "current iter: 11254000/24576000\n",
      "current iter: 11255000/24576000\n",
      "current iter: 11256000/24576000\n",
      "current iter: 11257000/24576000\n",
      "current iter: 11258000/24576000\n",
      "current iter: 11259000/24576000\n",
      "current iter: 11260000/24576000\n",
      "current iter: 11261000/24576000\n",
      "current iter: 11262000/24576000\n",
      "current iter: 11263000/24576000\n",
      "current iter: 11264000/24576000\n",
      "current iter: 11265000/24576000\n",
      "current iter: 11266000/24576000\n",
      "current iter: 11267000/24576000\n",
      "current iter: 11268000/24576000\n",
      "current iter: 11269000/24576000\n",
      "current iter: 11270000/24576000\n",
      "current iter: 11271000/24576000\n",
      "current iter: 11272000/24576000\n",
      "current iter: 11273000/24576000\n",
      "current iter: 11274000/24576000\n",
      "current iter: 11275000/24576000\n",
      "current iter: 11276000/24576000\n",
      "current iter: 11277000/24576000\n",
      "current iter: 11278000/24576000\n",
      "current iter: 11279000/24576000\n",
      "current iter: 11280000/24576000\n",
      "current iter: 11281000/24576000\n",
      "current iter: 11282000/24576000\n",
      "current iter: 11283000/24576000\n",
      "current iter: 11284000/24576000\n",
      "current iter: 11285000/24576000\n",
      "current iter: 11286000/24576000\n",
      "current iter: 11287000/24576000\n",
      "current iter: 11288000/24576000\n",
      "current iter: 11289000/24576000\n",
      "current iter: 11290000/24576000\n",
      "current iter: 11291000/24576000\n",
      "current iter: 11292000/24576000\n",
      "current iter: 11293000/24576000\n",
      "current iter: 11294000/24576000\n",
      "current iter: 11295000/24576000\n",
      "current iter: 11296000/24576000\n",
      "current iter: 11297000/24576000\n",
      "current iter: 11298000/24576000\n",
      "current iter: 11299000/24576000\n",
      "current iter: 11300000/24576000\n",
      "current iter: 11301000/24576000\n",
      "current iter: 11302000/24576000\n",
      "current iter: 11303000/24576000\n",
      "current iter: 11304000/24576000\n",
      "current iter: 11305000/24576000\n",
      "current iter: 11306000/24576000\n",
      "current iter: 11307000/24576000\n",
      "current iter: 11308000/24576000\n",
      "current iter: 11309000/24576000\n",
      "current iter: 11310000/24576000\n",
      "current iter: 11311000/24576000\n",
      "current iter: 11312000/24576000\n",
      "current iter: 11313000/24576000\n",
      "current iter: 11314000/24576000\n",
      "current iter: 11315000/24576000\n",
      "current iter: 11316000/24576000\n",
      "current iter: 11317000/24576000\n",
      "current iter: 11318000/24576000\n",
      "current iter: 11319000/24576000\n",
      "current iter: 11320000/24576000\n",
      "current iter: 11321000/24576000\n",
      "current iter: 11322000/24576000\n",
      "current iter: 11323000/24576000\n",
      "current iter: 11324000/24576000\n",
      "current iter: 11325000/24576000\n",
      "current iter: 11326000/24576000\n",
      "current iter: 11327000/24576000\n",
      "current iter: 11328000/24576000\n",
      "current iter: 11329000/24576000\n",
      "current iter: 11330000/24576000\n",
      "current iter: 11331000/24576000\n",
      "current iter: 11332000/24576000\n",
      "current iter: 11333000/24576000\n",
      "current iter: 11334000/24576000\n",
      "current iter: 11335000/24576000\n",
      "current iter: 11336000/24576000\n",
      "current iter: 11337000/24576000\n",
      "current iter: 11338000/24576000\n",
      "current iter: 11339000/24576000\n",
      "current iter: 11340000/24576000\n",
      "current iter: 11341000/24576000\n",
      "current iter: 11342000/24576000\n",
      "current iter: 11343000/24576000\n",
      "current iter: 11344000/24576000\n",
      "current iter: 11345000/24576000\n",
      "current iter: 11346000/24576000\n",
      "current iter: 11347000/24576000\n",
      "current iter: 11348000/24576000\n",
      "current iter: 11349000/24576000\n",
      "current iter: 11350000/24576000\n",
      "current iter: 11351000/24576000\n",
      "current iter: 11352000/24576000\n",
      "current iter: 11353000/24576000\n",
      "current iter: 11354000/24576000\n",
      "current iter: 11355000/24576000\n",
      "current iter: 11356000/24576000\n",
      "current iter: 11357000/24576000\n",
      "current iter: 11358000/24576000\n",
      "current iter: 11359000/24576000\n",
      "current iter: 11360000/24576000\n",
      "current iter: 11361000/24576000\n",
      "current iter: 11362000/24576000\n",
      "current iter: 11363000/24576000\n",
      "current iter: 11364000/24576000\n",
      "current iter: 11365000/24576000\n",
      "current iter: 11366000/24576000\n",
      "current iter: 11367000/24576000\n",
      "current iter: 11368000/24576000\n",
      "current iter: 11369000/24576000\n",
      "current iter: 11370000/24576000\n",
      "current iter: 11371000/24576000\n",
      "current iter: 11372000/24576000\n",
      "current iter: 11373000/24576000\n",
      "current iter: 11374000/24576000\n",
      "current iter: 11375000/24576000\n",
      "current iter: 11376000/24576000\n",
      "current iter: 11377000/24576000\n",
      "current iter: 11378000/24576000\n",
      "current iter: 11379000/24576000\n",
      "current iter: 11380000/24576000\n",
      "current iter: 11381000/24576000\n",
      "current iter: 11382000/24576000\n",
      "current iter: 11383000/24576000\n",
      "current iter: 11384000/24576000\n",
      "current iter: 11385000/24576000\n",
      "current iter: 11386000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 11387000/24576000\n",
      "current iter: 11388000/24576000\n",
      "current iter: 11389000/24576000\n",
      "current iter: 11390000/24576000\n",
      "current iter: 11391000/24576000\n",
      "current iter: 11392000/24576000\n",
      "current iter: 11393000/24576000\n",
      "current iter: 11394000/24576000\n",
      "current iter: 11395000/24576000\n",
      "current iter: 11396000/24576000\n",
      "current iter: 11397000/24576000\n",
      "current iter: 11398000/24576000\n",
      "current iter: 11399000/24576000\n",
      "current iter: 11400000/24576000\n",
      "current iter: 11401000/24576000\n",
      "current iter: 11402000/24576000\n",
      "current iter: 11403000/24576000\n",
      "current iter: 11404000/24576000\n",
      "current iter: 11405000/24576000\n",
      "current iter: 11406000/24576000\n",
      "current iter: 11407000/24576000\n",
      "current iter: 11408000/24576000\n",
      "current iter: 11409000/24576000\n",
      "current iter: 11410000/24576000\n",
      "current iter: 11411000/24576000\n",
      "current iter: 11412000/24576000\n",
      "current iter: 11413000/24576000\n",
      "current iter: 11414000/24576000\n",
      "current iter: 11415000/24576000\n",
      "current iter: 11416000/24576000\n",
      "current iter: 11417000/24576000\n",
      "current iter: 11418000/24576000\n",
      "current iter: 11419000/24576000\n",
      "current iter: 11420000/24576000\n",
      "current iter: 11421000/24576000\n",
      "current iter: 11422000/24576000\n",
      "current iter: 11423000/24576000\n",
      "current iter: 11424000/24576000\n",
      "current iter: 11425000/24576000\n",
      "current iter: 11426000/24576000\n",
      "current iter: 11427000/24576000\n",
      "current iter: 11428000/24576000\n",
      "current iter: 11429000/24576000\n",
      "current iter: 11430000/24576000\n",
      "current iter: 11431000/24576000\n",
      "current iter: 11432000/24576000\n",
      "current iter: 11433000/24576000\n",
      "current iter: 11434000/24576000\n",
      "current iter: 11435000/24576000\n",
      "current iter: 11436000/24576000\n",
      "current iter: 11437000/24576000\n",
      "current iter: 11438000/24576000\n",
      "current iter: 11439000/24576000\n",
      "current iter: 11440000/24576000\n",
      "current iter: 11441000/24576000\n",
      "current iter: 11442000/24576000\n",
      "current iter: 11443000/24576000\n",
      "current iter: 11444000/24576000\n",
      "current iter: 11445000/24576000\n",
      "current iter: 11446000/24576000\n",
      "current iter: 11447000/24576000\n",
      "current iter: 11448000/24576000\n",
      "current iter: 11449000/24576000\n",
      "current iter: 11450000/24576000\n",
      "current iter: 11451000/24576000\n",
      "current iter: 11452000/24576000\n",
      "current iter: 11453000/24576000\n",
      "current iter: 11454000/24576000\n",
      "current iter: 11455000/24576000\n",
      "current iter: 11456000/24576000\n",
      "current iter: 11457000/24576000\n",
      "current iter: 11458000/24576000\n",
      "current iter: 11459000/24576000\n",
      "current iter: 11460000/24576000\n",
      "current iter: 11461000/24576000\n",
      "current iter: 11462000/24576000\n",
      "current iter: 11463000/24576000\n",
      "current iter: 11464000/24576000\n",
      "current iter: 11465000/24576000\n",
      "current iter: 11466000/24576000\n",
      "current iter: 11467000/24576000\n",
      "current iter: 11468000/24576000\n",
      "current iter: 11469000/24576000\n",
      "current iter: 11470000/24576000\n",
      "current iter: 11471000/24576000\n",
      "current iter: 11472000/24576000\n",
      "current iter: 11473000/24576000\n",
      "current iter: 11474000/24576000\n",
      "current iter: 11475000/24576000\n",
      "current iter: 11476000/24576000\n",
      "current iter: 11477000/24576000\n",
      "current iter: 11478000/24576000\n",
      "current iter: 11479000/24576000\n",
      "current iter: 11480000/24576000\n",
      "current iter: 11481000/24576000\n",
      "current iter: 11482000/24576000\n",
      "current iter: 11483000/24576000\n",
      "current iter: 11484000/24576000\n",
      "current iter: 11485000/24576000\n",
      "current iter: 11486000/24576000\n",
      "current iter: 11487000/24576000\n",
      "current iter: 11488000/24576000\n",
      "current iter: 11489000/24576000\n",
      "current iter: 11490000/24576000\n",
      "current iter: 11491000/24576000\n",
      "current iter: 11492000/24576000\n",
      "current iter: 11493000/24576000\n",
      "current iter: 11494000/24576000\n",
      "current iter: 11495000/24576000\n",
      "current iter: 11496000/24576000\n",
      "current iter: 11497000/24576000\n",
      "current iter: 11498000/24576000\n",
      "current iter: 11499000/24576000\n",
      "current iter: 11500000/24576000\n",
      "current iter: 11501000/24576000\n",
      "current iter: 11502000/24576000\n",
      "current iter: 11503000/24576000\n",
      "current iter: 11504000/24576000\n",
      "current iter: 11505000/24576000\n",
      "current iter: 11506000/24576000\n",
      "current iter: 11507000/24576000\n",
      "current iter: 11508000/24576000\n",
      "current iter: 11509000/24576000\n",
      "current iter: 11510000/24576000\n",
      "current iter: 11511000/24576000\n",
      "current iter: 11512000/24576000\n",
      "current iter: 11513000/24576000\n",
      "current iter: 11514000/24576000\n",
      "current iter: 11515000/24576000\n",
      "current iter: 11516000/24576000\n",
      "current iter: 11517000/24576000\n",
      "current iter: 11518000/24576000\n",
      "current iter: 11519000/24576000\n",
      "current iter: 11520000/24576000\n",
      "current iter: 11521000/24576000\n",
      "current iter: 11522000/24576000\n",
      "current iter: 11523000/24576000\n",
      "current iter: 11524000/24576000\n",
      "current iter: 11525000/24576000\n",
      "current iter: 11526000/24576000\n",
      "current iter: 11527000/24576000\n",
      "current iter: 11528000/24576000\n",
      "current iter: 11529000/24576000\n",
      "current iter: 11530000/24576000\n",
      "current iter: 11531000/24576000\n",
      "current iter: 11532000/24576000\n",
      "current iter: 11533000/24576000\n",
      "current iter: 11534000/24576000\n",
      "current iter: 11535000/24576000\n",
      "current iter: 11536000/24576000\n",
      "current iter: 11537000/24576000\n",
      "current iter: 11538000/24576000\n",
      "current iter: 11539000/24576000\n",
      "current iter: 11540000/24576000\n",
      "current iter: 11541000/24576000\n",
      "current iter: 11542000/24576000\n",
      "current iter: 11543000/24576000\n",
      "current iter: 11544000/24576000\n",
      "current iter: 11545000/24576000\n",
      "current iter: 11546000/24576000\n",
      "current iter: 11547000/24576000\n",
      "current iter: 11548000/24576000\n",
      "current iter: 11549000/24576000\n",
      "current iter: 11550000/24576000\n",
      "current iter: 11551000/24576000\n",
      "current iter: 11552000/24576000\n",
      "current iter: 11553000/24576000\n",
      "current iter: 11554000/24576000\n",
      "current iter: 11555000/24576000\n",
      "current iter: 11556000/24576000\n",
      "current iter: 11557000/24576000\n",
      "current iter: 11558000/24576000\n",
      "current iter: 11559000/24576000\n",
      "current iter: 11560000/24576000\n",
      "current iter: 11561000/24576000\n",
      "current iter: 11562000/24576000\n",
      "current iter: 11563000/24576000\n",
      "current iter: 11564000/24576000\n",
      "current iter: 11565000/24576000\n",
      "current iter: 11566000/24576000\n",
      "current iter: 11567000/24576000\n",
      "current iter: 11568000/24576000\n",
      "current iter: 11569000/24576000\n",
      "current iter: 11570000/24576000\n",
      "current iter: 11571000/24576000\n",
      "current iter: 11572000/24576000\n",
      "current iter: 11573000/24576000\n",
      "current iter: 11574000/24576000\n",
      "current iter: 11575000/24576000\n",
      "current iter: 11576000/24576000\n",
      "current iter: 11577000/24576000\n",
      "current iter: 11578000/24576000\n",
      "current iter: 11579000/24576000\n",
      "current iter: 11580000/24576000\n",
      "current iter: 11581000/24576000\n",
      "current iter: 11582000/24576000\n",
      "current iter: 11583000/24576000\n",
      "current iter: 11584000/24576000\n",
      "current iter: 11585000/24576000\n",
      "current iter: 11586000/24576000\n",
      "current iter: 11587000/24576000\n",
      "current iter: 11588000/24576000\n",
      "current iter: 11589000/24576000\n",
      "current iter: 11590000/24576000\n",
      "current iter: 11591000/24576000\n",
      "current iter: 11592000/24576000\n",
      "current iter: 11593000/24576000\n",
      "current iter: 11594000/24576000\n",
      "current iter: 11595000/24576000\n",
      "current iter: 11596000/24576000\n",
      "current iter: 11597000/24576000\n",
      "current iter: 11598000/24576000\n",
      "current iter: 11599000/24576000\n",
      "current iter: 11600000/24576000\n",
      "current iter: 11601000/24576000\n",
      "current iter: 11602000/24576000\n",
      "current iter: 11603000/24576000\n",
      "current iter: 11604000/24576000\n",
      "current iter: 11605000/24576000\n",
      "current iter: 11606000/24576000\n",
      "current iter: 11607000/24576000\n",
      "current iter: 11608000/24576000\n",
      "current iter: 11609000/24576000\n",
      "current iter: 11610000/24576000\n",
      "current iter: 11611000/24576000\n",
      "current iter: 11612000/24576000\n",
      "current iter: 11613000/24576000\n",
      "current iter: 11614000/24576000\n",
      "current iter: 11615000/24576000\n",
      "current iter: 11616000/24576000\n",
      "current iter: 11617000/24576000\n",
      "current iter: 11618000/24576000\n",
      "current iter: 11619000/24576000\n",
      "current iter: 11620000/24576000\n",
      "current iter: 11621000/24576000\n",
      "current iter: 11622000/24576000\n",
      "current iter: 11623000/24576000\n",
      "current iter: 11624000/24576000\n",
      "current iter: 11625000/24576000\n",
      "current iter: 11626000/24576000\n",
      "current iter: 11627000/24576000\n",
      "current iter: 11628000/24576000\n",
      "current iter: 11629000/24576000\n",
      "current iter: 11630000/24576000\n",
      "current iter: 11631000/24576000\n",
      "current iter: 11632000/24576000\n",
      "current iter: 11633000/24576000\n",
      "current iter: 11634000/24576000\n",
      "current iter: 11635000/24576000\n",
      "current iter: 11636000/24576000\n",
      "current iter: 11637000/24576000\n",
      "current iter: 11638000/24576000\n",
      "current iter: 11639000/24576000\n",
      "current iter: 11640000/24576000\n",
      "current iter: 11641000/24576000\n",
      "current iter: 11642000/24576000\n",
      "current iter: 11643000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 11644000/24576000\n",
      "current iter: 11645000/24576000\n",
      "current iter: 11646000/24576000\n",
      "current iter: 11647000/24576000\n",
      "current iter: 11648000/24576000\n",
      "current iter: 11649000/24576000\n",
      "current iter: 11650000/24576000\n",
      "current iter: 11651000/24576000\n",
      "current iter: 11652000/24576000\n",
      "current iter: 11653000/24576000\n",
      "current iter: 11654000/24576000\n",
      "current iter: 11655000/24576000\n",
      "current iter: 11656000/24576000\n",
      "current iter: 11657000/24576000\n",
      "current iter: 11658000/24576000\n",
      "current iter: 11659000/24576000\n",
      "current iter: 11660000/24576000\n",
      "current iter: 11661000/24576000\n",
      "current iter: 11662000/24576000\n",
      "current iter: 11663000/24576000\n",
      "current iter: 11664000/24576000\n",
      "current iter: 11665000/24576000\n",
      "current iter: 11666000/24576000\n",
      "current iter: 11667000/24576000\n",
      "current iter: 11668000/24576000\n",
      "current iter: 11669000/24576000\n",
      "current iter: 11670000/24576000\n",
      "current iter: 11671000/24576000\n",
      "current iter: 11672000/24576000\n",
      "current iter: 11673000/24576000\n",
      "current iter: 11674000/24576000\n",
      "current iter: 11675000/24576000\n",
      "current iter: 11676000/24576000\n",
      "current iter: 11677000/24576000\n",
      "current iter: 11678000/24576000\n",
      "current iter: 11679000/24576000\n",
      "current iter: 11680000/24576000\n",
      "current iter: 11681000/24576000\n",
      "current iter: 11682000/24576000\n",
      "current iter: 11683000/24576000\n",
      "current iter: 11684000/24576000\n",
      "current iter: 11685000/24576000\n",
      "current iter: 11686000/24576000\n",
      "current iter: 11687000/24576000\n",
      "current iter: 11688000/24576000\n",
      "current iter: 11689000/24576000\n",
      "current iter: 11690000/24576000\n",
      "current iter: 11691000/24576000\n",
      "current iter: 11692000/24576000\n",
      "current iter: 11693000/24576000\n",
      "current iter: 11694000/24576000\n",
      "current iter: 11695000/24576000\n",
      "current iter: 11696000/24576000\n",
      "current iter: 11697000/24576000\n",
      "current iter: 11698000/24576000\n",
      "current iter: 11699000/24576000\n",
      "current iter: 11700000/24576000\n",
      "current iter: 11701000/24576000\n",
      "current iter: 11702000/24576000\n",
      "current iter: 11703000/24576000\n",
      "current iter: 11704000/24576000\n",
      "current iter: 11705000/24576000\n",
      "current iter: 11706000/24576000\n",
      "current iter: 11707000/24576000\n",
      "current iter: 11708000/24576000\n",
      "current iter: 11709000/24576000\n",
      "current iter: 11710000/24576000\n",
      "current iter: 11711000/24576000\n",
      "current iter: 11712000/24576000\n",
      "current iter: 11713000/24576000\n",
      "current iter: 11714000/24576000\n",
      "current iter: 11715000/24576000\n",
      "current iter: 11716000/24576000\n",
      "current iter: 11717000/24576000\n",
      "current iter: 11718000/24576000\n",
      "current iter: 11719000/24576000\n",
      "current iter: 11720000/24576000\n",
      "current iter: 11721000/24576000\n",
      "current iter: 11722000/24576000\n",
      "current iter: 11723000/24576000\n",
      "current iter: 11724000/24576000\n",
      "current iter: 11725000/24576000\n",
      "current iter: 11726000/24576000\n",
      "current iter: 11727000/24576000\n",
      "current iter: 11728000/24576000\n",
      "current iter: 11729000/24576000\n",
      "current iter: 11730000/24576000\n",
      "current iter: 11731000/24576000\n",
      "current iter: 11732000/24576000\n",
      "current iter: 11733000/24576000\n",
      "current iter: 11734000/24576000\n",
      "current iter: 11735000/24576000\n",
      "current iter: 11736000/24576000\n",
      "current iter: 11737000/24576000\n",
      "current iter: 11738000/24576000\n",
      "current iter: 11739000/24576000\n",
      "current iter: 11740000/24576000\n",
      "current iter: 11741000/24576000\n",
      "current iter: 11742000/24576000\n",
      "current iter: 11743000/24576000\n",
      "current iter: 11744000/24576000\n",
      "current iter: 11745000/24576000\n",
      "current iter: 11746000/24576000\n",
      "current iter: 11747000/24576000\n",
      "current iter: 11748000/24576000\n",
      "current iter: 11749000/24576000\n",
      "current iter: 11750000/24576000\n",
      "current iter: 11751000/24576000\n",
      "current iter: 11752000/24576000\n",
      "current iter: 11753000/24576000\n",
      "current iter: 11754000/24576000\n",
      "current iter: 11755000/24576000\n",
      "current iter: 11756000/24576000\n",
      "current iter: 11757000/24576000\n",
      "current iter: 11758000/24576000\n",
      "current iter: 11759000/24576000\n",
      "current iter: 11760000/24576000\n",
      "current iter: 11761000/24576000\n",
      "current iter: 11762000/24576000\n",
      "current iter: 11763000/24576000\n",
      "current iter: 11764000/24576000\n",
      "current iter: 11765000/24576000\n",
      "current iter: 11766000/24576000\n",
      "current iter: 11767000/24576000\n",
      "current iter: 11768000/24576000\n",
      "current iter: 11769000/24576000\n",
      "current iter: 11770000/24576000\n",
      "current iter: 11771000/24576000\n",
      "current iter: 11772000/24576000\n",
      "current iter: 11773000/24576000\n",
      "current iter: 11774000/24576000\n",
      "current iter: 11775000/24576000\n",
      "current iter: 11776000/24576000\n",
      "current iter: 11777000/24576000\n",
      "current iter: 11778000/24576000\n",
      "current iter: 11779000/24576000\n",
      "current iter: 11780000/24576000\n",
      "current iter: 11781000/24576000\n",
      "current iter: 11782000/24576000\n",
      "current iter: 11783000/24576000\n",
      "current iter: 11784000/24576000\n",
      "current iter: 11785000/24576000\n",
      "current iter: 11786000/24576000\n",
      "current iter: 11787000/24576000\n",
      "current iter: 11788000/24576000\n",
      "current iter: 11789000/24576000\n",
      "current iter: 11790000/24576000\n",
      "current iter: 11791000/24576000\n",
      "current iter: 11792000/24576000\n",
      "current iter: 11793000/24576000\n",
      "current iter: 11794000/24576000\n",
      "current iter: 11795000/24576000\n",
      "current iter: 11796000/24576000\n",
      "current iter: 11797000/24576000\n",
      "current iter: 11798000/24576000\n",
      "current iter: 11799000/24576000\n",
      "current iter: 11800000/24576000\n",
      "current iter: 11801000/24576000\n",
      "current iter: 11802000/24576000\n",
      "current iter: 11803000/24576000\n",
      "current iter: 11804000/24576000\n",
      "current iter: 11805000/24576000\n",
      "current iter: 11806000/24576000\n",
      "current iter: 11807000/24576000\n",
      "current iter: 11808000/24576000\n",
      "current iter: 11809000/24576000\n",
      "current iter: 11810000/24576000\n",
      "current iter: 11811000/24576000\n",
      "current iter: 11812000/24576000\n",
      "current iter: 11813000/24576000\n",
      "current iter: 11814000/24576000\n",
      "current iter: 11815000/24576000\n",
      "current iter: 11816000/24576000\n",
      "current iter: 11817000/24576000\n",
      "current iter: 11818000/24576000\n",
      "current iter: 11819000/24576000\n",
      "current iter: 11820000/24576000\n",
      "current iter: 11821000/24576000\n",
      "current iter: 11822000/24576000\n",
      "current iter: 11823000/24576000\n",
      "current iter: 11824000/24576000\n",
      "current iter: 11825000/24576000\n",
      "current iter: 11826000/24576000\n",
      "current iter: 11827000/24576000\n",
      "current iter: 11828000/24576000\n",
      "current iter: 11829000/24576000\n",
      "current iter: 11830000/24576000\n",
      "current iter: 11831000/24576000\n",
      "current iter: 11832000/24576000\n",
      "current iter: 11833000/24576000\n",
      "current iter: 11834000/24576000\n",
      "current iter: 11835000/24576000\n",
      "current iter: 11836000/24576000\n",
      "current iter: 11837000/24576000\n",
      "current iter: 11838000/24576000\n",
      "current iter: 11839000/24576000\n",
      "current iter: 11840000/24576000\n",
      "current iter: 11841000/24576000\n",
      "current iter: 11842000/24576000\n",
      "current iter: 11843000/24576000\n",
      "current iter: 11844000/24576000\n",
      "current iter: 11845000/24576000\n",
      "current iter: 11846000/24576000\n",
      "current iter: 11847000/24576000\n",
      "current iter: 11848000/24576000\n",
      "current iter: 11849000/24576000\n",
      "current iter: 11850000/24576000\n",
      "current iter: 11851000/24576000\n",
      "current iter: 11852000/24576000\n",
      "current iter: 11853000/24576000\n",
      "current iter: 11854000/24576000\n",
      "current iter: 11855000/24576000\n",
      "current iter: 11856000/24576000\n",
      "current iter: 11857000/24576000\n",
      "current iter: 11858000/24576000\n",
      "current iter: 11859000/24576000\n",
      "current iter: 11860000/24576000\n",
      "current iter: 11861000/24576000\n",
      "current iter: 11862000/24576000\n",
      "current iter: 11863000/24576000\n",
      "current iter: 11864000/24576000\n",
      "current iter: 11865000/24576000\n",
      "current iter: 11866000/24576000\n",
      "current iter: 11867000/24576000\n",
      "current iter: 11868000/24576000\n",
      "current iter: 11869000/24576000\n",
      "current iter: 11870000/24576000\n",
      "current iter: 11871000/24576000\n",
      "current iter: 11872000/24576000\n",
      "current iter: 11873000/24576000\n",
      "current iter: 11874000/24576000\n",
      "current iter: 11875000/24576000\n",
      "current iter: 11876000/24576000\n",
      "current iter: 11877000/24576000\n",
      "current iter: 11878000/24576000\n",
      "current iter: 11879000/24576000\n",
      "current iter: 11880000/24576000\n",
      "current iter: 11881000/24576000\n",
      "current iter: 11882000/24576000\n",
      "current iter: 11883000/24576000\n",
      "current iter: 11884000/24576000\n",
      "current iter: 11885000/24576000\n",
      "current iter: 11886000/24576000\n",
      "current iter: 11887000/24576000\n",
      "current iter: 11888000/24576000\n",
      "current iter: 11889000/24576000\n",
      "current iter: 11890000/24576000\n",
      "current iter: 11891000/24576000\n",
      "current iter: 11892000/24576000\n",
      "current iter: 11893000/24576000\n",
      "current iter: 11894000/24576000\n",
      "current iter: 11895000/24576000\n",
      "current iter: 11896000/24576000\n",
      "current iter: 11897000/24576000\n",
      "current iter: 11898000/24576000\n",
      "current iter: 11899000/24576000\n",
      "current iter: 11900000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 11901000/24576000\n",
      "current iter: 11902000/24576000\n",
      "current iter: 11903000/24576000\n",
      "current iter: 11904000/24576000\n",
      "current iter: 11905000/24576000\n",
      "current iter: 11906000/24576000\n",
      "current iter: 11907000/24576000\n",
      "current iter: 11908000/24576000\n",
      "current iter: 11909000/24576000\n",
      "current iter: 11910000/24576000\n",
      "current iter: 11911000/24576000\n",
      "current iter: 11912000/24576000\n",
      "current iter: 11913000/24576000\n",
      "current iter: 11914000/24576000\n",
      "current iter: 11915000/24576000\n",
      "current iter: 11916000/24576000\n",
      "current iter: 11917000/24576000\n",
      "current iter: 11918000/24576000\n",
      "current iter: 11919000/24576000\n",
      "current iter: 11920000/24576000\n",
      "current iter: 11921000/24576000\n",
      "current iter: 11922000/24576000\n",
      "current iter: 11923000/24576000\n",
      "current iter: 11924000/24576000\n",
      "current iter: 11925000/24576000\n",
      "current iter: 11926000/24576000\n",
      "current iter: 11927000/24576000\n",
      "current iter: 11928000/24576000\n",
      "current iter: 11929000/24576000\n",
      "current iter: 11930000/24576000\n",
      "current iter: 11931000/24576000\n",
      "current iter: 11932000/24576000\n",
      "current iter: 11933000/24576000\n",
      "current iter: 11934000/24576000\n",
      "current iter: 11935000/24576000\n",
      "current iter: 11936000/24576000\n",
      "current iter: 11937000/24576000\n",
      "current iter: 11938000/24576000\n",
      "current iter: 11939000/24576000\n",
      "current iter: 11940000/24576000\n",
      "current iter: 11941000/24576000\n",
      "current iter: 11942000/24576000\n",
      "current iter: 11943000/24576000\n",
      "current iter: 11944000/24576000\n",
      "current iter: 11945000/24576000\n",
      "current iter: 11946000/24576000\n",
      "current iter: 11947000/24576000\n",
      "current iter: 11948000/24576000\n",
      "current iter: 11949000/24576000\n",
      "current iter: 11950000/24576000\n",
      "current iter: 11951000/24576000\n",
      "current iter: 11952000/24576000\n",
      "current iter: 11953000/24576000\n",
      "current iter: 11954000/24576000\n",
      "current iter: 11955000/24576000\n",
      "current iter: 11956000/24576000\n",
      "current iter: 11957000/24576000\n",
      "current iter: 11958000/24576000\n",
      "current iter: 11959000/24576000\n",
      "current iter: 11960000/24576000\n",
      "current iter: 11961000/24576000\n",
      "current iter: 11962000/24576000\n",
      "current iter: 11963000/24576000\n",
      "current iter: 11964000/24576000\n",
      "current iter: 11965000/24576000\n",
      "current iter: 11966000/24576000\n",
      "current iter: 11967000/24576000\n",
      "current iter: 11968000/24576000\n",
      "current iter: 11969000/24576000\n",
      "current iter: 11970000/24576000\n",
      "current iter: 11971000/24576000\n",
      "current iter: 11972000/24576000\n",
      "current iter: 11973000/24576000\n",
      "current iter: 11974000/24576000\n",
      "current iter: 11975000/24576000\n",
      "current iter: 11976000/24576000\n",
      "current iter: 11977000/24576000\n",
      "current iter: 11978000/24576000\n",
      "current iter: 11979000/24576000\n",
      "current iter: 11980000/24576000\n",
      "current iter: 11981000/24576000\n",
      "current iter: 11982000/24576000\n",
      "current iter: 11983000/24576000\n",
      "current iter: 11984000/24576000\n",
      "current iter: 11985000/24576000\n",
      "current iter: 11986000/24576000\n",
      "current iter: 11987000/24576000\n",
      "current iter: 11988000/24576000\n",
      "current iter: 11989000/24576000\n",
      "current iter: 11990000/24576000\n",
      "current iter: 11991000/24576000\n",
      "current iter: 11992000/24576000\n",
      "current iter: 11993000/24576000\n",
      "current iter: 11994000/24576000\n",
      "current iter: 11995000/24576000\n",
      "current iter: 11996000/24576000\n",
      "current iter: 11997000/24576000\n",
      "current iter: 11998000/24576000\n",
      "current iter: 11999000/24576000\n",
      "current iter: 12000000/24576000\n",
      "current iter: 12001000/24576000\n",
      "current iter: 12002000/24576000\n",
      "current iter: 12003000/24576000\n",
      "current iter: 12004000/24576000\n",
      "current iter: 12005000/24576000\n",
      "current iter: 12006000/24576000\n",
      "current iter: 12007000/24576000\n",
      "current iter: 12008000/24576000\n",
      "current iter: 12009000/24576000\n",
      "current iter: 12010000/24576000\n",
      "current iter: 12011000/24576000\n",
      "current iter: 12012000/24576000\n",
      "current iter: 12013000/24576000\n",
      "current iter: 12014000/24576000\n",
      "current iter: 12015000/24576000\n",
      "current iter: 12016000/24576000\n",
      "current iter: 12017000/24576000\n",
      "current iter: 12018000/24576000\n",
      "current iter: 12019000/24576000\n",
      "current iter: 12020000/24576000\n",
      "current iter: 12021000/24576000\n",
      "current iter: 12022000/24576000\n",
      "current iter: 12023000/24576000\n",
      "current iter: 12024000/24576000\n",
      "current iter: 12025000/24576000\n",
      "current iter: 12026000/24576000\n",
      "current iter: 12027000/24576000\n",
      "current iter: 12028000/24576000\n",
      "current iter: 12029000/24576000\n",
      "current iter: 12030000/24576000\n",
      "current iter: 12031000/24576000\n",
      "current iter: 12032000/24576000\n",
      "current iter: 12033000/24576000\n",
      "current iter: 12034000/24576000\n",
      "current iter: 12035000/24576000\n",
      "current iter: 12036000/24576000\n",
      "current iter: 12037000/24576000\n",
      "current iter: 12038000/24576000\n",
      "current iter: 12039000/24576000\n",
      "current iter: 12040000/24576000\n",
      "current iter: 12041000/24576000\n",
      "current iter: 12042000/24576000\n",
      "current iter: 12043000/24576000\n",
      "current iter: 12044000/24576000\n",
      "current iter: 12045000/24576000\n",
      "current iter: 12046000/24576000\n",
      "current iter: 12047000/24576000\n",
      "current iter: 12048000/24576000\n",
      "current iter: 12049000/24576000\n",
      "current iter: 12050000/24576000\n",
      "current iter: 12051000/24576000\n",
      "current iter: 12052000/24576000\n",
      "current iter: 12053000/24576000\n",
      "current iter: 12054000/24576000\n",
      "current iter: 12055000/24576000\n",
      "current iter: 12056000/24576000\n",
      "current iter: 12057000/24576000\n",
      "current iter: 12058000/24576000\n",
      "current iter: 12059000/24576000\n",
      "current iter: 12060000/24576000\n",
      "current iter: 12061000/24576000\n",
      "current iter: 12062000/24576000\n",
      "current iter: 12063000/24576000\n",
      "current iter: 12064000/24576000\n",
      "current iter: 12065000/24576000\n",
      "current iter: 12066000/24576000\n",
      "current iter: 12067000/24576000\n",
      "current iter: 12068000/24576000\n",
      "current iter: 12069000/24576000\n",
      "current iter: 12070000/24576000\n",
      "current iter: 12071000/24576000\n",
      "current iter: 12072000/24576000\n",
      "current iter: 12073000/24576000\n",
      "current iter: 12074000/24576000\n",
      "current iter: 12075000/24576000\n",
      "current iter: 12076000/24576000\n",
      "current iter: 12077000/24576000\n",
      "current iter: 12078000/24576000\n",
      "current iter: 12079000/24576000\n",
      "current iter: 12080000/24576000\n",
      "current iter: 12081000/24576000\n",
      "current iter: 12082000/24576000\n",
      "current iter: 12083000/24576000\n",
      "current iter: 12084000/24576000\n",
      "current iter: 12085000/24576000\n",
      "current iter: 12086000/24576000\n",
      "current iter: 12087000/24576000\n",
      "current iter: 12088000/24576000\n",
      "current iter: 12089000/24576000\n",
      "current iter: 12090000/24576000\n",
      "current iter: 12091000/24576000\n",
      "current iter: 12092000/24576000\n",
      "current iter: 12093000/24576000\n",
      "current iter: 12094000/24576000\n",
      "current iter: 12095000/24576000\n",
      "current iter: 12096000/24576000\n",
      "current iter: 12097000/24576000\n",
      "current iter: 12098000/24576000\n",
      "current iter: 12099000/24576000\n",
      "current iter: 12100000/24576000\n",
      "current iter: 12101000/24576000\n",
      "current iter: 12102000/24576000\n",
      "current iter: 12103000/24576000\n",
      "current iter: 12104000/24576000\n",
      "current iter: 12105000/24576000\n",
      "current iter: 12106000/24576000\n",
      "current iter: 12107000/24576000\n",
      "current iter: 12108000/24576000\n",
      "current iter: 12109000/24576000\n",
      "current iter: 12110000/24576000\n",
      "current iter: 12111000/24576000\n",
      "current iter: 12112000/24576000\n",
      "current iter: 12113000/24576000\n",
      "current iter: 12114000/24576000\n",
      "current iter: 12115000/24576000\n",
      "current iter: 12116000/24576000\n",
      "current iter: 12117000/24576000\n",
      "current iter: 12118000/24576000\n",
      "current iter: 12119000/24576000\n",
      "current iter: 12120000/24576000\n",
      "current iter: 12121000/24576000\n",
      "current iter: 12122000/24576000\n",
      "current iter: 12123000/24576000\n",
      "current iter: 12124000/24576000\n",
      "current iter: 12125000/24576000\n",
      "current iter: 12126000/24576000\n",
      "current iter: 12127000/24576000\n",
      "current iter: 12128000/24576000\n",
      "current iter: 12129000/24576000\n",
      "current iter: 12130000/24576000\n",
      "current iter: 12131000/24576000\n",
      "current iter: 12132000/24576000\n",
      "current iter: 12133000/24576000\n",
      "current iter: 12134000/24576000\n",
      "current iter: 12135000/24576000\n",
      "current iter: 12136000/24576000\n",
      "current iter: 12137000/24576000\n",
      "current iter: 12138000/24576000\n",
      "current iter: 12139000/24576000\n",
      "current iter: 12140000/24576000\n",
      "current iter: 12141000/24576000\n",
      "current iter: 12142000/24576000\n",
      "current iter: 12143000/24576000\n",
      "current iter: 12144000/24576000\n",
      "current iter: 12145000/24576000\n",
      "current iter: 12146000/24576000\n",
      "current iter: 12147000/24576000\n",
      "current iter: 12148000/24576000\n",
      "current iter: 12149000/24576000\n",
      "current iter: 12150000/24576000\n",
      "current iter: 12151000/24576000\n",
      "current iter: 12152000/24576000\n",
      "current iter: 12153000/24576000\n",
      "current iter: 12154000/24576000\n",
      "current iter: 12155000/24576000\n",
      "current iter: 12156000/24576000\n",
      "current iter: 12157000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 12158000/24576000\n",
      "current iter: 12159000/24576000\n",
      "current iter: 12160000/24576000\n",
      "current iter: 12161000/24576000\n",
      "current iter: 12162000/24576000\n",
      "current iter: 12163000/24576000\n",
      "current iter: 12164000/24576000\n",
      "current iter: 12165000/24576000\n",
      "current iter: 12166000/24576000\n",
      "current iter: 12167000/24576000\n",
      "current iter: 12168000/24576000\n",
      "current iter: 12169000/24576000\n",
      "current iter: 12170000/24576000\n",
      "current iter: 12171000/24576000\n",
      "current iter: 12172000/24576000\n",
      "current iter: 12173000/24576000\n",
      "current iter: 12174000/24576000\n",
      "current iter: 12175000/24576000\n",
      "current iter: 12176000/24576000\n",
      "current iter: 12177000/24576000\n",
      "current iter: 12178000/24576000\n",
      "current iter: 12179000/24576000\n",
      "current iter: 12180000/24576000\n",
      "current iter: 12181000/24576000\n",
      "current iter: 12182000/24576000\n",
      "current iter: 12183000/24576000\n",
      "current iter: 12184000/24576000\n",
      "current iter: 12185000/24576000\n",
      "current iter: 12186000/24576000\n",
      "current iter: 12187000/24576000\n",
      "current iter: 12188000/24576000\n",
      "current iter: 12189000/24576000\n",
      "current iter: 12190000/24576000\n",
      "current iter: 12191000/24576000\n",
      "current iter: 12192000/24576000\n",
      "current iter: 12193000/24576000\n",
      "current iter: 12194000/24576000\n",
      "current iter: 12195000/24576000\n",
      "current iter: 12196000/24576000\n",
      "current iter: 12197000/24576000\n",
      "current iter: 12198000/24576000\n",
      "current iter: 12199000/24576000\n",
      "current iter: 12200000/24576000\n",
      "current iter: 12201000/24576000\n",
      "current iter: 12202000/24576000\n",
      "current iter: 12203000/24576000\n",
      "current iter: 12204000/24576000\n",
      "current iter: 12205000/24576000\n",
      "current iter: 12206000/24576000\n",
      "current iter: 12207000/24576000\n",
      "current iter: 12208000/24576000\n",
      "current iter: 12209000/24576000\n",
      "current iter: 12210000/24576000\n",
      "current iter: 12211000/24576000\n",
      "current iter: 12212000/24576000\n",
      "current iter: 12213000/24576000\n",
      "current iter: 12214000/24576000\n",
      "current iter: 12215000/24576000\n",
      "current iter: 12216000/24576000\n",
      "current iter: 12217000/24576000\n",
      "current iter: 12218000/24576000\n",
      "current iter: 12219000/24576000\n",
      "current iter: 12220000/24576000\n",
      "current iter: 12221000/24576000\n",
      "current iter: 12222000/24576000\n",
      "current iter: 12223000/24576000\n",
      "current iter: 12224000/24576000\n",
      "current iter: 12225000/24576000\n",
      "current iter: 12226000/24576000\n",
      "current iter: 12227000/24576000\n",
      "current iter: 12228000/24576000\n",
      "current iter: 12229000/24576000\n",
      "current iter: 12230000/24576000\n",
      "current iter: 12231000/24576000\n",
      "current iter: 12232000/24576000\n",
      "current iter: 12233000/24576000\n",
      "current iter: 12234000/24576000\n",
      "current iter: 12235000/24576000\n",
      "current iter: 12236000/24576000\n",
      "current iter: 12237000/24576000\n",
      "current iter: 12238000/24576000\n",
      "current iter: 12239000/24576000\n",
      "current iter: 12240000/24576000\n",
      "current iter: 12241000/24576000\n",
      "current iter: 12242000/24576000\n",
      "current iter: 12243000/24576000\n",
      "current iter: 12244000/24576000\n",
      "current iter: 12245000/24576000\n",
      "current iter: 12246000/24576000\n",
      "current iter: 12247000/24576000\n",
      "current iter: 12248000/24576000\n",
      "current iter: 12249000/24576000\n",
      "current iter: 12250000/24576000\n",
      "current iter: 12251000/24576000\n",
      "current iter: 12252000/24576000\n",
      "current iter: 12253000/24576000\n",
      "current iter: 12254000/24576000\n",
      "current iter: 12255000/24576000\n",
      "current iter: 12256000/24576000\n",
      "current iter: 12257000/24576000\n",
      "current iter: 12258000/24576000\n",
      "current iter: 12259000/24576000\n",
      "current iter: 12260000/24576000\n",
      "current iter: 12261000/24576000\n",
      "current iter: 12262000/24576000\n",
      "current iter: 12263000/24576000\n",
      "current iter: 12264000/24576000\n",
      "current iter: 12265000/24576000\n",
      "current iter: 12266000/24576000\n",
      "current iter: 12267000/24576000\n",
      "current iter: 12268000/24576000\n",
      "current iter: 12269000/24576000\n",
      "current iter: 12270000/24576000\n",
      "current iter: 12271000/24576000\n",
      "current iter: 12272000/24576000\n",
      "current iter: 12273000/24576000\n",
      "current iter: 12274000/24576000\n",
      "current iter: 12275000/24576000\n",
      "current iter: 12276000/24576000\n",
      "current iter: 12277000/24576000\n",
      "current iter: 12278000/24576000\n",
      "current iter: 12279000/24576000\n",
      "current iter: 12280000/24576000\n",
      "current iter: 12281000/24576000\n",
      "current iter: 12282000/24576000\n",
      "current iter: 12283000/24576000\n",
      "current iter: 12284000/24576000\n",
      "current iter: 12285000/24576000\n",
      "current iter: 12286000/24576000\n",
      "current iter: 12287000/24576000\n",
      "current iter: 12288000/24576000\n",
      "current iter: 12289000/24576000\n",
      "current iter: 12290000/24576000\n",
      "current iter: 12291000/24576000\n",
      "current iter: 12292000/24576000\n",
      "current iter: 12293000/24576000\n",
      "current iter: 12294000/24576000\n",
      "current iter: 12295000/24576000\n",
      "current iter: 12296000/24576000\n",
      "current iter: 12297000/24576000\n",
      "current iter: 12298000/24576000\n",
      "current iter: 12299000/24576000\n",
      "current iter: 12300000/24576000\n",
      "current iter: 12301000/24576000\n",
      "current iter: 12302000/24576000\n",
      "current iter: 12303000/24576000\n",
      "current iter: 12304000/24576000\n",
      "current iter: 12305000/24576000\n",
      "current iter: 12306000/24576000\n",
      "current iter: 12307000/24576000\n",
      "current iter: 12308000/24576000\n",
      "current iter: 12309000/24576000\n",
      "current iter: 12310000/24576000\n",
      "current iter: 12311000/24576000\n",
      "current iter: 12312000/24576000\n",
      "current iter: 12313000/24576000\n",
      "current iter: 12314000/24576000\n",
      "current iter: 12315000/24576000\n",
      "current iter: 12316000/24576000\n",
      "current iter: 12317000/24576000\n",
      "current iter: 12318000/24576000\n",
      "current iter: 12319000/24576000\n",
      "current iter: 12320000/24576000\n",
      "current iter: 12321000/24576000\n",
      "current iter: 12322000/24576000\n",
      "current iter: 12323000/24576000\n",
      "current iter: 12324000/24576000\n",
      "current iter: 12325000/24576000\n",
      "current iter: 12326000/24576000\n",
      "current iter: 12327000/24576000\n",
      "current iter: 12328000/24576000\n",
      "current iter: 12329000/24576000\n",
      "current iter: 12330000/24576000\n",
      "current iter: 12331000/24576000\n",
      "current iter: 12332000/24576000\n",
      "current iter: 12333000/24576000\n",
      "current iter: 12334000/24576000\n",
      "current iter: 12335000/24576000\n",
      "current iter: 12336000/24576000\n",
      "current iter: 12337000/24576000\n",
      "current iter: 12338000/24576000\n",
      "current iter: 12339000/24576000\n",
      "current iter: 12340000/24576000\n",
      "current iter: 12341000/24576000\n",
      "current iter: 12342000/24576000\n",
      "current iter: 12343000/24576000\n",
      "current iter: 12344000/24576000\n",
      "current iter: 12345000/24576000\n",
      "current iter: 12346000/24576000\n",
      "current iter: 12347000/24576000\n",
      "current iter: 12348000/24576000\n",
      "current iter: 12349000/24576000\n",
      "current iter: 12350000/24576000\n",
      "current iter: 12351000/24576000\n",
      "current iter: 12352000/24576000\n",
      "current iter: 12353000/24576000\n",
      "current iter: 12354000/24576000\n",
      "current iter: 12355000/24576000\n",
      "current iter: 12356000/24576000\n",
      "current iter: 12357000/24576000\n",
      "current iter: 12358000/24576000\n",
      "current iter: 12359000/24576000\n",
      "current iter: 12360000/24576000\n",
      "current iter: 12361000/24576000\n",
      "current iter: 12362000/24576000\n",
      "current iter: 12363000/24576000\n",
      "current iter: 12364000/24576000\n",
      "current iter: 12365000/24576000\n",
      "current iter: 12366000/24576000\n",
      "current iter: 12367000/24576000\n",
      "current iter: 12368000/24576000\n",
      "current iter: 12369000/24576000\n",
      "current iter: 12370000/24576000\n",
      "current iter: 12371000/24576000\n",
      "current iter: 12372000/24576000\n",
      "current iter: 12373000/24576000\n",
      "current iter: 12374000/24576000\n",
      "current iter: 12375000/24576000\n",
      "current iter: 12376000/24576000\n",
      "current iter: 12377000/24576000\n",
      "current iter: 12378000/24576000\n",
      "current iter: 12379000/24576000\n",
      "current iter: 12380000/24576000\n",
      "current iter: 12381000/24576000\n",
      "current iter: 12382000/24576000\n",
      "current iter: 12383000/24576000\n",
      "current iter: 12384000/24576000\n",
      "current iter: 12385000/24576000\n",
      "current iter: 12386000/24576000\n",
      "current iter: 12387000/24576000\n",
      "current iter: 12388000/24576000\n",
      "current iter: 12389000/24576000\n",
      "current iter: 12390000/24576000\n",
      "current iter: 12391000/24576000\n",
      "current iter: 12392000/24576000\n",
      "current iter: 12393000/24576000\n",
      "current iter: 12394000/24576000\n",
      "current iter: 12395000/24576000\n",
      "current iter: 12396000/24576000\n",
      "current iter: 12397000/24576000\n",
      "current iter: 12398000/24576000\n",
      "current iter: 12399000/24576000\n",
      "current iter: 12400000/24576000\n",
      "current iter: 12401000/24576000\n",
      "current iter: 12402000/24576000\n",
      "current iter: 12403000/24576000\n",
      "current iter: 12404000/24576000\n",
      "current iter: 12405000/24576000\n",
      "current iter: 12406000/24576000\n",
      "current iter: 12407000/24576000\n",
      "current iter: 12408000/24576000\n",
      "current iter: 12409000/24576000\n",
      "current iter: 12410000/24576000\n",
      "current iter: 12411000/24576000\n",
      "current iter: 12412000/24576000\n",
      "current iter: 12413000/24576000\n",
      "current iter: 12414000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 12415000/24576000\n",
      "current iter: 12416000/24576000\n",
      "current iter: 12417000/24576000\n",
      "current iter: 12418000/24576000\n",
      "current iter: 12419000/24576000\n",
      "current iter: 12420000/24576000\n",
      "current iter: 12421000/24576000\n",
      "current iter: 12422000/24576000\n",
      "current iter: 12423000/24576000\n",
      "current iter: 12424000/24576000\n",
      "current iter: 12425000/24576000\n",
      "current iter: 12426000/24576000\n",
      "current iter: 12427000/24576000\n",
      "current iter: 12428000/24576000\n",
      "current iter: 12429000/24576000\n",
      "current iter: 12430000/24576000\n",
      "current iter: 12431000/24576000\n",
      "current iter: 12432000/24576000\n",
      "current iter: 12433000/24576000\n",
      "current iter: 12434000/24576000\n",
      "current iter: 12435000/24576000\n",
      "current iter: 12436000/24576000\n",
      "current iter: 12437000/24576000\n",
      "current iter: 12438000/24576000\n",
      "current iter: 12439000/24576000\n",
      "current iter: 12440000/24576000\n",
      "current iter: 12441000/24576000\n",
      "current iter: 12442000/24576000\n",
      "current iter: 12443000/24576000\n",
      "current iter: 12444000/24576000\n",
      "current iter: 12445000/24576000\n",
      "current iter: 12446000/24576000\n",
      "current iter: 12447000/24576000\n",
      "current iter: 12448000/24576000\n",
      "current iter: 12449000/24576000\n",
      "current iter: 12450000/24576000\n",
      "current iter: 12451000/24576000\n",
      "current iter: 12452000/24576000\n",
      "current iter: 12453000/24576000\n",
      "current iter: 12454000/24576000\n",
      "current iter: 12455000/24576000\n",
      "current iter: 12456000/24576000\n",
      "current iter: 12457000/24576000\n",
      "current iter: 12458000/24576000\n",
      "current iter: 12459000/24576000\n",
      "current iter: 12460000/24576000\n",
      "current iter: 12461000/24576000\n",
      "current iter: 12462000/24576000\n",
      "current iter: 12463000/24576000\n",
      "current iter: 12464000/24576000\n",
      "current iter: 12465000/24576000\n",
      "current iter: 12466000/24576000\n",
      "current iter: 12467000/24576000\n",
      "current iter: 12468000/24576000\n",
      "current iter: 12469000/24576000\n",
      "current iter: 12470000/24576000\n",
      "current iter: 12471000/24576000\n",
      "current iter: 12472000/24576000\n",
      "current iter: 12473000/24576000\n",
      "current iter: 12474000/24576000\n",
      "current iter: 12475000/24576000\n",
      "current iter: 12476000/24576000\n",
      "current iter: 12477000/24576000\n",
      "current iter: 12478000/24576000\n",
      "current iter: 12479000/24576000\n",
      "current iter: 12480000/24576000\n",
      "current iter: 12481000/24576000\n",
      "current iter: 12482000/24576000\n",
      "current iter: 12483000/24576000\n",
      "current iter: 12484000/24576000\n",
      "current iter: 12485000/24576000\n",
      "current iter: 12486000/24576000\n",
      "current iter: 12487000/24576000\n",
      "current iter: 12488000/24576000\n",
      "current iter: 12489000/24576000\n",
      "current iter: 12490000/24576000\n",
      "current iter: 12491000/24576000\n",
      "current iter: 12492000/24576000\n",
      "current iter: 12493000/24576000\n",
      "current iter: 12494000/24576000\n",
      "current iter: 12495000/24576000\n",
      "current iter: 12496000/24576000\n",
      "current iter: 12497000/24576000\n",
      "current iter: 12498000/24576000\n",
      "current iter: 12499000/24576000\n",
      "current iter: 12500000/24576000\n",
      "current iter: 12501000/24576000\n",
      "current iter: 12502000/24576000\n",
      "current iter: 12503000/24576000\n",
      "current iter: 12504000/24576000\n",
      "current iter: 12505000/24576000\n",
      "current iter: 12506000/24576000\n",
      "current iter: 12507000/24576000\n",
      "current iter: 12508000/24576000\n",
      "current iter: 12509000/24576000\n",
      "current iter: 12510000/24576000\n",
      "current iter: 12511000/24576000\n",
      "current iter: 12512000/24576000\n",
      "current iter: 12513000/24576000\n",
      "current iter: 12514000/24576000\n",
      "current iter: 12515000/24576000\n",
      "current iter: 12516000/24576000\n",
      "current iter: 12517000/24576000\n",
      "current iter: 12518000/24576000\n",
      "current iter: 12519000/24576000\n",
      "current iter: 12520000/24576000\n",
      "current iter: 12521000/24576000\n",
      "current iter: 12522000/24576000\n",
      "current iter: 12523000/24576000\n",
      "current iter: 12524000/24576000\n",
      "current iter: 12525000/24576000\n",
      "current iter: 12526000/24576000\n",
      "current iter: 12527000/24576000\n",
      "current iter: 12528000/24576000\n",
      "current iter: 12529000/24576000\n",
      "current iter: 12530000/24576000\n",
      "current iter: 12531000/24576000\n",
      "current iter: 12532000/24576000\n",
      "current iter: 12533000/24576000\n",
      "current iter: 12534000/24576000\n",
      "current iter: 12535000/24576000\n",
      "current iter: 12536000/24576000\n",
      "current iter: 12537000/24576000\n",
      "current iter: 12538000/24576000\n",
      "current iter: 12539000/24576000\n",
      "current iter: 12540000/24576000\n",
      "current iter: 12541000/24576000\n",
      "current iter: 12542000/24576000\n",
      "current iter: 12543000/24576000\n",
      "current iter: 12544000/24576000\n",
      "current iter: 12545000/24576000\n",
      "current iter: 12546000/24576000\n",
      "current iter: 12547000/24576000\n",
      "current iter: 12548000/24576000\n",
      "current iter: 12549000/24576000\n",
      "current iter: 12550000/24576000\n",
      "current iter: 12551000/24576000\n",
      "current iter: 12552000/24576000\n",
      "current iter: 12553000/24576000\n",
      "current iter: 12554000/24576000\n",
      "current iter: 12555000/24576000\n",
      "current iter: 12556000/24576000\n",
      "current iter: 12557000/24576000\n",
      "current iter: 12558000/24576000\n",
      "current iter: 12559000/24576000\n",
      "current iter: 12560000/24576000\n",
      "current iter: 12561000/24576000\n",
      "current iter: 12562000/24576000\n",
      "current iter: 12563000/24576000\n",
      "current iter: 12564000/24576000\n",
      "current iter: 12565000/24576000\n",
      "current iter: 12566000/24576000\n",
      "current iter: 12567000/24576000\n",
      "current iter: 12568000/24576000\n",
      "current iter: 12569000/24576000\n",
      "current iter: 12570000/24576000\n",
      "current iter: 12571000/24576000\n",
      "current iter: 12572000/24576000\n",
      "current iter: 12573000/24576000\n",
      "current iter: 12574000/24576000\n",
      "current iter: 12575000/24576000\n",
      "current iter: 12576000/24576000\n",
      "current iter: 12577000/24576000\n",
      "current iter: 12578000/24576000\n",
      "current iter: 12579000/24576000\n",
      "current iter: 12580000/24576000\n",
      "current iter: 12581000/24576000\n",
      "current iter: 12582000/24576000\n",
      "current iter: 12583000/24576000\n",
      "current iter: 12584000/24576000\n",
      "current iter: 12585000/24576000\n",
      "current iter: 12586000/24576000\n",
      "current iter: 12587000/24576000\n",
      "current iter: 12588000/24576000\n",
      "current iter: 12589000/24576000\n",
      "current iter: 12590000/24576000\n",
      "current iter: 12591000/24576000\n",
      "current iter: 12592000/24576000\n",
      "current iter: 12593000/24576000\n",
      "current iter: 12594000/24576000\n",
      "current iter: 12595000/24576000\n",
      "current iter: 12596000/24576000\n",
      "current iter: 12597000/24576000\n",
      "current iter: 12598000/24576000\n",
      "current iter: 12599000/24576000\n",
      "current iter: 12600000/24576000\n",
      "current iter: 12601000/24576000\n",
      "current iter: 12602000/24576000\n",
      "current iter: 12603000/24576000\n",
      "current iter: 12604000/24576000\n",
      "current iter: 12605000/24576000\n",
      "current iter: 12606000/24576000\n",
      "current iter: 12607000/24576000\n",
      "current iter: 12608000/24576000\n",
      "current iter: 12609000/24576000\n",
      "current iter: 12610000/24576000\n",
      "current iter: 12611000/24576000\n",
      "current iter: 12612000/24576000\n",
      "current iter: 12613000/24576000\n",
      "current iter: 12614000/24576000\n",
      "current iter: 12615000/24576000\n",
      "current iter: 12616000/24576000\n",
      "current iter: 12617000/24576000\n",
      "current iter: 12618000/24576000\n",
      "current iter: 12619000/24576000\n",
      "current iter: 12620000/24576000\n",
      "current iter: 12621000/24576000\n",
      "current iter: 12622000/24576000\n",
      "current iter: 12623000/24576000\n",
      "current iter: 12624000/24576000\n",
      "current iter: 12625000/24576000\n",
      "current iter: 12626000/24576000\n",
      "current iter: 12627000/24576000\n",
      "current iter: 12628000/24576000\n",
      "current iter: 12629000/24576000\n",
      "current iter: 12630000/24576000\n",
      "current iter: 12631000/24576000\n",
      "current iter: 12632000/24576000\n",
      "current iter: 12633000/24576000\n",
      "current iter: 12634000/24576000\n",
      "current iter: 12635000/24576000\n",
      "current iter: 12636000/24576000\n",
      "current iter: 12637000/24576000\n",
      "current iter: 12638000/24576000\n",
      "current iter: 12639000/24576000\n",
      "current iter: 12640000/24576000\n",
      "current iter: 12641000/24576000\n",
      "current iter: 12642000/24576000\n",
      "current iter: 12643000/24576000\n",
      "current iter: 12644000/24576000\n",
      "current iter: 12645000/24576000\n",
      "current iter: 12646000/24576000\n",
      "current iter: 12647000/24576000\n",
      "current iter: 12648000/24576000\n",
      "current iter: 12649000/24576000\n",
      "current iter: 12650000/24576000\n",
      "current iter: 12651000/24576000\n",
      "current iter: 12652000/24576000\n",
      "current iter: 12653000/24576000\n",
      "current iter: 12654000/24576000\n",
      "current iter: 12655000/24576000\n",
      "current iter: 12656000/24576000\n",
      "current iter: 12657000/24576000\n",
      "current iter: 12658000/24576000\n",
      "current iter: 12659000/24576000\n",
      "current iter: 12660000/24576000\n",
      "current iter: 12661000/24576000\n",
      "current iter: 12662000/24576000\n",
      "current iter: 12663000/24576000\n",
      "current iter: 12664000/24576000\n",
      "current iter: 12665000/24576000\n",
      "current iter: 12666000/24576000\n",
      "current iter: 12667000/24576000\n",
      "current iter: 12668000/24576000\n",
      "current iter: 12669000/24576000\n",
      "current iter: 12670000/24576000\n",
      "current iter: 12671000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 12672000/24576000\n",
      "current iter: 12673000/24576000\n",
      "current iter: 12674000/24576000\n",
      "current iter: 12675000/24576000\n",
      "current iter: 12676000/24576000\n",
      "current iter: 12677000/24576000\n",
      "current iter: 12678000/24576000\n",
      "current iter: 12679000/24576000\n",
      "current iter: 12680000/24576000\n",
      "current iter: 12681000/24576000\n",
      "current iter: 12682000/24576000\n",
      "current iter: 12683000/24576000\n",
      "current iter: 12684000/24576000\n",
      "current iter: 12685000/24576000\n",
      "current iter: 12686000/24576000\n",
      "current iter: 12687000/24576000\n",
      "current iter: 12688000/24576000\n",
      "current iter: 12689000/24576000\n",
      "current iter: 12690000/24576000\n",
      "current iter: 12691000/24576000\n",
      "current iter: 12692000/24576000\n",
      "current iter: 12693000/24576000\n",
      "current iter: 12694000/24576000\n",
      "current iter: 12695000/24576000\n",
      "current iter: 12696000/24576000\n",
      "current iter: 12697000/24576000\n",
      "current iter: 12698000/24576000\n",
      "current iter: 12699000/24576000\n",
      "current iter: 12700000/24576000\n",
      "current iter: 12701000/24576000\n",
      "current iter: 12702000/24576000\n",
      "current iter: 12703000/24576000\n",
      "current iter: 12704000/24576000\n",
      "current iter: 12705000/24576000\n",
      "current iter: 12706000/24576000\n",
      "current iter: 12707000/24576000\n",
      "current iter: 12708000/24576000\n",
      "current iter: 12709000/24576000\n",
      "current iter: 12710000/24576000\n",
      "current iter: 12711000/24576000\n",
      "current iter: 12712000/24576000\n",
      "current iter: 12713000/24576000\n",
      "current iter: 12714000/24576000\n",
      "current iter: 12715000/24576000\n",
      "current iter: 12716000/24576000\n",
      "current iter: 12717000/24576000\n",
      "current iter: 12718000/24576000\n",
      "current iter: 12719000/24576000\n",
      "current iter: 12720000/24576000\n",
      "current iter: 12721000/24576000\n",
      "current iter: 12722000/24576000\n",
      "current iter: 12723000/24576000\n",
      "current iter: 12724000/24576000\n",
      "current iter: 12725000/24576000\n",
      "current iter: 12726000/24576000\n",
      "current iter: 12727000/24576000\n",
      "current iter: 12728000/24576000\n",
      "current iter: 12729000/24576000\n",
      "current iter: 12730000/24576000\n",
      "current iter: 12731000/24576000\n",
      "current iter: 12732000/24576000\n",
      "current iter: 12733000/24576000\n",
      "current iter: 12734000/24576000\n",
      "current iter: 12735000/24576000\n",
      "current iter: 12736000/24576000\n",
      "current iter: 12737000/24576000\n",
      "current iter: 12738000/24576000\n",
      "current iter: 12739000/24576000\n",
      "current iter: 12740000/24576000\n",
      "current iter: 12741000/24576000\n",
      "current iter: 12742000/24576000\n",
      "current iter: 12743000/24576000\n",
      "current iter: 12744000/24576000\n",
      "current iter: 12745000/24576000\n",
      "current iter: 12746000/24576000\n",
      "current iter: 12747000/24576000\n",
      "current iter: 12748000/24576000\n",
      "current iter: 12749000/24576000\n",
      "current iter: 12750000/24576000\n",
      "current iter: 12751000/24576000\n",
      "current iter: 12752000/24576000\n",
      "current iter: 12753000/24576000\n",
      "current iter: 12754000/24576000\n",
      "current iter: 12755000/24576000\n",
      "current iter: 12756000/24576000\n",
      "current iter: 12757000/24576000\n",
      "current iter: 12758000/24576000\n",
      "current iter: 12759000/24576000\n",
      "current iter: 12760000/24576000\n",
      "current iter: 12761000/24576000\n",
      "current iter: 12762000/24576000\n",
      "current iter: 12763000/24576000\n",
      "current iter: 12764000/24576000\n",
      "current iter: 12765000/24576000\n",
      "current iter: 12766000/24576000\n",
      "current iter: 12767000/24576000\n",
      "current iter: 12768000/24576000\n",
      "current iter: 12769000/24576000\n",
      "current iter: 12770000/24576000\n",
      "current iter: 12771000/24576000\n",
      "current iter: 12772000/24576000\n",
      "current iter: 12773000/24576000\n",
      "current iter: 12774000/24576000\n",
      "current iter: 12775000/24576000\n",
      "current iter: 12776000/24576000\n",
      "current iter: 12777000/24576000\n",
      "current iter: 12778000/24576000\n",
      "current iter: 12779000/24576000\n",
      "current iter: 12780000/24576000\n",
      "current iter: 12781000/24576000\n",
      "current iter: 12782000/24576000\n",
      "current iter: 12783000/24576000\n",
      "current iter: 12784000/24576000\n",
      "current iter: 12785000/24576000\n",
      "current iter: 12786000/24576000\n",
      "current iter: 12787000/24576000\n",
      "current iter: 12788000/24576000\n",
      "current iter: 12789000/24576000\n",
      "current iter: 12790000/24576000\n",
      "current iter: 12791000/24576000\n",
      "current iter: 12792000/24576000\n",
      "current iter: 12793000/24576000\n",
      "current iter: 12794000/24576000\n",
      "current iter: 12795000/24576000\n",
      "current iter: 12796000/24576000\n",
      "current iter: 12797000/24576000\n",
      "current iter: 12798000/24576000\n",
      "current iter: 12799000/24576000\n",
      "current iter: 12800000/24576000\n",
      "current iter: 12801000/24576000\n",
      "current iter: 12802000/24576000\n",
      "current iter: 12803000/24576000\n",
      "current iter: 12804000/24576000\n",
      "current iter: 12805000/24576000\n",
      "current iter: 12806000/24576000\n",
      "current iter: 12807000/24576000\n",
      "current iter: 12808000/24576000\n",
      "current iter: 12809000/24576000\n",
      "current iter: 12810000/24576000\n",
      "current iter: 12811000/24576000\n",
      "current iter: 12812000/24576000\n",
      "current iter: 12813000/24576000\n",
      "current iter: 12814000/24576000\n",
      "current iter: 12815000/24576000\n",
      "current iter: 12816000/24576000\n",
      "current iter: 12817000/24576000\n",
      "current iter: 12818000/24576000\n",
      "current iter: 12819000/24576000\n",
      "current iter: 12820000/24576000\n",
      "current iter: 12821000/24576000\n",
      "current iter: 12822000/24576000\n",
      "current iter: 12823000/24576000\n",
      "current iter: 12824000/24576000\n",
      "current iter: 12825000/24576000\n",
      "current iter: 12826000/24576000\n",
      "current iter: 12827000/24576000\n",
      "current iter: 12828000/24576000\n",
      "current iter: 12829000/24576000\n",
      "current iter: 12830000/24576000\n",
      "current iter: 12831000/24576000\n",
      "current iter: 12832000/24576000\n",
      "current iter: 12833000/24576000\n",
      "current iter: 12834000/24576000\n",
      "current iter: 12835000/24576000\n",
      "current iter: 12836000/24576000\n",
      "current iter: 12837000/24576000\n",
      "current iter: 12838000/24576000\n",
      "current iter: 12839000/24576000\n",
      "current iter: 12840000/24576000\n",
      "current iter: 12841000/24576000\n",
      "current iter: 12842000/24576000\n",
      "current iter: 12843000/24576000\n",
      "current iter: 12844000/24576000\n",
      "current iter: 12845000/24576000\n",
      "current iter: 12846000/24576000\n",
      "current iter: 12847000/24576000\n",
      "current iter: 12848000/24576000\n",
      "current iter: 12849000/24576000\n",
      "current iter: 12850000/24576000\n",
      "current iter: 12851000/24576000\n",
      "current iter: 12852000/24576000\n",
      "current iter: 12853000/24576000\n",
      "current iter: 12854000/24576000\n",
      "current iter: 12855000/24576000\n",
      "current iter: 12856000/24576000\n",
      "current iter: 12857000/24576000\n",
      "current iter: 12858000/24576000\n",
      "current iter: 12859000/24576000\n",
      "current iter: 12860000/24576000\n",
      "current iter: 12861000/24576000\n",
      "current iter: 12862000/24576000\n",
      "current iter: 12863000/24576000\n",
      "current iter: 12864000/24576000\n",
      "current iter: 12865000/24576000\n",
      "current iter: 12866000/24576000\n",
      "current iter: 12867000/24576000\n",
      "current iter: 12868000/24576000\n",
      "current iter: 12869000/24576000\n",
      "current iter: 12870000/24576000\n",
      "current iter: 12871000/24576000\n",
      "current iter: 12872000/24576000\n",
      "current iter: 12873000/24576000\n",
      "current iter: 12874000/24576000\n",
      "current iter: 12875000/24576000\n",
      "current iter: 12876000/24576000\n",
      "current iter: 12877000/24576000\n",
      "current iter: 12878000/24576000\n",
      "current iter: 12879000/24576000\n",
      "current iter: 12880000/24576000\n",
      "current iter: 12881000/24576000\n",
      "current iter: 12882000/24576000\n",
      "current iter: 12883000/24576000\n",
      "current iter: 12884000/24576000\n",
      "current iter: 12885000/24576000\n",
      "current iter: 12886000/24576000\n",
      "current iter: 12887000/24576000\n",
      "current iter: 12888000/24576000\n",
      "current iter: 12889000/24576000\n",
      "current iter: 12890000/24576000\n",
      "current iter: 12891000/24576000\n",
      "current iter: 12892000/24576000\n",
      "current iter: 12893000/24576000\n",
      "current iter: 12894000/24576000\n",
      "current iter: 12895000/24576000\n",
      "current iter: 12896000/24576000\n",
      "current iter: 12897000/24576000\n",
      "current iter: 12898000/24576000\n",
      "current iter: 12899000/24576000\n",
      "current iter: 12900000/24576000\n",
      "current iter: 12901000/24576000\n",
      "current iter: 12902000/24576000\n",
      "current iter: 12903000/24576000\n",
      "current iter: 12904000/24576000\n",
      "current iter: 12905000/24576000\n",
      "current iter: 12906000/24576000\n",
      "current iter: 12907000/24576000\n",
      "current iter: 12908000/24576000\n",
      "current iter: 12909000/24576000\n",
      "current iter: 12910000/24576000\n",
      "current iter: 12911000/24576000\n",
      "current iter: 12912000/24576000\n",
      "current iter: 12913000/24576000\n",
      "current iter: 12914000/24576000\n",
      "current iter: 12915000/24576000\n",
      "current iter: 12916000/24576000\n",
      "current iter: 12917000/24576000\n",
      "current iter: 12918000/24576000\n",
      "current iter: 12919000/24576000\n",
      "current iter: 12920000/24576000\n",
      "current iter: 12921000/24576000\n",
      "current iter: 12922000/24576000\n",
      "current iter: 12923000/24576000\n",
      "current iter: 12924000/24576000\n",
      "current iter: 12925000/24576000\n",
      "current iter: 12926000/24576000\n",
      "current iter: 12927000/24576000\n",
      "current iter: 12928000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 12929000/24576000\n",
      "current iter: 12930000/24576000\n",
      "current iter: 12931000/24576000\n",
      "current iter: 12932000/24576000\n",
      "current iter: 12933000/24576000\n",
      "current iter: 12934000/24576000\n",
      "current iter: 12935000/24576000\n",
      "current iter: 12936000/24576000\n",
      "current iter: 12937000/24576000\n",
      "current iter: 12938000/24576000\n",
      "current iter: 12939000/24576000\n",
      "current iter: 12940000/24576000\n",
      "current iter: 12941000/24576000\n",
      "current iter: 12942000/24576000\n",
      "current iter: 12943000/24576000\n",
      "current iter: 12944000/24576000\n",
      "current iter: 12945000/24576000\n",
      "current iter: 12946000/24576000\n",
      "current iter: 12947000/24576000\n",
      "current iter: 12948000/24576000\n",
      "current iter: 12949000/24576000\n",
      "current iter: 12950000/24576000\n",
      "current iter: 12951000/24576000\n",
      "current iter: 12952000/24576000\n",
      "current iter: 12953000/24576000\n",
      "current iter: 12954000/24576000\n",
      "current iter: 12955000/24576000\n",
      "current iter: 12956000/24576000\n",
      "current iter: 12957000/24576000\n",
      "current iter: 12958000/24576000\n",
      "current iter: 12959000/24576000\n",
      "current iter: 12960000/24576000\n",
      "current iter: 12961000/24576000\n",
      "current iter: 12962000/24576000\n",
      "current iter: 12963000/24576000\n",
      "current iter: 12964000/24576000\n",
      "current iter: 12965000/24576000\n",
      "current iter: 12966000/24576000\n",
      "current iter: 12967000/24576000\n",
      "current iter: 12968000/24576000\n",
      "current iter: 12969000/24576000\n",
      "current iter: 12970000/24576000\n",
      "current iter: 12971000/24576000\n",
      "current iter: 12972000/24576000\n",
      "current iter: 12973000/24576000\n",
      "current iter: 12974000/24576000\n",
      "current iter: 12975000/24576000\n",
      "current iter: 12976000/24576000\n",
      "current iter: 12977000/24576000\n",
      "current iter: 12978000/24576000\n",
      "current iter: 12979000/24576000\n",
      "current iter: 12980000/24576000\n",
      "current iter: 12981000/24576000\n",
      "current iter: 12982000/24576000\n",
      "current iter: 12983000/24576000\n",
      "current iter: 12984000/24576000\n",
      "current iter: 12985000/24576000\n",
      "current iter: 12986000/24576000\n",
      "current iter: 12987000/24576000\n",
      "current iter: 12988000/24576000\n",
      "current iter: 12989000/24576000\n",
      "current iter: 12990000/24576000\n",
      "current iter: 12991000/24576000\n",
      "current iter: 12992000/24576000\n",
      "current iter: 12993000/24576000\n",
      "current iter: 12994000/24576000\n",
      "current iter: 12995000/24576000\n",
      "current iter: 12996000/24576000\n",
      "current iter: 12997000/24576000\n",
      "current iter: 12998000/24576000\n",
      "current iter: 12999000/24576000\n",
      "current iter: 13000000/24576000\n",
      "current iter: 13001000/24576000\n",
      "current iter: 13002000/24576000\n",
      "current iter: 13003000/24576000\n",
      "current iter: 13004000/24576000\n",
      "current iter: 13005000/24576000\n",
      "current iter: 13006000/24576000\n",
      "current iter: 13007000/24576000\n",
      "current iter: 13008000/24576000\n",
      "current iter: 13009000/24576000\n",
      "current iter: 13010000/24576000\n",
      "current iter: 13011000/24576000\n",
      "current iter: 13012000/24576000\n",
      "current iter: 13013000/24576000\n",
      "current iter: 13014000/24576000\n",
      "current iter: 13015000/24576000\n",
      "current iter: 13016000/24576000\n",
      "current iter: 13017000/24576000\n",
      "current iter: 13018000/24576000\n",
      "current iter: 13019000/24576000\n",
      "current iter: 13020000/24576000\n",
      "current iter: 13021000/24576000\n",
      "current iter: 13022000/24576000\n",
      "current iter: 13023000/24576000\n",
      "current iter: 13024000/24576000\n",
      "current iter: 13025000/24576000\n",
      "current iter: 13026000/24576000\n",
      "current iter: 13027000/24576000\n",
      "current iter: 13028000/24576000\n",
      "current iter: 13029000/24576000\n",
      "current iter: 13030000/24576000\n",
      "current iter: 13031000/24576000\n",
      "current iter: 13032000/24576000\n",
      "current iter: 13033000/24576000\n",
      "current iter: 13034000/24576000\n",
      "current iter: 13035000/24576000\n",
      "current iter: 13036000/24576000\n",
      "current iter: 13037000/24576000\n",
      "current iter: 13038000/24576000\n",
      "current iter: 13039000/24576000\n",
      "current iter: 13040000/24576000\n",
      "current iter: 13041000/24576000\n",
      "current iter: 13042000/24576000\n",
      "current iter: 13043000/24576000\n",
      "current iter: 13044000/24576000\n",
      "current iter: 13045000/24576000\n",
      "current iter: 13046000/24576000\n",
      "current iter: 13047000/24576000\n",
      "current iter: 13048000/24576000\n",
      "current iter: 13049000/24576000\n",
      "current iter: 13050000/24576000\n",
      "current iter: 13051000/24576000\n",
      "current iter: 13052000/24576000\n",
      "current iter: 13053000/24576000\n",
      "current iter: 13054000/24576000\n",
      "current iter: 13055000/24576000\n",
      "current iter: 13056000/24576000\n",
      "current iter: 13057000/24576000\n",
      "current iter: 13058000/24576000\n",
      "current iter: 13059000/24576000\n",
      "current iter: 13060000/24576000\n",
      "current iter: 13061000/24576000\n",
      "current iter: 13062000/24576000\n",
      "current iter: 13063000/24576000\n",
      "current iter: 13064000/24576000\n",
      "current iter: 13065000/24576000\n",
      "current iter: 13066000/24576000\n",
      "current iter: 13067000/24576000\n",
      "current iter: 13068000/24576000\n",
      "current iter: 13069000/24576000\n",
      "current iter: 13070000/24576000\n",
      "current iter: 13071000/24576000\n",
      "current iter: 13072000/24576000\n",
      "current iter: 13073000/24576000\n",
      "current iter: 13074000/24576000\n",
      "current iter: 13075000/24576000\n",
      "current iter: 13076000/24576000\n",
      "current iter: 13077000/24576000\n",
      "current iter: 13078000/24576000\n",
      "current iter: 13079000/24576000\n",
      "current iter: 13080000/24576000\n",
      "current iter: 13081000/24576000\n",
      "current iter: 13082000/24576000\n",
      "current iter: 13083000/24576000\n",
      "current iter: 13084000/24576000\n",
      "current iter: 13085000/24576000\n",
      "current iter: 13086000/24576000\n",
      "current iter: 13087000/24576000\n",
      "current iter: 13088000/24576000\n",
      "current iter: 13089000/24576000\n",
      "current iter: 13090000/24576000\n",
      "current iter: 13091000/24576000\n",
      "current iter: 13092000/24576000\n",
      "current iter: 13093000/24576000\n",
      "current iter: 13094000/24576000\n",
      "current iter: 13095000/24576000\n",
      "current iter: 13096000/24576000\n",
      "current iter: 13097000/24576000\n",
      "current iter: 13098000/24576000\n",
      "current iter: 13099000/24576000\n",
      "current iter: 13100000/24576000\n",
      "current iter: 13101000/24576000\n",
      "current iter: 13102000/24576000\n",
      "current iter: 13103000/24576000\n",
      "current iter: 13104000/24576000\n",
      "current iter: 13105000/24576000\n",
      "current iter: 13106000/24576000\n",
      "current iter: 13107000/24576000\n",
      "current iter: 13108000/24576000\n",
      "current iter: 13109000/24576000\n",
      "current iter: 13110000/24576000\n",
      "current iter: 13111000/24576000\n",
      "current iter: 13112000/24576000\n",
      "current iter: 13113000/24576000\n",
      "current iter: 13114000/24576000\n",
      "current iter: 13115000/24576000\n",
      "current iter: 13116000/24576000\n",
      "current iter: 13117000/24576000\n",
      "current iter: 13118000/24576000\n",
      "current iter: 13119000/24576000\n",
      "current iter: 13120000/24576000\n",
      "current iter: 13121000/24576000\n",
      "current iter: 13122000/24576000\n",
      "current iter: 13123000/24576000\n",
      "current iter: 13124000/24576000\n",
      "current iter: 13125000/24576000\n",
      "current iter: 13126000/24576000\n",
      "current iter: 13127000/24576000\n",
      "current iter: 13128000/24576000\n",
      "current iter: 13129000/24576000\n",
      "current iter: 13130000/24576000\n",
      "current iter: 13131000/24576000\n",
      "current iter: 13132000/24576000\n",
      "current iter: 13133000/24576000\n",
      "current iter: 13134000/24576000\n",
      "current iter: 13135000/24576000\n",
      "current iter: 13136000/24576000\n",
      "current iter: 13137000/24576000\n",
      "current iter: 13138000/24576000\n",
      "current iter: 13139000/24576000\n",
      "current iter: 13140000/24576000\n",
      "current iter: 13141000/24576000\n",
      "current iter: 13142000/24576000\n",
      "current iter: 13143000/24576000\n",
      "current iter: 13144000/24576000\n",
      "current iter: 13145000/24576000\n",
      "current iter: 13146000/24576000\n",
      "current iter: 13147000/24576000\n",
      "current iter: 13148000/24576000\n",
      "current iter: 13149000/24576000\n",
      "current iter: 13150000/24576000\n",
      "current iter: 13151000/24576000\n",
      "current iter: 13152000/24576000\n",
      "current iter: 13153000/24576000\n",
      "current iter: 13154000/24576000\n",
      "current iter: 13155000/24576000\n",
      "current iter: 13156000/24576000\n",
      "current iter: 13157000/24576000\n",
      "current iter: 13158000/24576000\n",
      "current iter: 13159000/24576000\n",
      "current iter: 13160000/24576000\n",
      "current iter: 13161000/24576000\n",
      "current iter: 13162000/24576000\n",
      "current iter: 13163000/24576000\n",
      "current iter: 13164000/24576000\n",
      "current iter: 13165000/24576000\n",
      "current iter: 13166000/24576000\n",
      "current iter: 13167000/24576000\n",
      "current iter: 13168000/24576000\n",
      "current iter: 13169000/24576000\n",
      "current iter: 13170000/24576000\n",
      "current iter: 13171000/24576000\n",
      "current iter: 13172000/24576000\n",
      "current iter: 13173000/24576000\n",
      "current iter: 13174000/24576000\n",
      "current iter: 13175000/24576000\n",
      "current iter: 13176000/24576000\n",
      "current iter: 13177000/24576000\n",
      "current iter: 13178000/24576000\n",
      "current iter: 13179000/24576000\n",
      "current iter: 13180000/24576000\n",
      "current iter: 13181000/24576000\n",
      "current iter: 13182000/24576000\n",
      "current iter: 13183000/24576000\n",
      "current iter: 13184000/24576000\n",
      "current iter: 13185000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 13186000/24576000\n",
      "current iter: 13187000/24576000\n",
      "current iter: 13188000/24576000\n",
      "current iter: 13189000/24576000\n",
      "current iter: 13190000/24576000\n",
      "current iter: 13191000/24576000\n",
      "current iter: 13192000/24576000\n",
      "current iter: 13193000/24576000\n",
      "current iter: 13194000/24576000\n",
      "current iter: 13195000/24576000\n",
      "current iter: 13196000/24576000\n",
      "current iter: 13197000/24576000\n",
      "current iter: 13198000/24576000\n",
      "current iter: 13199000/24576000\n",
      "current iter: 13200000/24576000\n",
      "current iter: 13201000/24576000\n",
      "current iter: 13202000/24576000\n",
      "current iter: 13203000/24576000\n",
      "current iter: 13204000/24576000\n",
      "current iter: 13205000/24576000\n",
      "current iter: 13206000/24576000\n",
      "current iter: 13207000/24576000\n",
      "current iter: 13208000/24576000\n",
      "current iter: 13209000/24576000\n",
      "current iter: 13210000/24576000\n",
      "current iter: 13211000/24576000\n",
      "current iter: 13212000/24576000\n",
      "current iter: 13213000/24576000\n",
      "current iter: 13214000/24576000\n",
      "current iter: 13215000/24576000\n",
      "current iter: 13216000/24576000\n",
      "current iter: 13217000/24576000\n",
      "current iter: 13218000/24576000\n",
      "current iter: 13219000/24576000\n",
      "current iter: 13220000/24576000\n",
      "current iter: 13221000/24576000\n",
      "current iter: 13222000/24576000\n",
      "current iter: 13223000/24576000\n",
      "current iter: 13224000/24576000\n",
      "current iter: 13225000/24576000\n",
      "current iter: 13226000/24576000\n",
      "current iter: 13227000/24576000\n",
      "current iter: 13228000/24576000\n",
      "current iter: 13229000/24576000\n",
      "current iter: 13230000/24576000\n",
      "current iter: 13231000/24576000\n",
      "current iter: 13232000/24576000\n",
      "current iter: 13233000/24576000\n",
      "current iter: 13234000/24576000\n",
      "current iter: 13235000/24576000\n",
      "current iter: 13236000/24576000\n",
      "current iter: 13237000/24576000\n",
      "current iter: 13238000/24576000\n",
      "current iter: 13239000/24576000\n",
      "current iter: 13240000/24576000\n",
      "current iter: 13241000/24576000\n",
      "current iter: 13242000/24576000\n",
      "current iter: 13243000/24576000\n",
      "current iter: 13244000/24576000\n",
      "current iter: 13245000/24576000\n",
      "current iter: 13246000/24576000\n",
      "current iter: 13247000/24576000\n",
      "current iter: 13248000/24576000\n",
      "current iter: 13249000/24576000\n",
      "current iter: 13250000/24576000\n",
      "current iter: 13251000/24576000\n",
      "current iter: 13252000/24576000\n",
      "current iter: 13253000/24576000\n",
      "current iter: 13254000/24576000\n",
      "current iter: 13255000/24576000\n",
      "current iter: 13256000/24576000\n",
      "current iter: 13257000/24576000\n",
      "current iter: 13258000/24576000\n",
      "current iter: 13259000/24576000\n",
      "current iter: 13260000/24576000\n",
      "current iter: 13261000/24576000\n",
      "current iter: 13262000/24576000\n",
      "current iter: 13263000/24576000\n",
      "current iter: 13264000/24576000\n",
      "current iter: 13265000/24576000\n",
      "current iter: 13266000/24576000\n",
      "current iter: 13267000/24576000\n",
      "current iter: 13268000/24576000\n",
      "current iter: 13269000/24576000\n",
      "current iter: 13270000/24576000\n",
      "current iter: 13271000/24576000\n",
      "current iter: 13272000/24576000\n",
      "current iter: 13273000/24576000\n",
      "current iter: 13274000/24576000\n",
      "current iter: 13275000/24576000\n",
      "current iter: 13276000/24576000\n",
      "current iter: 13277000/24576000\n",
      "current iter: 13278000/24576000\n",
      "current iter: 13279000/24576000\n",
      "current iter: 13280000/24576000\n",
      "current iter: 13281000/24576000\n",
      "current iter: 13282000/24576000\n",
      "current iter: 13283000/24576000\n",
      "current iter: 13284000/24576000\n",
      "current iter: 13285000/24576000\n",
      "current iter: 13286000/24576000\n",
      "current iter: 13287000/24576000\n",
      "current iter: 13288000/24576000\n",
      "current iter: 13289000/24576000\n",
      "current iter: 13290000/24576000\n",
      "current iter: 13291000/24576000\n",
      "current iter: 13292000/24576000\n",
      "current iter: 13293000/24576000\n",
      "current iter: 13294000/24576000\n",
      "current iter: 13295000/24576000\n",
      "current iter: 13296000/24576000\n",
      "current iter: 13297000/24576000\n",
      "current iter: 13298000/24576000\n",
      "current iter: 13299000/24576000\n",
      "current iter: 13300000/24576000\n",
      "current iter: 13301000/24576000\n",
      "current iter: 13302000/24576000\n",
      "current iter: 13303000/24576000\n",
      "current iter: 13304000/24576000\n",
      "current iter: 13305000/24576000\n",
      "current iter: 13306000/24576000\n",
      "current iter: 13307000/24576000\n",
      "current iter: 13308000/24576000\n",
      "current iter: 13309000/24576000\n",
      "current iter: 13310000/24576000\n",
      "current iter: 13311000/24576000\n",
      "current iter: 13312000/24576000\n",
      "current iter: 13313000/24576000\n",
      "current iter: 13314000/24576000\n",
      "current iter: 13315000/24576000\n",
      "current iter: 13316000/24576000\n",
      "current iter: 13317000/24576000\n",
      "current iter: 13318000/24576000\n",
      "current iter: 13319000/24576000\n",
      "current iter: 13320000/24576000\n",
      "current iter: 13321000/24576000\n",
      "current iter: 13322000/24576000\n",
      "current iter: 13323000/24576000\n",
      "current iter: 13324000/24576000\n",
      "current iter: 13325000/24576000\n",
      "current iter: 13326000/24576000\n",
      "current iter: 13327000/24576000\n",
      "current iter: 13328000/24576000\n",
      "current iter: 13329000/24576000\n",
      "current iter: 13330000/24576000\n",
      "current iter: 13331000/24576000\n",
      "current iter: 13332000/24576000\n",
      "current iter: 13333000/24576000\n",
      "current iter: 13334000/24576000\n",
      "current iter: 13335000/24576000\n",
      "current iter: 13336000/24576000\n",
      "current iter: 13337000/24576000\n",
      "current iter: 13338000/24576000\n",
      "current iter: 13339000/24576000\n",
      "current iter: 13340000/24576000\n",
      "current iter: 13341000/24576000\n",
      "current iter: 13342000/24576000\n",
      "current iter: 13343000/24576000\n",
      "current iter: 13344000/24576000\n",
      "current iter: 13345000/24576000\n",
      "current iter: 13346000/24576000\n",
      "current iter: 13347000/24576000\n",
      "current iter: 13348000/24576000\n",
      "current iter: 13349000/24576000\n",
      "current iter: 13350000/24576000\n",
      "current iter: 13351000/24576000\n",
      "current iter: 13352000/24576000\n",
      "current iter: 13353000/24576000\n",
      "current iter: 13354000/24576000\n",
      "current iter: 13355000/24576000\n",
      "current iter: 13356000/24576000\n",
      "current iter: 13357000/24576000\n",
      "current iter: 13358000/24576000\n",
      "current iter: 13359000/24576000\n",
      "current iter: 13360000/24576000\n",
      "current iter: 13361000/24576000\n",
      "current iter: 13362000/24576000\n",
      "current iter: 13363000/24576000\n",
      "current iter: 13364000/24576000\n",
      "current iter: 13365000/24576000\n",
      "current iter: 13366000/24576000\n",
      "current iter: 13367000/24576000\n",
      "current iter: 13368000/24576000\n",
      "current iter: 13369000/24576000\n",
      "current iter: 13370000/24576000\n",
      "current iter: 13371000/24576000\n",
      "current iter: 13372000/24576000\n",
      "current iter: 13373000/24576000\n",
      "current iter: 13374000/24576000\n",
      "current iter: 13375000/24576000\n",
      "current iter: 13376000/24576000\n",
      "current iter: 13377000/24576000\n",
      "current iter: 13378000/24576000\n",
      "current iter: 13379000/24576000\n",
      "current iter: 13380000/24576000\n",
      "current iter: 13381000/24576000\n",
      "current iter: 13382000/24576000\n",
      "current iter: 13383000/24576000\n",
      "current iter: 13384000/24576000\n",
      "current iter: 13385000/24576000\n",
      "current iter: 13386000/24576000\n",
      "current iter: 13387000/24576000\n",
      "current iter: 13388000/24576000\n",
      "current iter: 13389000/24576000\n",
      "current iter: 13390000/24576000\n",
      "current iter: 13391000/24576000\n",
      "current iter: 13392000/24576000\n",
      "current iter: 13393000/24576000\n",
      "current iter: 13394000/24576000\n",
      "current iter: 13395000/24576000\n",
      "current iter: 13396000/24576000\n",
      "current iter: 13397000/24576000\n",
      "current iter: 13398000/24576000\n",
      "current iter: 13399000/24576000\n",
      "current iter: 13400000/24576000\n",
      "current iter: 13401000/24576000\n",
      "current iter: 13402000/24576000\n",
      "current iter: 13403000/24576000\n",
      "current iter: 13404000/24576000\n",
      "current iter: 13405000/24576000\n",
      "current iter: 13406000/24576000\n",
      "current iter: 13407000/24576000\n",
      "current iter: 13408000/24576000\n",
      "current iter: 13409000/24576000\n",
      "current iter: 13410000/24576000\n",
      "current iter: 13411000/24576000\n",
      "current iter: 13412000/24576000\n",
      "current iter: 13413000/24576000\n",
      "current iter: 13414000/24576000\n",
      "current iter: 13415000/24576000\n",
      "current iter: 13416000/24576000\n",
      "current iter: 13417000/24576000\n",
      "current iter: 13418000/24576000\n",
      "current iter: 13419000/24576000\n",
      "current iter: 13420000/24576000\n",
      "current iter: 13421000/24576000\n",
      "current iter: 13422000/24576000\n",
      "current iter: 13423000/24576000\n",
      "current iter: 13424000/24576000\n",
      "current iter: 13425000/24576000\n",
      "current iter: 13426000/24576000\n",
      "current iter: 13427000/24576000\n",
      "current iter: 13428000/24576000\n",
      "current iter: 13429000/24576000\n",
      "current iter: 13430000/24576000\n",
      "current iter: 13431000/24576000\n",
      "current iter: 13432000/24576000\n",
      "current iter: 13433000/24576000\n",
      "current iter: 13434000/24576000\n",
      "current iter: 13435000/24576000\n",
      "current iter: 13436000/24576000\n",
      "current iter: 13437000/24576000\n",
      "current iter: 13438000/24576000\n",
      "current iter: 13439000/24576000\n",
      "current iter: 13440000/24576000\n",
      "current iter: 13441000/24576000\n",
      "current iter: 13442000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 13443000/24576000\n",
      "current iter: 13444000/24576000\n",
      "current iter: 13445000/24576000\n",
      "current iter: 13446000/24576000\n",
      "current iter: 13447000/24576000\n",
      "current iter: 13448000/24576000\n",
      "current iter: 13449000/24576000\n",
      "current iter: 13450000/24576000\n",
      "current iter: 13451000/24576000\n",
      "current iter: 13452000/24576000\n",
      "current iter: 13453000/24576000\n",
      "current iter: 13454000/24576000\n",
      "current iter: 13455000/24576000\n",
      "current iter: 13456000/24576000\n",
      "current iter: 13457000/24576000\n",
      "current iter: 13458000/24576000\n",
      "current iter: 13459000/24576000\n",
      "current iter: 13460000/24576000\n",
      "current iter: 13461000/24576000\n",
      "current iter: 13462000/24576000\n",
      "current iter: 13463000/24576000\n",
      "current iter: 13464000/24576000\n",
      "current iter: 13465000/24576000\n",
      "current iter: 13466000/24576000\n",
      "current iter: 13467000/24576000\n",
      "current iter: 13468000/24576000\n",
      "current iter: 13469000/24576000\n",
      "current iter: 13470000/24576000\n",
      "current iter: 13471000/24576000\n",
      "current iter: 13472000/24576000\n",
      "current iter: 13473000/24576000\n",
      "current iter: 13474000/24576000\n",
      "current iter: 13475000/24576000\n",
      "current iter: 13476000/24576000\n",
      "current iter: 13477000/24576000\n",
      "current iter: 13478000/24576000\n",
      "current iter: 13479000/24576000\n",
      "current iter: 13480000/24576000\n",
      "current iter: 13481000/24576000\n",
      "current iter: 13482000/24576000\n",
      "current iter: 13483000/24576000\n",
      "current iter: 13484000/24576000\n",
      "current iter: 13485000/24576000\n",
      "current iter: 13486000/24576000\n",
      "current iter: 13487000/24576000\n",
      "current iter: 13488000/24576000\n",
      "current iter: 13489000/24576000\n",
      "current iter: 13490000/24576000\n",
      "current iter: 13491000/24576000\n",
      "current iter: 13492000/24576000\n",
      "current iter: 13493000/24576000\n",
      "current iter: 13494000/24576000\n",
      "current iter: 13495000/24576000\n",
      "current iter: 13496000/24576000\n",
      "current iter: 13497000/24576000\n",
      "current iter: 13498000/24576000\n",
      "current iter: 13499000/24576000\n",
      "current iter: 13500000/24576000\n",
      "current iter: 13501000/24576000\n",
      "current iter: 13502000/24576000\n",
      "current iter: 13503000/24576000\n",
      "current iter: 13504000/24576000\n",
      "current iter: 13505000/24576000\n",
      "current iter: 13506000/24576000\n",
      "current iter: 13507000/24576000\n",
      "current iter: 13508000/24576000\n",
      "current iter: 13509000/24576000\n",
      "current iter: 13510000/24576000\n",
      "current iter: 13511000/24576000\n",
      "current iter: 13512000/24576000\n",
      "current iter: 13513000/24576000\n",
      "current iter: 13514000/24576000\n",
      "current iter: 13515000/24576000\n",
      "current iter: 13516000/24576000\n",
      "current iter: 13517000/24576000\n",
      "current iter: 13518000/24576000\n",
      "current iter: 13519000/24576000\n",
      "current iter: 13520000/24576000\n",
      "current iter: 13521000/24576000\n",
      "current iter: 13522000/24576000\n",
      "current iter: 13523000/24576000\n",
      "current iter: 13524000/24576000\n",
      "current iter: 13525000/24576000\n",
      "current iter: 13526000/24576000\n",
      "current iter: 13527000/24576000\n",
      "current iter: 13528000/24576000\n",
      "current iter: 13529000/24576000\n",
      "current iter: 13530000/24576000\n",
      "current iter: 13531000/24576000\n",
      "current iter: 13532000/24576000\n",
      "current iter: 13533000/24576000\n",
      "current iter: 13534000/24576000\n",
      "current iter: 13535000/24576000\n",
      "current iter: 13536000/24576000\n",
      "current iter: 13537000/24576000\n",
      "current iter: 13538000/24576000\n",
      "current iter: 13539000/24576000\n",
      "current iter: 13540000/24576000\n",
      "current iter: 13541000/24576000\n",
      "current iter: 13542000/24576000\n",
      "current iter: 13543000/24576000\n",
      "current iter: 13544000/24576000\n",
      "current iter: 13545000/24576000\n",
      "current iter: 13546000/24576000\n",
      "current iter: 13547000/24576000\n",
      "current iter: 13548000/24576000\n",
      "current iter: 13549000/24576000\n",
      "current iter: 13550000/24576000\n",
      "current iter: 13551000/24576000\n",
      "current iter: 13552000/24576000\n",
      "current iter: 13553000/24576000\n",
      "current iter: 13554000/24576000\n",
      "current iter: 13555000/24576000\n",
      "current iter: 13556000/24576000\n",
      "current iter: 13557000/24576000\n",
      "current iter: 13558000/24576000\n",
      "current iter: 13559000/24576000\n",
      "current iter: 13560000/24576000\n",
      "current iter: 13561000/24576000\n",
      "current iter: 13562000/24576000\n",
      "current iter: 13563000/24576000\n",
      "current iter: 13564000/24576000\n",
      "current iter: 13565000/24576000\n",
      "current iter: 13566000/24576000\n",
      "current iter: 13567000/24576000\n",
      "current iter: 13568000/24576000\n",
      "current iter: 13569000/24576000\n",
      "current iter: 13570000/24576000\n",
      "current iter: 13571000/24576000\n",
      "current iter: 13572000/24576000\n",
      "current iter: 13573000/24576000\n",
      "current iter: 13574000/24576000\n",
      "current iter: 13575000/24576000\n",
      "current iter: 13576000/24576000\n",
      "current iter: 13577000/24576000\n",
      "current iter: 13578000/24576000\n",
      "current iter: 13579000/24576000\n",
      "current iter: 13580000/24576000\n",
      "current iter: 13581000/24576000\n",
      "current iter: 13582000/24576000\n",
      "current iter: 13583000/24576000\n",
      "current iter: 13584000/24576000\n",
      "current iter: 13585000/24576000\n",
      "current iter: 13586000/24576000\n",
      "current iter: 13587000/24576000\n",
      "current iter: 13588000/24576000\n",
      "current iter: 13589000/24576000\n",
      "current iter: 13590000/24576000\n",
      "current iter: 13591000/24576000\n",
      "current iter: 13592000/24576000\n",
      "current iter: 13593000/24576000\n",
      "current iter: 13594000/24576000\n",
      "current iter: 13595000/24576000\n",
      "current iter: 13596000/24576000\n",
      "current iter: 13597000/24576000\n",
      "current iter: 13598000/24576000\n",
      "current iter: 13599000/24576000\n",
      "current iter: 13600000/24576000\n",
      "current iter: 13601000/24576000\n",
      "current iter: 13602000/24576000\n",
      "current iter: 13603000/24576000\n",
      "current iter: 13604000/24576000\n",
      "current iter: 13605000/24576000\n",
      "current iter: 13606000/24576000\n",
      "current iter: 13607000/24576000\n",
      "current iter: 13608000/24576000\n",
      "current iter: 13609000/24576000\n",
      "current iter: 13610000/24576000\n",
      "current iter: 13611000/24576000\n",
      "current iter: 13612000/24576000\n",
      "current iter: 13613000/24576000\n",
      "current iter: 13614000/24576000\n",
      "current iter: 13615000/24576000\n",
      "current iter: 13616000/24576000\n",
      "current iter: 13617000/24576000\n",
      "current iter: 13618000/24576000\n",
      "current iter: 13619000/24576000\n",
      "current iter: 13620000/24576000\n",
      "current iter: 13621000/24576000\n",
      "current iter: 13622000/24576000\n",
      "current iter: 13623000/24576000\n",
      "current iter: 13624000/24576000\n",
      "current iter: 13625000/24576000\n",
      "current iter: 13626000/24576000\n",
      "current iter: 13627000/24576000\n",
      "current iter: 13628000/24576000\n",
      "current iter: 13629000/24576000\n",
      "current iter: 13630000/24576000\n",
      "current iter: 13631000/24576000\n",
      "current iter: 13632000/24576000\n",
      "current iter: 13633000/24576000\n",
      "current iter: 13634000/24576000\n",
      "current iter: 13635000/24576000\n",
      "current iter: 13636000/24576000\n",
      "current iter: 13637000/24576000\n",
      "current iter: 13638000/24576000\n",
      "current iter: 13639000/24576000\n",
      "current iter: 13640000/24576000\n",
      "current iter: 13641000/24576000\n",
      "current iter: 13642000/24576000\n",
      "current iter: 13643000/24576000\n",
      "current iter: 13644000/24576000\n",
      "current iter: 13645000/24576000\n",
      "current iter: 13646000/24576000\n",
      "current iter: 13647000/24576000\n",
      "current iter: 13648000/24576000\n",
      "current iter: 13649000/24576000\n",
      "current iter: 13650000/24576000\n",
      "current iter: 13651000/24576000\n",
      "current iter: 13652000/24576000\n",
      "current iter: 13653000/24576000\n",
      "current iter: 13654000/24576000\n",
      "current iter: 13655000/24576000\n",
      "current iter: 13656000/24576000\n",
      "current iter: 13657000/24576000\n",
      "current iter: 13658000/24576000\n",
      "current iter: 13659000/24576000\n",
      "current iter: 13660000/24576000\n",
      "current iter: 13661000/24576000\n",
      "current iter: 13662000/24576000\n",
      "current iter: 13663000/24576000\n",
      "current iter: 13664000/24576000\n",
      "current iter: 13665000/24576000\n",
      "current iter: 13666000/24576000\n",
      "current iter: 13667000/24576000\n",
      "current iter: 13668000/24576000\n",
      "current iter: 13669000/24576000\n",
      "current iter: 13670000/24576000\n",
      "current iter: 13671000/24576000\n",
      "current iter: 13672000/24576000\n",
      "current iter: 13673000/24576000\n",
      "current iter: 13674000/24576000\n",
      "current iter: 13675000/24576000\n",
      "current iter: 13676000/24576000\n",
      "current iter: 13677000/24576000\n",
      "current iter: 13678000/24576000\n",
      "current iter: 13679000/24576000\n",
      "current iter: 13680000/24576000\n",
      "current iter: 13681000/24576000\n",
      "current iter: 13682000/24576000\n",
      "current iter: 13683000/24576000\n",
      "current iter: 13684000/24576000\n",
      "current iter: 13685000/24576000\n",
      "current iter: 13686000/24576000\n",
      "current iter: 13687000/24576000\n",
      "current iter: 13688000/24576000\n",
      "current iter: 13689000/24576000\n",
      "current iter: 13690000/24576000\n",
      "current iter: 13691000/24576000\n",
      "current iter: 13692000/24576000\n",
      "current iter: 13693000/24576000\n",
      "current iter: 13694000/24576000\n",
      "current iter: 13695000/24576000\n",
      "current iter: 13696000/24576000\n",
      "current iter: 13697000/24576000\n",
      "current iter: 13698000/24576000\n",
      "current iter: 13699000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 13700000/24576000\n",
      "current iter: 13701000/24576000\n",
      "current iter: 13702000/24576000\n",
      "current iter: 13703000/24576000\n",
      "current iter: 13704000/24576000\n",
      "current iter: 13705000/24576000\n",
      "current iter: 13706000/24576000\n",
      "current iter: 13707000/24576000\n",
      "current iter: 13708000/24576000\n",
      "current iter: 13709000/24576000\n",
      "current iter: 13710000/24576000\n",
      "current iter: 13711000/24576000\n",
      "current iter: 13712000/24576000\n",
      "current iter: 13713000/24576000\n",
      "current iter: 13714000/24576000\n",
      "current iter: 13715000/24576000\n",
      "current iter: 13716000/24576000\n",
      "current iter: 13717000/24576000\n",
      "current iter: 13718000/24576000\n",
      "current iter: 13719000/24576000\n",
      "current iter: 13720000/24576000\n",
      "current iter: 13721000/24576000\n",
      "current iter: 13722000/24576000\n",
      "current iter: 13723000/24576000\n",
      "current iter: 13724000/24576000\n",
      "current iter: 13725000/24576000\n",
      "current iter: 13726000/24576000\n",
      "current iter: 13727000/24576000\n",
      "current iter: 13728000/24576000\n",
      "current iter: 13729000/24576000\n",
      "current iter: 13730000/24576000\n",
      "current iter: 13731000/24576000\n",
      "current iter: 13732000/24576000\n",
      "current iter: 13733000/24576000\n",
      "current iter: 13734000/24576000\n",
      "current iter: 13735000/24576000\n",
      "current iter: 13736000/24576000\n",
      "current iter: 13737000/24576000\n",
      "current iter: 13738000/24576000\n",
      "current iter: 13739000/24576000\n",
      "current iter: 13740000/24576000\n",
      "current iter: 13741000/24576000\n",
      "current iter: 13742000/24576000\n",
      "current iter: 13743000/24576000\n",
      "current iter: 13744000/24576000\n",
      "current iter: 13745000/24576000\n",
      "current iter: 13746000/24576000\n",
      "current iter: 13747000/24576000\n",
      "current iter: 13748000/24576000\n",
      "current iter: 13749000/24576000\n",
      "current iter: 13750000/24576000\n",
      "current iter: 13751000/24576000\n",
      "current iter: 13752000/24576000\n",
      "current iter: 13753000/24576000\n",
      "current iter: 13754000/24576000\n",
      "current iter: 13755000/24576000\n",
      "current iter: 13756000/24576000\n",
      "current iter: 13757000/24576000\n",
      "current iter: 13758000/24576000\n",
      "current iter: 13759000/24576000\n",
      "current iter: 13760000/24576000\n",
      "current iter: 13761000/24576000\n",
      "current iter: 13762000/24576000\n",
      "current iter: 13763000/24576000\n",
      "current iter: 13764000/24576000\n",
      "current iter: 13765000/24576000\n",
      "current iter: 13766000/24576000\n",
      "current iter: 13767000/24576000\n",
      "current iter: 13768000/24576000\n",
      "current iter: 13769000/24576000\n",
      "current iter: 13770000/24576000\n",
      "current iter: 13771000/24576000\n",
      "current iter: 13772000/24576000\n",
      "current iter: 13773000/24576000\n",
      "current iter: 13774000/24576000\n",
      "current iter: 13775000/24576000\n",
      "current iter: 13776000/24576000\n",
      "current iter: 13777000/24576000\n",
      "current iter: 13778000/24576000\n",
      "current iter: 13779000/24576000\n",
      "current iter: 13780000/24576000\n",
      "current iter: 13781000/24576000\n",
      "current iter: 13782000/24576000\n",
      "current iter: 13783000/24576000\n",
      "current iter: 13784000/24576000\n",
      "current iter: 13785000/24576000\n",
      "current iter: 13786000/24576000\n",
      "current iter: 13787000/24576000\n",
      "current iter: 13788000/24576000\n",
      "current iter: 13789000/24576000\n",
      "current iter: 13790000/24576000\n",
      "current iter: 13791000/24576000\n",
      "current iter: 13792000/24576000\n",
      "current iter: 13793000/24576000\n",
      "current iter: 13794000/24576000\n",
      "current iter: 13795000/24576000\n",
      "current iter: 13796000/24576000\n",
      "current iter: 13797000/24576000\n",
      "current iter: 13798000/24576000\n",
      "current iter: 13799000/24576000\n",
      "current iter: 13800000/24576000\n",
      "current iter: 13801000/24576000\n",
      "current iter: 13802000/24576000\n",
      "current iter: 13803000/24576000\n",
      "current iter: 13804000/24576000\n",
      "current iter: 13805000/24576000\n",
      "current iter: 13806000/24576000\n",
      "current iter: 13807000/24576000\n",
      "current iter: 13808000/24576000\n",
      "current iter: 13809000/24576000\n",
      "current iter: 13810000/24576000\n",
      "current iter: 13811000/24576000\n",
      "current iter: 13812000/24576000\n",
      "current iter: 13813000/24576000\n",
      "current iter: 13814000/24576000\n",
      "current iter: 13815000/24576000\n",
      "current iter: 13816000/24576000\n",
      "current iter: 13817000/24576000\n",
      "current iter: 13818000/24576000\n",
      "current iter: 13819000/24576000\n",
      "current iter: 13820000/24576000\n",
      "current iter: 13821000/24576000\n",
      "current iter: 13822000/24576000\n",
      "current iter: 13823000/24576000\n",
      "current iter: 13824000/24576000\n",
      "current iter: 13825000/24576000\n",
      "current iter: 13826000/24576000\n",
      "current iter: 13827000/24576000\n",
      "current iter: 13828000/24576000\n",
      "current iter: 13829000/24576000\n",
      "current iter: 13830000/24576000\n",
      "current iter: 13831000/24576000\n",
      "current iter: 13832000/24576000\n",
      "current iter: 13833000/24576000\n",
      "current iter: 13834000/24576000\n",
      "current iter: 13835000/24576000\n",
      "current iter: 13836000/24576000\n",
      "current iter: 13837000/24576000\n",
      "current iter: 13838000/24576000\n",
      "current iter: 13839000/24576000\n",
      "current iter: 13840000/24576000\n",
      "current iter: 13841000/24576000\n",
      "current iter: 13842000/24576000\n",
      "current iter: 13843000/24576000\n",
      "current iter: 13844000/24576000\n",
      "current iter: 13845000/24576000\n",
      "current iter: 13846000/24576000\n",
      "current iter: 13847000/24576000\n",
      "current iter: 13848000/24576000\n",
      "current iter: 13849000/24576000\n",
      "current iter: 13850000/24576000\n",
      "current iter: 13851000/24576000\n",
      "current iter: 13852000/24576000\n",
      "current iter: 13853000/24576000\n",
      "current iter: 13854000/24576000\n",
      "current iter: 13855000/24576000\n",
      "current iter: 13856000/24576000\n",
      "current iter: 13857000/24576000\n",
      "current iter: 13858000/24576000\n",
      "current iter: 13859000/24576000\n",
      "current iter: 13860000/24576000\n",
      "current iter: 13861000/24576000\n",
      "current iter: 13862000/24576000\n",
      "current iter: 13863000/24576000\n",
      "current iter: 13864000/24576000\n",
      "current iter: 13865000/24576000\n",
      "current iter: 13866000/24576000\n",
      "current iter: 13867000/24576000\n",
      "current iter: 13868000/24576000\n",
      "current iter: 13869000/24576000\n",
      "current iter: 13870000/24576000\n",
      "current iter: 13871000/24576000\n",
      "current iter: 13872000/24576000\n",
      "current iter: 13873000/24576000\n",
      "current iter: 13874000/24576000\n",
      "current iter: 13875000/24576000\n",
      "current iter: 13876000/24576000\n",
      "current iter: 13877000/24576000\n",
      "current iter: 13878000/24576000\n",
      "current iter: 13879000/24576000\n",
      "current iter: 13880000/24576000\n",
      "current iter: 13881000/24576000\n",
      "current iter: 13882000/24576000\n",
      "current iter: 13883000/24576000\n",
      "current iter: 13884000/24576000\n",
      "current iter: 13885000/24576000\n",
      "current iter: 13886000/24576000\n",
      "current iter: 13887000/24576000\n",
      "current iter: 13888000/24576000\n",
      "current iter: 13889000/24576000\n",
      "current iter: 13890000/24576000\n",
      "current iter: 13891000/24576000\n",
      "current iter: 13892000/24576000\n",
      "current iter: 13893000/24576000\n",
      "current iter: 13894000/24576000\n",
      "current iter: 13895000/24576000\n",
      "current iter: 13896000/24576000\n",
      "current iter: 13897000/24576000\n",
      "current iter: 13898000/24576000\n",
      "current iter: 13899000/24576000\n",
      "current iter: 13900000/24576000\n",
      "current iter: 13901000/24576000\n",
      "current iter: 13902000/24576000\n",
      "current iter: 13903000/24576000\n",
      "current iter: 13904000/24576000\n",
      "current iter: 13905000/24576000\n",
      "current iter: 13906000/24576000\n",
      "current iter: 13907000/24576000\n",
      "current iter: 13908000/24576000\n",
      "current iter: 13909000/24576000\n",
      "current iter: 13910000/24576000\n",
      "current iter: 13911000/24576000\n",
      "current iter: 13912000/24576000\n",
      "current iter: 13913000/24576000\n",
      "current iter: 13914000/24576000\n",
      "current iter: 13915000/24576000\n",
      "current iter: 13916000/24576000\n",
      "current iter: 13917000/24576000\n",
      "current iter: 13918000/24576000\n",
      "current iter: 13919000/24576000\n",
      "current iter: 13920000/24576000\n",
      "current iter: 13921000/24576000\n",
      "current iter: 13922000/24576000\n",
      "current iter: 13923000/24576000\n",
      "current iter: 13924000/24576000\n",
      "current iter: 13925000/24576000\n",
      "current iter: 13926000/24576000\n",
      "current iter: 13927000/24576000\n",
      "current iter: 13928000/24576000\n",
      "current iter: 13929000/24576000\n",
      "current iter: 13930000/24576000\n",
      "current iter: 13931000/24576000\n",
      "current iter: 13932000/24576000\n",
      "current iter: 13933000/24576000\n",
      "current iter: 13934000/24576000\n",
      "current iter: 13935000/24576000\n",
      "current iter: 13936000/24576000\n",
      "current iter: 13937000/24576000\n",
      "current iter: 13938000/24576000\n",
      "current iter: 13939000/24576000\n",
      "current iter: 13940000/24576000\n",
      "current iter: 13941000/24576000\n",
      "current iter: 13942000/24576000\n",
      "current iter: 13943000/24576000\n",
      "current iter: 13944000/24576000\n",
      "current iter: 13945000/24576000\n",
      "current iter: 13946000/24576000\n",
      "current iter: 13947000/24576000\n",
      "current iter: 13948000/24576000\n",
      "current iter: 13949000/24576000\n",
      "current iter: 13950000/24576000\n",
      "current iter: 13951000/24576000\n",
      "current iter: 13952000/24576000\n",
      "current iter: 13953000/24576000\n",
      "current iter: 13954000/24576000\n",
      "current iter: 13955000/24576000\n",
      "current iter: 13956000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 13957000/24576000\n",
      "current iter: 13958000/24576000\n",
      "current iter: 13959000/24576000\n",
      "current iter: 13960000/24576000\n",
      "current iter: 13961000/24576000\n",
      "current iter: 13962000/24576000\n",
      "current iter: 13963000/24576000\n",
      "current iter: 13964000/24576000\n",
      "current iter: 13965000/24576000\n",
      "current iter: 13966000/24576000\n",
      "current iter: 13967000/24576000\n",
      "current iter: 13968000/24576000\n",
      "current iter: 13969000/24576000\n",
      "current iter: 13970000/24576000\n",
      "current iter: 13971000/24576000\n",
      "current iter: 13972000/24576000\n",
      "current iter: 13973000/24576000\n",
      "current iter: 13974000/24576000\n",
      "current iter: 13975000/24576000\n",
      "current iter: 13976000/24576000\n",
      "current iter: 13977000/24576000\n",
      "current iter: 13978000/24576000\n",
      "current iter: 13979000/24576000\n",
      "current iter: 13980000/24576000\n",
      "current iter: 13981000/24576000\n",
      "current iter: 13982000/24576000\n",
      "current iter: 13983000/24576000\n",
      "current iter: 13984000/24576000\n",
      "current iter: 13985000/24576000\n",
      "current iter: 13986000/24576000\n",
      "current iter: 13987000/24576000\n",
      "current iter: 13988000/24576000\n",
      "current iter: 13989000/24576000\n",
      "current iter: 13990000/24576000\n",
      "current iter: 13991000/24576000\n",
      "current iter: 13992000/24576000\n",
      "current iter: 13993000/24576000\n",
      "current iter: 13994000/24576000\n",
      "current iter: 13995000/24576000\n",
      "current iter: 13996000/24576000\n",
      "current iter: 13997000/24576000\n",
      "current iter: 13998000/24576000\n",
      "current iter: 13999000/24576000\n",
      "current iter: 14000000/24576000\n",
      "current iter: 14001000/24576000\n",
      "current iter: 14002000/24576000\n",
      "current iter: 14003000/24576000\n",
      "current iter: 14004000/24576000\n",
      "current iter: 14005000/24576000\n",
      "current iter: 14006000/24576000\n",
      "current iter: 14007000/24576000\n",
      "current iter: 14008000/24576000\n",
      "current iter: 14009000/24576000\n",
      "current iter: 14010000/24576000\n",
      "current iter: 14011000/24576000\n",
      "current iter: 14012000/24576000\n",
      "current iter: 14013000/24576000\n",
      "current iter: 14014000/24576000\n",
      "current iter: 14015000/24576000\n",
      "current iter: 14016000/24576000\n",
      "current iter: 14017000/24576000\n",
      "current iter: 14018000/24576000\n",
      "current iter: 14019000/24576000\n",
      "current iter: 14020000/24576000\n",
      "current iter: 14021000/24576000\n",
      "current iter: 14022000/24576000\n",
      "current iter: 14023000/24576000\n",
      "current iter: 14024000/24576000\n",
      "current iter: 14025000/24576000\n",
      "current iter: 14026000/24576000\n",
      "current iter: 14027000/24576000\n",
      "current iter: 14028000/24576000\n",
      "current iter: 14029000/24576000\n",
      "current iter: 14030000/24576000\n",
      "current iter: 14031000/24576000\n",
      "current iter: 14032000/24576000\n",
      "current iter: 14033000/24576000\n",
      "current iter: 14034000/24576000\n",
      "current iter: 14035000/24576000\n",
      "current iter: 14036000/24576000\n",
      "current iter: 14037000/24576000\n",
      "current iter: 14038000/24576000\n",
      "current iter: 14039000/24576000\n",
      "current iter: 14040000/24576000\n",
      "current iter: 14041000/24576000\n",
      "current iter: 14042000/24576000\n",
      "current iter: 14043000/24576000\n",
      "current iter: 14044000/24576000\n",
      "current iter: 14045000/24576000\n",
      "current iter: 14046000/24576000\n",
      "current iter: 14047000/24576000\n",
      "current iter: 14048000/24576000\n",
      "current iter: 14049000/24576000\n",
      "current iter: 14050000/24576000\n",
      "current iter: 14051000/24576000\n",
      "current iter: 14052000/24576000\n",
      "current iter: 14053000/24576000\n",
      "current iter: 14054000/24576000\n",
      "current iter: 14055000/24576000\n",
      "current iter: 14056000/24576000\n",
      "current iter: 14057000/24576000\n",
      "current iter: 14058000/24576000\n",
      "current iter: 14059000/24576000\n",
      "current iter: 14060000/24576000\n",
      "current iter: 14061000/24576000\n",
      "current iter: 14062000/24576000\n",
      "current iter: 14063000/24576000\n",
      "current iter: 14064000/24576000\n",
      "current iter: 14065000/24576000\n",
      "current iter: 14066000/24576000\n",
      "current iter: 14067000/24576000\n",
      "current iter: 14068000/24576000\n",
      "current iter: 14069000/24576000\n",
      "current iter: 14070000/24576000\n",
      "current iter: 14071000/24576000\n",
      "current iter: 14072000/24576000\n",
      "current iter: 14073000/24576000\n",
      "current iter: 14074000/24576000\n",
      "current iter: 14075000/24576000\n",
      "current iter: 14076000/24576000\n",
      "current iter: 14077000/24576000\n",
      "current iter: 14078000/24576000\n",
      "current iter: 14079000/24576000\n",
      "current iter: 14080000/24576000\n",
      "current iter: 14081000/24576000\n",
      "current iter: 14082000/24576000\n",
      "current iter: 14083000/24576000\n",
      "current iter: 14084000/24576000\n",
      "current iter: 14085000/24576000\n",
      "current iter: 14086000/24576000\n",
      "current iter: 14087000/24576000\n",
      "current iter: 14088000/24576000\n",
      "current iter: 14089000/24576000\n",
      "current iter: 14090000/24576000\n",
      "current iter: 14091000/24576000\n",
      "current iter: 14092000/24576000\n",
      "current iter: 14093000/24576000\n",
      "current iter: 14094000/24576000\n",
      "current iter: 14095000/24576000\n",
      "current iter: 14096000/24576000\n",
      "current iter: 14097000/24576000\n",
      "current iter: 14098000/24576000\n",
      "current iter: 14099000/24576000\n",
      "current iter: 14100000/24576000\n",
      "current iter: 14101000/24576000\n",
      "current iter: 14102000/24576000\n",
      "current iter: 14103000/24576000\n",
      "current iter: 14104000/24576000\n",
      "current iter: 14105000/24576000\n",
      "current iter: 14106000/24576000\n",
      "current iter: 14107000/24576000\n",
      "current iter: 14108000/24576000\n",
      "current iter: 14109000/24576000\n",
      "current iter: 14110000/24576000\n",
      "current iter: 14111000/24576000\n",
      "current iter: 14112000/24576000\n",
      "current iter: 14113000/24576000\n",
      "current iter: 14114000/24576000\n",
      "current iter: 14115000/24576000\n",
      "current iter: 14116000/24576000\n",
      "current iter: 14117000/24576000\n",
      "current iter: 14118000/24576000\n",
      "current iter: 14119000/24576000\n",
      "current iter: 14120000/24576000\n",
      "current iter: 14121000/24576000\n",
      "current iter: 14122000/24576000\n",
      "current iter: 14123000/24576000\n",
      "current iter: 14124000/24576000\n",
      "current iter: 14125000/24576000\n",
      "current iter: 14126000/24576000\n",
      "current iter: 14127000/24576000\n",
      "current iter: 14128000/24576000\n",
      "current iter: 14129000/24576000\n",
      "current iter: 14130000/24576000\n",
      "current iter: 14131000/24576000\n",
      "current iter: 14132000/24576000\n",
      "current iter: 14133000/24576000\n",
      "current iter: 14134000/24576000\n",
      "current iter: 14135000/24576000\n",
      "current iter: 14136000/24576000\n",
      "current iter: 14137000/24576000\n",
      "current iter: 14138000/24576000\n",
      "current iter: 14139000/24576000\n",
      "current iter: 14140000/24576000\n",
      "current iter: 14141000/24576000\n",
      "current iter: 14142000/24576000\n",
      "current iter: 14143000/24576000\n",
      "current iter: 14144000/24576000\n",
      "current iter: 14145000/24576000\n",
      "current iter: 14146000/24576000\n",
      "current iter: 14147000/24576000\n",
      "current iter: 14148000/24576000\n",
      "current iter: 14149000/24576000\n",
      "current iter: 14150000/24576000\n",
      "current iter: 14151000/24576000\n",
      "current iter: 14152000/24576000\n",
      "current iter: 14153000/24576000\n",
      "current iter: 14154000/24576000\n",
      "current iter: 14155000/24576000\n",
      "current iter: 14156000/24576000\n",
      "current iter: 14157000/24576000\n",
      "current iter: 14158000/24576000\n",
      "current iter: 14159000/24576000\n",
      "current iter: 14160000/24576000\n",
      "current iter: 14161000/24576000\n",
      "current iter: 14162000/24576000\n",
      "current iter: 14163000/24576000\n",
      "current iter: 14164000/24576000\n",
      "current iter: 14165000/24576000\n",
      "current iter: 14166000/24576000\n",
      "current iter: 14167000/24576000\n",
      "current iter: 14168000/24576000\n",
      "current iter: 14169000/24576000\n",
      "current iter: 14170000/24576000\n",
      "current iter: 14171000/24576000\n",
      "current iter: 14172000/24576000\n",
      "current iter: 14173000/24576000\n",
      "current iter: 14174000/24576000\n",
      "current iter: 14175000/24576000\n",
      "current iter: 14176000/24576000\n",
      "current iter: 14177000/24576000\n",
      "current iter: 14178000/24576000\n",
      "current iter: 14179000/24576000\n",
      "current iter: 14180000/24576000\n",
      "current iter: 14181000/24576000\n",
      "current iter: 14182000/24576000\n",
      "current iter: 14183000/24576000\n",
      "current iter: 14184000/24576000\n",
      "current iter: 14185000/24576000\n",
      "current iter: 14186000/24576000\n",
      "current iter: 14187000/24576000\n",
      "current iter: 14188000/24576000\n",
      "current iter: 14189000/24576000\n",
      "current iter: 14190000/24576000\n",
      "current iter: 14191000/24576000\n",
      "current iter: 14192000/24576000\n",
      "current iter: 14193000/24576000\n",
      "current iter: 14194000/24576000\n",
      "current iter: 14195000/24576000\n",
      "current iter: 14196000/24576000\n",
      "current iter: 14197000/24576000\n",
      "current iter: 14198000/24576000\n",
      "current iter: 14199000/24576000\n",
      "current iter: 14200000/24576000\n",
      "current iter: 14201000/24576000\n",
      "current iter: 14202000/24576000\n",
      "current iter: 14203000/24576000\n",
      "current iter: 14204000/24576000\n",
      "current iter: 14205000/24576000\n",
      "current iter: 14206000/24576000\n",
      "current iter: 14207000/24576000\n",
      "current iter: 14208000/24576000\n",
      "current iter: 14209000/24576000\n",
      "current iter: 14210000/24576000\n",
      "current iter: 14211000/24576000\n",
      "current iter: 14212000/24576000\n",
      "current iter: 14213000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 14214000/24576000\n",
      "current iter: 14215000/24576000\n",
      "current iter: 14216000/24576000\n",
      "current iter: 14217000/24576000\n",
      "current iter: 14218000/24576000\n",
      "current iter: 14219000/24576000\n",
      "current iter: 14220000/24576000\n",
      "current iter: 14221000/24576000\n",
      "current iter: 14222000/24576000\n",
      "current iter: 14223000/24576000\n",
      "current iter: 14224000/24576000\n",
      "current iter: 14225000/24576000\n",
      "current iter: 14226000/24576000\n",
      "current iter: 14227000/24576000\n",
      "current iter: 14228000/24576000\n",
      "current iter: 14229000/24576000\n",
      "current iter: 14230000/24576000\n",
      "current iter: 14231000/24576000\n",
      "current iter: 14232000/24576000\n",
      "current iter: 14233000/24576000\n",
      "current iter: 14234000/24576000\n",
      "current iter: 14235000/24576000\n",
      "current iter: 14236000/24576000\n",
      "current iter: 14237000/24576000\n",
      "current iter: 14238000/24576000\n",
      "current iter: 14239000/24576000\n",
      "current iter: 14240000/24576000\n",
      "current iter: 14241000/24576000\n",
      "current iter: 14242000/24576000\n",
      "current iter: 14243000/24576000\n",
      "current iter: 14244000/24576000\n",
      "current iter: 14245000/24576000\n",
      "current iter: 14246000/24576000\n",
      "current iter: 14247000/24576000\n",
      "current iter: 14248000/24576000\n",
      "current iter: 14249000/24576000\n",
      "current iter: 14250000/24576000\n",
      "current iter: 14251000/24576000\n",
      "current iter: 14252000/24576000\n",
      "current iter: 14253000/24576000\n",
      "current iter: 14254000/24576000\n",
      "current iter: 14255000/24576000\n",
      "current iter: 14256000/24576000\n",
      "current iter: 14257000/24576000\n",
      "current iter: 14258000/24576000\n",
      "current iter: 14259000/24576000\n",
      "current iter: 14260000/24576000\n",
      "current iter: 14261000/24576000\n",
      "current iter: 14262000/24576000\n",
      "current iter: 14263000/24576000\n",
      "current iter: 14264000/24576000\n",
      "current iter: 14265000/24576000\n",
      "current iter: 14266000/24576000\n",
      "current iter: 14267000/24576000\n",
      "current iter: 14268000/24576000\n",
      "current iter: 14269000/24576000\n",
      "current iter: 14270000/24576000\n",
      "current iter: 14271000/24576000\n",
      "current iter: 14272000/24576000\n",
      "current iter: 14273000/24576000\n",
      "current iter: 14274000/24576000\n",
      "current iter: 14275000/24576000\n",
      "current iter: 14276000/24576000\n",
      "current iter: 14277000/24576000\n",
      "current iter: 14278000/24576000\n",
      "current iter: 14279000/24576000\n",
      "current iter: 14280000/24576000\n",
      "current iter: 14281000/24576000\n",
      "current iter: 14282000/24576000\n",
      "current iter: 14283000/24576000\n",
      "current iter: 14284000/24576000\n",
      "current iter: 14285000/24576000\n",
      "current iter: 14286000/24576000\n",
      "current iter: 14287000/24576000\n",
      "current iter: 14288000/24576000\n",
      "current iter: 14289000/24576000\n",
      "current iter: 14290000/24576000\n",
      "current iter: 14291000/24576000\n",
      "current iter: 14292000/24576000\n",
      "current iter: 14293000/24576000\n",
      "current iter: 14294000/24576000\n",
      "current iter: 14295000/24576000\n",
      "current iter: 14296000/24576000\n",
      "current iter: 14297000/24576000\n",
      "current iter: 14298000/24576000\n",
      "current iter: 14299000/24576000\n",
      "current iter: 14300000/24576000\n",
      "current iter: 14301000/24576000\n",
      "current iter: 14302000/24576000\n",
      "current iter: 14303000/24576000\n",
      "current iter: 14304000/24576000\n",
      "current iter: 14305000/24576000\n",
      "current iter: 14306000/24576000\n",
      "current iter: 14307000/24576000\n",
      "current iter: 14308000/24576000\n",
      "current iter: 14309000/24576000\n",
      "current iter: 14310000/24576000\n",
      "current iter: 14311000/24576000\n",
      "current iter: 14312000/24576000\n",
      "current iter: 14313000/24576000\n",
      "current iter: 14314000/24576000\n",
      "current iter: 14315000/24576000\n",
      "current iter: 14316000/24576000\n",
      "current iter: 14317000/24576000\n",
      "current iter: 14318000/24576000\n",
      "current iter: 14319000/24576000\n",
      "current iter: 14320000/24576000\n",
      "current iter: 14321000/24576000\n",
      "current iter: 14322000/24576000\n",
      "current iter: 14323000/24576000\n",
      "current iter: 14324000/24576000\n",
      "current iter: 14325000/24576000\n",
      "current iter: 14326000/24576000\n",
      "current iter: 14327000/24576000\n",
      "current iter: 14328000/24576000\n",
      "current iter: 14329000/24576000\n",
      "current iter: 14330000/24576000\n",
      "current iter: 14331000/24576000\n",
      "current iter: 14332000/24576000\n",
      "current iter: 14333000/24576000\n",
      "current iter: 14334000/24576000\n",
      "current iter: 14335000/24576000\n",
      "current iter: 14336000/24576000\n",
      "current iter: 14337000/24576000\n",
      "current iter: 14338000/24576000\n",
      "current iter: 14339000/24576000\n",
      "current iter: 14340000/24576000\n",
      "current iter: 14341000/24576000\n",
      "current iter: 14342000/24576000\n",
      "current iter: 14343000/24576000\n",
      "current iter: 14344000/24576000\n",
      "current iter: 14345000/24576000\n",
      "current iter: 14346000/24576000\n",
      "current iter: 14347000/24576000\n",
      "current iter: 14348000/24576000\n",
      "current iter: 14349000/24576000\n",
      "current iter: 14350000/24576000\n",
      "current iter: 14351000/24576000\n",
      "current iter: 14352000/24576000\n",
      "current iter: 14353000/24576000\n",
      "current iter: 14354000/24576000\n",
      "current iter: 14355000/24576000\n",
      "current iter: 14356000/24576000\n",
      "current iter: 14357000/24576000\n",
      "current iter: 14358000/24576000\n",
      "current iter: 14359000/24576000\n",
      "current iter: 14360000/24576000\n",
      "current iter: 14361000/24576000\n",
      "current iter: 14362000/24576000\n",
      "current iter: 14363000/24576000\n",
      "current iter: 14364000/24576000\n",
      "current iter: 14365000/24576000\n",
      "current iter: 14366000/24576000\n",
      "current iter: 14367000/24576000\n",
      "current iter: 14368000/24576000\n",
      "current iter: 14369000/24576000\n",
      "current iter: 14370000/24576000\n",
      "current iter: 14371000/24576000\n",
      "current iter: 14372000/24576000\n",
      "current iter: 14373000/24576000\n",
      "current iter: 14374000/24576000\n",
      "current iter: 14375000/24576000\n",
      "current iter: 14376000/24576000\n",
      "current iter: 14377000/24576000\n",
      "current iter: 14378000/24576000\n",
      "current iter: 14379000/24576000\n",
      "current iter: 14380000/24576000\n",
      "current iter: 14381000/24576000\n",
      "current iter: 14382000/24576000\n",
      "current iter: 14383000/24576000\n",
      "current iter: 14384000/24576000\n",
      "current iter: 14385000/24576000\n",
      "current iter: 14386000/24576000\n",
      "current iter: 14387000/24576000\n",
      "current iter: 14388000/24576000\n",
      "current iter: 14389000/24576000\n",
      "current iter: 14390000/24576000\n",
      "current iter: 14391000/24576000\n",
      "current iter: 14392000/24576000\n",
      "current iter: 14393000/24576000\n",
      "current iter: 14394000/24576000\n",
      "current iter: 14395000/24576000\n",
      "current iter: 14396000/24576000\n",
      "current iter: 14397000/24576000\n",
      "current iter: 14398000/24576000\n",
      "current iter: 14399000/24576000\n",
      "current iter: 14400000/24576000\n",
      "current iter: 14401000/24576000\n",
      "current iter: 14402000/24576000\n",
      "current iter: 14403000/24576000\n",
      "current iter: 14404000/24576000\n",
      "current iter: 14405000/24576000\n",
      "current iter: 14406000/24576000\n",
      "current iter: 14407000/24576000\n",
      "current iter: 14408000/24576000\n",
      "current iter: 14409000/24576000\n",
      "current iter: 14410000/24576000\n",
      "current iter: 14411000/24576000\n",
      "current iter: 14412000/24576000\n",
      "current iter: 14413000/24576000\n",
      "current iter: 14414000/24576000\n",
      "current iter: 14415000/24576000\n",
      "current iter: 14416000/24576000\n",
      "current iter: 14417000/24576000\n",
      "current iter: 14418000/24576000\n",
      "current iter: 14419000/24576000\n",
      "current iter: 14420000/24576000\n",
      "current iter: 14421000/24576000\n",
      "current iter: 14422000/24576000\n",
      "current iter: 14423000/24576000\n",
      "current iter: 14424000/24576000\n",
      "current iter: 14425000/24576000\n",
      "current iter: 14426000/24576000\n",
      "current iter: 14427000/24576000\n",
      "current iter: 14428000/24576000\n",
      "current iter: 14429000/24576000\n",
      "current iter: 14430000/24576000\n",
      "current iter: 14431000/24576000\n",
      "current iter: 14432000/24576000\n",
      "current iter: 14433000/24576000\n",
      "current iter: 14434000/24576000\n",
      "current iter: 14435000/24576000\n",
      "current iter: 14436000/24576000\n",
      "current iter: 14437000/24576000\n",
      "current iter: 14438000/24576000\n",
      "current iter: 14439000/24576000\n",
      "current iter: 14440000/24576000\n",
      "current iter: 14441000/24576000\n",
      "current iter: 14442000/24576000\n",
      "current iter: 14443000/24576000\n",
      "current iter: 14444000/24576000\n",
      "current iter: 14445000/24576000\n",
      "current iter: 14446000/24576000\n",
      "current iter: 14447000/24576000\n",
      "current iter: 14448000/24576000\n",
      "current iter: 14449000/24576000\n",
      "current iter: 14450000/24576000\n",
      "current iter: 14451000/24576000\n",
      "current iter: 14452000/24576000\n",
      "current iter: 14453000/24576000\n",
      "current iter: 14454000/24576000\n",
      "current iter: 14455000/24576000\n",
      "current iter: 14456000/24576000\n",
      "current iter: 14457000/24576000\n",
      "current iter: 14458000/24576000\n",
      "current iter: 14459000/24576000\n",
      "current iter: 14460000/24576000\n",
      "current iter: 14461000/24576000\n",
      "current iter: 14462000/24576000\n",
      "current iter: 14463000/24576000\n",
      "current iter: 14464000/24576000\n",
      "current iter: 14465000/24576000\n",
      "current iter: 14466000/24576000\n",
      "current iter: 14467000/24576000\n",
      "current iter: 14468000/24576000\n",
      "current iter: 14469000/24576000\n",
      "current iter: 14470000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 14471000/24576000\n",
      "current iter: 14472000/24576000\n",
      "current iter: 14473000/24576000\n",
      "current iter: 14474000/24576000\n",
      "current iter: 14475000/24576000\n",
      "current iter: 14476000/24576000\n",
      "current iter: 14477000/24576000\n",
      "current iter: 14478000/24576000\n",
      "current iter: 14479000/24576000\n",
      "current iter: 14480000/24576000\n",
      "current iter: 14481000/24576000\n",
      "current iter: 14482000/24576000\n",
      "current iter: 14483000/24576000\n",
      "current iter: 14484000/24576000\n",
      "current iter: 14485000/24576000\n",
      "current iter: 14486000/24576000\n",
      "current iter: 14487000/24576000\n",
      "current iter: 14488000/24576000\n",
      "current iter: 14489000/24576000\n",
      "current iter: 14490000/24576000\n",
      "current iter: 14491000/24576000\n",
      "current iter: 14492000/24576000\n",
      "current iter: 14493000/24576000\n",
      "current iter: 14494000/24576000\n",
      "current iter: 14495000/24576000\n",
      "current iter: 14496000/24576000\n",
      "current iter: 14497000/24576000\n",
      "current iter: 14498000/24576000\n",
      "current iter: 14499000/24576000\n",
      "current iter: 14500000/24576000\n",
      "current iter: 14501000/24576000\n",
      "current iter: 14502000/24576000\n",
      "current iter: 14503000/24576000\n",
      "current iter: 14504000/24576000\n",
      "current iter: 14505000/24576000\n",
      "current iter: 14506000/24576000\n",
      "current iter: 14507000/24576000\n",
      "current iter: 14508000/24576000\n",
      "current iter: 14509000/24576000\n",
      "current iter: 14510000/24576000\n",
      "current iter: 14511000/24576000\n",
      "current iter: 14512000/24576000\n",
      "current iter: 14513000/24576000\n",
      "current iter: 14514000/24576000\n",
      "current iter: 14515000/24576000\n",
      "current iter: 14516000/24576000\n",
      "current iter: 14517000/24576000\n",
      "current iter: 14518000/24576000\n",
      "current iter: 14519000/24576000\n",
      "current iter: 14520000/24576000\n",
      "current iter: 14521000/24576000\n",
      "current iter: 14522000/24576000\n",
      "current iter: 14523000/24576000\n",
      "current iter: 14524000/24576000\n",
      "current iter: 14525000/24576000\n",
      "current iter: 14526000/24576000\n",
      "current iter: 14527000/24576000\n",
      "current iter: 14528000/24576000\n",
      "current iter: 14529000/24576000\n",
      "current iter: 14530000/24576000\n",
      "current iter: 14531000/24576000\n",
      "current iter: 14532000/24576000\n",
      "current iter: 14533000/24576000\n",
      "current iter: 14534000/24576000\n",
      "current iter: 14535000/24576000\n",
      "current iter: 14536000/24576000\n",
      "current iter: 14537000/24576000\n",
      "current iter: 14538000/24576000\n",
      "current iter: 14539000/24576000\n",
      "current iter: 14540000/24576000\n",
      "current iter: 14541000/24576000\n",
      "current iter: 14542000/24576000\n",
      "current iter: 14543000/24576000\n",
      "current iter: 14544000/24576000\n",
      "current iter: 14545000/24576000\n",
      "current iter: 14546000/24576000\n",
      "current iter: 14547000/24576000\n",
      "current iter: 14548000/24576000\n",
      "current iter: 14549000/24576000\n",
      "current iter: 14550000/24576000\n",
      "current iter: 14551000/24576000\n",
      "current iter: 14552000/24576000\n",
      "current iter: 14553000/24576000\n",
      "current iter: 14554000/24576000\n",
      "current iter: 14555000/24576000\n",
      "current iter: 14556000/24576000\n",
      "current iter: 14557000/24576000\n",
      "current iter: 14558000/24576000\n",
      "current iter: 14559000/24576000\n",
      "current iter: 14560000/24576000\n",
      "current iter: 14561000/24576000\n",
      "current iter: 14562000/24576000\n",
      "current iter: 14563000/24576000\n",
      "current iter: 14564000/24576000\n",
      "current iter: 14565000/24576000\n",
      "current iter: 14566000/24576000\n",
      "current iter: 14567000/24576000\n",
      "current iter: 14568000/24576000\n",
      "current iter: 14569000/24576000\n",
      "current iter: 14570000/24576000\n",
      "current iter: 14571000/24576000\n",
      "current iter: 14572000/24576000\n",
      "current iter: 14573000/24576000\n",
      "current iter: 14574000/24576000\n",
      "current iter: 14575000/24576000\n",
      "current iter: 14576000/24576000\n",
      "current iter: 14577000/24576000\n",
      "current iter: 14578000/24576000\n",
      "current iter: 14579000/24576000\n",
      "current iter: 14580000/24576000\n",
      "current iter: 14581000/24576000\n",
      "current iter: 14582000/24576000\n",
      "current iter: 14583000/24576000\n",
      "current iter: 14584000/24576000\n",
      "current iter: 14585000/24576000\n",
      "current iter: 14586000/24576000\n",
      "current iter: 14587000/24576000\n",
      "current iter: 14588000/24576000\n",
      "current iter: 14589000/24576000\n",
      "current iter: 14590000/24576000\n",
      "current iter: 14591000/24576000\n",
      "current iter: 14592000/24576000\n",
      "current iter: 14593000/24576000\n",
      "current iter: 14594000/24576000\n",
      "current iter: 14595000/24576000\n",
      "current iter: 14596000/24576000\n",
      "current iter: 14597000/24576000\n",
      "current iter: 14598000/24576000\n",
      "current iter: 14599000/24576000\n",
      "current iter: 14600000/24576000\n",
      "current iter: 14601000/24576000\n",
      "current iter: 14602000/24576000\n",
      "current iter: 14603000/24576000\n",
      "current iter: 14604000/24576000\n",
      "current iter: 14605000/24576000\n",
      "current iter: 14606000/24576000\n",
      "current iter: 14607000/24576000\n",
      "current iter: 14608000/24576000\n",
      "current iter: 14609000/24576000\n",
      "current iter: 14610000/24576000\n",
      "current iter: 14611000/24576000\n",
      "current iter: 14612000/24576000\n",
      "current iter: 14613000/24576000\n",
      "current iter: 14614000/24576000\n",
      "current iter: 14615000/24576000\n",
      "current iter: 14616000/24576000\n",
      "current iter: 14617000/24576000\n",
      "current iter: 14618000/24576000\n",
      "current iter: 14619000/24576000\n",
      "current iter: 14620000/24576000\n",
      "current iter: 14621000/24576000\n",
      "current iter: 14622000/24576000\n",
      "current iter: 14623000/24576000\n",
      "current iter: 14624000/24576000\n",
      "current iter: 14625000/24576000\n",
      "current iter: 14626000/24576000\n",
      "current iter: 14627000/24576000\n",
      "current iter: 14628000/24576000\n",
      "current iter: 14629000/24576000\n",
      "current iter: 14630000/24576000\n",
      "current iter: 14631000/24576000\n",
      "current iter: 14632000/24576000\n",
      "current iter: 14633000/24576000\n",
      "current iter: 14634000/24576000\n",
      "current iter: 14635000/24576000\n",
      "current iter: 14636000/24576000\n",
      "current iter: 14637000/24576000\n",
      "current iter: 14638000/24576000\n",
      "current iter: 14639000/24576000\n",
      "current iter: 14640000/24576000\n",
      "current iter: 14641000/24576000\n",
      "current iter: 14642000/24576000\n",
      "current iter: 14643000/24576000\n",
      "current iter: 14644000/24576000\n",
      "current iter: 14645000/24576000\n",
      "current iter: 14646000/24576000\n",
      "current iter: 14647000/24576000\n",
      "current iter: 14648000/24576000\n",
      "current iter: 14649000/24576000\n",
      "current iter: 14650000/24576000\n",
      "current iter: 14651000/24576000\n",
      "current iter: 14652000/24576000\n",
      "current iter: 14653000/24576000\n",
      "current iter: 14654000/24576000\n",
      "current iter: 14655000/24576000\n",
      "current iter: 14656000/24576000\n",
      "current iter: 14657000/24576000\n",
      "current iter: 14658000/24576000\n",
      "current iter: 14659000/24576000\n",
      "current iter: 14660000/24576000\n",
      "current iter: 14661000/24576000\n",
      "current iter: 14662000/24576000\n",
      "current iter: 14663000/24576000\n",
      "current iter: 14664000/24576000\n",
      "current iter: 14665000/24576000\n",
      "current iter: 14666000/24576000\n",
      "current iter: 14667000/24576000\n",
      "current iter: 14668000/24576000\n",
      "current iter: 14669000/24576000\n",
      "current iter: 14670000/24576000\n",
      "current iter: 14671000/24576000\n",
      "current iter: 14672000/24576000\n",
      "current iter: 14673000/24576000\n",
      "current iter: 14674000/24576000\n",
      "current iter: 14675000/24576000\n",
      "current iter: 14676000/24576000\n",
      "current iter: 14677000/24576000\n",
      "current iter: 14678000/24576000\n",
      "current iter: 14679000/24576000\n",
      "current iter: 14680000/24576000\n",
      "current iter: 14681000/24576000\n",
      "current iter: 14682000/24576000\n",
      "current iter: 14683000/24576000\n",
      "current iter: 14684000/24576000\n",
      "current iter: 14685000/24576000\n",
      "current iter: 14686000/24576000\n",
      "current iter: 14687000/24576000\n",
      "current iter: 14688000/24576000\n",
      "current iter: 14689000/24576000\n",
      "current iter: 14690000/24576000\n",
      "current iter: 14691000/24576000\n",
      "current iter: 14692000/24576000\n",
      "current iter: 14693000/24576000\n",
      "current iter: 14694000/24576000\n",
      "current iter: 14695000/24576000\n",
      "current iter: 14696000/24576000\n",
      "current iter: 14697000/24576000\n",
      "current iter: 14698000/24576000\n",
      "current iter: 14699000/24576000\n",
      "current iter: 14700000/24576000\n",
      "current iter: 14701000/24576000\n",
      "current iter: 14702000/24576000\n",
      "current iter: 14703000/24576000\n",
      "current iter: 14704000/24576000\n",
      "current iter: 14705000/24576000\n",
      "current iter: 14706000/24576000\n",
      "current iter: 14707000/24576000\n",
      "current iter: 14708000/24576000\n",
      "current iter: 14709000/24576000\n",
      "current iter: 14710000/24576000\n",
      "current iter: 14711000/24576000\n",
      "current iter: 14712000/24576000\n",
      "current iter: 14713000/24576000\n",
      "current iter: 14714000/24576000\n",
      "current iter: 14715000/24576000\n",
      "current iter: 14716000/24576000\n",
      "current iter: 14717000/24576000\n",
      "current iter: 14718000/24576000\n",
      "current iter: 14719000/24576000\n",
      "current iter: 14720000/24576000\n",
      "current iter: 14721000/24576000\n",
      "current iter: 14722000/24576000\n",
      "current iter: 14723000/24576000\n",
      "current iter: 14724000/24576000\n",
      "current iter: 14725000/24576000\n",
      "current iter: 14726000/24576000\n",
      "current iter: 14727000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 14728000/24576000\n",
      "current iter: 14729000/24576000\n",
      "current iter: 14730000/24576000\n",
      "current iter: 14731000/24576000\n",
      "current iter: 14732000/24576000\n",
      "current iter: 14733000/24576000\n",
      "current iter: 14734000/24576000\n",
      "current iter: 14735000/24576000\n",
      "current iter: 14736000/24576000\n",
      "current iter: 14737000/24576000\n",
      "current iter: 14738000/24576000\n",
      "current iter: 14739000/24576000\n",
      "current iter: 14740000/24576000\n",
      "current iter: 14741000/24576000\n",
      "current iter: 14742000/24576000\n",
      "current iter: 14743000/24576000\n",
      "current iter: 14744000/24576000\n",
      "current iter: 14745000/24576000\n",
      "current iter: 14746000/24576000\n",
      "current iter: 14747000/24576000\n",
      "current iter: 14748000/24576000\n",
      "current iter: 14749000/24576000\n",
      "current iter: 14750000/24576000\n",
      "current iter: 14751000/24576000\n",
      "current iter: 14752000/24576000\n",
      "current iter: 14753000/24576000\n",
      "current iter: 14754000/24576000\n",
      "current iter: 14755000/24576000\n",
      "current iter: 14756000/24576000\n",
      "current iter: 14757000/24576000\n",
      "current iter: 14758000/24576000\n",
      "current iter: 14759000/24576000\n",
      "current iter: 14760000/24576000\n",
      "current iter: 14761000/24576000\n",
      "current iter: 14762000/24576000\n",
      "current iter: 14763000/24576000\n",
      "current iter: 14764000/24576000\n",
      "current iter: 14765000/24576000\n",
      "current iter: 14766000/24576000\n",
      "current iter: 14767000/24576000\n",
      "current iter: 14768000/24576000\n",
      "current iter: 14769000/24576000\n",
      "current iter: 14770000/24576000\n",
      "current iter: 14771000/24576000\n",
      "current iter: 14772000/24576000\n",
      "current iter: 14773000/24576000\n",
      "current iter: 14774000/24576000\n",
      "current iter: 14775000/24576000\n",
      "current iter: 14776000/24576000\n",
      "current iter: 14777000/24576000\n",
      "current iter: 14778000/24576000\n",
      "current iter: 14779000/24576000\n",
      "current iter: 14780000/24576000\n",
      "current iter: 14781000/24576000\n",
      "current iter: 14782000/24576000\n",
      "current iter: 14783000/24576000\n",
      "current iter: 14784000/24576000\n",
      "current iter: 14785000/24576000\n",
      "current iter: 14786000/24576000\n",
      "current iter: 14787000/24576000\n",
      "current iter: 14788000/24576000\n",
      "current iter: 14789000/24576000\n",
      "current iter: 14790000/24576000\n",
      "current iter: 14791000/24576000\n",
      "current iter: 14792000/24576000\n",
      "current iter: 14793000/24576000\n",
      "current iter: 14794000/24576000\n",
      "current iter: 14795000/24576000\n",
      "current iter: 14796000/24576000\n",
      "current iter: 14797000/24576000\n",
      "current iter: 14798000/24576000\n",
      "current iter: 14799000/24576000\n",
      "current iter: 14800000/24576000\n",
      "current iter: 14801000/24576000\n",
      "current iter: 14802000/24576000\n",
      "current iter: 14803000/24576000\n",
      "current iter: 14804000/24576000\n",
      "current iter: 14805000/24576000\n",
      "current iter: 14806000/24576000\n",
      "current iter: 14807000/24576000\n",
      "current iter: 14808000/24576000\n",
      "current iter: 14809000/24576000\n",
      "current iter: 14810000/24576000\n",
      "current iter: 14811000/24576000\n",
      "current iter: 14812000/24576000\n",
      "current iter: 14813000/24576000\n",
      "current iter: 14814000/24576000\n",
      "current iter: 14815000/24576000\n",
      "current iter: 14816000/24576000\n",
      "current iter: 14817000/24576000\n",
      "current iter: 14818000/24576000\n",
      "current iter: 14819000/24576000\n",
      "current iter: 14820000/24576000\n",
      "current iter: 14821000/24576000\n",
      "current iter: 14822000/24576000\n",
      "current iter: 14823000/24576000\n",
      "current iter: 14824000/24576000\n",
      "current iter: 14825000/24576000\n",
      "current iter: 14826000/24576000\n",
      "current iter: 14827000/24576000\n",
      "current iter: 14828000/24576000\n",
      "current iter: 14829000/24576000\n",
      "current iter: 14830000/24576000\n",
      "current iter: 14831000/24576000\n",
      "current iter: 14832000/24576000\n",
      "current iter: 14833000/24576000\n",
      "current iter: 14834000/24576000\n",
      "current iter: 14835000/24576000\n",
      "current iter: 14836000/24576000\n",
      "current iter: 14837000/24576000\n",
      "current iter: 14838000/24576000\n",
      "current iter: 14839000/24576000\n",
      "current iter: 14840000/24576000\n",
      "current iter: 14841000/24576000\n",
      "current iter: 14842000/24576000\n",
      "current iter: 14843000/24576000\n",
      "current iter: 14844000/24576000\n",
      "current iter: 14845000/24576000\n",
      "current iter: 14846000/24576000\n",
      "current iter: 14847000/24576000\n",
      "current iter: 14848000/24576000\n",
      "current iter: 14849000/24576000\n",
      "current iter: 14850000/24576000\n",
      "current iter: 14851000/24576000\n",
      "current iter: 14852000/24576000\n",
      "current iter: 14853000/24576000\n",
      "current iter: 14854000/24576000\n",
      "current iter: 14855000/24576000\n",
      "current iter: 14856000/24576000\n",
      "current iter: 14857000/24576000\n",
      "current iter: 14858000/24576000\n",
      "current iter: 14859000/24576000\n",
      "current iter: 14860000/24576000\n",
      "current iter: 14861000/24576000\n",
      "current iter: 14862000/24576000\n",
      "current iter: 14863000/24576000\n",
      "current iter: 14864000/24576000\n",
      "current iter: 14865000/24576000\n",
      "current iter: 14866000/24576000\n",
      "current iter: 14867000/24576000\n",
      "current iter: 14868000/24576000\n",
      "current iter: 14869000/24576000\n",
      "current iter: 14870000/24576000\n",
      "current iter: 14871000/24576000\n",
      "current iter: 14872000/24576000\n",
      "current iter: 14873000/24576000\n",
      "current iter: 14874000/24576000\n",
      "current iter: 14875000/24576000\n",
      "current iter: 14876000/24576000\n",
      "current iter: 14877000/24576000\n",
      "current iter: 14878000/24576000\n",
      "current iter: 14879000/24576000\n",
      "current iter: 14880000/24576000\n",
      "current iter: 14881000/24576000\n",
      "current iter: 14882000/24576000\n",
      "current iter: 14883000/24576000\n",
      "current iter: 14884000/24576000\n",
      "current iter: 14885000/24576000\n",
      "current iter: 14886000/24576000\n",
      "current iter: 14887000/24576000\n",
      "current iter: 14888000/24576000\n",
      "current iter: 14889000/24576000\n",
      "current iter: 14890000/24576000\n",
      "current iter: 14891000/24576000\n",
      "current iter: 14892000/24576000\n",
      "current iter: 14893000/24576000\n",
      "current iter: 14894000/24576000\n",
      "current iter: 14895000/24576000\n",
      "current iter: 14896000/24576000\n",
      "current iter: 14897000/24576000\n",
      "current iter: 14898000/24576000\n",
      "current iter: 14899000/24576000\n",
      "current iter: 14900000/24576000\n",
      "current iter: 14901000/24576000\n",
      "current iter: 14902000/24576000\n",
      "current iter: 14903000/24576000\n",
      "current iter: 14904000/24576000\n",
      "current iter: 14905000/24576000\n",
      "current iter: 14906000/24576000\n",
      "current iter: 14907000/24576000\n",
      "current iter: 14908000/24576000\n",
      "current iter: 14909000/24576000\n",
      "current iter: 14910000/24576000\n",
      "current iter: 14911000/24576000\n",
      "current iter: 14912000/24576000\n",
      "current iter: 14913000/24576000\n",
      "current iter: 14914000/24576000\n",
      "current iter: 14915000/24576000\n",
      "current iter: 14916000/24576000\n",
      "current iter: 14917000/24576000\n",
      "current iter: 14918000/24576000\n",
      "current iter: 14919000/24576000\n",
      "current iter: 14920000/24576000\n",
      "current iter: 14921000/24576000\n",
      "current iter: 14922000/24576000\n",
      "current iter: 14923000/24576000\n",
      "current iter: 14924000/24576000\n",
      "current iter: 14925000/24576000\n",
      "current iter: 14926000/24576000\n",
      "current iter: 14927000/24576000\n",
      "current iter: 14928000/24576000\n",
      "current iter: 14929000/24576000\n",
      "current iter: 14930000/24576000\n",
      "current iter: 14931000/24576000\n",
      "current iter: 14932000/24576000\n",
      "current iter: 14933000/24576000\n",
      "current iter: 14934000/24576000\n",
      "current iter: 14935000/24576000\n",
      "current iter: 14936000/24576000\n",
      "current iter: 14937000/24576000\n",
      "current iter: 14938000/24576000\n",
      "current iter: 14939000/24576000\n",
      "current iter: 14940000/24576000\n",
      "current iter: 14941000/24576000\n",
      "current iter: 14942000/24576000\n",
      "current iter: 14943000/24576000\n",
      "current iter: 14944000/24576000\n",
      "current iter: 14945000/24576000\n",
      "current iter: 14946000/24576000\n",
      "current iter: 14947000/24576000\n",
      "current iter: 14948000/24576000\n",
      "current iter: 14949000/24576000\n",
      "current iter: 14950000/24576000\n",
      "current iter: 14951000/24576000\n",
      "current iter: 14952000/24576000\n",
      "current iter: 14953000/24576000\n",
      "current iter: 14954000/24576000\n",
      "current iter: 14955000/24576000\n",
      "current iter: 14956000/24576000\n",
      "current iter: 14957000/24576000\n",
      "current iter: 14958000/24576000\n",
      "current iter: 14959000/24576000\n",
      "current iter: 14960000/24576000\n",
      "current iter: 14961000/24576000\n",
      "current iter: 14962000/24576000\n",
      "current iter: 14963000/24576000\n",
      "current iter: 14964000/24576000\n",
      "current iter: 14965000/24576000\n",
      "current iter: 14966000/24576000\n",
      "current iter: 14967000/24576000\n",
      "current iter: 14968000/24576000\n",
      "current iter: 14969000/24576000\n",
      "current iter: 14970000/24576000\n",
      "current iter: 14971000/24576000\n",
      "current iter: 14972000/24576000\n",
      "current iter: 14973000/24576000\n",
      "current iter: 14974000/24576000\n",
      "current iter: 14975000/24576000\n",
      "current iter: 14976000/24576000\n",
      "current iter: 14977000/24576000\n",
      "current iter: 14978000/24576000\n",
      "current iter: 14979000/24576000\n",
      "current iter: 14980000/24576000\n",
      "current iter: 14981000/24576000\n",
      "current iter: 14982000/24576000\n",
      "current iter: 14983000/24576000\n",
      "current iter: 14984000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 14985000/24576000\n",
      "current iter: 14986000/24576000\n",
      "current iter: 14987000/24576000\n",
      "current iter: 14988000/24576000\n",
      "current iter: 14989000/24576000\n",
      "current iter: 14990000/24576000\n",
      "current iter: 14991000/24576000\n",
      "current iter: 14992000/24576000\n",
      "current iter: 14993000/24576000\n",
      "current iter: 14994000/24576000\n",
      "current iter: 14995000/24576000\n",
      "current iter: 14996000/24576000\n",
      "current iter: 14997000/24576000\n",
      "current iter: 14998000/24576000\n",
      "current iter: 14999000/24576000\n",
      "current iter: 15000000/24576000\n",
      "current iter: 15001000/24576000\n",
      "current iter: 15002000/24576000\n",
      "current iter: 15003000/24576000\n",
      "current iter: 15004000/24576000\n",
      "current iter: 15005000/24576000\n",
      "current iter: 15006000/24576000\n",
      "current iter: 15007000/24576000\n",
      "current iter: 15008000/24576000\n",
      "current iter: 15009000/24576000\n",
      "current iter: 15010000/24576000\n",
      "current iter: 15011000/24576000\n",
      "current iter: 15012000/24576000\n",
      "current iter: 15013000/24576000\n",
      "current iter: 15014000/24576000\n",
      "current iter: 15015000/24576000\n",
      "current iter: 15016000/24576000\n",
      "current iter: 15017000/24576000\n",
      "current iter: 15018000/24576000\n",
      "current iter: 15019000/24576000\n",
      "current iter: 15020000/24576000\n",
      "current iter: 15021000/24576000\n",
      "current iter: 15022000/24576000\n",
      "current iter: 15023000/24576000\n",
      "current iter: 15024000/24576000\n",
      "current iter: 15025000/24576000\n",
      "current iter: 15026000/24576000\n",
      "current iter: 15027000/24576000\n",
      "current iter: 15028000/24576000\n",
      "current iter: 15029000/24576000\n",
      "current iter: 15030000/24576000\n",
      "current iter: 15031000/24576000\n",
      "current iter: 15032000/24576000\n",
      "current iter: 15033000/24576000\n",
      "current iter: 15034000/24576000\n",
      "current iter: 15035000/24576000\n",
      "current iter: 15036000/24576000\n",
      "current iter: 15037000/24576000\n",
      "current iter: 15038000/24576000\n",
      "current iter: 15039000/24576000\n",
      "current iter: 15040000/24576000\n",
      "current iter: 15041000/24576000\n",
      "current iter: 15042000/24576000\n",
      "current iter: 15043000/24576000\n",
      "current iter: 15044000/24576000\n",
      "current iter: 15045000/24576000\n",
      "current iter: 15046000/24576000\n",
      "current iter: 15047000/24576000\n",
      "current iter: 15048000/24576000\n",
      "current iter: 15049000/24576000\n",
      "current iter: 15050000/24576000\n",
      "current iter: 15051000/24576000\n",
      "current iter: 15052000/24576000\n",
      "current iter: 15053000/24576000\n",
      "current iter: 15054000/24576000\n",
      "current iter: 15055000/24576000\n",
      "current iter: 15056000/24576000\n",
      "current iter: 15057000/24576000\n",
      "current iter: 15058000/24576000\n",
      "current iter: 15059000/24576000\n",
      "current iter: 15060000/24576000\n",
      "current iter: 15061000/24576000\n",
      "current iter: 15062000/24576000\n",
      "current iter: 15063000/24576000\n",
      "current iter: 15064000/24576000\n",
      "current iter: 15065000/24576000\n",
      "current iter: 15066000/24576000\n",
      "current iter: 15067000/24576000\n",
      "current iter: 15068000/24576000\n",
      "current iter: 15069000/24576000\n",
      "current iter: 15070000/24576000\n",
      "current iter: 15071000/24576000\n",
      "current iter: 15072000/24576000\n",
      "current iter: 15073000/24576000\n",
      "current iter: 15074000/24576000\n",
      "current iter: 15075000/24576000\n",
      "current iter: 15076000/24576000\n",
      "current iter: 15077000/24576000\n",
      "current iter: 15078000/24576000\n",
      "current iter: 15079000/24576000\n",
      "current iter: 15080000/24576000\n",
      "current iter: 15081000/24576000\n",
      "current iter: 15082000/24576000\n",
      "current iter: 15083000/24576000\n",
      "current iter: 15084000/24576000\n",
      "current iter: 15085000/24576000\n",
      "current iter: 15086000/24576000\n",
      "current iter: 15087000/24576000\n",
      "current iter: 15088000/24576000\n",
      "current iter: 15089000/24576000\n",
      "current iter: 15090000/24576000\n",
      "current iter: 15091000/24576000\n",
      "current iter: 15092000/24576000\n",
      "current iter: 15093000/24576000\n",
      "current iter: 15094000/24576000\n",
      "current iter: 15095000/24576000\n",
      "current iter: 15096000/24576000\n",
      "current iter: 15097000/24576000\n",
      "current iter: 15098000/24576000\n",
      "current iter: 15099000/24576000\n",
      "current iter: 15100000/24576000\n",
      "current iter: 15101000/24576000\n",
      "current iter: 15102000/24576000\n",
      "current iter: 15103000/24576000\n",
      "current iter: 15104000/24576000\n",
      "current iter: 15105000/24576000\n",
      "current iter: 15106000/24576000\n",
      "current iter: 15107000/24576000\n",
      "current iter: 15108000/24576000\n",
      "current iter: 15109000/24576000\n",
      "current iter: 15110000/24576000\n",
      "current iter: 15111000/24576000\n",
      "current iter: 15112000/24576000\n",
      "current iter: 15113000/24576000\n",
      "current iter: 15114000/24576000\n",
      "current iter: 15115000/24576000\n",
      "current iter: 15116000/24576000\n",
      "current iter: 15117000/24576000\n",
      "current iter: 15118000/24576000\n",
      "current iter: 15119000/24576000\n",
      "current iter: 15120000/24576000\n",
      "current iter: 15121000/24576000\n",
      "current iter: 15122000/24576000\n",
      "current iter: 15123000/24576000\n",
      "current iter: 15124000/24576000\n",
      "current iter: 15125000/24576000\n",
      "current iter: 15126000/24576000\n",
      "current iter: 15127000/24576000\n",
      "current iter: 15128000/24576000\n",
      "current iter: 15129000/24576000\n",
      "current iter: 15130000/24576000\n",
      "current iter: 15131000/24576000\n",
      "current iter: 15132000/24576000\n",
      "current iter: 15133000/24576000\n",
      "current iter: 15134000/24576000\n",
      "current iter: 15135000/24576000\n",
      "current iter: 15136000/24576000\n",
      "current iter: 15137000/24576000\n",
      "current iter: 15138000/24576000\n",
      "current iter: 15139000/24576000\n",
      "current iter: 15140000/24576000\n",
      "current iter: 15141000/24576000\n",
      "current iter: 15142000/24576000\n",
      "current iter: 15143000/24576000\n",
      "current iter: 15144000/24576000\n",
      "current iter: 15145000/24576000\n",
      "current iter: 15146000/24576000\n",
      "current iter: 15147000/24576000\n",
      "current iter: 15148000/24576000\n",
      "current iter: 15149000/24576000\n",
      "current iter: 15150000/24576000\n",
      "current iter: 15151000/24576000\n",
      "current iter: 15152000/24576000\n",
      "current iter: 15153000/24576000\n",
      "current iter: 15154000/24576000\n",
      "current iter: 15155000/24576000\n",
      "current iter: 15156000/24576000\n",
      "current iter: 15157000/24576000\n",
      "current iter: 15158000/24576000\n",
      "current iter: 15159000/24576000\n",
      "current iter: 15160000/24576000\n",
      "current iter: 15161000/24576000\n",
      "current iter: 15162000/24576000\n",
      "current iter: 15163000/24576000\n",
      "current iter: 15164000/24576000\n",
      "current iter: 15165000/24576000\n",
      "current iter: 15166000/24576000\n",
      "current iter: 15167000/24576000\n",
      "current iter: 15168000/24576000\n",
      "current iter: 15169000/24576000\n",
      "current iter: 15170000/24576000\n",
      "current iter: 15171000/24576000\n",
      "current iter: 15172000/24576000\n",
      "current iter: 15173000/24576000\n",
      "current iter: 15174000/24576000\n",
      "current iter: 15175000/24576000\n",
      "current iter: 15176000/24576000\n",
      "current iter: 15177000/24576000\n",
      "current iter: 15178000/24576000\n",
      "current iter: 15179000/24576000\n",
      "current iter: 15180000/24576000\n",
      "current iter: 15181000/24576000\n",
      "current iter: 15182000/24576000\n",
      "current iter: 15183000/24576000\n",
      "current iter: 15184000/24576000\n",
      "current iter: 15185000/24576000\n",
      "current iter: 15186000/24576000\n",
      "current iter: 15187000/24576000\n",
      "current iter: 15188000/24576000\n",
      "current iter: 15189000/24576000\n",
      "current iter: 15190000/24576000\n",
      "current iter: 15191000/24576000\n",
      "current iter: 15192000/24576000\n",
      "current iter: 15193000/24576000\n",
      "current iter: 15194000/24576000\n",
      "current iter: 15195000/24576000\n",
      "current iter: 15196000/24576000\n",
      "current iter: 15197000/24576000\n",
      "current iter: 15198000/24576000\n",
      "current iter: 15199000/24576000\n",
      "current iter: 15200000/24576000\n",
      "current iter: 15201000/24576000\n",
      "current iter: 15202000/24576000\n",
      "current iter: 15203000/24576000\n",
      "current iter: 15204000/24576000\n",
      "current iter: 15205000/24576000\n",
      "current iter: 15206000/24576000\n",
      "current iter: 15207000/24576000\n",
      "current iter: 15208000/24576000\n",
      "current iter: 15209000/24576000\n",
      "current iter: 15210000/24576000\n",
      "current iter: 15211000/24576000\n",
      "current iter: 15212000/24576000\n",
      "current iter: 15213000/24576000\n",
      "current iter: 15214000/24576000\n",
      "current iter: 15215000/24576000\n",
      "current iter: 15216000/24576000\n",
      "current iter: 15217000/24576000\n",
      "current iter: 15218000/24576000\n",
      "current iter: 15219000/24576000\n",
      "current iter: 15220000/24576000\n",
      "current iter: 15221000/24576000\n",
      "current iter: 15222000/24576000\n",
      "current iter: 15223000/24576000\n",
      "current iter: 15224000/24576000\n",
      "current iter: 15225000/24576000\n",
      "current iter: 15226000/24576000\n",
      "current iter: 15227000/24576000\n",
      "current iter: 15228000/24576000\n",
      "current iter: 15229000/24576000\n",
      "current iter: 15230000/24576000\n",
      "current iter: 15231000/24576000\n",
      "current iter: 15232000/24576000\n",
      "current iter: 15233000/24576000\n",
      "current iter: 15234000/24576000\n",
      "current iter: 15235000/24576000\n",
      "current iter: 15236000/24576000\n",
      "current iter: 15237000/24576000\n",
      "current iter: 15238000/24576000\n",
      "current iter: 15239000/24576000\n",
      "current iter: 15240000/24576000\n",
      "current iter: 15241000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 15242000/24576000\n",
      "current iter: 15243000/24576000\n",
      "current iter: 15244000/24576000\n",
      "current iter: 15245000/24576000\n",
      "current iter: 15246000/24576000\n",
      "current iter: 15247000/24576000\n",
      "current iter: 15248000/24576000\n",
      "current iter: 15249000/24576000\n",
      "current iter: 15250000/24576000\n",
      "current iter: 15251000/24576000\n",
      "current iter: 15252000/24576000\n",
      "current iter: 15253000/24576000\n",
      "current iter: 15254000/24576000\n",
      "current iter: 15255000/24576000\n",
      "current iter: 15256000/24576000\n",
      "current iter: 15257000/24576000\n",
      "current iter: 15258000/24576000\n",
      "current iter: 15259000/24576000\n",
      "current iter: 15260000/24576000\n",
      "current iter: 15261000/24576000\n",
      "current iter: 15262000/24576000\n",
      "current iter: 15263000/24576000\n",
      "current iter: 15264000/24576000\n",
      "current iter: 15265000/24576000\n",
      "current iter: 15266000/24576000\n",
      "current iter: 15267000/24576000\n",
      "current iter: 15268000/24576000\n",
      "current iter: 15269000/24576000\n",
      "current iter: 15270000/24576000\n",
      "current iter: 15271000/24576000\n",
      "current iter: 15272000/24576000\n",
      "current iter: 15273000/24576000\n",
      "current iter: 15274000/24576000\n",
      "current iter: 15275000/24576000\n",
      "current iter: 15276000/24576000\n",
      "current iter: 15277000/24576000\n",
      "current iter: 15278000/24576000\n",
      "current iter: 15279000/24576000\n",
      "current iter: 15280000/24576000\n",
      "current iter: 15281000/24576000\n",
      "current iter: 15282000/24576000\n",
      "current iter: 15283000/24576000\n",
      "current iter: 15284000/24576000\n",
      "current iter: 15285000/24576000\n",
      "current iter: 15286000/24576000\n",
      "current iter: 15287000/24576000\n",
      "current iter: 15288000/24576000\n",
      "current iter: 15289000/24576000\n",
      "current iter: 15290000/24576000\n",
      "current iter: 15291000/24576000\n",
      "current iter: 15292000/24576000\n",
      "current iter: 15293000/24576000\n",
      "current iter: 15294000/24576000\n",
      "current iter: 15295000/24576000\n",
      "current iter: 15296000/24576000\n",
      "current iter: 15297000/24576000\n",
      "current iter: 15298000/24576000\n",
      "current iter: 15299000/24576000\n",
      "current iter: 15300000/24576000\n",
      "current iter: 15301000/24576000\n",
      "current iter: 15302000/24576000\n",
      "current iter: 15303000/24576000\n",
      "current iter: 15304000/24576000\n",
      "current iter: 15305000/24576000\n",
      "current iter: 15306000/24576000\n",
      "current iter: 15307000/24576000\n",
      "current iter: 15308000/24576000\n",
      "current iter: 15309000/24576000\n",
      "current iter: 15310000/24576000\n",
      "current iter: 15311000/24576000\n",
      "current iter: 15312000/24576000\n",
      "current iter: 15313000/24576000\n",
      "current iter: 15314000/24576000\n",
      "current iter: 15315000/24576000\n",
      "current iter: 15316000/24576000\n",
      "current iter: 15317000/24576000\n",
      "current iter: 15318000/24576000\n",
      "current iter: 15319000/24576000\n",
      "current iter: 15320000/24576000\n",
      "current iter: 15321000/24576000\n",
      "current iter: 15322000/24576000\n",
      "current iter: 15323000/24576000\n",
      "current iter: 15324000/24576000\n",
      "current iter: 15325000/24576000\n",
      "current iter: 15326000/24576000\n",
      "current iter: 15327000/24576000\n",
      "current iter: 15328000/24576000\n",
      "current iter: 15329000/24576000\n",
      "current iter: 15330000/24576000\n",
      "current iter: 15331000/24576000\n",
      "current iter: 15332000/24576000\n",
      "current iter: 15333000/24576000\n",
      "current iter: 15334000/24576000\n",
      "current iter: 15335000/24576000\n",
      "current iter: 15336000/24576000\n",
      "current iter: 15337000/24576000\n",
      "current iter: 15338000/24576000\n",
      "current iter: 15339000/24576000\n",
      "current iter: 15340000/24576000\n",
      "current iter: 15341000/24576000\n",
      "current iter: 15342000/24576000\n",
      "current iter: 15343000/24576000\n",
      "current iter: 15344000/24576000\n",
      "current iter: 15345000/24576000\n",
      "current iter: 15346000/24576000\n",
      "current iter: 15347000/24576000\n",
      "current iter: 15348000/24576000\n",
      "current iter: 15349000/24576000\n",
      "current iter: 15350000/24576000\n",
      "current iter: 15351000/24576000\n",
      "current iter: 15352000/24576000\n",
      "current iter: 15353000/24576000\n",
      "current iter: 15354000/24576000\n",
      "current iter: 15355000/24576000\n",
      "current iter: 15356000/24576000\n",
      "current iter: 15357000/24576000\n",
      "current iter: 15358000/24576000\n",
      "current iter: 15359000/24576000\n",
      "current iter: 15360000/24576000\n",
      "current iter: 15361000/24576000\n",
      "current iter: 15362000/24576000\n",
      "current iter: 15363000/24576000\n",
      "current iter: 15364000/24576000\n",
      "current iter: 15365000/24576000\n",
      "current iter: 15366000/24576000\n",
      "current iter: 15367000/24576000\n",
      "current iter: 15368000/24576000\n",
      "current iter: 15369000/24576000\n",
      "current iter: 15370000/24576000\n",
      "current iter: 15371000/24576000\n",
      "current iter: 15372000/24576000\n",
      "current iter: 15373000/24576000\n",
      "current iter: 15374000/24576000\n",
      "current iter: 15375000/24576000\n",
      "current iter: 15376000/24576000\n",
      "current iter: 15377000/24576000\n",
      "current iter: 15378000/24576000\n",
      "current iter: 15379000/24576000\n",
      "current iter: 15380000/24576000\n",
      "current iter: 15381000/24576000\n",
      "current iter: 15382000/24576000\n",
      "current iter: 15383000/24576000\n",
      "current iter: 15384000/24576000\n",
      "current iter: 15385000/24576000\n",
      "current iter: 15386000/24576000\n",
      "current iter: 15387000/24576000\n",
      "current iter: 15388000/24576000\n",
      "current iter: 15389000/24576000\n",
      "current iter: 15390000/24576000\n",
      "current iter: 15391000/24576000\n",
      "current iter: 15392000/24576000\n",
      "current iter: 15393000/24576000\n",
      "current iter: 15394000/24576000\n",
      "current iter: 15395000/24576000\n",
      "current iter: 15396000/24576000\n",
      "current iter: 15397000/24576000\n",
      "current iter: 15398000/24576000\n",
      "current iter: 15399000/24576000\n",
      "current iter: 15400000/24576000\n",
      "current iter: 15401000/24576000\n",
      "current iter: 15402000/24576000\n",
      "current iter: 15403000/24576000\n",
      "current iter: 15404000/24576000\n",
      "current iter: 15405000/24576000\n",
      "current iter: 15406000/24576000\n",
      "current iter: 15407000/24576000\n",
      "current iter: 15408000/24576000\n",
      "current iter: 15409000/24576000\n",
      "current iter: 15410000/24576000\n",
      "current iter: 15411000/24576000\n",
      "current iter: 15412000/24576000\n",
      "current iter: 15413000/24576000\n",
      "current iter: 15414000/24576000\n",
      "current iter: 15415000/24576000\n",
      "current iter: 15416000/24576000\n",
      "current iter: 15417000/24576000\n",
      "current iter: 15418000/24576000\n",
      "current iter: 15419000/24576000\n",
      "current iter: 15420000/24576000\n",
      "current iter: 15421000/24576000\n",
      "current iter: 15422000/24576000\n",
      "current iter: 15423000/24576000\n",
      "current iter: 15424000/24576000\n",
      "current iter: 15425000/24576000\n",
      "current iter: 15426000/24576000\n",
      "current iter: 15427000/24576000\n",
      "current iter: 15428000/24576000\n",
      "current iter: 15429000/24576000\n",
      "current iter: 15430000/24576000\n",
      "current iter: 15431000/24576000\n",
      "current iter: 15432000/24576000\n",
      "current iter: 15433000/24576000\n",
      "current iter: 15434000/24576000\n",
      "current iter: 15435000/24576000\n",
      "current iter: 15436000/24576000\n",
      "current iter: 15437000/24576000\n",
      "current iter: 15438000/24576000\n",
      "current iter: 15439000/24576000\n",
      "current iter: 15440000/24576000\n",
      "current iter: 15441000/24576000\n",
      "current iter: 15442000/24576000\n",
      "current iter: 15443000/24576000\n",
      "current iter: 15444000/24576000\n",
      "current iter: 15445000/24576000\n",
      "current iter: 15446000/24576000\n",
      "current iter: 15447000/24576000\n",
      "current iter: 15448000/24576000\n",
      "current iter: 15449000/24576000\n",
      "current iter: 15450000/24576000\n",
      "current iter: 15451000/24576000\n",
      "current iter: 15452000/24576000\n",
      "current iter: 15453000/24576000\n",
      "current iter: 15454000/24576000\n",
      "current iter: 15455000/24576000\n",
      "current iter: 15456000/24576000\n",
      "current iter: 15457000/24576000\n",
      "current iter: 15458000/24576000\n",
      "current iter: 15459000/24576000\n",
      "current iter: 15460000/24576000\n",
      "current iter: 15461000/24576000\n",
      "current iter: 15462000/24576000\n",
      "current iter: 15463000/24576000\n",
      "current iter: 15464000/24576000\n",
      "current iter: 15465000/24576000\n",
      "current iter: 15466000/24576000\n",
      "current iter: 15467000/24576000\n",
      "current iter: 15468000/24576000\n",
      "current iter: 15469000/24576000\n",
      "current iter: 15470000/24576000\n",
      "current iter: 15471000/24576000\n",
      "current iter: 15472000/24576000\n",
      "current iter: 15473000/24576000\n",
      "current iter: 15474000/24576000\n",
      "current iter: 15475000/24576000\n",
      "current iter: 15476000/24576000\n",
      "current iter: 15477000/24576000\n",
      "current iter: 15478000/24576000\n",
      "current iter: 15479000/24576000\n",
      "current iter: 15480000/24576000\n",
      "current iter: 15481000/24576000\n",
      "current iter: 15482000/24576000\n",
      "current iter: 15483000/24576000\n",
      "current iter: 15484000/24576000\n",
      "current iter: 15485000/24576000\n",
      "current iter: 15486000/24576000\n",
      "current iter: 15487000/24576000\n",
      "current iter: 15488000/24576000\n",
      "current iter: 15489000/24576000\n",
      "current iter: 15490000/24576000\n",
      "current iter: 15491000/24576000\n",
      "current iter: 15492000/24576000\n",
      "current iter: 15493000/24576000\n",
      "current iter: 15494000/24576000\n",
      "current iter: 15495000/24576000\n",
      "current iter: 15496000/24576000\n",
      "current iter: 15497000/24576000\n",
      "current iter: 15498000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 15499000/24576000\n",
      "current iter: 15500000/24576000\n",
      "current iter: 15501000/24576000\n",
      "current iter: 15502000/24576000\n",
      "current iter: 15503000/24576000\n",
      "current iter: 15504000/24576000\n",
      "current iter: 15505000/24576000\n",
      "current iter: 15506000/24576000\n",
      "current iter: 15507000/24576000\n",
      "current iter: 15508000/24576000\n",
      "current iter: 15509000/24576000\n",
      "current iter: 15510000/24576000\n",
      "current iter: 15511000/24576000\n",
      "current iter: 15512000/24576000\n",
      "current iter: 15513000/24576000\n",
      "current iter: 15514000/24576000\n",
      "current iter: 15515000/24576000\n",
      "current iter: 15516000/24576000\n",
      "current iter: 15517000/24576000\n",
      "current iter: 15518000/24576000\n",
      "current iter: 15519000/24576000\n",
      "current iter: 15520000/24576000\n",
      "current iter: 15521000/24576000\n",
      "current iter: 15522000/24576000\n",
      "current iter: 15523000/24576000\n",
      "current iter: 15524000/24576000\n",
      "current iter: 15525000/24576000\n",
      "current iter: 15526000/24576000\n",
      "current iter: 15527000/24576000\n",
      "current iter: 15528000/24576000\n",
      "current iter: 15529000/24576000\n",
      "current iter: 15530000/24576000\n",
      "current iter: 15531000/24576000\n",
      "current iter: 15532000/24576000\n",
      "current iter: 15533000/24576000\n",
      "current iter: 15534000/24576000\n",
      "current iter: 15535000/24576000\n",
      "current iter: 15536000/24576000\n",
      "current iter: 15537000/24576000\n",
      "current iter: 15538000/24576000\n",
      "current iter: 15539000/24576000\n",
      "current iter: 15540000/24576000\n",
      "current iter: 15541000/24576000\n",
      "current iter: 15542000/24576000\n",
      "current iter: 15543000/24576000\n",
      "current iter: 15544000/24576000\n",
      "current iter: 15545000/24576000\n",
      "current iter: 15546000/24576000\n",
      "current iter: 15547000/24576000\n",
      "current iter: 15548000/24576000\n",
      "current iter: 15549000/24576000\n",
      "current iter: 15550000/24576000\n",
      "current iter: 15551000/24576000\n",
      "current iter: 15552000/24576000\n",
      "current iter: 15553000/24576000\n",
      "current iter: 15554000/24576000\n",
      "current iter: 15555000/24576000\n",
      "current iter: 15556000/24576000\n",
      "current iter: 15557000/24576000\n",
      "current iter: 15558000/24576000\n",
      "current iter: 15559000/24576000\n",
      "current iter: 15560000/24576000\n",
      "current iter: 15561000/24576000\n",
      "current iter: 15562000/24576000\n",
      "current iter: 15563000/24576000\n",
      "current iter: 15564000/24576000\n",
      "current iter: 15565000/24576000\n",
      "current iter: 15566000/24576000\n",
      "current iter: 15567000/24576000\n",
      "current iter: 15568000/24576000\n",
      "current iter: 15569000/24576000\n",
      "current iter: 15570000/24576000\n",
      "current iter: 15571000/24576000\n",
      "current iter: 15572000/24576000\n",
      "current iter: 15573000/24576000\n",
      "current iter: 15574000/24576000\n",
      "current iter: 15575000/24576000\n",
      "current iter: 15576000/24576000\n",
      "current iter: 15577000/24576000\n",
      "current iter: 15578000/24576000\n",
      "current iter: 15579000/24576000\n",
      "current iter: 15580000/24576000\n",
      "current iter: 15581000/24576000\n",
      "current iter: 15582000/24576000\n",
      "current iter: 15583000/24576000\n",
      "current iter: 15584000/24576000\n",
      "current iter: 15585000/24576000\n",
      "current iter: 15586000/24576000\n",
      "current iter: 15587000/24576000\n",
      "current iter: 15588000/24576000\n",
      "current iter: 15589000/24576000\n",
      "current iter: 15590000/24576000\n",
      "current iter: 15591000/24576000\n",
      "current iter: 15592000/24576000\n",
      "current iter: 15593000/24576000\n",
      "current iter: 15594000/24576000\n",
      "current iter: 15595000/24576000\n",
      "current iter: 15596000/24576000\n",
      "current iter: 15597000/24576000\n",
      "current iter: 15598000/24576000\n",
      "current iter: 15599000/24576000\n",
      "current iter: 15600000/24576000\n",
      "current iter: 15601000/24576000\n",
      "current iter: 15602000/24576000\n",
      "current iter: 15603000/24576000\n",
      "current iter: 15604000/24576000\n",
      "current iter: 15605000/24576000\n",
      "current iter: 15606000/24576000\n",
      "current iter: 15607000/24576000\n",
      "current iter: 15608000/24576000\n",
      "current iter: 15609000/24576000\n",
      "current iter: 15610000/24576000\n",
      "current iter: 15611000/24576000\n",
      "current iter: 15612000/24576000\n",
      "current iter: 15613000/24576000\n",
      "current iter: 15614000/24576000\n",
      "current iter: 15615000/24576000\n",
      "current iter: 15616000/24576000\n",
      "current iter: 15617000/24576000\n",
      "current iter: 15618000/24576000\n",
      "current iter: 15619000/24576000\n",
      "current iter: 15620000/24576000\n",
      "current iter: 15621000/24576000\n",
      "current iter: 15622000/24576000\n",
      "current iter: 15623000/24576000\n",
      "current iter: 15624000/24576000\n",
      "current iter: 15625000/24576000\n",
      "current iter: 15626000/24576000\n",
      "current iter: 15627000/24576000\n",
      "current iter: 15628000/24576000\n",
      "current iter: 15629000/24576000\n",
      "current iter: 15630000/24576000\n",
      "current iter: 15631000/24576000\n",
      "current iter: 15632000/24576000\n",
      "current iter: 15633000/24576000\n",
      "current iter: 15634000/24576000\n",
      "current iter: 15635000/24576000\n",
      "current iter: 15636000/24576000\n",
      "current iter: 15637000/24576000\n",
      "current iter: 15638000/24576000\n",
      "current iter: 15639000/24576000\n",
      "current iter: 15640000/24576000\n",
      "current iter: 15641000/24576000\n",
      "current iter: 15642000/24576000\n",
      "current iter: 15643000/24576000\n",
      "current iter: 15644000/24576000\n",
      "current iter: 15645000/24576000\n",
      "current iter: 15646000/24576000\n",
      "current iter: 15647000/24576000\n",
      "current iter: 15648000/24576000\n",
      "current iter: 15649000/24576000\n",
      "current iter: 15650000/24576000\n",
      "current iter: 15651000/24576000\n",
      "current iter: 15652000/24576000\n",
      "current iter: 15653000/24576000\n",
      "current iter: 15654000/24576000\n",
      "current iter: 15655000/24576000\n",
      "current iter: 15656000/24576000\n",
      "current iter: 15657000/24576000\n",
      "current iter: 15658000/24576000\n",
      "current iter: 15659000/24576000\n",
      "current iter: 15660000/24576000\n",
      "current iter: 15661000/24576000\n",
      "current iter: 15662000/24576000\n",
      "current iter: 15663000/24576000\n",
      "current iter: 15664000/24576000\n",
      "current iter: 15665000/24576000\n",
      "current iter: 15666000/24576000\n",
      "current iter: 15667000/24576000\n",
      "current iter: 15668000/24576000\n",
      "current iter: 15669000/24576000\n",
      "current iter: 15670000/24576000\n",
      "current iter: 15671000/24576000\n",
      "current iter: 15672000/24576000\n",
      "current iter: 15673000/24576000\n",
      "current iter: 15674000/24576000\n",
      "current iter: 15675000/24576000\n",
      "current iter: 15676000/24576000\n",
      "current iter: 15677000/24576000\n",
      "current iter: 15678000/24576000\n",
      "current iter: 15679000/24576000\n",
      "current iter: 15680000/24576000\n",
      "current iter: 15681000/24576000\n",
      "current iter: 15682000/24576000\n",
      "current iter: 15683000/24576000\n",
      "current iter: 15684000/24576000\n",
      "current iter: 15685000/24576000\n",
      "current iter: 15686000/24576000\n",
      "current iter: 15687000/24576000\n",
      "current iter: 15688000/24576000\n",
      "current iter: 15689000/24576000\n",
      "current iter: 15690000/24576000\n",
      "current iter: 15691000/24576000\n",
      "current iter: 15692000/24576000\n",
      "current iter: 15693000/24576000\n",
      "current iter: 15694000/24576000\n",
      "current iter: 15695000/24576000\n",
      "current iter: 15696000/24576000\n",
      "current iter: 15697000/24576000\n",
      "current iter: 15698000/24576000\n",
      "current iter: 15699000/24576000\n",
      "current iter: 15700000/24576000\n",
      "current iter: 15701000/24576000\n",
      "current iter: 15702000/24576000\n",
      "current iter: 15703000/24576000\n",
      "current iter: 15704000/24576000\n",
      "current iter: 15705000/24576000\n",
      "current iter: 15706000/24576000\n",
      "current iter: 15707000/24576000\n",
      "current iter: 15708000/24576000\n",
      "current iter: 15709000/24576000\n",
      "current iter: 15710000/24576000\n",
      "current iter: 15711000/24576000\n",
      "current iter: 15712000/24576000\n",
      "current iter: 15713000/24576000\n",
      "current iter: 15714000/24576000\n",
      "current iter: 15715000/24576000\n",
      "current iter: 15716000/24576000\n",
      "current iter: 15717000/24576000\n",
      "current iter: 15718000/24576000\n",
      "current iter: 15719000/24576000\n",
      "current iter: 15720000/24576000\n",
      "current iter: 15721000/24576000\n",
      "current iter: 15722000/24576000\n",
      "current iter: 15723000/24576000\n",
      "current iter: 15724000/24576000\n",
      "current iter: 15725000/24576000\n",
      "current iter: 15726000/24576000\n",
      "current iter: 15727000/24576000\n",
      "current iter: 15728000/24576000\n",
      "current iter: 15729000/24576000\n",
      "current iter: 15730000/24576000\n",
      "current iter: 15731000/24576000\n",
      "current iter: 15732000/24576000\n",
      "current iter: 15733000/24576000\n",
      "current iter: 15734000/24576000\n",
      "current iter: 15735000/24576000\n",
      "current iter: 15736000/24576000\n",
      "current iter: 15737000/24576000\n",
      "current iter: 15738000/24576000\n",
      "current iter: 15739000/24576000\n",
      "current iter: 15740000/24576000\n",
      "current iter: 15741000/24576000\n",
      "current iter: 15742000/24576000\n",
      "current iter: 15743000/24576000\n",
      "current iter: 15744000/24576000\n",
      "current iter: 15745000/24576000\n",
      "current iter: 15746000/24576000\n",
      "current iter: 15747000/24576000\n",
      "current iter: 15748000/24576000\n",
      "current iter: 15749000/24576000\n",
      "current iter: 15750000/24576000\n",
      "current iter: 15751000/24576000\n",
      "current iter: 15752000/24576000\n",
      "current iter: 15753000/24576000\n",
      "current iter: 15754000/24576000\n",
      "current iter: 15755000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 15756000/24576000\n",
      "current iter: 15757000/24576000\n",
      "current iter: 15758000/24576000\n",
      "current iter: 15759000/24576000\n",
      "current iter: 15760000/24576000\n",
      "current iter: 15761000/24576000\n",
      "current iter: 15762000/24576000\n",
      "current iter: 15763000/24576000\n",
      "current iter: 15764000/24576000\n",
      "current iter: 15765000/24576000\n",
      "current iter: 15766000/24576000\n",
      "current iter: 15767000/24576000\n",
      "current iter: 15768000/24576000\n",
      "current iter: 15769000/24576000\n",
      "current iter: 15770000/24576000\n",
      "current iter: 15771000/24576000\n",
      "current iter: 15772000/24576000\n",
      "current iter: 15773000/24576000\n",
      "current iter: 15774000/24576000\n",
      "current iter: 15775000/24576000\n",
      "current iter: 15776000/24576000\n",
      "current iter: 15777000/24576000\n",
      "current iter: 15778000/24576000\n",
      "current iter: 15779000/24576000\n",
      "current iter: 15780000/24576000\n",
      "current iter: 15781000/24576000\n",
      "current iter: 15782000/24576000\n",
      "current iter: 15783000/24576000\n",
      "current iter: 15784000/24576000\n",
      "current iter: 15785000/24576000\n",
      "current iter: 15786000/24576000\n",
      "current iter: 15787000/24576000\n",
      "current iter: 15788000/24576000\n",
      "current iter: 15789000/24576000\n",
      "current iter: 15790000/24576000\n",
      "current iter: 15791000/24576000\n",
      "current iter: 15792000/24576000\n",
      "current iter: 15793000/24576000\n",
      "current iter: 15794000/24576000\n",
      "current iter: 15795000/24576000\n",
      "current iter: 15796000/24576000\n",
      "current iter: 15797000/24576000\n",
      "current iter: 15798000/24576000\n",
      "current iter: 15799000/24576000\n",
      "current iter: 15800000/24576000\n",
      "current iter: 15801000/24576000\n",
      "current iter: 15802000/24576000\n",
      "current iter: 15803000/24576000\n",
      "current iter: 15804000/24576000\n",
      "current iter: 15805000/24576000\n",
      "current iter: 15806000/24576000\n",
      "current iter: 15807000/24576000\n",
      "current iter: 15808000/24576000\n",
      "current iter: 15809000/24576000\n",
      "current iter: 15810000/24576000\n",
      "current iter: 15811000/24576000\n",
      "current iter: 15812000/24576000\n",
      "current iter: 15813000/24576000\n",
      "current iter: 15814000/24576000\n",
      "current iter: 15815000/24576000\n",
      "current iter: 15816000/24576000\n",
      "current iter: 15817000/24576000\n",
      "current iter: 15818000/24576000\n",
      "current iter: 15819000/24576000\n",
      "current iter: 15820000/24576000\n",
      "current iter: 15821000/24576000\n",
      "current iter: 15822000/24576000\n",
      "current iter: 15823000/24576000\n",
      "current iter: 15824000/24576000\n",
      "current iter: 15825000/24576000\n",
      "current iter: 15826000/24576000\n",
      "current iter: 15827000/24576000\n",
      "current iter: 15828000/24576000\n",
      "current iter: 15829000/24576000\n",
      "current iter: 15830000/24576000\n",
      "current iter: 15831000/24576000\n",
      "current iter: 15832000/24576000\n",
      "current iter: 15833000/24576000\n",
      "current iter: 15834000/24576000\n",
      "current iter: 15835000/24576000\n",
      "current iter: 15836000/24576000\n",
      "current iter: 15837000/24576000\n",
      "current iter: 15838000/24576000\n",
      "current iter: 15839000/24576000\n",
      "current iter: 15840000/24576000\n",
      "current iter: 15841000/24576000\n",
      "current iter: 15842000/24576000\n",
      "current iter: 15843000/24576000\n",
      "current iter: 15844000/24576000\n",
      "current iter: 15845000/24576000\n",
      "current iter: 15846000/24576000\n",
      "current iter: 15847000/24576000\n",
      "current iter: 15848000/24576000\n",
      "current iter: 15849000/24576000\n",
      "current iter: 15850000/24576000\n",
      "current iter: 15851000/24576000\n",
      "current iter: 15852000/24576000\n",
      "current iter: 15853000/24576000\n",
      "current iter: 15854000/24576000\n",
      "current iter: 15855000/24576000\n",
      "current iter: 15856000/24576000\n",
      "current iter: 15857000/24576000\n",
      "current iter: 15858000/24576000\n",
      "current iter: 15859000/24576000\n",
      "current iter: 15860000/24576000\n",
      "current iter: 15861000/24576000\n",
      "current iter: 15862000/24576000\n",
      "current iter: 15863000/24576000\n",
      "current iter: 15864000/24576000\n",
      "current iter: 15865000/24576000\n",
      "current iter: 15866000/24576000\n",
      "current iter: 15867000/24576000\n",
      "current iter: 15868000/24576000\n",
      "current iter: 15869000/24576000\n",
      "current iter: 15870000/24576000\n",
      "current iter: 15871000/24576000\n",
      "current iter: 15872000/24576000\n",
      "current iter: 15873000/24576000\n",
      "current iter: 15874000/24576000\n",
      "current iter: 15875000/24576000\n",
      "current iter: 15876000/24576000\n",
      "current iter: 15877000/24576000\n",
      "current iter: 15878000/24576000\n",
      "current iter: 15879000/24576000\n",
      "current iter: 15880000/24576000\n",
      "current iter: 15881000/24576000\n",
      "current iter: 15882000/24576000\n",
      "current iter: 15883000/24576000\n",
      "current iter: 15884000/24576000\n",
      "current iter: 15885000/24576000\n",
      "current iter: 15886000/24576000\n",
      "current iter: 15887000/24576000\n",
      "current iter: 15888000/24576000\n",
      "current iter: 15889000/24576000\n",
      "current iter: 15890000/24576000\n",
      "current iter: 15891000/24576000\n",
      "current iter: 15892000/24576000\n",
      "current iter: 15893000/24576000\n",
      "current iter: 15894000/24576000\n",
      "current iter: 15895000/24576000\n",
      "current iter: 15896000/24576000\n",
      "current iter: 15897000/24576000\n",
      "current iter: 15898000/24576000\n",
      "current iter: 15899000/24576000\n",
      "current iter: 15900000/24576000\n",
      "current iter: 15901000/24576000\n",
      "current iter: 15902000/24576000\n",
      "current iter: 15903000/24576000\n",
      "current iter: 15904000/24576000\n",
      "current iter: 15905000/24576000\n",
      "current iter: 15906000/24576000\n",
      "current iter: 15907000/24576000\n",
      "current iter: 15908000/24576000\n",
      "current iter: 15909000/24576000\n",
      "current iter: 15910000/24576000\n",
      "current iter: 15911000/24576000\n",
      "current iter: 15912000/24576000\n",
      "current iter: 15913000/24576000\n",
      "current iter: 15914000/24576000\n",
      "current iter: 15915000/24576000\n",
      "current iter: 15916000/24576000\n",
      "current iter: 15917000/24576000\n",
      "current iter: 15918000/24576000\n",
      "current iter: 15919000/24576000\n",
      "current iter: 15920000/24576000\n",
      "current iter: 15921000/24576000\n",
      "current iter: 15922000/24576000\n",
      "current iter: 15923000/24576000\n",
      "current iter: 15924000/24576000\n",
      "current iter: 15925000/24576000\n",
      "current iter: 15926000/24576000\n",
      "current iter: 15927000/24576000\n",
      "current iter: 15928000/24576000\n",
      "current iter: 15929000/24576000\n",
      "current iter: 15930000/24576000\n",
      "current iter: 15931000/24576000\n",
      "current iter: 15932000/24576000\n",
      "current iter: 15933000/24576000\n",
      "current iter: 15934000/24576000\n",
      "current iter: 15935000/24576000\n",
      "current iter: 15936000/24576000\n",
      "current iter: 15937000/24576000\n",
      "current iter: 15938000/24576000\n",
      "current iter: 15939000/24576000\n",
      "current iter: 15940000/24576000\n",
      "current iter: 15941000/24576000\n",
      "current iter: 15942000/24576000\n",
      "current iter: 15943000/24576000\n",
      "current iter: 15944000/24576000\n",
      "current iter: 15945000/24576000\n",
      "current iter: 15946000/24576000\n",
      "current iter: 15947000/24576000\n",
      "current iter: 15948000/24576000\n",
      "current iter: 15949000/24576000\n",
      "current iter: 15950000/24576000\n",
      "current iter: 15951000/24576000\n",
      "current iter: 15952000/24576000\n",
      "current iter: 15953000/24576000\n",
      "current iter: 15954000/24576000\n",
      "current iter: 15955000/24576000\n",
      "current iter: 15956000/24576000\n",
      "current iter: 15957000/24576000\n",
      "current iter: 15958000/24576000\n",
      "current iter: 15959000/24576000\n",
      "current iter: 15960000/24576000\n",
      "current iter: 15961000/24576000\n",
      "current iter: 15962000/24576000\n",
      "current iter: 15963000/24576000\n",
      "current iter: 15964000/24576000\n",
      "current iter: 15965000/24576000\n",
      "current iter: 15966000/24576000\n",
      "current iter: 15967000/24576000\n",
      "current iter: 15968000/24576000\n",
      "current iter: 15969000/24576000\n",
      "current iter: 15970000/24576000\n",
      "current iter: 15971000/24576000\n",
      "current iter: 15972000/24576000\n",
      "current iter: 15973000/24576000\n",
      "current iter: 15974000/24576000\n",
      "current iter: 15975000/24576000\n",
      "current iter: 15976000/24576000\n",
      "current iter: 15977000/24576000\n",
      "current iter: 15978000/24576000\n",
      "current iter: 15979000/24576000\n",
      "current iter: 15980000/24576000\n",
      "current iter: 15981000/24576000\n",
      "current iter: 15982000/24576000\n",
      "current iter: 15983000/24576000\n",
      "current iter: 15984000/24576000\n",
      "current iter: 15985000/24576000\n",
      "current iter: 15986000/24576000\n",
      "current iter: 15987000/24576000\n",
      "current iter: 15988000/24576000\n",
      "current iter: 15989000/24576000\n",
      "current iter: 15990000/24576000\n",
      "current iter: 15991000/24576000\n",
      "current iter: 15992000/24576000\n",
      "current iter: 15993000/24576000\n",
      "current iter: 15994000/24576000\n",
      "current iter: 15995000/24576000\n",
      "current iter: 15996000/24576000\n",
      "current iter: 15997000/24576000\n",
      "current iter: 15998000/24576000\n",
      "current iter: 15999000/24576000\n",
      "current iter: 16000000/24576000\n",
      "current iter: 16001000/24576000\n",
      "current iter: 16002000/24576000\n",
      "current iter: 16003000/24576000\n",
      "current iter: 16004000/24576000\n",
      "current iter: 16005000/24576000\n",
      "current iter: 16006000/24576000\n",
      "current iter: 16007000/24576000\n",
      "current iter: 16008000/24576000\n",
      "current iter: 16009000/24576000\n",
      "current iter: 16010000/24576000\n",
      "current iter: 16011000/24576000\n",
      "current iter: 16012000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 16013000/24576000\n",
      "current iter: 16014000/24576000\n",
      "current iter: 16015000/24576000\n",
      "current iter: 16016000/24576000\n",
      "current iter: 16017000/24576000\n",
      "current iter: 16018000/24576000\n",
      "current iter: 16019000/24576000\n",
      "current iter: 16020000/24576000\n",
      "current iter: 16021000/24576000\n",
      "current iter: 16022000/24576000\n",
      "current iter: 16023000/24576000\n",
      "current iter: 16024000/24576000\n",
      "current iter: 16025000/24576000\n",
      "current iter: 16026000/24576000\n",
      "current iter: 16027000/24576000\n",
      "current iter: 16028000/24576000\n",
      "current iter: 16029000/24576000\n",
      "current iter: 16030000/24576000\n",
      "current iter: 16031000/24576000\n",
      "current iter: 16032000/24576000\n",
      "current iter: 16033000/24576000\n",
      "current iter: 16034000/24576000\n",
      "current iter: 16035000/24576000\n",
      "current iter: 16036000/24576000\n",
      "current iter: 16037000/24576000\n",
      "current iter: 16038000/24576000\n",
      "current iter: 16039000/24576000\n",
      "current iter: 16040000/24576000\n",
      "current iter: 16041000/24576000\n",
      "current iter: 16042000/24576000\n",
      "current iter: 16043000/24576000\n",
      "current iter: 16044000/24576000\n",
      "current iter: 16045000/24576000\n",
      "current iter: 16046000/24576000\n",
      "current iter: 16047000/24576000\n",
      "current iter: 16048000/24576000\n",
      "current iter: 16049000/24576000\n",
      "current iter: 16050000/24576000\n",
      "current iter: 16051000/24576000\n",
      "current iter: 16052000/24576000\n",
      "current iter: 16053000/24576000\n",
      "current iter: 16054000/24576000\n",
      "current iter: 16055000/24576000\n",
      "current iter: 16056000/24576000\n",
      "current iter: 16057000/24576000\n",
      "current iter: 16058000/24576000\n",
      "current iter: 16059000/24576000\n",
      "current iter: 16060000/24576000\n",
      "current iter: 16061000/24576000\n",
      "current iter: 16062000/24576000\n",
      "current iter: 16063000/24576000\n",
      "current iter: 16064000/24576000\n",
      "current iter: 16065000/24576000\n",
      "current iter: 16066000/24576000\n",
      "current iter: 16067000/24576000\n",
      "current iter: 16068000/24576000\n",
      "current iter: 16069000/24576000\n",
      "current iter: 16070000/24576000\n",
      "current iter: 16071000/24576000\n",
      "current iter: 16072000/24576000\n",
      "current iter: 16073000/24576000\n",
      "current iter: 16074000/24576000\n",
      "current iter: 16075000/24576000\n",
      "current iter: 16076000/24576000\n",
      "current iter: 16077000/24576000\n",
      "current iter: 16078000/24576000\n",
      "current iter: 16079000/24576000\n",
      "current iter: 16080000/24576000\n",
      "current iter: 16081000/24576000\n",
      "current iter: 16082000/24576000\n",
      "current iter: 16083000/24576000\n",
      "current iter: 16084000/24576000\n",
      "current iter: 16085000/24576000\n",
      "current iter: 16086000/24576000\n",
      "current iter: 16087000/24576000\n",
      "current iter: 16088000/24576000\n",
      "current iter: 16089000/24576000\n",
      "current iter: 16090000/24576000\n",
      "current iter: 16091000/24576000\n",
      "current iter: 16092000/24576000\n",
      "current iter: 16093000/24576000\n",
      "current iter: 16094000/24576000\n",
      "current iter: 16095000/24576000\n",
      "current iter: 16096000/24576000\n",
      "current iter: 16097000/24576000\n",
      "current iter: 16098000/24576000\n",
      "current iter: 16099000/24576000\n",
      "current iter: 16100000/24576000\n",
      "current iter: 16101000/24576000\n",
      "current iter: 16102000/24576000\n",
      "current iter: 16103000/24576000\n",
      "current iter: 16104000/24576000\n",
      "current iter: 16105000/24576000\n",
      "current iter: 16106000/24576000\n",
      "current iter: 16107000/24576000\n",
      "current iter: 16108000/24576000\n",
      "current iter: 16109000/24576000\n",
      "current iter: 16110000/24576000\n",
      "current iter: 16111000/24576000\n",
      "current iter: 16112000/24576000\n",
      "current iter: 16113000/24576000\n",
      "current iter: 16114000/24576000\n",
      "current iter: 16115000/24576000\n",
      "current iter: 16116000/24576000\n",
      "current iter: 16117000/24576000\n",
      "current iter: 16118000/24576000\n",
      "current iter: 16119000/24576000\n",
      "current iter: 16120000/24576000\n",
      "current iter: 16121000/24576000\n",
      "current iter: 16122000/24576000\n",
      "current iter: 16123000/24576000\n",
      "current iter: 16124000/24576000\n",
      "current iter: 16125000/24576000\n",
      "current iter: 16126000/24576000\n",
      "current iter: 16127000/24576000\n",
      "current iter: 16128000/24576000\n",
      "current iter: 16129000/24576000\n",
      "current iter: 16130000/24576000\n",
      "current iter: 16131000/24576000\n",
      "current iter: 16132000/24576000\n",
      "current iter: 16133000/24576000\n",
      "current iter: 16134000/24576000\n",
      "current iter: 16135000/24576000\n",
      "current iter: 16136000/24576000\n",
      "current iter: 16137000/24576000\n",
      "current iter: 16138000/24576000\n",
      "current iter: 16139000/24576000\n",
      "current iter: 16140000/24576000\n",
      "current iter: 16141000/24576000\n",
      "current iter: 16142000/24576000\n",
      "current iter: 16143000/24576000\n",
      "current iter: 16144000/24576000\n",
      "current iter: 16145000/24576000\n",
      "current iter: 16146000/24576000\n",
      "current iter: 16147000/24576000\n",
      "current iter: 16148000/24576000\n",
      "current iter: 16149000/24576000\n",
      "current iter: 16150000/24576000\n",
      "current iter: 16151000/24576000\n",
      "current iter: 16152000/24576000\n",
      "current iter: 16153000/24576000\n",
      "current iter: 16154000/24576000\n",
      "current iter: 16155000/24576000\n",
      "current iter: 16156000/24576000\n",
      "current iter: 16157000/24576000\n",
      "current iter: 16158000/24576000\n",
      "current iter: 16159000/24576000\n",
      "current iter: 16160000/24576000\n",
      "current iter: 16161000/24576000\n",
      "current iter: 16162000/24576000\n",
      "current iter: 16163000/24576000\n",
      "current iter: 16164000/24576000\n",
      "current iter: 16165000/24576000\n",
      "current iter: 16166000/24576000\n",
      "current iter: 16167000/24576000\n",
      "current iter: 16168000/24576000\n",
      "current iter: 16169000/24576000\n",
      "current iter: 16170000/24576000\n",
      "current iter: 16171000/24576000\n",
      "current iter: 16172000/24576000\n",
      "current iter: 16173000/24576000\n",
      "current iter: 16174000/24576000\n",
      "current iter: 16175000/24576000\n",
      "current iter: 16176000/24576000\n",
      "current iter: 16177000/24576000\n",
      "current iter: 16178000/24576000\n",
      "current iter: 16179000/24576000\n",
      "current iter: 16180000/24576000\n",
      "current iter: 16181000/24576000\n",
      "current iter: 16182000/24576000\n",
      "current iter: 16183000/24576000\n",
      "current iter: 16184000/24576000\n",
      "current iter: 16185000/24576000\n",
      "current iter: 16186000/24576000\n",
      "current iter: 16187000/24576000\n",
      "current iter: 16188000/24576000\n",
      "current iter: 16189000/24576000\n",
      "current iter: 16190000/24576000\n",
      "current iter: 16191000/24576000\n",
      "current iter: 16192000/24576000\n",
      "current iter: 16193000/24576000\n",
      "current iter: 16194000/24576000\n",
      "current iter: 16195000/24576000\n",
      "current iter: 16196000/24576000\n",
      "current iter: 16197000/24576000\n",
      "current iter: 16198000/24576000\n",
      "current iter: 16199000/24576000\n",
      "current iter: 16200000/24576000\n",
      "current iter: 16201000/24576000\n",
      "current iter: 16202000/24576000\n",
      "current iter: 16203000/24576000\n",
      "current iter: 16204000/24576000\n",
      "current iter: 16205000/24576000\n",
      "current iter: 16206000/24576000\n",
      "current iter: 16207000/24576000\n",
      "current iter: 16208000/24576000\n",
      "current iter: 16209000/24576000\n",
      "current iter: 16210000/24576000\n",
      "current iter: 16211000/24576000\n",
      "current iter: 16212000/24576000\n",
      "current iter: 16213000/24576000\n",
      "current iter: 16214000/24576000\n",
      "current iter: 16215000/24576000\n",
      "current iter: 16216000/24576000\n",
      "current iter: 16217000/24576000\n",
      "current iter: 16218000/24576000\n",
      "current iter: 16219000/24576000\n",
      "current iter: 16220000/24576000\n",
      "current iter: 16221000/24576000\n",
      "current iter: 16222000/24576000\n",
      "current iter: 16223000/24576000\n",
      "current iter: 16224000/24576000\n",
      "current iter: 16225000/24576000\n",
      "current iter: 16226000/24576000\n",
      "current iter: 16227000/24576000\n",
      "current iter: 16228000/24576000\n",
      "current iter: 16229000/24576000\n",
      "current iter: 16230000/24576000\n",
      "current iter: 16231000/24576000\n",
      "current iter: 16232000/24576000\n",
      "current iter: 16233000/24576000\n",
      "current iter: 16234000/24576000\n",
      "current iter: 16235000/24576000\n",
      "current iter: 16236000/24576000\n",
      "current iter: 16237000/24576000\n",
      "current iter: 16238000/24576000\n",
      "current iter: 16239000/24576000\n",
      "current iter: 16240000/24576000\n",
      "current iter: 16241000/24576000\n",
      "current iter: 16242000/24576000\n",
      "current iter: 16243000/24576000\n",
      "current iter: 16244000/24576000\n",
      "current iter: 16245000/24576000\n",
      "current iter: 16246000/24576000\n",
      "current iter: 16247000/24576000\n",
      "current iter: 16248000/24576000\n",
      "current iter: 16249000/24576000\n",
      "current iter: 16250000/24576000\n",
      "current iter: 16251000/24576000\n",
      "current iter: 16252000/24576000\n",
      "current iter: 16253000/24576000\n",
      "current iter: 16254000/24576000\n",
      "current iter: 16255000/24576000\n",
      "current iter: 16256000/24576000\n",
      "current iter: 16257000/24576000\n",
      "current iter: 16258000/24576000\n",
      "current iter: 16259000/24576000\n",
      "current iter: 16260000/24576000\n",
      "current iter: 16261000/24576000\n",
      "current iter: 16262000/24576000\n",
      "current iter: 16263000/24576000\n",
      "current iter: 16264000/24576000\n",
      "current iter: 16265000/24576000\n",
      "current iter: 16266000/24576000\n",
      "current iter: 16267000/24576000\n",
      "current iter: 16268000/24576000\n",
      "current iter: 16269000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 16270000/24576000\n",
      "current iter: 16271000/24576000\n",
      "current iter: 16272000/24576000\n",
      "current iter: 16273000/24576000\n",
      "current iter: 16274000/24576000\n",
      "current iter: 16275000/24576000\n",
      "current iter: 16276000/24576000\n",
      "current iter: 16277000/24576000\n",
      "current iter: 16278000/24576000\n",
      "current iter: 16279000/24576000\n",
      "current iter: 16280000/24576000\n",
      "current iter: 16281000/24576000\n",
      "current iter: 16282000/24576000\n",
      "current iter: 16283000/24576000\n",
      "current iter: 16284000/24576000\n",
      "current iter: 16285000/24576000\n",
      "current iter: 16286000/24576000\n",
      "current iter: 16287000/24576000\n",
      "current iter: 16288000/24576000\n",
      "current iter: 16289000/24576000\n",
      "current iter: 16290000/24576000\n",
      "current iter: 16291000/24576000\n",
      "current iter: 16292000/24576000\n",
      "current iter: 16293000/24576000\n",
      "current iter: 16294000/24576000\n",
      "current iter: 16295000/24576000\n",
      "current iter: 16296000/24576000\n",
      "current iter: 16297000/24576000\n",
      "current iter: 16298000/24576000\n",
      "current iter: 16299000/24576000\n",
      "current iter: 16300000/24576000\n",
      "current iter: 16301000/24576000\n",
      "current iter: 16302000/24576000\n",
      "current iter: 16303000/24576000\n",
      "current iter: 16304000/24576000\n",
      "current iter: 16305000/24576000\n",
      "current iter: 16306000/24576000\n",
      "current iter: 16307000/24576000\n",
      "current iter: 16308000/24576000\n",
      "current iter: 16309000/24576000\n",
      "current iter: 16310000/24576000\n",
      "current iter: 16311000/24576000\n",
      "current iter: 16312000/24576000\n",
      "current iter: 16313000/24576000\n",
      "current iter: 16314000/24576000\n",
      "current iter: 16315000/24576000\n",
      "current iter: 16316000/24576000\n",
      "current iter: 16317000/24576000\n",
      "current iter: 16318000/24576000\n",
      "current iter: 16319000/24576000\n",
      "current iter: 16320000/24576000\n",
      "current iter: 16321000/24576000\n",
      "current iter: 16322000/24576000\n",
      "current iter: 16323000/24576000\n",
      "current iter: 16324000/24576000\n",
      "current iter: 16325000/24576000\n",
      "current iter: 16326000/24576000\n",
      "current iter: 16327000/24576000\n",
      "current iter: 16328000/24576000\n",
      "current iter: 16329000/24576000\n",
      "current iter: 16330000/24576000\n",
      "current iter: 16331000/24576000\n",
      "current iter: 16332000/24576000\n",
      "current iter: 16333000/24576000\n",
      "current iter: 16334000/24576000\n",
      "current iter: 16335000/24576000\n",
      "current iter: 16336000/24576000\n",
      "current iter: 16337000/24576000\n",
      "current iter: 16338000/24576000\n",
      "current iter: 16339000/24576000\n",
      "current iter: 16340000/24576000\n",
      "current iter: 16341000/24576000\n",
      "current iter: 16342000/24576000\n",
      "current iter: 16343000/24576000\n",
      "current iter: 16344000/24576000\n",
      "current iter: 16345000/24576000\n",
      "current iter: 16346000/24576000\n",
      "current iter: 16347000/24576000\n",
      "current iter: 16348000/24576000\n",
      "current iter: 16349000/24576000\n",
      "current iter: 16350000/24576000\n",
      "current iter: 16351000/24576000\n",
      "current iter: 16352000/24576000\n",
      "current iter: 16353000/24576000\n",
      "current iter: 16354000/24576000\n",
      "current iter: 16355000/24576000\n",
      "current iter: 16356000/24576000\n",
      "current iter: 16357000/24576000\n",
      "current iter: 16358000/24576000\n",
      "current iter: 16359000/24576000\n",
      "current iter: 16360000/24576000\n",
      "current iter: 16361000/24576000\n",
      "current iter: 16362000/24576000\n",
      "current iter: 16363000/24576000\n",
      "current iter: 16364000/24576000\n",
      "current iter: 16365000/24576000\n",
      "current iter: 16366000/24576000\n",
      "current iter: 16367000/24576000\n",
      "current iter: 16368000/24576000\n",
      "current iter: 16369000/24576000\n",
      "current iter: 16370000/24576000\n",
      "current iter: 16371000/24576000\n",
      "current iter: 16372000/24576000\n",
      "current iter: 16373000/24576000\n",
      "current iter: 16374000/24576000\n",
      "current iter: 16375000/24576000\n",
      "current iter: 16376000/24576000\n",
      "current iter: 16377000/24576000\n",
      "current iter: 16378000/24576000\n",
      "current iter: 16379000/24576000\n",
      "current iter: 16380000/24576000\n",
      "current iter: 16381000/24576000\n",
      "current iter: 16382000/24576000\n",
      "current iter: 16383000/24576000\n",
      "current iter: 16384000/24576000\n",
      "current iter: 16385000/24576000\n",
      "current iter: 16386000/24576000\n",
      "current iter: 16387000/24576000\n",
      "current iter: 16388000/24576000\n",
      "current iter: 16389000/24576000\n",
      "current iter: 16390000/24576000\n",
      "current iter: 16391000/24576000\n",
      "current iter: 16392000/24576000\n",
      "current iter: 16393000/24576000\n",
      "current iter: 16394000/24576000\n",
      "current iter: 16395000/24576000\n",
      "current iter: 16396000/24576000\n",
      "current iter: 16397000/24576000\n",
      "current iter: 16398000/24576000\n",
      "current iter: 16399000/24576000\n",
      "current iter: 16400000/24576000\n",
      "current iter: 16401000/24576000\n",
      "current iter: 16402000/24576000\n",
      "current iter: 16403000/24576000\n",
      "current iter: 16404000/24576000\n",
      "current iter: 16405000/24576000\n",
      "current iter: 16406000/24576000\n",
      "current iter: 16407000/24576000\n",
      "current iter: 16408000/24576000\n",
      "current iter: 16409000/24576000\n",
      "current iter: 16410000/24576000\n",
      "current iter: 16411000/24576000\n",
      "current iter: 16412000/24576000\n",
      "current iter: 16413000/24576000\n",
      "current iter: 16414000/24576000\n",
      "current iter: 16415000/24576000\n",
      "current iter: 16416000/24576000\n",
      "current iter: 16417000/24576000\n",
      "current iter: 16418000/24576000\n",
      "current iter: 16419000/24576000\n",
      "current iter: 16420000/24576000\n",
      "current iter: 16421000/24576000\n",
      "current iter: 16422000/24576000\n",
      "current iter: 16423000/24576000\n",
      "current iter: 16424000/24576000\n",
      "current iter: 16425000/24576000\n",
      "current iter: 16426000/24576000\n",
      "current iter: 16427000/24576000\n",
      "current iter: 16428000/24576000\n",
      "current iter: 16429000/24576000\n",
      "current iter: 16430000/24576000\n",
      "current iter: 16431000/24576000\n",
      "current iter: 16432000/24576000\n",
      "current iter: 16433000/24576000\n",
      "current iter: 16434000/24576000\n",
      "current iter: 16435000/24576000\n",
      "current iter: 16436000/24576000\n",
      "current iter: 16437000/24576000\n",
      "current iter: 16438000/24576000\n",
      "current iter: 16439000/24576000\n",
      "current iter: 16440000/24576000\n",
      "current iter: 16441000/24576000\n",
      "current iter: 16442000/24576000\n",
      "current iter: 16443000/24576000\n",
      "current iter: 16444000/24576000\n",
      "current iter: 16445000/24576000\n",
      "current iter: 16446000/24576000\n",
      "current iter: 16447000/24576000\n",
      "current iter: 16448000/24576000\n",
      "current iter: 16449000/24576000\n",
      "current iter: 16450000/24576000\n",
      "current iter: 16451000/24576000\n",
      "current iter: 16452000/24576000\n",
      "current iter: 16453000/24576000\n",
      "current iter: 16454000/24576000\n",
      "current iter: 16455000/24576000\n",
      "current iter: 16456000/24576000\n",
      "current iter: 16457000/24576000\n",
      "current iter: 16458000/24576000\n",
      "current iter: 16459000/24576000\n",
      "current iter: 16460000/24576000\n",
      "current iter: 16461000/24576000\n",
      "current iter: 16462000/24576000\n",
      "current iter: 16463000/24576000\n",
      "current iter: 16464000/24576000\n",
      "current iter: 16465000/24576000\n",
      "current iter: 16466000/24576000\n",
      "current iter: 16467000/24576000\n",
      "current iter: 16468000/24576000\n",
      "current iter: 16469000/24576000\n",
      "current iter: 16470000/24576000\n",
      "current iter: 16471000/24576000\n",
      "current iter: 16472000/24576000\n",
      "current iter: 16473000/24576000\n",
      "current iter: 16474000/24576000\n",
      "current iter: 16475000/24576000\n",
      "current iter: 16476000/24576000\n",
      "current iter: 16477000/24576000\n",
      "current iter: 16478000/24576000\n",
      "current iter: 16479000/24576000\n",
      "current iter: 16480000/24576000\n",
      "current iter: 16481000/24576000\n",
      "current iter: 16482000/24576000\n",
      "current iter: 16483000/24576000\n",
      "current iter: 16484000/24576000\n",
      "current iter: 16485000/24576000\n",
      "current iter: 16486000/24576000\n",
      "current iter: 16487000/24576000\n",
      "current iter: 16488000/24576000\n",
      "current iter: 16489000/24576000\n",
      "current iter: 16490000/24576000\n",
      "current iter: 16491000/24576000\n",
      "current iter: 16492000/24576000\n",
      "current iter: 16493000/24576000\n",
      "current iter: 16494000/24576000\n",
      "current iter: 16495000/24576000\n",
      "current iter: 16496000/24576000\n",
      "current iter: 16497000/24576000\n",
      "current iter: 16498000/24576000\n",
      "current iter: 16499000/24576000\n",
      "current iter: 16500000/24576000\n",
      "current iter: 16501000/24576000\n",
      "current iter: 16502000/24576000\n",
      "current iter: 16503000/24576000\n",
      "current iter: 16504000/24576000\n",
      "current iter: 16505000/24576000\n",
      "current iter: 16506000/24576000\n",
      "current iter: 16507000/24576000\n",
      "current iter: 16508000/24576000\n",
      "current iter: 16509000/24576000\n",
      "current iter: 16510000/24576000\n",
      "current iter: 16511000/24576000\n",
      "current iter: 16512000/24576000\n",
      "current iter: 16513000/24576000\n",
      "current iter: 16514000/24576000\n",
      "current iter: 16515000/24576000\n",
      "current iter: 16516000/24576000\n",
      "current iter: 16517000/24576000\n",
      "current iter: 16518000/24576000\n",
      "current iter: 16519000/24576000\n",
      "current iter: 16520000/24576000\n",
      "current iter: 16521000/24576000\n",
      "current iter: 16522000/24576000\n",
      "current iter: 16523000/24576000\n",
      "current iter: 16524000/24576000\n",
      "current iter: 16525000/24576000\n",
      "current iter: 16526000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 16527000/24576000\n",
      "current iter: 16528000/24576000\n",
      "current iter: 16529000/24576000\n",
      "current iter: 16530000/24576000\n",
      "current iter: 16531000/24576000\n",
      "current iter: 16532000/24576000\n",
      "current iter: 16533000/24576000\n",
      "current iter: 16534000/24576000\n",
      "current iter: 16535000/24576000\n",
      "current iter: 16536000/24576000\n",
      "current iter: 16537000/24576000\n",
      "current iter: 16538000/24576000\n",
      "current iter: 16539000/24576000\n",
      "current iter: 16540000/24576000\n",
      "current iter: 16541000/24576000\n",
      "current iter: 16542000/24576000\n",
      "current iter: 16543000/24576000\n",
      "current iter: 16544000/24576000\n",
      "current iter: 16545000/24576000\n",
      "current iter: 16546000/24576000\n",
      "current iter: 16547000/24576000\n",
      "current iter: 16548000/24576000\n",
      "current iter: 16549000/24576000\n",
      "current iter: 16550000/24576000\n",
      "current iter: 16551000/24576000\n",
      "current iter: 16552000/24576000\n",
      "current iter: 16553000/24576000\n",
      "current iter: 16554000/24576000\n",
      "current iter: 16555000/24576000\n",
      "current iter: 16556000/24576000\n",
      "current iter: 16557000/24576000\n",
      "current iter: 16558000/24576000\n",
      "current iter: 16559000/24576000\n",
      "current iter: 16560000/24576000\n",
      "current iter: 16561000/24576000\n",
      "current iter: 16562000/24576000\n",
      "current iter: 16563000/24576000\n",
      "current iter: 16564000/24576000\n",
      "current iter: 16565000/24576000\n",
      "current iter: 16566000/24576000\n",
      "current iter: 16567000/24576000\n",
      "current iter: 16568000/24576000\n",
      "current iter: 16569000/24576000\n",
      "current iter: 16570000/24576000\n",
      "current iter: 16571000/24576000\n",
      "current iter: 16572000/24576000\n",
      "current iter: 16573000/24576000\n",
      "current iter: 16574000/24576000\n",
      "current iter: 16575000/24576000\n",
      "current iter: 16576000/24576000\n",
      "current iter: 16577000/24576000\n",
      "current iter: 16578000/24576000\n",
      "current iter: 16579000/24576000\n",
      "current iter: 16580000/24576000\n",
      "current iter: 16581000/24576000\n",
      "current iter: 16582000/24576000\n",
      "current iter: 16583000/24576000\n",
      "current iter: 16584000/24576000\n",
      "current iter: 16585000/24576000\n",
      "current iter: 16586000/24576000\n",
      "current iter: 16587000/24576000\n",
      "current iter: 16588000/24576000\n",
      "current iter: 16589000/24576000\n",
      "current iter: 16590000/24576000\n",
      "current iter: 16591000/24576000\n",
      "current iter: 16592000/24576000\n",
      "current iter: 16593000/24576000\n",
      "current iter: 16594000/24576000\n",
      "current iter: 16595000/24576000\n",
      "current iter: 16596000/24576000\n",
      "current iter: 16597000/24576000\n",
      "current iter: 16598000/24576000\n",
      "current iter: 16599000/24576000\n",
      "current iter: 16600000/24576000\n",
      "current iter: 16601000/24576000\n",
      "current iter: 16602000/24576000\n",
      "current iter: 16603000/24576000\n",
      "current iter: 16604000/24576000\n",
      "current iter: 16605000/24576000\n",
      "current iter: 16606000/24576000\n",
      "current iter: 16607000/24576000\n",
      "current iter: 16608000/24576000\n",
      "current iter: 16609000/24576000\n",
      "current iter: 16610000/24576000\n",
      "current iter: 16611000/24576000\n",
      "current iter: 16612000/24576000\n",
      "current iter: 16613000/24576000\n",
      "current iter: 16614000/24576000\n",
      "current iter: 16615000/24576000\n",
      "current iter: 16616000/24576000\n",
      "current iter: 16617000/24576000\n",
      "current iter: 16618000/24576000\n",
      "current iter: 16619000/24576000\n",
      "current iter: 16620000/24576000\n",
      "current iter: 16621000/24576000\n",
      "current iter: 16622000/24576000\n",
      "current iter: 16623000/24576000\n",
      "current iter: 16624000/24576000\n",
      "current iter: 16625000/24576000\n",
      "current iter: 16626000/24576000\n",
      "current iter: 16627000/24576000\n",
      "current iter: 16628000/24576000\n",
      "current iter: 16629000/24576000\n",
      "current iter: 16630000/24576000\n",
      "current iter: 16631000/24576000\n",
      "current iter: 16632000/24576000\n",
      "current iter: 16633000/24576000\n",
      "current iter: 16634000/24576000\n",
      "current iter: 16635000/24576000\n",
      "current iter: 16636000/24576000\n",
      "current iter: 16637000/24576000\n",
      "current iter: 16638000/24576000\n",
      "current iter: 16639000/24576000\n",
      "current iter: 16640000/24576000\n",
      "current iter: 16641000/24576000\n",
      "current iter: 16642000/24576000\n",
      "current iter: 16643000/24576000\n",
      "current iter: 16644000/24576000\n",
      "current iter: 16645000/24576000\n",
      "current iter: 16646000/24576000\n",
      "current iter: 16647000/24576000\n",
      "current iter: 16648000/24576000\n",
      "current iter: 16649000/24576000\n",
      "current iter: 16650000/24576000\n",
      "current iter: 16651000/24576000\n",
      "current iter: 16652000/24576000\n",
      "current iter: 16653000/24576000\n",
      "current iter: 16654000/24576000\n",
      "current iter: 16655000/24576000\n",
      "current iter: 16656000/24576000\n",
      "current iter: 16657000/24576000\n",
      "current iter: 16658000/24576000\n",
      "current iter: 16659000/24576000\n",
      "current iter: 16660000/24576000\n",
      "current iter: 16661000/24576000\n",
      "current iter: 16662000/24576000\n",
      "current iter: 16663000/24576000\n",
      "current iter: 16664000/24576000\n",
      "current iter: 16665000/24576000\n",
      "current iter: 16666000/24576000\n",
      "current iter: 16667000/24576000\n",
      "current iter: 16668000/24576000\n",
      "current iter: 16669000/24576000\n",
      "current iter: 16670000/24576000\n",
      "current iter: 16671000/24576000\n",
      "current iter: 16672000/24576000\n",
      "current iter: 16673000/24576000\n",
      "current iter: 16674000/24576000\n",
      "current iter: 16675000/24576000\n",
      "current iter: 16676000/24576000\n",
      "current iter: 16677000/24576000\n",
      "current iter: 16678000/24576000\n",
      "current iter: 16679000/24576000\n",
      "current iter: 16680000/24576000\n",
      "current iter: 16681000/24576000\n",
      "current iter: 16682000/24576000\n",
      "current iter: 16683000/24576000\n",
      "current iter: 16684000/24576000\n",
      "current iter: 16685000/24576000\n",
      "current iter: 16686000/24576000\n",
      "current iter: 16687000/24576000\n",
      "current iter: 16688000/24576000\n",
      "current iter: 16689000/24576000\n",
      "current iter: 16690000/24576000\n",
      "current iter: 16691000/24576000\n",
      "current iter: 16692000/24576000\n",
      "current iter: 16693000/24576000\n",
      "current iter: 16694000/24576000\n",
      "current iter: 16695000/24576000\n",
      "current iter: 16696000/24576000\n",
      "current iter: 16697000/24576000\n",
      "current iter: 16698000/24576000\n",
      "current iter: 16699000/24576000\n",
      "current iter: 16700000/24576000\n",
      "current iter: 16701000/24576000\n",
      "current iter: 16702000/24576000\n",
      "current iter: 16703000/24576000\n",
      "current iter: 16704000/24576000\n",
      "current iter: 16705000/24576000\n",
      "current iter: 16706000/24576000\n",
      "current iter: 16707000/24576000\n",
      "current iter: 16708000/24576000\n",
      "current iter: 16709000/24576000\n",
      "current iter: 16710000/24576000\n",
      "current iter: 16711000/24576000\n",
      "current iter: 16712000/24576000\n",
      "current iter: 16713000/24576000\n",
      "current iter: 16714000/24576000\n",
      "current iter: 16715000/24576000\n",
      "current iter: 16716000/24576000\n",
      "current iter: 16717000/24576000\n",
      "current iter: 16718000/24576000\n",
      "current iter: 16719000/24576000\n",
      "current iter: 16720000/24576000\n",
      "current iter: 16721000/24576000\n",
      "current iter: 16722000/24576000\n",
      "current iter: 16723000/24576000\n",
      "current iter: 16724000/24576000\n",
      "current iter: 16725000/24576000\n",
      "current iter: 16726000/24576000\n",
      "current iter: 16727000/24576000\n",
      "current iter: 16728000/24576000\n",
      "current iter: 16729000/24576000\n",
      "current iter: 16730000/24576000\n",
      "current iter: 16731000/24576000\n",
      "current iter: 16732000/24576000\n",
      "current iter: 16733000/24576000\n",
      "current iter: 16734000/24576000\n",
      "current iter: 16735000/24576000\n",
      "current iter: 16736000/24576000\n",
      "current iter: 16737000/24576000\n",
      "current iter: 16738000/24576000\n",
      "current iter: 16739000/24576000\n",
      "current iter: 16740000/24576000\n",
      "current iter: 16741000/24576000\n",
      "current iter: 16742000/24576000\n",
      "current iter: 16743000/24576000\n",
      "current iter: 16744000/24576000\n",
      "current iter: 16745000/24576000\n",
      "current iter: 16746000/24576000\n",
      "current iter: 16747000/24576000\n",
      "current iter: 16748000/24576000\n",
      "current iter: 16749000/24576000\n",
      "current iter: 16750000/24576000\n",
      "current iter: 16751000/24576000\n",
      "current iter: 16752000/24576000\n",
      "current iter: 16753000/24576000\n",
      "current iter: 16754000/24576000\n",
      "current iter: 16755000/24576000\n",
      "current iter: 16756000/24576000\n",
      "current iter: 16757000/24576000\n",
      "current iter: 16758000/24576000\n",
      "current iter: 16759000/24576000\n",
      "current iter: 16760000/24576000\n",
      "current iter: 16761000/24576000\n",
      "current iter: 16762000/24576000\n",
      "current iter: 16763000/24576000\n",
      "current iter: 16764000/24576000\n",
      "current iter: 16765000/24576000\n",
      "current iter: 16766000/24576000\n",
      "current iter: 16767000/24576000\n",
      "current iter: 16768000/24576000\n",
      "current iter: 16769000/24576000\n",
      "current iter: 16770000/24576000\n",
      "current iter: 16771000/24576000\n",
      "current iter: 16772000/24576000\n",
      "current iter: 16773000/24576000\n",
      "current iter: 16774000/24576000\n",
      "current iter: 16775000/24576000\n",
      "current iter: 16776000/24576000\n",
      "current iter: 16777000/24576000\n",
      "current iter: 16778000/24576000\n",
      "current iter: 16779000/24576000\n",
      "current iter: 16780000/24576000\n",
      "current iter: 16781000/24576000\n",
      "current iter: 16782000/24576000\n",
      "current iter: 16783000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 16784000/24576000\n",
      "current iter: 16785000/24576000\n",
      "current iter: 16786000/24576000\n",
      "current iter: 16787000/24576000\n",
      "current iter: 16788000/24576000\n",
      "current iter: 16789000/24576000\n",
      "current iter: 16790000/24576000\n",
      "current iter: 16791000/24576000\n",
      "current iter: 16792000/24576000\n",
      "current iter: 16793000/24576000\n",
      "current iter: 16794000/24576000\n",
      "current iter: 16795000/24576000\n",
      "current iter: 16796000/24576000\n",
      "current iter: 16797000/24576000\n",
      "current iter: 16798000/24576000\n",
      "current iter: 16799000/24576000\n",
      "current iter: 16800000/24576000\n",
      "current iter: 16801000/24576000\n",
      "current iter: 16802000/24576000\n",
      "current iter: 16803000/24576000\n",
      "current iter: 16804000/24576000\n",
      "current iter: 16805000/24576000\n",
      "current iter: 16806000/24576000\n",
      "current iter: 16807000/24576000\n",
      "current iter: 16808000/24576000\n",
      "current iter: 16809000/24576000\n",
      "current iter: 16810000/24576000\n",
      "current iter: 16811000/24576000\n",
      "current iter: 16812000/24576000\n",
      "current iter: 16813000/24576000\n",
      "current iter: 16814000/24576000\n",
      "current iter: 16815000/24576000\n",
      "current iter: 16816000/24576000\n",
      "current iter: 16817000/24576000\n",
      "current iter: 16818000/24576000\n",
      "current iter: 16819000/24576000\n",
      "current iter: 16820000/24576000\n",
      "current iter: 16821000/24576000\n",
      "current iter: 16822000/24576000\n",
      "current iter: 16823000/24576000\n",
      "current iter: 16824000/24576000\n",
      "current iter: 16825000/24576000\n",
      "current iter: 16826000/24576000\n",
      "current iter: 16827000/24576000\n",
      "current iter: 16828000/24576000\n",
      "current iter: 16829000/24576000\n",
      "current iter: 16830000/24576000\n",
      "current iter: 16831000/24576000\n",
      "current iter: 16832000/24576000\n",
      "current iter: 16833000/24576000\n",
      "current iter: 16834000/24576000\n",
      "current iter: 16835000/24576000\n",
      "current iter: 16836000/24576000\n",
      "current iter: 16837000/24576000\n",
      "current iter: 16838000/24576000\n",
      "current iter: 16839000/24576000\n",
      "current iter: 16840000/24576000\n",
      "current iter: 16841000/24576000\n",
      "current iter: 16842000/24576000\n",
      "current iter: 16843000/24576000\n",
      "current iter: 16844000/24576000\n",
      "current iter: 16845000/24576000\n",
      "current iter: 16846000/24576000\n",
      "current iter: 16847000/24576000\n",
      "current iter: 16848000/24576000\n",
      "current iter: 16849000/24576000\n",
      "current iter: 16850000/24576000\n",
      "current iter: 16851000/24576000\n",
      "current iter: 16852000/24576000\n",
      "current iter: 16853000/24576000\n",
      "current iter: 16854000/24576000\n",
      "current iter: 16855000/24576000\n",
      "current iter: 16856000/24576000\n",
      "current iter: 16857000/24576000\n",
      "current iter: 16858000/24576000\n",
      "current iter: 16859000/24576000\n",
      "current iter: 16860000/24576000\n",
      "current iter: 16861000/24576000\n",
      "current iter: 16862000/24576000\n",
      "current iter: 16863000/24576000\n",
      "current iter: 16864000/24576000\n",
      "current iter: 16865000/24576000\n",
      "current iter: 16866000/24576000\n",
      "current iter: 16867000/24576000\n",
      "current iter: 16868000/24576000\n",
      "current iter: 16869000/24576000\n",
      "current iter: 16870000/24576000\n",
      "current iter: 16871000/24576000\n",
      "current iter: 16872000/24576000\n",
      "current iter: 16873000/24576000\n",
      "current iter: 16874000/24576000\n",
      "current iter: 16875000/24576000\n",
      "current iter: 16876000/24576000\n",
      "current iter: 16877000/24576000\n",
      "current iter: 16878000/24576000\n",
      "current iter: 16879000/24576000\n",
      "current iter: 16880000/24576000\n",
      "current iter: 16881000/24576000\n",
      "current iter: 16882000/24576000\n",
      "current iter: 16883000/24576000\n",
      "current iter: 16884000/24576000\n",
      "current iter: 16885000/24576000\n",
      "current iter: 16886000/24576000\n",
      "current iter: 16887000/24576000\n",
      "current iter: 16888000/24576000\n",
      "current iter: 16889000/24576000\n",
      "current iter: 16890000/24576000\n",
      "current iter: 16891000/24576000\n",
      "current iter: 16892000/24576000\n",
      "current iter: 16893000/24576000\n",
      "current iter: 16894000/24576000\n",
      "current iter: 16895000/24576000\n",
      "current iter: 16896000/24576000\n",
      "current iter: 16897000/24576000\n",
      "current iter: 16898000/24576000\n",
      "current iter: 16899000/24576000\n",
      "current iter: 16900000/24576000\n",
      "current iter: 16901000/24576000\n",
      "current iter: 16902000/24576000\n",
      "current iter: 16903000/24576000\n",
      "current iter: 16904000/24576000\n",
      "current iter: 16905000/24576000\n",
      "current iter: 16906000/24576000\n",
      "current iter: 16907000/24576000\n",
      "current iter: 16908000/24576000\n",
      "current iter: 16909000/24576000\n",
      "current iter: 16910000/24576000\n",
      "current iter: 16911000/24576000\n",
      "current iter: 16912000/24576000\n",
      "current iter: 16913000/24576000\n",
      "current iter: 16914000/24576000\n",
      "current iter: 16915000/24576000\n",
      "current iter: 16916000/24576000\n",
      "current iter: 16917000/24576000\n",
      "current iter: 16918000/24576000\n",
      "current iter: 16919000/24576000\n",
      "current iter: 16920000/24576000\n",
      "current iter: 16921000/24576000\n",
      "current iter: 16922000/24576000\n",
      "current iter: 16923000/24576000\n",
      "current iter: 16924000/24576000\n",
      "current iter: 16925000/24576000\n",
      "current iter: 16926000/24576000\n",
      "current iter: 16927000/24576000\n",
      "current iter: 16928000/24576000\n",
      "current iter: 16929000/24576000\n",
      "current iter: 16930000/24576000\n",
      "current iter: 16931000/24576000\n",
      "current iter: 16932000/24576000\n",
      "current iter: 16933000/24576000\n",
      "current iter: 16934000/24576000\n",
      "current iter: 16935000/24576000\n",
      "current iter: 16936000/24576000\n",
      "current iter: 16937000/24576000\n",
      "current iter: 16938000/24576000\n",
      "current iter: 16939000/24576000\n",
      "current iter: 16940000/24576000\n",
      "current iter: 16941000/24576000\n",
      "current iter: 16942000/24576000\n",
      "current iter: 16943000/24576000\n",
      "current iter: 16944000/24576000\n",
      "current iter: 16945000/24576000\n",
      "current iter: 16946000/24576000\n",
      "current iter: 16947000/24576000\n",
      "current iter: 16948000/24576000\n",
      "current iter: 16949000/24576000\n",
      "current iter: 16950000/24576000\n",
      "current iter: 16951000/24576000\n",
      "current iter: 16952000/24576000\n",
      "current iter: 16953000/24576000\n",
      "current iter: 16954000/24576000\n",
      "current iter: 16955000/24576000\n",
      "current iter: 16956000/24576000\n",
      "current iter: 16957000/24576000\n",
      "current iter: 16958000/24576000\n",
      "current iter: 16959000/24576000\n",
      "current iter: 16960000/24576000\n",
      "current iter: 16961000/24576000\n",
      "current iter: 16962000/24576000\n",
      "current iter: 16963000/24576000\n",
      "current iter: 16964000/24576000\n",
      "current iter: 16965000/24576000\n",
      "current iter: 16966000/24576000\n",
      "current iter: 16967000/24576000\n",
      "current iter: 16968000/24576000\n",
      "current iter: 16969000/24576000\n",
      "current iter: 16970000/24576000\n",
      "current iter: 16971000/24576000\n",
      "current iter: 16972000/24576000\n",
      "current iter: 16973000/24576000\n",
      "current iter: 16974000/24576000\n",
      "current iter: 16975000/24576000\n",
      "current iter: 16976000/24576000\n",
      "current iter: 16977000/24576000\n",
      "current iter: 16978000/24576000\n",
      "current iter: 16979000/24576000\n",
      "current iter: 16980000/24576000\n",
      "current iter: 16981000/24576000\n",
      "current iter: 16982000/24576000\n",
      "current iter: 16983000/24576000\n",
      "current iter: 16984000/24576000\n",
      "current iter: 16985000/24576000\n",
      "current iter: 16986000/24576000\n",
      "current iter: 16987000/24576000\n",
      "current iter: 16988000/24576000\n",
      "current iter: 16989000/24576000\n",
      "current iter: 16990000/24576000\n",
      "current iter: 16991000/24576000\n",
      "current iter: 16992000/24576000\n",
      "current iter: 16993000/24576000\n",
      "current iter: 16994000/24576000\n",
      "current iter: 16995000/24576000\n",
      "current iter: 16996000/24576000\n",
      "current iter: 16997000/24576000\n",
      "current iter: 16998000/24576000\n",
      "current iter: 16999000/24576000\n",
      "current iter: 17000000/24576000\n",
      "current iter: 17001000/24576000\n",
      "current iter: 17002000/24576000\n",
      "current iter: 17003000/24576000\n",
      "current iter: 17004000/24576000\n",
      "current iter: 17005000/24576000\n",
      "current iter: 17006000/24576000\n",
      "current iter: 17007000/24576000\n",
      "current iter: 17008000/24576000\n",
      "current iter: 17009000/24576000\n",
      "current iter: 17010000/24576000\n",
      "current iter: 17011000/24576000\n",
      "current iter: 17012000/24576000\n",
      "current iter: 17013000/24576000\n",
      "current iter: 17014000/24576000\n",
      "current iter: 17015000/24576000\n",
      "current iter: 17016000/24576000\n",
      "current iter: 17017000/24576000\n",
      "current iter: 17018000/24576000\n",
      "current iter: 17019000/24576000\n",
      "current iter: 17020000/24576000\n",
      "current iter: 17021000/24576000\n",
      "current iter: 17022000/24576000\n",
      "current iter: 17023000/24576000\n",
      "current iter: 17024000/24576000\n",
      "current iter: 17025000/24576000\n",
      "current iter: 17026000/24576000\n",
      "current iter: 17027000/24576000\n",
      "current iter: 17028000/24576000\n",
      "current iter: 17029000/24576000\n",
      "current iter: 17030000/24576000\n",
      "current iter: 17031000/24576000\n",
      "current iter: 17032000/24576000\n",
      "current iter: 17033000/24576000\n",
      "current iter: 17034000/24576000\n",
      "current iter: 17035000/24576000\n",
      "current iter: 17036000/24576000\n",
      "current iter: 17037000/24576000\n",
      "current iter: 17038000/24576000\n",
      "current iter: 17039000/24576000\n",
      "current iter: 17040000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 17041000/24576000\n",
      "current iter: 17042000/24576000\n",
      "current iter: 17043000/24576000\n",
      "current iter: 17044000/24576000\n",
      "current iter: 17045000/24576000\n",
      "current iter: 17046000/24576000\n",
      "current iter: 17047000/24576000\n",
      "current iter: 17048000/24576000\n",
      "current iter: 17049000/24576000\n",
      "current iter: 17050000/24576000\n",
      "current iter: 17051000/24576000\n",
      "current iter: 17052000/24576000\n",
      "current iter: 17053000/24576000\n",
      "current iter: 17054000/24576000\n",
      "current iter: 17055000/24576000\n",
      "current iter: 17056000/24576000\n",
      "current iter: 17057000/24576000\n",
      "current iter: 17058000/24576000\n",
      "current iter: 17059000/24576000\n",
      "current iter: 17060000/24576000\n",
      "current iter: 17061000/24576000\n",
      "current iter: 17062000/24576000\n",
      "current iter: 17063000/24576000\n",
      "current iter: 17064000/24576000\n",
      "current iter: 17065000/24576000\n",
      "current iter: 17066000/24576000\n",
      "current iter: 17067000/24576000\n",
      "current iter: 17068000/24576000\n",
      "current iter: 17069000/24576000\n",
      "current iter: 17070000/24576000\n",
      "current iter: 17071000/24576000\n",
      "current iter: 17072000/24576000\n",
      "current iter: 17073000/24576000\n",
      "current iter: 17074000/24576000\n",
      "current iter: 17075000/24576000\n",
      "current iter: 17076000/24576000\n",
      "current iter: 17077000/24576000\n",
      "current iter: 17078000/24576000\n",
      "current iter: 17079000/24576000\n",
      "current iter: 17080000/24576000\n",
      "current iter: 17081000/24576000\n",
      "current iter: 17082000/24576000\n",
      "current iter: 17083000/24576000\n",
      "current iter: 17084000/24576000\n",
      "current iter: 17085000/24576000\n",
      "current iter: 17086000/24576000\n",
      "current iter: 17087000/24576000\n",
      "current iter: 17088000/24576000\n",
      "current iter: 17089000/24576000\n",
      "current iter: 17090000/24576000\n",
      "current iter: 17091000/24576000\n",
      "current iter: 17092000/24576000\n",
      "current iter: 17093000/24576000\n",
      "current iter: 17094000/24576000\n",
      "current iter: 17095000/24576000\n",
      "current iter: 17096000/24576000\n",
      "current iter: 17097000/24576000\n",
      "current iter: 17098000/24576000\n",
      "current iter: 17099000/24576000\n",
      "current iter: 17100000/24576000\n",
      "current iter: 17101000/24576000\n",
      "current iter: 17102000/24576000\n",
      "current iter: 17103000/24576000\n",
      "current iter: 17104000/24576000\n",
      "current iter: 17105000/24576000\n",
      "current iter: 17106000/24576000\n",
      "current iter: 17107000/24576000\n",
      "current iter: 17108000/24576000\n",
      "current iter: 17109000/24576000\n",
      "current iter: 17110000/24576000\n",
      "current iter: 17111000/24576000\n",
      "current iter: 17112000/24576000\n",
      "current iter: 17113000/24576000\n",
      "current iter: 17114000/24576000\n",
      "current iter: 17115000/24576000\n",
      "current iter: 17116000/24576000\n",
      "current iter: 17117000/24576000\n",
      "current iter: 17118000/24576000\n",
      "current iter: 17119000/24576000\n",
      "current iter: 17120000/24576000\n",
      "current iter: 17121000/24576000\n",
      "current iter: 17122000/24576000\n",
      "current iter: 17123000/24576000\n",
      "current iter: 17124000/24576000\n",
      "current iter: 17125000/24576000\n",
      "current iter: 17126000/24576000\n",
      "current iter: 17127000/24576000\n",
      "current iter: 17128000/24576000\n",
      "current iter: 17129000/24576000\n",
      "current iter: 17130000/24576000\n",
      "current iter: 17131000/24576000\n",
      "current iter: 17132000/24576000\n",
      "current iter: 17133000/24576000\n",
      "current iter: 17134000/24576000\n",
      "current iter: 17135000/24576000\n",
      "current iter: 17136000/24576000\n",
      "current iter: 17137000/24576000\n",
      "current iter: 17138000/24576000\n",
      "current iter: 17139000/24576000\n",
      "current iter: 17140000/24576000\n",
      "current iter: 17141000/24576000\n",
      "current iter: 17142000/24576000\n",
      "current iter: 17143000/24576000\n",
      "current iter: 17144000/24576000\n",
      "current iter: 17145000/24576000\n",
      "current iter: 17146000/24576000\n",
      "current iter: 17147000/24576000\n",
      "current iter: 17148000/24576000\n",
      "current iter: 17149000/24576000\n",
      "current iter: 17150000/24576000\n",
      "current iter: 17151000/24576000\n",
      "current iter: 17152000/24576000\n",
      "current iter: 17153000/24576000\n",
      "current iter: 17154000/24576000\n",
      "current iter: 17155000/24576000\n",
      "current iter: 17156000/24576000\n",
      "current iter: 17157000/24576000\n",
      "current iter: 17158000/24576000\n",
      "current iter: 17159000/24576000\n",
      "current iter: 17160000/24576000\n",
      "current iter: 17161000/24576000\n",
      "current iter: 17162000/24576000\n",
      "current iter: 17163000/24576000\n",
      "current iter: 17164000/24576000\n",
      "current iter: 17165000/24576000\n",
      "current iter: 17166000/24576000\n",
      "current iter: 17167000/24576000\n",
      "current iter: 17168000/24576000\n",
      "current iter: 17169000/24576000\n",
      "current iter: 17170000/24576000\n",
      "current iter: 17171000/24576000\n",
      "current iter: 17172000/24576000\n",
      "current iter: 17173000/24576000\n",
      "current iter: 17174000/24576000\n",
      "current iter: 17175000/24576000\n",
      "current iter: 17176000/24576000\n",
      "current iter: 17177000/24576000\n",
      "current iter: 17178000/24576000\n",
      "current iter: 17179000/24576000\n",
      "current iter: 17180000/24576000\n",
      "current iter: 17181000/24576000\n",
      "current iter: 17182000/24576000\n",
      "current iter: 17183000/24576000\n",
      "current iter: 17184000/24576000\n",
      "current iter: 17185000/24576000\n",
      "current iter: 17186000/24576000\n",
      "current iter: 17187000/24576000\n",
      "current iter: 17188000/24576000\n",
      "current iter: 17189000/24576000\n",
      "current iter: 17190000/24576000\n",
      "current iter: 17191000/24576000\n",
      "current iter: 17192000/24576000\n",
      "current iter: 17193000/24576000\n",
      "current iter: 17194000/24576000\n",
      "current iter: 17195000/24576000\n",
      "current iter: 17196000/24576000\n",
      "current iter: 17197000/24576000\n",
      "current iter: 17198000/24576000\n",
      "current iter: 17199000/24576000\n",
      "current iter: 17200000/24576000\n",
      "current iter: 17201000/24576000\n",
      "current iter: 17202000/24576000\n",
      "current iter: 17203000/24576000\n",
      "current iter: 17204000/24576000\n",
      "current iter: 17205000/24576000\n",
      "current iter: 17206000/24576000\n",
      "current iter: 17207000/24576000\n",
      "current iter: 17208000/24576000\n",
      "current iter: 17209000/24576000\n",
      "current iter: 17210000/24576000\n",
      "current iter: 17211000/24576000\n",
      "current iter: 17212000/24576000\n",
      "current iter: 17213000/24576000\n",
      "current iter: 17214000/24576000\n",
      "current iter: 17215000/24576000\n",
      "current iter: 17216000/24576000\n",
      "current iter: 17217000/24576000\n",
      "current iter: 17218000/24576000\n",
      "current iter: 17219000/24576000\n",
      "current iter: 17220000/24576000\n",
      "current iter: 17221000/24576000\n",
      "current iter: 17222000/24576000\n",
      "current iter: 17223000/24576000\n",
      "current iter: 17224000/24576000\n",
      "current iter: 17225000/24576000\n",
      "current iter: 17226000/24576000\n",
      "current iter: 17227000/24576000\n",
      "current iter: 17228000/24576000\n",
      "current iter: 17229000/24576000\n",
      "current iter: 17230000/24576000\n",
      "current iter: 17231000/24576000\n",
      "current iter: 17232000/24576000\n",
      "current iter: 17233000/24576000\n",
      "current iter: 17234000/24576000\n",
      "current iter: 17235000/24576000\n",
      "current iter: 17236000/24576000\n",
      "current iter: 17237000/24576000\n",
      "current iter: 17238000/24576000\n",
      "current iter: 17239000/24576000\n",
      "current iter: 17240000/24576000\n",
      "current iter: 17241000/24576000\n",
      "current iter: 17242000/24576000\n",
      "current iter: 17243000/24576000\n",
      "current iter: 17244000/24576000\n",
      "current iter: 17245000/24576000\n",
      "current iter: 17246000/24576000\n",
      "current iter: 17247000/24576000\n",
      "current iter: 17248000/24576000\n",
      "current iter: 17249000/24576000\n",
      "current iter: 17250000/24576000\n",
      "current iter: 17251000/24576000\n",
      "current iter: 17252000/24576000\n",
      "current iter: 17253000/24576000\n",
      "current iter: 17254000/24576000\n",
      "current iter: 17255000/24576000\n",
      "current iter: 17256000/24576000\n",
      "current iter: 17257000/24576000\n",
      "current iter: 17258000/24576000\n",
      "current iter: 17259000/24576000\n",
      "current iter: 17260000/24576000\n",
      "current iter: 17261000/24576000\n",
      "current iter: 17262000/24576000\n",
      "current iter: 17263000/24576000\n",
      "current iter: 17264000/24576000\n",
      "current iter: 17265000/24576000\n",
      "current iter: 17266000/24576000\n",
      "current iter: 17267000/24576000\n",
      "current iter: 17268000/24576000\n",
      "current iter: 17269000/24576000\n",
      "current iter: 17270000/24576000\n",
      "current iter: 17271000/24576000\n",
      "current iter: 17272000/24576000\n",
      "current iter: 17273000/24576000\n",
      "current iter: 17274000/24576000\n",
      "current iter: 17275000/24576000\n",
      "current iter: 17276000/24576000\n",
      "current iter: 17277000/24576000\n",
      "current iter: 17278000/24576000\n",
      "current iter: 17279000/24576000\n",
      "current iter: 17280000/24576000\n",
      "current iter: 17281000/24576000\n",
      "current iter: 17282000/24576000\n",
      "current iter: 17283000/24576000\n",
      "current iter: 17284000/24576000\n",
      "current iter: 17285000/24576000\n",
      "current iter: 17286000/24576000\n",
      "current iter: 17287000/24576000\n",
      "current iter: 17288000/24576000\n",
      "current iter: 17289000/24576000\n",
      "current iter: 17290000/24576000\n",
      "current iter: 17291000/24576000\n",
      "current iter: 17292000/24576000\n",
      "current iter: 17293000/24576000\n",
      "current iter: 17294000/24576000\n",
      "current iter: 17295000/24576000\n",
      "current iter: 17296000/24576000\n",
      "current iter: 17297000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 17298000/24576000\n",
      "current iter: 17299000/24576000\n",
      "current iter: 17300000/24576000\n",
      "current iter: 17301000/24576000\n",
      "current iter: 17302000/24576000\n",
      "current iter: 17303000/24576000\n",
      "current iter: 17304000/24576000\n",
      "current iter: 17305000/24576000\n",
      "current iter: 17306000/24576000\n",
      "current iter: 17307000/24576000\n",
      "current iter: 17308000/24576000\n",
      "current iter: 17309000/24576000\n",
      "current iter: 17310000/24576000\n",
      "current iter: 17311000/24576000\n",
      "current iter: 17312000/24576000\n",
      "current iter: 17313000/24576000\n",
      "current iter: 17314000/24576000\n",
      "current iter: 17315000/24576000\n",
      "current iter: 17316000/24576000\n",
      "current iter: 17317000/24576000\n",
      "current iter: 17318000/24576000\n",
      "current iter: 17319000/24576000\n",
      "current iter: 17320000/24576000\n",
      "current iter: 17321000/24576000\n",
      "current iter: 17322000/24576000\n",
      "current iter: 17323000/24576000\n",
      "current iter: 17324000/24576000\n",
      "current iter: 17325000/24576000\n",
      "current iter: 17326000/24576000\n",
      "current iter: 17327000/24576000\n",
      "current iter: 17328000/24576000\n",
      "current iter: 17329000/24576000\n",
      "current iter: 17330000/24576000\n",
      "current iter: 17331000/24576000\n",
      "current iter: 17332000/24576000\n",
      "current iter: 17333000/24576000\n",
      "current iter: 17334000/24576000\n",
      "current iter: 17335000/24576000\n",
      "current iter: 17336000/24576000\n",
      "current iter: 17337000/24576000\n",
      "current iter: 17338000/24576000\n",
      "current iter: 17339000/24576000\n",
      "current iter: 17340000/24576000\n",
      "current iter: 17341000/24576000\n",
      "current iter: 17342000/24576000\n",
      "current iter: 17343000/24576000\n",
      "current iter: 17344000/24576000\n",
      "current iter: 17345000/24576000\n",
      "current iter: 17346000/24576000\n",
      "current iter: 17347000/24576000\n",
      "current iter: 17348000/24576000\n",
      "current iter: 17349000/24576000\n",
      "current iter: 17350000/24576000\n",
      "current iter: 17351000/24576000\n",
      "current iter: 17352000/24576000\n",
      "current iter: 17353000/24576000\n",
      "current iter: 17354000/24576000\n",
      "current iter: 17355000/24576000\n",
      "current iter: 17356000/24576000\n",
      "current iter: 17357000/24576000\n",
      "current iter: 17358000/24576000\n",
      "current iter: 17359000/24576000\n",
      "current iter: 17360000/24576000\n",
      "current iter: 17361000/24576000\n",
      "current iter: 17362000/24576000\n",
      "current iter: 17363000/24576000\n",
      "current iter: 17364000/24576000\n",
      "current iter: 17365000/24576000\n",
      "current iter: 17366000/24576000\n",
      "current iter: 17367000/24576000\n",
      "current iter: 17368000/24576000\n",
      "current iter: 17369000/24576000\n",
      "current iter: 17370000/24576000\n",
      "current iter: 17371000/24576000\n",
      "current iter: 17372000/24576000\n",
      "current iter: 17373000/24576000\n",
      "current iter: 17374000/24576000\n",
      "current iter: 17375000/24576000\n",
      "current iter: 17376000/24576000\n",
      "current iter: 17377000/24576000\n",
      "current iter: 17378000/24576000\n",
      "current iter: 17379000/24576000\n",
      "current iter: 17380000/24576000\n",
      "current iter: 17381000/24576000\n",
      "current iter: 17382000/24576000\n",
      "current iter: 17383000/24576000\n",
      "current iter: 17384000/24576000\n",
      "current iter: 17385000/24576000\n",
      "current iter: 17386000/24576000\n",
      "current iter: 17387000/24576000\n",
      "current iter: 17388000/24576000\n",
      "current iter: 17389000/24576000\n",
      "current iter: 17390000/24576000\n",
      "current iter: 17391000/24576000\n",
      "current iter: 17392000/24576000\n",
      "current iter: 17393000/24576000\n",
      "current iter: 17394000/24576000\n",
      "current iter: 17395000/24576000\n",
      "current iter: 17396000/24576000\n",
      "current iter: 17397000/24576000\n",
      "current iter: 17398000/24576000\n",
      "current iter: 17399000/24576000\n",
      "current iter: 17400000/24576000\n",
      "current iter: 17401000/24576000\n",
      "current iter: 17402000/24576000\n",
      "current iter: 17403000/24576000\n",
      "current iter: 17404000/24576000\n",
      "current iter: 17405000/24576000\n",
      "current iter: 17406000/24576000\n",
      "current iter: 17407000/24576000\n",
      "current iter: 17408000/24576000\n",
      "current iter: 17409000/24576000\n",
      "current iter: 17410000/24576000\n",
      "current iter: 17411000/24576000\n",
      "current iter: 17412000/24576000\n",
      "current iter: 17413000/24576000\n",
      "current iter: 17414000/24576000\n",
      "current iter: 17415000/24576000\n",
      "current iter: 17416000/24576000\n",
      "current iter: 17417000/24576000\n",
      "current iter: 17418000/24576000\n",
      "current iter: 17419000/24576000\n",
      "current iter: 17420000/24576000\n",
      "current iter: 17421000/24576000\n",
      "current iter: 17422000/24576000\n",
      "current iter: 17423000/24576000\n",
      "current iter: 17424000/24576000\n",
      "current iter: 17425000/24576000\n",
      "current iter: 17426000/24576000\n",
      "current iter: 17427000/24576000\n",
      "current iter: 17428000/24576000\n",
      "current iter: 17429000/24576000\n",
      "current iter: 17430000/24576000\n",
      "current iter: 17431000/24576000\n",
      "current iter: 17432000/24576000\n",
      "current iter: 17433000/24576000\n",
      "current iter: 17434000/24576000\n",
      "current iter: 17435000/24576000\n",
      "current iter: 17436000/24576000\n",
      "current iter: 17437000/24576000\n",
      "current iter: 17438000/24576000\n",
      "current iter: 17439000/24576000\n",
      "current iter: 17440000/24576000\n",
      "current iter: 17441000/24576000\n",
      "current iter: 17442000/24576000\n",
      "current iter: 17443000/24576000\n",
      "current iter: 17444000/24576000\n",
      "current iter: 17445000/24576000\n",
      "current iter: 17446000/24576000\n",
      "current iter: 17447000/24576000\n",
      "current iter: 17448000/24576000\n",
      "current iter: 17449000/24576000\n",
      "current iter: 17450000/24576000\n",
      "current iter: 17451000/24576000\n",
      "current iter: 17452000/24576000\n",
      "current iter: 17453000/24576000\n",
      "current iter: 17454000/24576000\n",
      "current iter: 17455000/24576000\n",
      "current iter: 17456000/24576000\n",
      "current iter: 17457000/24576000\n",
      "current iter: 17458000/24576000\n",
      "current iter: 17459000/24576000\n",
      "current iter: 17460000/24576000\n",
      "current iter: 17461000/24576000\n",
      "current iter: 17462000/24576000\n",
      "current iter: 17463000/24576000\n",
      "current iter: 17464000/24576000\n",
      "current iter: 17465000/24576000\n",
      "current iter: 17466000/24576000\n",
      "current iter: 17467000/24576000\n",
      "current iter: 17468000/24576000\n",
      "current iter: 17469000/24576000\n",
      "current iter: 17470000/24576000\n",
      "current iter: 17471000/24576000\n",
      "current iter: 17472000/24576000\n",
      "current iter: 17473000/24576000\n",
      "current iter: 17474000/24576000\n",
      "current iter: 17475000/24576000\n",
      "current iter: 17476000/24576000\n",
      "current iter: 17477000/24576000\n",
      "current iter: 17478000/24576000\n",
      "current iter: 17479000/24576000\n",
      "current iter: 17480000/24576000\n",
      "current iter: 17481000/24576000\n",
      "current iter: 17482000/24576000\n",
      "current iter: 17483000/24576000\n",
      "current iter: 17484000/24576000\n",
      "current iter: 17485000/24576000\n",
      "current iter: 17486000/24576000\n",
      "current iter: 17487000/24576000\n",
      "current iter: 17488000/24576000\n",
      "current iter: 17489000/24576000\n",
      "current iter: 17490000/24576000\n",
      "current iter: 17491000/24576000\n",
      "current iter: 17492000/24576000\n",
      "current iter: 17493000/24576000\n",
      "current iter: 17494000/24576000\n",
      "current iter: 17495000/24576000\n",
      "current iter: 17496000/24576000\n",
      "current iter: 17497000/24576000\n",
      "current iter: 17498000/24576000\n",
      "current iter: 17499000/24576000\n",
      "current iter: 17500000/24576000\n",
      "current iter: 17501000/24576000\n",
      "current iter: 17502000/24576000\n",
      "current iter: 17503000/24576000\n",
      "current iter: 17504000/24576000\n",
      "current iter: 17505000/24576000\n",
      "current iter: 17506000/24576000\n",
      "current iter: 17507000/24576000\n",
      "current iter: 17508000/24576000\n",
      "current iter: 17509000/24576000\n",
      "current iter: 17510000/24576000\n",
      "current iter: 17511000/24576000\n",
      "current iter: 17512000/24576000\n",
      "current iter: 17513000/24576000\n",
      "current iter: 17514000/24576000\n",
      "current iter: 17515000/24576000\n",
      "current iter: 17516000/24576000\n",
      "current iter: 17517000/24576000\n",
      "current iter: 17518000/24576000\n",
      "current iter: 17519000/24576000\n",
      "current iter: 17520000/24576000\n",
      "current iter: 17521000/24576000\n",
      "current iter: 17522000/24576000\n",
      "current iter: 17523000/24576000\n",
      "current iter: 17524000/24576000\n",
      "current iter: 17525000/24576000\n",
      "current iter: 17526000/24576000\n",
      "current iter: 17527000/24576000\n",
      "current iter: 17528000/24576000\n",
      "current iter: 17529000/24576000\n",
      "current iter: 17530000/24576000\n",
      "current iter: 17531000/24576000\n",
      "current iter: 17532000/24576000\n",
      "current iter: 17533000/24576000\n",
      "current iter: 17534000/24576000\n",
      "current iter: 17535000/24576000\n",
      "current iter: 17536000/24576000\n",
      "current iter: 17537000/24576000\n",
      "current iter: 17538000/24576000\n",
      "current iter: 17539000/24576000\n",
      "current iter: 17540000/24576000\n",
      "current iter: 17541000/24576000\n",
      "current iter: 17542000/24576000\n",
      "current iter: 17543000/24576000\n",
      "current iter: 17544000/24576000\n",
      "current iter: 17545000/24576000\n",
      "current iter: 17546000/24576000\n",
      "current iter: 17547000/24576000\n",
      "current iter: 17548000/24576000\n",
      "current iter: 17549000/24576000\n",
      "current iter: 17550000/24576000\n",
      "current iter: 17551000/24576000\n",
      "current iter: 17552000/24576000\n",
      "current iter: 17553000/24576000\n",
      "current iter: 17554000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 17555000/24576000\n",
      "current iter: 17556000/24576000\n",
      "current iter: 17557000/24576000\n",
      "current iter: 17558000/24576000\n",
      "current iter: 17559000/24576000\n",
      "current iter: 17560000/24576000\n",
      "current iter: 17561000/24576000\n",
      "current iter: 17562000/24576000\n",
      "current iter: 17563000/24576000\n",
      "current iter: 17564000/24576000\n",
      "current iter: 17565000/24576000\n",
      "current iter: 17566000/24576000\n",
      "current iter: 17567000/24576000\n",
      "current iter: 17568000/24576000\n",
      "current iter: 17569000/24576000\n",
      "current iter: 17570000/24576000\n",
      "current iter: 17571000/24576000\n",
      "current iter: 17572000/24576000\n",
      "current iter: 17573000/24576000\n",
      "current iter: 17574000/24576000\n",
      "current iter: 17575000/24576000\n",
      "current iter: 17576000/24576000\n",
      "current iter: 17577000/24576000\n",
      "current iter: 17578000/24576000\n",
      "current iter: 17579000/24576000\n",
      "current iter: 17580000/24576000\n",
      "current iter: 17581000/24576000\n",
      "current iter: 17582000/24576000\n",
      "current iter: 17583000/24576000\n",
      "current iter: 17584000/24576000\n",
      "current iter: 17585000/24576000\n",
      "current iter: 17586000/24576000\n",
      "current iter: 17587000/24576000\n",
      "current iter: 17588000/24576000\n",
      "current iter: 17589000/24576000\n",
      "current iter: 17590000/24576000\n",
      "current iter: 17591000/24576000\n",
      "current iter: 17592000/24576000\n",
      "current iter: 17593000/24576000\n",
      "current iter: 17594000/24576000\n",
      "current iter: 17595000/24576000\n",
      "current iter: 17596000/24576000\n",
      "current iter: 17597000/24576000\n",
      "current iter: 17598000/24576000\n",
      "current iter: 17599000/24576000\n",
      "current iter: 17600000/24576000\n",
      "current iter: 17601000/24576000\n",
      "current iter: 17602000/24576000\n",
      "current iter: 17603000/24576000\n",
      "current iter: 17604000/24576000\n",
      "current iter: 17605000/24576000\n",
      "current iter: 17606000/24576000\n",
      "current iter: 17607000/24576000\n",
      "current iter: 17608000/24576000\n",
      "current iter: 17609000/24576000\n",
      "current iter: 17610000/24576000\n",
      "current iter: 17611000/24576000\n",
      "current iter: 17612000/24576000\n",
      "current iter: 17613000/24576000\n",
      "current iter: 17614000/24576000\n",
      "current iter: 17615000/24576000\n",
      "current iter: 17616000/24576000\n",
      "current iter: 17617000/24576000\n",
      "current iter: 17618000/24576000\n",
      "current iter: 17619000/24576000\n",
      "current iter: 17620000/24576000\n",
      "current iter: 17621000/24576000\n",
      "current iter: 17622000/24576000\n",
      "current iter: 17623000/24576000\n",
      "current iter: 17624000/24576000\n",
      "current iter: 17625000/24576000\n",
      "current iter: 17626000/24576000\n",
      "current iter: 17627000/24576000\n",
      "current iter: 17628000/24576000\n",
      "current iter: 17629000/24576000\n",
      "current iter: 17630000/24576000\n",
      "current iter: 17631000/24576000\n",
      "current iter: 17632000/24576000\n",
      "current iter: 17633000/24576000\n",
      "current iter: 17634000/24576000\n",
      "current iter: 17635000/24576000\n",
      "current iter: 17636000/24576000\n",
      "current iter: 17637000/24576000\n",
      "current iter: 17638000/24576000\n",
      "current iter: 17639000/24576000\n",
      "current iter: 17640000/24576000\n",
      "current iter: 17641000/24576000\n",
      "current iter: 17642000/24576000\n",
      "current iter: 17643000/24576000\n",
      "current iter: 17644000/24576000\n",
      "current iter: 17645000/24576000\n",
      "current iter: 17646000/24576000\n",
      "current iter: 17647000/24576000\n",
      "current iter: 17648000/24576000\n",
      "current iter: 17649000/24576000\n",
      "current iter: 17650000/24576000\n",
      "current iter: 17651000/24576000\n",
      "current iter: 17652000/24576000\n",
      "current iter: 17653000/24576000\n",
      "current iter: 17654000/24576000\n",
      "current iter: 17655000/24576000\n",
      "current iter: 17656000/24576000\n",
      "current iter: 17657000/24576000\n",
      "current iter: 17658000/24576000\n",
      "current iter: 17659000/24576000\n",
      "current iter: 17660000/24576000\n",
      "current iter: 17661000/24576000\n",
      "current iter: 17662000/24576000\n",
      "current iter: 17663000/24576000\n",
      "current iter: 17664000/24576000\n",
      "current iter: 17665000/24576000\n",
      "current iter: 17666000/24576000\n",
      "current iter: 17667000/24576000\n",
      "current iter: 17668000/24576000\n",
      "current iter: 17669000/24576000\n",
      "current iter: 17670000/24576000\n",
      "current iter: 17671000/24576000\n",
      "current iter: 17672000/24576000\n",
      "current iter: 17673000/24576000\n",
      "current iter: 17674000/24576000\n",
      "current iter: 17675000/24576000\n",
      "current iter: 17676000/24576000\n",
      "current iter: 17677000/24576000\n",
      "current iter: 17678000/24576000\n",
      "current iter: 17679000/24576000\n",
      "current iter: 17680000/24576000\n",
      "current iter: 17681000/24576000\n",
      "current iter: 17682000/24576000\n",
      "current iter: 17683000/24576000\n",
      "current iter: 17684000/24576000\n",
      "current iter: 17685000/24576000\n",
      "current iter: 17686000/24576000\n",
      "current iter: 17687000/24576000\n",
      "current iter: 17688000/24576000\n",
      "current iter: 17689000/24576000\n",
      "current iter: 17690000/24576000\n",
      "current iter: 17691000/24576000\n",
      "current iter: 17692000/24576000\n",
      "current iter: 17693000/24576000\n",
      "current iter: 17694000/24576000\n",
      "current iter: 17695000/24576000\n",
      "current iter: 17696000/24576000\n",
      "current iter: 17697000/24576000\n",
      "current iter: 17698000/24576000\n",
      "current iter: 17699000/24576000\n",
      "current iter: 17700000/24576000\n",
      "current iter: 17701000/24576000\n",
      "current iter: 17702000/24576000\n",
      "current iter: 17703000/24576000\n",
      "current iter: 17704000/24576000\n",
      "current iter: 17705000/24576000\n",
      "current iter: 17706000/24576000\n",
      "current iter: 17707000/24576000\n",
      "current iter: 17708000/24576000\n",
      "current iter: 17709000/24576000\n",
      "current iter: 17710000/24576000\n",
      "current iter: 17711000/24576000\n",
      "current iter: 17712000/24576000\n",
      "current iter: 17713000/24576000\n",
      "current iter: 17714000/24576000\n",
      "current iter: 17715000/24576000\n",
      "current iter: 17716000/24576000\n",
      "current iter: 17717000/24576000\n",
      "current iter: 17718000/24576000\n",
      "current iter: 17719000/24576000\n",
      "current iter: 17720000/24576000\n",
      "current iter: 17721000/24576000\n",
      "current iter: 17722000/24576000\n",
      "current iter: 17723000/24576000\n",
      "current iter: 17724000/24576000\n",
      "current iter: 17725000/24576000\n",
      "current iter: 17726000/24576000\n",
      "current iter: 17727000/24576000\n",
      "current iter: 17728000/24576000\n",
      "current iter: 17729000/24576000\n",
      "current iter: 17730000/24576000\n",
      "current iter: 17731000/24576000\n",
      "current iter: 17732000/24576000\n",
      "current iter: 17733000/24576000\n",
      "current iter: 17734000/24576000\n",
      "current iter: 17735000/24576000\n",
      "current iter: 17736000/24576000\n",
      "current iter: 17737000/24576000\n",
      "current iter: 17738000/24576000\n",
      "current iter: 17739000/24576000\n",
      "current iter: 17740000/24576000\n",
      "current iter: 17741000/24576000\n",
      "current iter: 17742000/24576000\n",
      "current iter: 17743000/24576000\n",
      "current iter: 17744000/24576000\n",
      "current iter: 17745000/24576000\n",
      "current iter: 17746000/24576000\n",
      "current iter: 17747000/24576000\n",
      "current iter: 17748000/24576000\n",
      "current iter: 17749000/24576000\n",
      "current iter: 17750000/24576000\n",
      "current iter: 17751000/24576000\n",
      "current iter: 17752000/24576000\n",
      "current iter: 17753000/24576000\n",
      "current iter: 17754000/24576000\n",
      "current iter: 17755000/24576000\n",
      "current iter: 17756000/24576000\n",
      "current iter: 17757000/24576000\n",
      "current iter: 17758000/24576000\n",
      "current iter: 17759000/24576000\n",
      "current iter: 17760000/24576000\n",
      "current iter: 17761000/24576000\n",
      "current iter: 17762000/24576000\n",
      "current iter: 17763000/24576000\n",
      "current iter: 17764000/24576000\n",
      "current iter: 17765000/24576000\n",
      "current iter: 17766000/24576000\n",
      "current iter: 17767000/24576000\n",
      "current iter: 17768000/24576000\n",
      "current iter: 17769000/24576000\n",
      "current iter: 17770000/24576000\n",
      "current iter: 17771000/24576000\n",
      "current iter: 17772000/24576000\n",
      "current iter: 17773000/24576000\n",
      "current iter: 17774000/24576000\n",
      "current iter: 17775000/24576000\n",
      "current iter: 17776000/24576000\n",
      "current iter: 17777000/24576000\n",
      "current iter: 17778000/24576000\n",
      "current iter: 17779000/24576000\n",
      "current iter: 17780000/24576000\n",
      "current iter: 17781000/24576000\n",
      "current iter: 17782000/24576000\n",
      "current iter: 17783000/24576000\n",
      "current iter: 17784000/24576000\n",
      "current iter: 17785000/24576000\n",
      "current iter: 17786000/24576000\n",
      "current iter: 17787000/24576000\n",
      "current iter: 17788000/24576000\n",
      "current iter: 17789000/24576000\n",
      "current iter: 17790000/24576000\n",
      "current iter: 17791000/24576000\n",
      "current iter: 17792000/24576000\n",
      "current iter: 17793000/24576000\n",
      "current iter: 17794000/24576000\n",
      "current iter: 17795000/24576000\n",
      "current iter: 17796000/24576000\n",
      "current iter: 17797000/24576000\n",
      "current iter: 17798000/24576000\n",
      "current iter: 17799000/24576000\n",
      "current iter: 17800000/24576000\n",
      "current iter: 17801000/24576000\n",
      "current iter: 17802000/24576000\n",
      "current iter: 17803000/24576000\n",
      "current iter: 17804000/24576000\n",
      "current iter: 17805000/24576000\n",
      "current iter: 17806000/24576000\n",
      "current iter: 17807000/24576000\n",
      "current iter: 17808000/24576000\n",
      "current iter: 17809000/24576000\n",
      "current iter: 17810000/24576000\n",
      "current iter: 17811000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 17812000/24576000\n",
      "current iter: 17813000/24576000\n",
      "current iter: 17814000/24576000\n",
      "current iter: 17815000/24576000\n",
      "current iter: 17816000/24576000\n",
      "current iter: 17817000/24576000\n",
      "current iter: 17818000/24576000\n",
      "current iter: 17819000/24576000\n",
      "current iter: 17820000/24576000\n",
      "current iter: 17821000/24576000\n",
      "current iter: 17822000/24576000\n",
      "current iter: 17823000/24576000\n",
      "current iter: 17824000/24576000\n",
      "current iter: 17825000/24576000\n",
      "current iter: 17826000/24576000\n",
      "current iter: 17827000/24576000\n",
      "current iter: 17828000/24576000\n",
      "current iter: 17829000/24576000\n",
      "current iter: 17830000/24576000\n",
      "current iter: 17831000/24576000\n",
      "current iter: 17832000/24576000\n",
      "current iter: 17833000/24576000\n",
      "current iter: 17834000/24576000\n",
      "current iter: 17835000/24576000\n",
      "current iter: 17836000/24576000\n",
      "current iter: 17837000/24576000\n",
      "current iter: 17838000/24576000\n",
      "current iter: 17839000/24576000\n",
      "current iter: 17840000/24576000\n",
      "current iter: 17841000/24576000\n",
      "current iter: 17842000/24576000\n",
      "current iter: 17843000/24576000\n",
      "current iter: 17844000/24576000\n",
      "current iter: 17845000/24576000\n",
      "current iter: 17846000/24576000\n",
      "current iter: 17847000/24576000\n",
      "current iter: 17848000/24576000\n",
      "current iter: 17849000/24576000\n",
      "current iter: 17850000/24576000\n",
      "current iter: 17851000/24576000\n",
      "current iter: 17852000/24576000\n",
      "current iter: 17853000/24576000\n",
      "current iter: 17854000/24576000\n",
      "current iter: 17855000/24576000\n",
      "current iter: 17856000/24576000\n",
      "current iter: 17857000/24576000\n",
      "current iter: 17858000/24576000\n",
      "current iter: 17859000/24576000\n",
      "current iter: 17860000/24576000\n",
      "current iter: 17861000/24576000\n",
      "current iter: 17862000/24576000\n",
      "current iter: 17863000/24576000\n",
      "current iter: 17864000/24576000\n",
      "current iter: 17865000/24576000\n",
      "current iter: 17866000/24576000\n",
      "current iter: 17867000/24576000\n",
      "current iter: 17868000/24576000\n",
      "current iter: 17869000/24576000\n",
      "current iter: 17870000/24576000\n",
      "current iter: 17871000/24576000\n",
      "current iter: 17872000/24576000\n",
      "current iter: 17873000/24576000\n",
      "current iter: 17874000/24576000\n",
      "current iter: 17875000/24576000\n",
      "current iter: 17876000/24576000\n",
      "current iter: 17877000/24576000\n",
      "current iter: 17878000/24576000\n",
      "current iter: 17879000/24576000\n",
      "current iter: 17880000/24576000\n",
      "current iter: 17881000/24576000\n",
      "current iter: 17882000/24576000\n",
      "current iter: 17883000/24576000\n",
      "current iter: 17884000/24576000\n",
      "current iter: 17885000/24576000\n",
      "current iter: 17886000/24576000\n",
      "current iter: 17887000/24576000\n",
      "current iter: 17888000/24576000\n",
      "current iter: 17889000/24576000\n",
      "current iter: 17890000/24576000\n",
      "current iter: 17891000/24576000\n",
      "current iter: 17892000/24576000\n",
      "current iter: 17893000/24576000\n",
      "current iter: 17894000/24576000\n",
      "current iter: 17895000/24576000\n",
      "current iter: 17896000/24576000\n",
      "current iter: 17897000/24576000\n",
      "current iter: 17898000/24576000\n",
      "current iter: 17899000/24576000\n",
      "current iter: 17900000/24576000\n",
      "current iter: 17901000/24576000\n",
      "current iter: 17902000/24576000\n",
      "current iter: 17903000/24576000\n",
      "current iter: 17904000/24576000\n",
      "current iter: 17905000/24576000\n",
      "current iter: 17906000/24576000\n",
      "current iter: 17907000/24576000\n",
      "current iter: 17908000/24576000\n",
      "current iter: 17909000/24576000\n",
      "current iter: 17910000/24576000\n",
      "current iter: 17911000/24576000\n",
      "current iter: 17912000/24576000\n",
      "current iter: 17913000/24576000\n",
      "current iter: 17914000/24576000\n",
      "current iter: 17915000/24576000\n",
      "current iter: 17916000/24576000\n",
      "current iter: 17917000/24576000\n",
      "current iter: 17918000/24576000\n",
      "current iter: 17919000/24576000\n",
      "current iter: 17920000/24576000\n",
      "current iter: 17921000/24576000\n",
      "current iter: 17922000/24576000\n",
      "current iter: 17923000/24576000\n",
      "current iter: 17924000/24576000\n",
      "current iter: 17925000/24576000\n",
      "current iter: 17926000/24576000\n",
      "current iter: 17927000/24576000\n",
      "current iter: 17928000/24576000\n",
      "current iter: 17929000/24576000\n",
      "current iter: 17930000/24576000\n",
      "current iter: 17931000/24576000\n",
      "current iter: 17932000/24576000\n",
      "current iter: 17933000/24576000\n",
      "current iter: 17934000/24576000\n",
      "current iter: 17935000/24576000\n",
      "current iter: 17936000/24576000\n",
      "current iter: 17937000/24576000\n",
      "current iter: 17938000/24576000\n",
      "current iter: 17939000/24576000\n",
      "current iter: 17940000/24576000\n",
      "current iter: 17941000/24576000\n",
      "current iter: 17942000/24576000\n",
      "current iter: 17943000/24576000\n",
      "current iter: 17944000/24576000\n",
      "current iter: 17945000/24576000\n",
      "current iter: 17946000/24576000\n",
      "current iter: 17947000/24576000\n",
      "current iter: 17948000/24576000\n",
      "current iter: 17949000/24576000\n",
      "current iter: 17950000/24576000\n",
      "current iter: 17951000/24576000\n",
      "current iter: 17952000/24576000\n",
      "current iter: 17953000/24576000\n",
      "current iter: 17954000/24576000\n",
      "current iter: 17955000/24576000\n",
      "current iter: 17956000/24576000\n",
      "current iter: 17957000/24576000\n",
      "current iter: 17958000/24576000\n",
      "current iter: 17959000/24576000\n",
      "current iter: 17960000/24576000\n",
      "current iter: 17961000/24576000\n",
      "current iter: 17962000/24576000\n",
      "current iter: 17963000/24576000\n",
      "current iter: 17964000/24576000\n",
      "current iter: 17965000/24576000\n",
      "current iter: 17966000/24576000\n",
      "current iter: 17967000/24576000\n",
      "current iter: 17968000/24576000\n",
      "current iter: 17969000/24576000\n",
      "current iter: 17970000/24576000\n",
      "current iter: 17971000/24576000\n",
      "current iter: 17972000/24576000\n",
      "current iter: 17973000/24576000\n",
      "current iter: 17974000/24576000\n",
      "current iter: 17975000/24576000\n",
      "current iter: 17976000/24576000\n",
      "current iter: 17977000/24576000\n",
      "current iter: 17978000/24576000\n",
      "current iter: 17979000/24576000\n",
      "current iter: 17980000/24576000\n",
      "current iter: 17981000/24576000\n",
      "current iter: 17982000/24576000\n",
      "current iter: 17983000/24576000\n",
      "current iter: 17984000/24576000\n",
      "current iter: 17985000/24576000\n",
      "current iter: 17986000/24576000\n",
      "current iter: 17987000/24576000\n",
      "current iter: 17988000/24576000\n",
      "current iter: 17989000/24576000\n",
      "current iter: 17990000/24576000\n",
      "current iter: 17991000/24576000\n",
      "current iter: 17992000/24576000\n",
      "current iter: 17993000/24576000\n",
      "current iter: 17994000/24576000\n",
      "current iter: 17995000/24576000\n",
      "current iter: 17996000/24576000\n",
      "current iter: 17997000/24576000\n",
      "current iter: 17998000/24576000\n",
      "current iter: 17999000/24576000\n",
      "current iter: 18000000/24576000\n",
      "current iter: 18001000/24576000\n",
      "current iter: 18002000/24576000\n",
      "current iter: 18003000/24576000\n",
      "current iter: 18004000/24576000\n",
      "current iter: 18005000/24576000\n",
      "current iter: 18006000/24576000\n",
      "current iter: 18007000/24576000\n",
      "current iter: 18008000/24576000\n",
      "current iter: 18009000/24576000\n",
      "current iter: 18010000/24576000\n",
      "current iter: 18011000/24576000\n",
      "current iter: 18012000/24576000\n",
      "current iter: 18013000/24576000\n",
      "current iter: 18014000/24576000\n",
      "current iter: 18015000/24576000\n",
      "current iter: 18016000/24576000\n",
      "current iter: 18017000/24576000\n",
      "current iter: 18018000/24576000\n",
      "current iter: 18019000/24576000\n",
      "current iter: 18020000/24576000\n",
      "current iter: 18021000/24576000\n",
      "current iter: 18022000/24576000\n",
      "current iter: 18023000/24576000\n",
      "current iter: 18024000/24576000\n",
      "current iter: 18025000/24576000\n",
      "current iter: 18026000/24576000\n",
      "current iter: 18027000/24576000\n",
      "current iter: 18028000/24576000\n",
      "current iter: 18029000/24576000\n",
      "current iter: 18030000/24576000\n",
      "current iter: 18031000/24576000\n",
      "current iter: 18032000/24576000\n",
      "current iter: 18033000/24576000\n",
      "current iter: 18034000/24576000\n",
      "current iter: 18035000/24576000\n",
      "current iter: 18036000/24576000\n",
      "current iter: 18037000/24576000\n",
      "current iter: 18038000/24576000\n",
      "current iter: 18039000/24576000\n",
      "current iter: 18040000/24576000\n",
      "current iter: 18041000/24576000\n",
      "current iter: 18042000/24576000\n",
      "current iter: 18043000/24576000\n",
      "current iter: 18044000/24576000\n",
      "current iter: 18045000/24576000\n",
      "current iter: 18046000/24576000\n",
      "current iter: 18047000/24576000\n",
      "current iter: 18048000/24576000\n",
      "current iter: 18049000/24576000\n",
      "current iter: 18050000/24576000\n",
      "current iter: 18051000/24576000\n",
      "current iter: 18052000/24576000\n",
      "current iter: 18053000/24576000\n",
      "current iter: 18054000/24576000\n",
      "current iter: 18055000/24576000\n",
      "current iter: 18056000/24576000\n",
      "current iter: 18057000/24576000\n",
      "current iter: 18058000/24576000\n",
      "current iter: 18059000/24576000\n",
      "current iter: 18060000/24576000\n",
      "current iter: 18061000/24576000\n",
      "current iter: 18062000/24576000\n",
      "current iter: 18063000/24576000\n",
      "current iter: 18064000/24576000\n",
      "current iter: 18065000/24576000\n",
      "current iter: 18066000/24576000\n",
      "current iter: 18067000/24576000\n",
      "current iter: 18068000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 18069000/24576000\n",
      "current iter: 18070000/24576000\n",
      "current iter: 18071000/24576000\n",
      "current iter: 18072000/24576000\n",
      "current iter: 18073000/24576000\n",
      "current iter: 18074000/24576000\n",
      "current iter: 18075000/24576000\n",
      "current iter: 18076000/24576000\n",
      "current iter: 18077000/24576000\n",
      "current iter: 18078000/24576000\n",
      "current iter: 18079000/24576000\n",
      "current iter: 18080000/24576000\n",
      "current iter: 18081000/24576000\n",
      "current iter: 18082000/24576000\n",
      "current iter: 18083000/24576000\n",
      "current iter: 18084000/24576000\n",
      "current iter: 18085000/24576000\n",
      "current iter: 18086000/24576000\n",
      "current iter: 18087000/24576000\n",
      "current iter: 18088000/24576000\n",
      "current iter: 18089000/24576000\n",
      "current iter: 18090000/24576000\n",
      "current iter: 18091000/24576000\n",
      "current iter: 18092000/24576000\n",
      "current iter: 18093000/24576000\n",
      "current iter: 18094000/24576000\n",
      "current iter: 18095000/24576000\n",
      "current iter: 18096000/24576000\n",
      "current iter: 18097000/24576000\n",
      "current iter: 18098000/24576000\n",
      "current iter: 18099000/24576000\n",
      "current iter: 18100000/24576000\n",
      "current iter: 18101000/24576000\n",
      "current iter: 18102000/24576000\n",
      "current iter: 18103000/24576000\n",
      "current iter: 18104000/24576000\n",
      "current iter: 18105000/24576000\n",
      "current iter: 18106000/24576000\n",
      "current iter: 18107000/24576000\n",
      "current iter: 18108000/24576000\n",
      "current iter: 18109000/24576000\n",
      "current iter: 18110000/24576000\n",
      "current iter: 18111000/24576000\n",
      "current iter: 18112000/24576000\n",
      "current iter: 18113000/24576000\n",
      "current iter: 18114000/24576000\n",
      "current iter: 18115000/24576000\n",
      "current iter: 18116000/24576000\n",
      "current iter: 18117000/24576000\n",
      "current iter: 18118000/24576000\n",
      "current iter: 18119000/24576000\n",
      "current iter: 18120000/24576000\n",
      "current iter: 18121000/24576000\n",
      "current iter: 18122000/24576000\n",
      "current iter: 18123000/24576000\n",
      "current iter: 18124000/24576000\n",
      "current iter: 18125000/24576000\n",
      "current iter: 18126000/24576000\n",
      "current iter: 18127000/24576000\n",
      "current iter: 18128000/24576000\n",
      "current iter: 18129000/24576000\n",
      "current iter: 18130000/24576000\n",
      "current iter: 18131000/24576000\n",
      "current iter: 18132000/24576000\n",
      "current iter: 18133000/24576000\n",
      "current iter: 18134000/24576000\n",
      "current iter: 18135000/24576000\n",
      "current iter: 18136000/24576000\n",
      "current iter: 18137000/24576000\n",
      "current iter: 18138000/24576000\n",
      "current iter: 18139000/24576000\n",
      "current iter: 18140000/24576000\n",
      "current iter: 18141000/24576000\n",
      "current iter: 18142000/24576000\n",
      "current iter: 18143000/24576000\n",
      "current iter: 18144000/24576000\n",
      "current iter: 18145000/24576000\n",
      "current iter: 18146000/24576000\n",
      "current iter: 18147000/24576000\n",
      "current iter: 18148000/24576000\n",
      "current iter: 18149000/24576000\n",
      "current iter: 18150000/24576000\n",
      "current iter: 18151000/24576000\n",
      "current iter: 18152000/24576000\n",
      "current iter: 18153000/24576000\n",
      "current iter: 18154000/24576000\n",
      "current iter: 18155000/24576000\n",
      "current iter: 18156000/24576000\n",
      "current iter: 18157000/24576000\n",
      "current iter: 18158000/24576000\n",
      "current iter: 18159000/24576000\n",
      "current iter: 18160000/24576000\n",
      "current iter: 18161000/24576000\n",
      "current iter: 18162000/24576000\n",
      "current iter: 18163000/24576000\n",
      "current iter: 18164000/24576000\n",
      "current iter: 18165000/24576000\n",
      "current iter: 18166000/24576000\n",
      "current iter: 18167000/24576000\n",
      "current iter: 18168000/24576000\n",
      "current iter: 18169000/24576000\n",
      "current iter: 18170000/24576000\n",
      "current iter: 18171000/24576000\n",
      "current iter: 18172000/24576000\n",
      "current iter: 18173000/24576000\n",
      "current iter: 18174000/24576000\n",
      "current iter: 18175000/24576000\n",
      "current iter: 18176000/24576000\n",
      "current iter: 18177000/24576000\n",
      "current iter: 18178000/24576000\n",
      "current iter: 18179000/24576000\n",
      "current iter: 18180000/24576000\n",
      "current iter: 18181000/24576000\n",
      "current iter: 18182000/24576000\n",
      "current iter: 18183000/24576000\n",
      "current iter: 18184000/24576000\n",
      "current iter: 18185000/24576000\n",
      "current iter: 18186000/24576000\n",
      "current iter: 18187000/24576000\n",
      "current iter: 18188000/24576000\n",
      "current iter: 18189000/24576000\n",
      "current iter: 18190000/24576000\n",
      "current iter: 18191000/24576000\n",
      "current iter: 18192000/24576000\n",
      "current iter: 18193000/24576000\n",
      "current iter: 18194000/24576000\n",
      "current iter: 18195000/24576000\n",
      "current iter: 18196000/24576000\n",
      "current iter: 18197000/24576000\n",
      "current iter: 18198000/24576000\n",
      "current iter: 18199000/24576000\n",
      "current iter: 18200000/24576000\n",
      "current iter: 18201000/24576000\n",
      "current iter: 18202000/24576000\n",
      "current iter: 18203000/24576000\n",
      "current iter: 18204000/24576000\n",
      "current iter: 18205000/24576000\n",
      "current iter: 18206000/24576000\n",
      "current iter: 18207000/24576000\n",
      "current iter: 18208000/24576000\n",
      "current iter: 18209000/24576000\n",
      "current iter: 18210000/24576000\n",
      "current iter: 18211000/24576000\n",
      "current iter: 18212000/24576000\n",
      "current iter: 18213000/24576000\n",
      "current iter: 18214000/24576000\n",
      "current iter: 18215000/24576000\n",
      "current iter: 18216000/24576000\n",
      "current iter: 18217000/24576000\n",
      "current iter: 18218000/24576000\n",
      "current iter: 18219000/24576000\n",
      "current iter: 18220000/24576000\n",
      "current iter: 18221000/24576000\n",
      "current iter: 18222000/24576000\n",
      "current iter: 18223000/24576000\n",
      "current iter: 18224000/24576000\n",
      "current iter: 18225000/24576000\n",
      "current iter: 18226000/24576000\n",
      "current iter: 18227000/24576000\n",
      "current iter: 18228000/24576000\n",
      "current iter: 18229000/24576000\n",
      "current iter: 18230000/24576000\n",
      "current iter: 18231000/24576000\n",
      "current iter: 18232000/24576000\n",
      "current iter: 18233000/24576000\n",
      "current iter: 18234000/24576000\n",
      "current iter: 18235000/24576000\n",
      "current iter: 18236000/24576000\n",
      "current iter: 18237000/24576000\n",
      "current iter: 18238000/24576000\n",
      "current iter: 18239000/24576000\n",
      "current iter: 18240000/24576000\n",
      "current iter: 18241000/24576000\n",
      "current iter: 18242000/24576000\n",
      "current iter: 18243000/24576000\n",
      "current iter: 18244000/24576000\n",
      "current iter: 18245000/24576000\n",
      "current iter: 18246000/24576000\n",
      "current iter: 18247000/24576000\n",
      "current iter: 18248000/24576000\n",
      "current iter: 18249000/24576000\n",
      "current iter: 18250000/24576000\n",
      "current iter: 18251000/24576000\n",
      "current iter: 18252000/24576000\n",
      "current iter: 18253000/24576000\n",
      "current iter: 18254000/24576000\n",
      "current iter: 18255000/24576000\n",
      "current iter: 18256000/24576000\n",
      "current iter: 18257000/24576000\n",
      "current iter: 18258000/24576000\n",
      "current iter: 18259000/24576000\n",
      "current iter: 18260000/24576000\n",
      "current iter: 18261000/24576000\n",
      "current iter: 18262000/24576000\n",
      "current iter: 18263000/24576000\n",
      "current iter: 18264000/24576000\n",
      "current iter: 18265000/24576000\n",
      "current iter: 18266000/24576000\n",
      "current iter: 18267000/24576000\n",
      "current iter: 18268000/24576000\n",
      "current iter: 18269000/24576000\n",
      "current iter: 18270000/24576000\n",
      "current iter: 18271000/24576000\n",
      "current iter: 18272000/24576000\n",
      "current iter: 18273000/24576000\n",
      "current iter: 18274000/24576000\n",
      "current iter: 18275000/24576000\n",
      "current iter: 18276000/24576000\n",
      "current iter: 18277000/24576000\n",
      "current iter: 18278000/24576000\n",
      "current iter: 18279000/24576000\n",
      "current iter: 18280000/24576000\n",
      "current iter: 18281000/24576000\n",
      "current iter: 18282000/24576000\n",
      "current iter: 18283000/24576000\n",
      "current iter: 18284000/24576000\n",
      "current iter: 18285000/24576000\n",
      "current iter: 18286000/24576000\n",
      "current iter: 18287000/24576000\n",
      "current iter: 18288000/24576000\n",
      "current iter: 18289000/24576000\n",
      "current iter: 18290000/24576000\n",
      "current iter: 18291000/24576000\n",
      "current iter: 18292000/24576000\n",
      "current iter: 18293000/24576000\n",
      "current iter: 18294000/24576000\n",
      "current iter: 18295000/24576000\n",
      "current iter: 18296000/24576000\n",
      "current iter: 18297000/24576000\n",
      "current iter: 18298000/24576000\n",
      "current iter: 18299000/24576000\n",
      "current iter: 18300000/24576000\n",
      "current iter: 18301000/24576000\n",
      "current iter: 18302000/24576000\n",
      "current iter: 18303000/24576000\n",
      "current iter: 18304000/24576000\n",
      "current iter: 18305000/24576000\n",
      "current iter: 18306000/24576000\n",
      "current iter: 18307000/24576000\n",
      "current iter: 18308000/24576000\n",
      "current iter: 18309000/24576000\n",
      "current iter: 18310000/24576000\n",
      "current iter: 18311000/24576000\n",
      "current iter: 18312000/24576000\n",
      "current iter: 18313000/24576000\n",
      "current iter: 18314000/24576000\n",
      "current iter: 18315000/24576000\n",
      "current iter: 18316000/24576000\n",
      "current iter: 18317000/24576000\n",
      "current iter: 18318000/24576000\n",
      "current iter: 18319000/24576000\n",
      "current iter: 18320000/24576000\n",
      "current iter: 18321000/24576000\n",
      "current iter: 18322000/24576000\n",
      "current iter: 18323000/24576000\n",
      "current iter: 18324000/24576000\n",
      "current iter: 18325000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 18326000/24576000\n",
      "current iter: 18327000/24576000\n",
      "current iter: 18328000/24576000\n",
      "current iter: 18329000/24576000\n",
      "current iter: 18330000/24576000\n",
      "current iter: 18331000/24576000\n",
      "current iter: 18332000/24576000\n",
      "current iter: 18333000/24576000\n",
      "current iter: 18334000/24576000\n",
      "current iter: 18335000/24576000\n",
      "current iter: 18336000/24576000\n",
      "current iter: 18337000/24576000\n",
      "current iter: 18338000/24576000\n",
      "current iter: 18339000/24576000\n",
      "current iter: 18340000/24576000\n",
      "current iter: 18341000/24576000\n",
      "current iter: 18342000/24576000\n",
      "current iter: 18343000/24576000\n",
      "current iter: 18344000/24576000\n",
      "current iter: 18345000/24576000\n",
      "current iter: 18346000/24576000\n",
      "current iter: 18347000/24576000\n",
      "current iter: 18348000/24576000\n",
      "current iter: 18349000/24576000\n",
      "current iter: 18350000/24576000\n",
      "current iter: 18351000/24576000\n",
      "current iter: 18352000/24576000\n",
      "current iter: 18353000/24576000\n",
      "current iter: 18354000/24576000\n",
      "current iter: 18355000/24576000\n",
      "current iter: 18356000/24576000\n",
      "current iter: 18357000/24576000\n",
      "current iter: 18358000/24576000\n",
      "current iter: 18359000/24576000\n",
      "current iter: 18360000/24576000\n",
      "current iter: 18361000/24576000\n",
      "current iter: 18362000/24576000\n",
      "current iter: 18363000/24576000\n",
      "current iter: 18364000/24576000\n",
      "current iter: 18365000/24576000\n",
      "current iter: 18366000/24576000\n",
      "current iter: 18367000/24576000\n",
      "current iter: 18368000/24576000\n",
      "current iter: 18369000/24576000\n",
      "current iter: 18370000/24576000\n",
      "current iter: 18371000/24576000\n",
      "current iter: 18372000/24576000\n",
      "current iter: 18373000/24576000\n",
      "current iter: 18374000/24576000\n",
      "current iter: 18375000/24576000\n",
      "current iter: 18376000/24576000\n",
      "current iter: 18377000/24576000\n",
      "current iter: 18378000/24576000\n",
      "current iter: 18379000/24576000\n",
      "current iter: 18380000/24576000\n",
      "current iter: 18381000/24576000\n",
      "current iter: 18382000/24576000\n",
      "current iter: 18383000/24576000\n",
      "current iter: 18384000/24576000\n",
      "current iter: 18385000/24576000\n",
      "current iter: 18386000/24576000\n",
      "current iter: 18387000/24576000\n",
      "current iter: 18388000/24576000\n",
      "current iter: 18389000/24576000\n",
      "current iter: 18390000/24576000\n",
      "current iter: 18391000/24576000\n",
      "current iter: 18392000/24576000\n",
      "current iter: 18393000/24576000\n",
      "current iter: 18394000/24576000\n",
      "current iter: 18395000/24576000\n",
      "current iter: 18396000/24576000\n",
      "current iter: 18397000/24576000\n",
      "current iter: 18398000/24576000\n",
      "current iter: 18399000/24576000\n",
      "current iter: 18400000/24576000\n",
      "current iter: 18401000/24576000\n",
      "current iter: 18402000/24576000\n",
      "current iter: 18403000/24576000\n",
      "current iter: 18404000/24576000\n",
      "current iter: 18405000/24576000\n",
      "current iter: 18406000/24576000\n",
      "current iter: 18407000/24576000\n",
      "current iter: 18408000/24576000\n",
      "current iter: 18409000/24576000\n",
      "current iter: 18410000/24576000\n",
      "current iter: 18411000/24576000\n",
      "current iter: 18412000/24576000\n",
      "current iter: 18413000/24576000\n",
      "current iter: 18414000/24576000\n",
      "current iter: 18415000/24576000\n",
      "current iter: 18416000/24576000\n",
      "current iter: 18417000/24576000\n",
      "current iter: 18418000/24576000\n",
      "current iter: 18419000/24576000\n",
      "current iter: 18420000/24576000\n",
      "current iter: 18421000/24576000\n",
      "current iter: 18422000/24576000\n",
      "current iter: 18423000/24576000\n",
      "current iter: 18424000/24576000\n",
      "current iter: 18425000/24576000\n",
      "current iter: 18426000/24576000\n",
      "current iter: 18427000/24576000\n",
      "current iter: 18428000/24576000\n",
      "current iter: 18429000/24576000\n",
      "current iter: 18430000/24576000\n",
      "current iter: 18431000/24576000\n",
      "current iter: 18432000/24576000\n",
      "current iter: 18433000/24576000\n",
      "current iter: 18434000/24576000\n",
      "current iter: 18435000/24576000\n",
      "current iter: 18436000/24576000\n",
      "current iter: 18437000/24576000\n",
      "current iter: 18438000/24576000\n",
      "current iter: 18439000/24576000\n",
      "current iter: 18440000/24576000\n",
      "current iter: 18441000/24576000\n",
      "current iter: 18442000/24576000\n",
      "current iter: 18443000/24576000\n",
      "current iter: 18444000/24576000\n",
      "current iter: 18445000/24576000\n",
      "current iter: 18446000/24576000\n",
      "current iter: 18447000/24576000\n",
      "current iter: 18448000/24576000\n",
      "current iter: 18449000/24576000\n",
      "current iter: 18450000/24576000\n",
      "current iter: 18451000/24576000\n",
      "current iter: 18452000/24576000\n",
      "current iter: 18453000/24576000\n",
      "current iter: 18454000/24576000\n",
      "current iter: 18455000/24576000\n",
      "current iter: 18456000/24576000\n",
      "current iter: 18457000/24576000\n",
      "current iter: 18458000/24576000\n",
      "current iter: 18459000/24576000\n",
      "current iter: 18460000/24576000\n",
      "current iter: 18461000/24576000\n",
      "current iter: 18462000/24576000\n",
      "current iter: 18463000/24576000\n",
      "current iter: 18464000/24576000\n",
      "current iter: 18465000/24576000\n",
      "current iter: 18466000/24576000\n",
      "current iter: 18467000/24576000\n",
      "current iter: 18468000/24576000\n",
      "current iter: 18469000/24576000\n",
      "current iter: 18470000/24576000\n",
      "current iter: 18471000/24576000\n",
      "current iter: 18472000/24576000\n",
      "current iter: 18473000/24576000\n",
      "current iter: 18474000/24576000\n",
      "current iter: 18475000/24576000\n",
      "current iter: 18476000/24576000\n",
      "current iter: 18477000/24576000\n",
      "current iter: 18478000/24576000\n",
      "current iter: 18479000/24576000\n",
      "current iter: 18480000/24576000\n",
      "current iter: 18481000/24576000\n",
      "current iter: 18482000/24576000\n",
      "current iter: 18483000/24576000\n",
      "current iter: 18484000/24576000\n",
      "current iter: 18485000/24576000\n",
      "current iter: 18486000/24576000\n",
      "current iter: 18487000/24576000\n",
      "current iter: 18488000/24576000\n",
      "current iter: 18489000/24576000\n",
      "current iter: 18490000/24576000\n",
      "current iter: 18491000/24576000\n",
      "current iter: 18492000/24576000\n",
      "current iter: 18493000/24576000\n",
      "current iter: 18494000/24576000\n",
      "current iter: 18495000/24576000\n",
      "current iter: 18496000/24576000\n",
      "current iter: 18497000/24576000\n",
      "current iter: 18498000/24576000\n",
      "current iter: 18499000/24576000\n",
      "current iter: 18500000/24576000\n",
      "current iter: 18501000/24576000\n",
      "current iter: 18502000/24576000\n",
      "current iter: 18503000/24576000\n",
      "current iter: 18504000/24576000\n",
      "current iter: 18505000/24576000\n",
      "current iter: 18506000/24576000\n",
      "current iter: 18507000/24576000\n",
      "current iter: 18508000/24576000\n",
      "current iter: 18509000/24576000\n",
      "current iter: 18510000/24576000\n",
      "current iter: 18511000/24576000\n",
      "current iter: 18512000/24576000\n",
      "current iter: 18513000/24576000\n",
      "current iter: 18514000/24576000\n",
      "current iter: 18515000/24576000\n",
      "current iter: 18516000/24576000\n",
      "current iter: 18517000/24576000\n",
      "current iter: 18518000/24576000\n",
      "current iter: 18519000/24576000\n",
      "current iter: 18520000/24576000\n",
      "current iter: 18521000/24576000\n",
      "current iter: 18522000/24576000\n",
      "current iter: 18523000/24576000\n",
      "current iter: 18524000/24576000\n",
      "current iter: 18525000/24576000\n",
      "current iter: 18526000/24576000\n",
      "current iter: 18527000/24576000\n",
      "current iter: 18528000/24576000\n",
      "current iter: 18529000/24576000\n",
      "current iter: 18530000/24576000\n",
      "current iter: 18531000/24576000\n",
      "current iter: 18532000/24576000\n",
      "current iter: 18533000/24576000\n",
      "current iter: 18534000/24576000\n",
      "current iter: 18535000/24576000\n",
      "current iter: 18536000/24576000\n",
      "current iter: 18537000/24576000\n",
      "current iter: 18538000/24576000\n",
      "current iter: 18539000/24576000\n",
      "current iter: 18540000/24576000\n",
      "current iter: 18541000/24576000\n",
      "current iter: 18542000/24576000\n",
      "current iter: 18543000/24576000\n",
      "current iter: 18544000/24576000\n",
      "current iter: 18545000/24576000\n",
      "current iter: 18546000/24576000\n",
      "current iter: 18547000/24576000\n",
      "current iter: 18548000/24576000\n",
      "current iter: 18549000/24576000\n",
      "current iter: 18550000/24576000\n",
      "current iter: 18551000/24576000\n",
      "current iter: 18552000/24576000\n",
      "current iter: 18553000/24576000\n",
      "current iter: 18554000/24576000\n",
      "current iter: 18555000/24576000\n",
      "current iter: 18556000/24576000\n",
      "current iter: 18557000/24576000\n",
      "current iter: 18558000/24576000\n",
      "current iter: 18559000/24576000\n",
      "current iter: 18560000/24576000\n",
      "current iter: 18561000/24576000\n",
      "current iter: 18562000/24576000\n",
      "current iter: 18563000/24576000\n",
      "current iter: 18564000/24576000\n",
      "current iter: 18565000/24576000\n",
      "current iter: 18566000/24576000\n",
      "current iter: 18567000/24576000\n",
      "current iter: 18568000/24576000\n",
      "current iter: 18569000/24576000\n",
      "current iter: 18570000/24576000\n",
      "current iter: 18571000/24576000\n",
      "current iter: 18572000/24576000\n",
      "current iter: 18573000/24576000\n",
      "current iter: 18574000/24576000\n",
      "current iter: 18575000/24576000\n",
      "current iter: 18576000/24576000\n",
      "current iter: 18577000/24576000\n",
      "current iter: 18578000/24576000\n",
      "current iter: 18579000/24576000\n",
      "current iter: 18580000/24576000\n",
      "current iter: 18581000/24576000\n",
      "current iter: 18582000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 18583000/24576000\n",
      "current iter: 18584000/24576000\n",
      "current iter: 18585000/24576000\n",
      "current iter: 18586000/24576000\n",
      "current iter: 18587000/24576000\n",
      "current iter: 18588000/24576000\n",
      "current iter: 18589000/24576000\n",
      "current iter: 18590000/24576000\n",
      "current iter: 18591000/24576000\n",
      "current iter: 18592000/24576000\n",
      "current iter: 18593000/24576000\n",
      "current iter: 18594000/24576000\n",
      "current iter: 18595000/24576000\n",
      "current iter: 18596000/24576000\n",
      "current iter: 18597000/24576000\n",
      "current iter: 18598000/24576000\n",
      "current iter: 18599000/24576000\n",
      "current iter: 18600000/24576000\n",
      "current iter: 18601000/24576000\n",
      "current iter: 18602000/24576000\n",
      "current iter: 18603000/24576000\n",
      "current iter: 18604000/24576000\n",
      "current iter: 18605000/24576000\n",
      "current iter: 18606000/24576000\n",
      "current iter: 18607000/24576000\n",
      "current iter: 18608000/24576000\n",
      "current iter: 18609000/24576000\n",
      "current iter: 18610000/24576000\n",
      "current iter: 18611000/24576000\n",
      "current iter: 18612000/24576000\n",
      "current iter: 18613000/24576000\n",
      "current iter: 18614000/24576000\n",
      "current iter: 18615000/24576000\n",
      "current iter: 18616000/24576000\n",
      "current iter: 18617000/24576000\n",
      "current iter: 18618000/24576000\n",
      "current iter: 18619000/24576000\n",
      "current iter: 18620000/24576000\n",
      "current iter: 18621000/24576000\n",
      "current iter: 18622000/24576000\n",
      "current iter: 18623000/24576000\n",
      "current iter: 18624000/24576000\n",
      "current iter: 18625000/24576000\n",
      "current iter: 18626000/24576000\n",
      "current iter: 18627000/24576000\n",
      "current iter: 18628000/24576000\n",
      "current iter: 18629000/24576000\n",
      "current iter: 18630000/24576000\n",
      "current iter: 18631000/24576000\n",
      "current iter: 18632000/24576000\n",
      "current iter: 18633000/24576000\n",
      "current iter: 18634000/24576000\n",
      "current iter: 18635000/24576000\n",
      "current iter: 18636000/24576000\n",
      "current iter: 18637000/24576000\n",
      "current iter: 18638000/24576000\n",
      "current iter: 18639000/24576000\n",
      "current iter: 18640000/24576000\n",
      "current iter: 18641000/24576000\n",
      "current iter: 18642000/24576000\n",
      "current iter: 18643000/24576000\n",
      "current iter: 18644000/24576000\n",
      "current iter: 18645000/24576000\n",
      "current iter: 18646000/24576000\n",
      "current iter: 18647000/24576000\n",
      "current iter: 18648000/24576000\n",
      "current iter: 18649000/24576000\n",
      "current iter: 18650000/24576000\n",
      "current iter: 18651000/24576000\n",
      "current iter: 18652000/24576000\n",
      "current iter: 18653000/24576000\n",
      "current iter: 18654000/24576000\n",
      "current iter: 18655000/24576000\n",
      "current iter: 18656000/24576000\n",
      "current iter: 18657000/24576000\n",
      "current iter: 18658000/24576000\n",
      "current iter: 18659000/24576000\n",
      "current iter: 18660000/24576000\n",
      "current iter: 18661000/24576000\n",
      "current iter: 18662000/24576000\n",
      "current iter: 18663000/24576000\n",
      "current iter: 18664000/24576000\n",
      "current iter: 18665000/24576000\n",
      "current iter: 18666000/24576000\n",
      "current iter: 18667000/24576000\n",
      "current iter: 18668000/24576000\n",
      "current iter: 18669000/24576000\n",
      "current iter: 18670000/24576000\n",
      "current iter: 18671000/24576000\n",
      "current iter: 18672000/24576000\n",
      "current iter: 18673000/24576000\n",
      "current iter: 18674000/24576000\n",
      "current iter: 18675000/24576000\n",
      "current iter: 18676000/24576000\n",
      "current iter: 18677000/24576000\n",
      "current iter: 18678000/24576000\n",
      "current iter: 18679000/24576000\n",
      "current iter: 18680000/24576000\n",
      "current iter: 18681000/24576000\n",
      "current iter: 18682000/24576000\n",
      "current iter: 18683000/24576000\n",
      "current iter: 18684000/24576000\n",
      "current iter: 18685000/24576000\n",
      "current iter: 18686000/24576000\n",
      "current iter: 18687000/24576000\n",
      "current iter: 18688000/24576000\n",
      "current iter: 18689000/24576000\n",
      "current iter: 18690000/24576000\n",
      "current iter: 18691000/24576000\n",
      "current iter: 18692000/24576000\n",
      "current iter: 18693000/24576000\n",
      "current iter: 18694000/24576000\n",
      "current iter: 18695000/24576000\n",
      "current iter: 18696000/24576000\n",
      "current iter: 18697000/24576000\n",
      "current iter: 18698000/24576000\n",
      "current iter: 18699000/24576000\n",
      "current iter: 18700000/24576000\n",
      "current iter: 18701000/24576000\n",
      "current iter: 18702000/24576000\n",
      "current iter: 18703000/24576000\n",
      "current iter: 18704000/24576000\n",
      "current iter: 18705000/24576000\n",
      "current iter: 18706000/24576000\n",
      "current iter: 18707000/24576000\n",
      "current iter: 18708000/24576000\n",
      "current iter: 18709000/24576000\n",
      "current iter: 18710000/24576000\n",
      "current iter: 18711000/24576000\n",
      "current iter: 18712000/24576000\n",
      "current iter: 18713000/24576000\n",
      "current iter: 18714000/24576000\n",
      "current iter: 18715000/24576000\n",
      "current iter: 18716000/24576000\n",
      "current iter: 18717000/24576000\n",
      "current iter: 18718000/24576000\n",
      "current iter: 18719000/24576000\n",
      "current iter: 18720000/24576000\n",
      "current iter: 18721000/24576000\n",
      "current iter: 18722000/24576000\n",
      "current iter: 18723000/24576000\n",
      "current iter: 18724000/24576000\n",
      "current iter: 18725000/24576000\n",
      "current iter: 18726000/24576000\n",
      "current iter: 18727000/24576000\n",
      "current iter: 18728000/24576000\n",
      "current iter: 18729000/24576000\n",
      "current iter: 18730000/24576000\n",
      "current iter: 18731000/24576000\n",
      "current iter: 18732000/24576000\n",
      "current iter: 18733000/24576000\n",
      "current iter: 18734000/24576000\n",
      "current iter: 18735000/24576000\n",
      "current iter: 18736000/24576000\n",
      "current iter: 18737000/24576000\n",
      "current iter: 18738000/24576000\n",
      "current iter: 18739000/24576000\n",
      "current iter: 18740000/24576000\n",
      "current iter: 18741000/24576000\n",
      "current iter: 18742000/24576000\n",
      "current iter: 18743000/24576000\n",
      "current iter: 18744000/24576000\n",
      "current iter: 18745000/24576000\n",
      "current iter: 18746000/24576000\n",
      "current iter: 18747000/24576000\n",
      "current iter: 18748000/24576000\n",
      "current iter: 18749000/24576000\n",
      "current iter: 18750000/24576000\n",
      "current iter: 18751000/24576000\n",
      "current iter: 18752000/24576000\n",
      "current iter: 18753000/24576000\n",
      "current iter: 18754000/24576000\n",
      "current iter: 18755000/24576000\n",
      "current iter: 18756000/24576000\n",
      "current iter: 18757000/24576000\n",
      "current iter: 18758000/24576000\n",
      "current iter: 18759000/24576000\n",
      "current iter: 18760000/24576000\n",
      "current iter: 18761000/24576000\n",
      "current iter: 18762000/24576000\n",
      "current iter: 18763000/24576000\n",
      "current iter: 18764000/24576000\n",
      "current iter: 18765000/24576000\n",
      "current iter: 18766000/24576000\n",
      "current iter: 18767000/24576000\n",
      "current iter: 18768000/24576000\n",
      "current iter: 18769000/24576000\n",
      "current iter: 18770000/24576000\n",
      "current iter: 18771000/24576000\n",
      "current iter: 18772000/24576000\n",
      "current iter: 18773000/24576000\n",
      "current iter: 18774000/24576000\n",
      "current iter: 18775000/24576000\n",
      "current iter: 18776000/24576000\n",
      "current iter: 18777000/24576000\n",
      "current iter: 18778000/24576000\n",
      "current iter: 18779000/24576000\n",
      "current iter: 18780000/24576000\n",
      "current iter: 18781000/24576000\n",
      "current iter: 18782000/24576000\n",
      "current iter: 18783000/24576000\n",
      "current iter: 18784000/24576000\n",
      "current iter: 18785000/24576000\n",
      "current iter: 18786000/24576000\n",
      "current iter: 18787000/24576000\n",
      "current iter: 18788000/24576000\n",
      "current iter: 18789000/24576000\n",
      "current iter: 18790000/24576000\n",
      "current iter: 18791000/24576000\n",
      "current iter: 18792000/24576000\n",
      "current iter: 18793000/24576000\n",
      "current iter: 18794000/24576000\n",
      "current iter: 18795000/24576000\n",
      "current iter: 18796000/24576000\n",
      "current iter: 18797000/24576000\n",
      "current iter: 18798000/24576000\n",
      "current iter: 18799000/24576000\n",
      "current iter: 18800000/24576000\n",
      "current iter: 18801000/24576000\n",
      "current iter: 18802000/24576000\n",
      "current iter: 18803000/24576000\n",
      "current iter: 18804000/24576000\n",
      "current iter: 18805000/24576000\n",
      "current iter: 18806000/24576000\n",
      "current iter: 18807000/24576000\n",
      "current iter: 18808000/24576000\n",
      "current iter: 18809000/24576000\n",
      "current iter: 18810000/24576000\n",
      "current iter: 18811000/24576000\n",
      "current iter: 18812000/24576000\n",
      "current iter: 18813000/24576000\n",
      "current iter: 18814000/24576000\n",
      "current iter: 18815000/24576000\n",
      "current iter: 18816000/24576000\n",
      "current iter: 18817000/24576000\n",
      "current iter: 18818000/24576000\n",
      "current iter: 18819000/24576000\n",
      "current iter: 18820000/24576000\n",
      "current iter: 18821000/24576000\n",
      "current iter: 18822000/24576000\n",
      "current iter: 18823000/24576000\n",
      "current iter: 18824000/24576000\n",
      "current iter: 18825000/24576000\n",
      "current iter: 18826000/24576000\n",
      "current iter: 18827000/24576000\n",
      "current iter: 18828000/24576000\n",
      "current iter: 18829000/24576000\n",
      "current iter: 18830000/24576000\n",
      "current iter: 18831000/24576000\n",
      "current iter: 18832000/24576000\n",
      "current iter: 18833000/24576000\n",
      "current iter: 18834000/24576000\n",
      "current iter: 18835000/24576000\n",
      "current iter: 18836000/24576000\n",
      "current iter: 18837000/24576000\n",
      "current iter: 18838000/24576000\n",
      "current iter: 18839000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 18840000/24576000\n",
      "current iter: 18841000/24576000\n",
      "current iter: 18842000/24576000\n",
      "current iter: 18843000/24576000\n",
      "current iter: 18844000/24576000\n",
      "current iter: 18845000/24576000\n",
      "current iter: 18846000/24576000\n",
      "current iter: 18847000/24576000\n",
      "current iter: 18848000/24576000\n",
      "current iter: 18849000/24576000\n",
      "current iter: 18850000/24576000\n",
      "current iter: 18851000/24576000\n",
      "current iter: 18852000/24576000\n",
      "current iter: 18853000/24576000\n",
      "current iter: 18854000/24576000\n",
      "current iter: 18855000/24576000\n",
      "current iter: 18856000/24576000\n",
      "current iter: 18857000/24576000\n",
      "current iter: 18858000/24576000\n",
      "current iter: 18859000/24576000\n",
      "current iter: 18860000/24576000\n",
      "current iter: 18861000/24576000\n",
      "current iter: 18862000/24576000\n",
      "current iter: 18863000/24576000\n",
      "current iter: 18864000/24576000\n",
      "current iter: 18865000/24576000\n",
      "current iter: 18866000/24576000\n",
      "current iter: 18867000/24576000\n",
      "current iter: 18868000/24576000\n",
      "current iter: 18869000/24576000\n",
      "current iter: 18870000/24576000\n",
      "current iter: 18871000/24576000\n",
      "current iter: 18872000/24576000\n",
      "current iter: 18873000/24576000\n",
      "current iter: 18874000/24576000\n",
      "current iter: 18875000/24576000\n",
      "current iter: 18876000/24576000\n",
      "current iter: 18877000/24576000\n",
      "current iter: 18878000/24576000\n",
      "current iter: 18879000/24576000\n",
      "current iter: 18880000/24576000\n",
      "current iter: 18881000/24576000\n",
      "current iter: 18882000/24576000\n",
      "current iter: 18883000/24576000\n",
      "current iter: 18884000/24576000\n",
      "current iter: 18885000/24576000\n",
      "current iter: 18886000/24576000\n",
      "current iter: 18887000/24576000\n",
      "current iter: 18888000/24576000\n",
      "current iter: 18889000/24576000\n",
      "current iter: 18890000/24576000\n",
      "current iter: 18891000/24576000\n",
      "current iter: 18892000/24576000\n",
      "current iter: 18893000/24576000\n",
      "current iter: 18894000/24576000\n",
      "current iter: 18895000/24576000\n",
      "current iter: 18896000/24576000\n",
      "current iter: 18897000/24576000\n",
      "current iter: 18898000/24576000\n",
      "current iter: 18899000/24576000\n",
      "current iter: 18900000/24576000\n",
      "current iter: 18901000/24576000\n",
      "current iter: 18902000/24576000\n",
      "current iter: 18903000/24576000\n",
      "current iter: 18904000/24576000\n",
      "current iter: 18905000/24576000\n",
      "current iter: 18906000/24576000\n",
      "current iter: 18907000/24576000\n",
      "current iter: 18908000/24576000\n",
      "current iter: 18909000/24576000\n",
      "current iter: 18910000/24576000\n",
      "current iter: 18911000/24576000\n",
      "current iter: 18912000/24576000\n",
      "current iter: 18913000/24576000\n",
      "current iter: 18914000/24576000\n",
      "current iter: 18915000/24576000\n",
      "current iter: 18916000/24576000\n",
      "current iter: 18917000/24576000\n",
      "current iter: 18918000/24576000\n",
      "current iter: 18919000/24576000\n",
      "current iter: 18920000/24576000\n",
      "current iter: 18921000/24576000\n",
      "current iter: 18922000/24576000\n",
      "current iter: 18923000/24576000\n",
      "current iter: 18924000/24576000\n",
      "current iter: 18925000/24576000\n",
      "current iter: 18926000/24576000\n",
      "current iter: 18927000/24576000\n",
      "current iter: 18928000/24576000\n",
      "current iter: 18929000/24576000\n",
      "current iter: 18930000/24576000\n",
      "current iter: 18931000/24576000\n",
      "current iter: 18932000/24576000\n",
      "current iter: 18933000/24576000\n",
      "current iter: 18934000/24576000\n",
      "current iter: 18935000/24576000\n",
      "current iter: 18936000/24576000\n",
      "current iter: 18937000/24576000\n",
      "current iter: 18938000/24576000\n",
      "current iter: 18939000/24576000\n",
      "current iter: 18940000/24576000\n",
      "current iter: 18941000/24576000\n",
      "current iter: 18942000/24576000\n",
      "current iter: 18943000/24576000\n",
      "current iter: 18944000/24576000\n",
      "current iter: 18945000/24576000\n",
      "current iter: 18946000/24576000\n",
      "current iter: 18947000/24576000\n",
      "current iter: 18948000/24576000\n",
      "current iter: 18949000/24576000\n",
      "current iter: 18950000/24576000\n",
      "current iter: 18951000/24576000\n",
      "current iter: 18952000/24576000\n",
      "current iter: 18953000/24576000\n",
      "current iter: 18954000/24576000\n",
      "current iter: 18955000/24576000\n",
      "current iter: 18956000/24576000\n",
      "current iter: 18957000/24576000\n",
      "current iter: 18958000/24576000\n",
      "current iter: 18959000/24576000\n",
      "current iter: 18960000/24576000\n",
      "current iter: 18961000/24576000\n",
      "current iter: 18962000/24576000\n",
      "current iter: 18963000/24576000\n",
      "current iter: 18964000/24576000\n",
      "current iter: 18965000/24576000\n",
      "current iter: 18966000/24576000\n",
      "current iter: 18967000/24576000\n",
      "current iter: 18968000/24576000\n",
      "current iter: 18969000/24576000\n",
      "current iter: 18970000/24576000\n",
      "current iter: 18971000/24576000\n",
      "current iter: 18972000/24576000\n",
      "current iter: 18973000/24576000\n",
      "current iter: 18974000/24576000\n",
      "current iter: 18975000/24576000\n",
      "current iter: 18976000/24576000\n",
      "current iter: 18977000/24576000\n",
      "current iter: 18978000/24576000\n",
      "current iter: 18979000/24576000\n",
      "current iter: 18980000/24576000\n",
      "current iter: 18981000/24576000\n",
      "current iter: 18982000/24576000\n",
      "current iter: 18983000/24576000\n",
      "current iter: 18984000/24576000\n",
      "current iter: 18985000/24576000\n",
      "current iter: 18986000/24576000\n",
      "current iter: 18987000/24576000\n",
      "current iter: 18988000/24576000\n",
      "current iter: 18989000/24576000\n",
      "current iter: 18990000/24576000\n",
      "current iter: 18991000/24576000\n",
      "current iter: 18992000/24576000\n",
      "current iter: 18993000/24576000\n",
      "current iter: 18994000/24576000\n",
      "current iter: 18995000/24576000\n",
      "current iter: 18996000/24576000\n",
      "current iter: 18997000/24576000\n",
      "current iter: 18998000/24576000\n",
      "current iter: 18999000/24576000\n",
      "current iter: 19000000/24576000\n",
      "current iter: 19001000/24576000\n",
      "current iter: 19002000/24576000\n",
      "current iter: 19003000/24576000\n",
      "current iter: 19004000/24576000\n",
      "current iter: 19005000/24576000\n",
      "current iter: 19006000/24576000\n",
      "current iter: 19007000/24576000\n",
      "current iter: 19008000/24576000\n",
      "current iter: 19009000/24576000\n",
      "current iter: 19010000/24576000\n",
      "current iter: 19011000/24576000\n",
      "current iter: 19012000/24576000\n",
      "current iter: 19013000/24576000\n",
      "current iter: 19014000/24576000\n",
      "current iter: 19015000/24576000\n",
      "current iter: 19016000/24576000\n",
      "current iter: 19017000/24576000\n",
      "current iter: 19018000/24576000\n",
      "current iter: 19019000/24576000\n",
      "current iter: 19020000/24576000\n",
      "current iter: 19021000/24576000\n",
      "current iter: 19022000/24576000\n",
      "current iter: 19023000/24576000\n",
      "current iter: 19024000/24576000\n",
      "current iter: 19025000/24576000\n",
      "current iter: 19026000/24576000\n",
      "current iter: 19027000/24576000\n",
      "current iter: 19028000/24576000\n",
      "current iter: 19029000/24576000\n",
      "current iter: 19030000/24576000\n",
      "current iter: 19031000/24576000\n",
      "current iter: 19032000/24576000\n",
      "current iter: 19033000/24576000\n",
      "current iter: 19034000/24576000\n",
      "current iter: 19035000/24576000\n",
      "current iter: 19036000/24576000\n",
      "current iter: 19037000/24576000\n",
      "current iter: 19038000/24576000\n",
      "current iter: 19039000/24576000\n",
      "current iter: 19040000/24576000\n",
      "current iter: 19041000/24576000\n",
      "current iter: 19042000/24576000\n",
      "current iter: 19043000/24576000\n",
      "current iter: 19044000/24576000\n",
      "current iter: 19045000/24576000\n",
      "current iter: 19046000/24576000\n",
      "current iter: 19047000/24576000\n",
      "current iter: 19048000/24576000\n",
      "current iter: 19049000/24576000\n",
      "current iter: 19050000/24576000\n",
      "current iter: 19051000/24576000\n",
      "current iter: 19052000/24576000\n",
      "current iter: 19053000/24576000\n",
      "current iter: 19054000/24576000\n",
      "current iter: 19055000/24576000\n",
      "current iter: 19056000/24576000\n",
      "current iter: 19057000/24576000\n",
      "current iter: 19058000/24576000\n",
      "current iter: 19059000/24576000\n",
      "current iter: 19060000/24576000\n",
      "current iter: 19061000/24576000\n",
      "current iter: 19062000/24576000\n",
      "current iter: 19063000/24576000\n",
      "current iter: 19064000/24576000\n",
      "current iter: 19065000/24576000\n",
      "current iter: 19066000/24576000\n",
      "current iter: 19067000/24576000\n",
      "current iter: 19068000/24576000\n",
      "current iter: 19069000/24576000\n",
      "current iter: 19070000/24576000\n",
      "current iter: 19071000/24576000\n",
      "current iter: 19072000/24576000\n",
      "current iter: 19073000/24576000\n",
      "current iter: 19074000/24576000\n",
      "current iter: 19075000/24576000\n",
      "current iter: 19076000/24576000\n",
      "current iter: 19077000/24576000\n",
      "current iter: 19078000/24576000\n",
      "current iter: 19079000/24576000\n",
      "current iter: 19080000/24576000\n",
      "current iter: 19081000/24576000\n",
      "current iter: 19082000/24576000\n",
      "current iter: 19083000/24576000\n",
      "current iter: 19084000/24576000\n",
      "current iter: 19085000/24576000\n",
      "current iter: 19086000/24576000\n",
      "current iter: 19087000/24576000\n",
      "current iter: 19088000/24576000\n",
      "current iter: 19089000/24576000\n",
      "current iter: 19090000/24576000\n",
      "current iter: 19091000/24576000\n",
      "current iter: 19092000/24576000\n",
      "current iter: 19093000/24576000\n",
      "current iter: 19094000/24576000\n",
      "current iter: 19095000/24576000\n",
      "current iter: 19096000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 19097000/24576000\n",
      "current iter: 19098000/24576000\n",
      "current iter: 19099000/24576000\n",
      "current iter: 19100000/24576000\n",
      "current iter: 19101000/24576000\n",
      "current iter: 19102000/24576000\n",
      "current iter: 19103000/24576000\n",
      "current iter: 19104000/24576000\n",
      "current iter: 19105000/24576000\n",
      "current iter: 19106000/24576000\n",
      "current iter: 19107000/24576000\n",
      "current iter: 19108000/24576000\n",
      "current iter: 19109000/24576000\n",
      "current iter: 19110000/24576000\n",
      "current iter: 19111000/24576000\n",
      "current iter: 19112000/24576000\n",
      "current iter: 19113000/24576000\n",
      "current iter: 19114000/24576000\n",
      "current iter: 19115000/24576000\n",
      "current iter: 19116000/24576000\n",
      "current iter: 19117000/24576000\n",
      "current iter: 19118000/24576000\n",
      "current iter: 19119000/24576000\n",
      "current iter: 19120000/24576000\n",
      "current iter: 19121000/24576000\n",
      "current iter: 19122000/24576000\n",
      "current iter: 19123000/24576000\n",
      "current iter: 19124000/24576000\n",
      "current iter: 19125000/24576000\n",
      "current iter: 19126000/24576000\n",
      "current iter: 19127000/24576000\n",
      "current iter: 19128000/24576000\n",
      "current iter: 19129000/24576000\n",
      "current iter: 19130000/24576000\n",
      "current iter: 19131000/24576000\n",
      "current iter: 19132000/24576000\n",
      "current iter: 19133000/24576000\n",
      "current iter: 19134000/24576000\n",
      "current iter: 19135000/24576000\n",
      "current iter: 19136000/24576000\n",
      "current iter: 19137000/24576000\n",
      "current iter: 19138000/24576000\n",
      "current iter: 19139000/24576000\n",
      "current iter: 19140000/24576000\n",
      "current iter: 19141000/24576000\n",
      "current iter: 19142000/24576000\n",
      "current iter: 19143000/24576000\n",
      "current iter: 19144000/24576000\n",
      "current iter: 19145000/24576000\n",
      "current iter: 19146000/24576000\n",
      "current iter: 19147000/24576000\n",
      "current iter: 19148000/24576000\n",
      "current iter: 19149000/24576000\n",
      "current iter: 19150000/24576000\n",
      "current iter: 19151000/24576000\n",
      "current iter: 19152000/24576000\n",
      "current iter: 19153000/24576000\n",
      "current iter: 19154000/24576000\n",
      "current iter: 19155000/24576000\n",
      "current iter: 19156000/24576000\n",
      "current iter: 19157000/24576000\n",
      "current iter: 19158000/24576000\n",
      "current iter: 19159000/24576000\n",
      "current iter: 19160000/24576000\n",
      "current iter: 19161000/24576000\n",
      "current iter: 19162000/24576000\n",
      "current iter: 19163000/24576000\n",
      "current iter: 19164000/24576000\n",
      "current iter: 19165000/24576000\n",
      "current iter: 19166000/24576000\n",
      "current iter: 19167000/24576000\n",
      "current iter: 19168000/24576000\n",
      "current iter: 19169000/24576000\n",
      "current iter: 19170000/24576000\n",
      "current iter: 19171000/24576000\n",
      "current iter: 19172000/24576000\n",
      "current iter: 19173000/24576000\n",
      "current iter: 19174000/24576000\n",
      "current iter: 19175000/24576000\n",
      "current iter: 19176000/24576000\n",
      "current iter: 19177000/24576000\n",
      "current iter: 19178000/24576000\n",
      "current iter: 19179000/24576000\n",
      "current iter: 19180000/24576000\n",
      "current iter: 19181000/24576000\n",
      "current iter: 19182000/24576000\n",
      "current iter: 19183000/24576000\n",
      "current iter: 19184000/24576000\n",
      "current iter: 19185000/24576000\n",
      "current iter: 19186000/24576000\n",
      "current iter: 19187000/24576000\n",
      "current iter: 19188000/24576000\n",
      "current iter: 19189000/24576000\n",
      "current iter: 19190000/24576000\n",
      "current iter: 19191000/24576000\n",
      "current iter: 19192000/24576000\n",
      "current iter: 19193000/24576000\n",
      "current iter: 19194000/24576000\n",
      "current iter: 19195000/24576000\n",
      "current iter: 19196000/24576000\n",
      "current iter: 19197000/24576000\n",
      "current iter: 19198000/24576000\n",
      "current iter: 19199000/24576000\n",
      "current iter: 19200000/24576000\n",
      "current iter: 19201000/24576000\n",
      "current iter: 19202000/24576000\n",
      "current iter: 19203000/24576000\n",
      "current iter: 19204000/24576000\n",
      "current iter: 19205000/24576000\n",
      "current iter: 19206000/24576000\n",
      "current iter: 19207000/24576000\n",
      "current iter: 19208000/24576000\n",
      "current iter: 19209000/24576000\n",
      "current iter: 19210000/24576000\n",
      "current iter: 19211000/24576000\n",
      "current iter: 19212000/24576000\n",
      "current iter: 19213000/24576000\n",
      "current iter: 19214000/24576000\n",
      "current iter: 19215000/24576000\n",
      "current iter: 19216000/24576000\n",
      "current iter: 19217000/24576000\n",
      "current iter: 19218000/24576000\n",
      "current iter: 19219000/24576000\n",
      "current iter: 19220000/24576000\n",
      "current iter: 19221000/24576000\n",
      "current iter: 19222000/24576000\n",
      "current iter: 19223000/24576000\n",
      "current iter: 19224000/24576000\n",
      "current iter: 19225000/24576000\n",
      "current iter: 19226000/24576000\n",
      "current iter: 19227000/24576000\n",
      "current iter: 19228000/24576000\n",
      "current iter: 19229000/24576000\n",
      "current iter: 19230000/24576000\n",
      "current iter: 19231000/24576000\n",
      "current iter: 19232000/24576000\n",
      "current iter: 19233000/24576000\n",
      "current iter: 19234000/24576000\n",
      "current iter: 19235000/24576000\n",
      "current iter: 19236000/24576000\n",
      "current iter: 19237000/24576000\n",
      "current iter: 19238000/24576000\n",
      "current iter: 19239000/24576000\n",
      "current iter: 19240000/24576000\n",
      "current iter: 19241000/24576000\n",
      "current iter: 19242000/24576000\n",
      "current iter: 19243000/24576000\n",
      "current iter: 19244000/24576000\n",
      "current iter: 19245000/24576000\n",
      "current iter: 19246000/24576000\n",
      "current iter: 19247000/24576000\n",
      "current iter: 19248000/24576000\n",
      "current iter: 19249000/24576000\n",
      "current iter: 19250000/24576000\n",
      "current iter: 19251000/24576000\n",
      "current iter: 19252000/24576000\n",
      "current iter: 19253000/24576000\n",
      "current iter: 19254000/24576000\n",
      "current iter: 19255000/24576000\n",
      "current iter: 19256000/24576000\n",
      "current iter: 19257000/24576000\n",
      "current iter: 19258000/24576000\n",
      "current iter: 19259000/24576000\n",
      "current iter: 19260000/24576000\n",
      "current iter: 19261000/24576000\n",
      "current iter: 19262000/24576000\n",
      "current iter: 19263000/24576000\n",
      "current iter: 19264000/24576000\n",
      "current iter: 19265000/24576000\n",
      "current iter: 19266000/24576000\n",
      "current iter: 19267000/24576000\n",
      "current iter: 19268000/24576000\n",
      "current iter: 19269000/24576000\n",
      "current iter: 19270000/24576000\n",
      "current iter: 19271000/24576000\n",
      "current iter: 19272000/24576000\n",
      "current iter: 19273000/24576000\n",
      "current iter: 19274000/24576000\n",
      "current iter: 19275000/24576000\n",
      "current iter: 19276000/24576000\n",
      "current iter: 19277000/24576000\n",
      "current iter: 19278000/24576000\n",
      "current iter: 19279000/24576000\n",
      "current iter: 19280000/24576000\n",
      "current iter: 19281000/24576000\n",
      "current iter: 19282000/24576000\n",
      "current iter: 19283000/24576000\n",
      "current iter: 19284000/24576000\n",
      "current iter: 19285000/24576000\n",
      "current iter: 19286000/24576000\n",
      "current iter: 19287000/24576000\n",
      "current iter: 19288000/24576000\n",
      "current iter: 19289000/24576000\n",
      "current iter: 19290000/24576000\n",
      "current iter: 19291000/24576000\n",
      "current iter: 19292000/24576000\n",
      "current iter: 19293000/24576000\n",
      "current iter: 19294000/24576000\n",
      "current iter: 19295000/24576000\n",
      "current iter: 19296000/24576000\n",
      "current iter: 19297000/24576000\n",
      "current iter: 19298000/24576000\n",
      "current iter: 19299000/24576000\n",
      "current iter: 19300000/24576000\n",
      "current iter: 19301000/24576000\n",
      "current iter: 19302000/24576000\n",
      "current iter: 19303000/24576000\n",
      "current iter: 19304000/24576000\n",
      "current iter: 19305000/24576000\n",
      "current iter: 19306000/24576000\n",
      "current iter: 19307000/24576000\n",
      "current iter: 19308000/24576000\n",
      "current iter: 19309000/24576000\n",
      "current iter: 19310000/24576000\n",
      "current iter: 19311000/24576000\n",
      "current iter: 19312000/24576000\n",
      "current iter: 19313000/24576000\n",
      "current iter: 19314000/24576000\n",
      "current iter: 19315000/24576000\n",
      "current iter: 19316000/24576000\n",
      "current iter: 19317000/24576000\n",
      "current iter: 19318000/24576000\n",
      "current iter: 19319000/24576000\n",
      "current iter: 19320000/24576000\n",
      "current iter: 19321000/24576000\n",
      "current iter: 19322000/24576000\n",
      "current iter: 19323000/24576000\n",
      "current iter: 19324000/24576000\n",
      "current iter: 19325000/24576000\n",
      "current iter: 19326000/24576000\n",
      "current iter: 19327000/24576000\n",
      "current iter: 19328000/24576000\n",
      "current iter: 19329000/24576000\n",
      "current iter: 19330000/24576000\n",
      "current iter: 19331000/24576000\n",
      "current iter: 19332000/24576000\n",
      "current iter: 19333000/24576000\n",
      "current iter: 19334000/24576000\n",
      "current iter: 19335000/24576000\n",
      "current iter: 19336000/24576000\n",
      "current iter: 19337000/24576000\n",
      "current iter: 19338000/24576000\n",
      "current iter: 19339000/24576000\n",
      "current iter: 19340000/24576000\n",
      "current iter: 19341000/24576000\n",
      "current iter: 19342000/24576000\n",
      "current iter: 19343000/24576000\n",
      "current iter: 19344000/24576000\n",
      "current iter: 19345000/24576000\n",
      "current iter: 19346000/24576000\n",
      "current iter: 19347000/24576000\n",
      "current iter: 19348000/24576000\n",
      "current iter: 19349000/24576000\n",
      "current iter: 19350000/24576000\n",
      "current iter: 19351000/24576000\n",
      "current iter: 19352000/24576000\n",
      "current iter: 19353000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 19354000/24576000\n",
      "current iter: 19355000/24576000\n",
      "current iter: 19356000/24576000\n",
      "current iter: 19357000/24576000\n",
      "current iter: 19358000/24576000\n",
      "current iter: 19359000/24576000\n",
      "current iter: 19360000/24576000\n",
      "current iter: 19361000/24576000\n",
      "current iter: 19362000/24576000\n",
      "current iter: 19363000/24576000\n",
      "current iter: 19364000/24576000\n",
      "current iter: 19365000/24576000\n",
      "current iter: 19366000/24576000\n",
      "current iter: 19367000/24576000\n",
      "current iter: 19368000/24576000\n",
      "current iter: 19369000/24576000\n",
      "current iter: 19370000/24576000\n",
      "current iter: 19371000/24576000\n",
      "current iter: 19372000/24576000\n",
      "current iter: 19373000/24576000\n",
      "current iter: 19374000/24576000\n",
      "current iter: 19375000/24576000\n",
      "current iter: 19376000/24576000\n",
      "current iter: 19377000/24576000\n",
      "current iter: 19378000/24576000\n",
      "current iter: 19379000/24576000\n",
      "current iter: 19380000/24576000\n",
      "current iter: 19381000/24576000\n",
      "current iter: 19382000/24576000\n",
      "current iter: 19383000/24576000\n",
      "current iter: 19384000/24576000\n",
      "current iter: 19385000/24576000\n",
      "current iter: 19386000/24576000\n",
      "current iter: 19387000/24576000\n",
      "current iter: 19388000/24576000\n",
      "current iter: 19389000/24576000\n",
      "current iter: 19390000/24576000\n",
      "current iter: 19391000/24576000\n",
      "current iter: 19392000/24576000\n",
      "current iter: 19393000/24576000\n",
      "current iter: 19394000/24576000\n",
      "current iter: 19395000/24576000\n",
      "current iter: 19396000/24576000\n",
      "current iter: 19397000/24576000\n",
      "current iter: 19398000/24576000\n",
      "current iter: 19399000/24576000\n",
      "current iter: 19400000/24576000\n",
      "current iter: 19401000/24576000\n",
      "current iter: 19402000/24576000\n",
      "current iter: 19403000/24576000\n",
      "current iter: 19404000/24576000\n",
      "current iter: 19405000/24576000\n",
      "current iter: 19406000/24576000\n",
      "current iter: 19407000/24576000\n",
      "current iter: 19408000/24576000\n",
      "current iter: 19409000/24576000\n",
      "current iter: 19410000/24576000\n",
      "current iter: 19411000/24576000\n",
      "current iter: 19412000/24576000\n",
      "current iter: 19413000/24576000\n",
      "current iter: 19414000/24576000\n",
      "current iter: 19415000/24576000\n",
      "current iter: 19416000/24576000\n",
      "current iter: 19417000/24576000\n",
      "current iter: 19418000/24576000\n",
      "current iter: 19419000/24576000\n",
      "current iter: 19420000/24576000\n",
      "current iter: 19421000/24576000\n",
      "current iter: 19422000/24576000\n",
      "current iter: 19423000/24576000\n",
      "current iter: 19424000/24576000\n",
      "current iter: 19425000/24576000\n",
      "current iter: 19426000/24576000\n",
      "current iter: 19427000/24576000\n",
      "current iter: 19428000/24576000\n",
      "current iter: 19429000/24576000\n",
      "current iter: 19430000/24576000\n",
      "current iter: 19431000/24576000\n",
      "current iter: 19432000/24576000\n",
      "current iter: 19433000/24576000\n",
      "current iter: 19434000/24576000\n",
      "current iter: 19435000/24576000\n",
      "current iter: 19436000/24576000\n",
      "current iter: 19437000/24576000\n",
      "current iter: 19438000/24576000\n",
      "current iter: 19439000/24576000\n",
      "current iter: 19440000/24576000\n",
      "current iter: 19441000/24576000\n",
      "current iter: 19442000/24576000\n",
      "current iter: 19443000/24576000\n",
      "current iter: 19444000/24576000\n",
      "current iter: 19445000/24576000\n",
      "current iter: 19446000/24576000\n",
      "current iter: 19447000/24576000\n",
      "current iter: 19448000/24576000\n",
      "current iter: 19449000/24576000\n",
      "current iter: 19450000/24576000\n",
      "current iter: 19451000/24576000\n",
      "current iter: 19452000/24576000\n",
      "current iter: 19453000/24576000\n",
      "current iter: 19454000/24576000\n",
      "current iter: 19455000/24576000\n",
      "current iter: 19456000/24576000\n",
      "current iter: 19457000/24576000\n",
      "current iter: 19458000/24576000\n",
      "current iter: 19459000/24576000\n",
      "current iter: 19460000/24576000\n",
      "current iter: 19461000/24576000\n",
      "current iter: 19462000/24576000\n",
      "current iter: 19463000/24576000\n",
      "current iter: 19464000/24576000\n",
      "current iter: 19465000/24576000\n",
      "current iter: 19466000/24576000\n",
      "current iter: 19467000/24576000\n",
      "current iter: 19468000/24576000\n",
      "current iter: 19469000/24576000\n",
      "current iter: 19470000/24576000\n",
      "current iter: 19471000/24576000\n",
      "current iter: 19472000/24576000\n",
      "current iter: 19473000/24576000\n",
      "current iter: 19474000/24576000\n",
      "current iter: 19475000/24576000\n",
      "current iter: 19476000/24576000\n",
      "current iter: 19477000/24576000\n",
      "current iter: 19478000/24576000\n",
      "current iter: 19479000/24576000\n",
      "current iter: 19480000/24576000\n",
      "current iter: 19481000/24576000\n",
      "current iter: 19482000/24576000\n",
      "current iter: 19483000/24576000\n",
      "current iter: 19484000/24576000\n",
      "current iter: 19485000/24576000\n",
      "current iter: 19486000/24576000\n",
      "current iter: 19487000/24576000\n",
      "current iter: 19488000/24576000\n",
      "current iter: 19489000/24576000\n",
      "current iter: 19490000/24576000\n",
      "current iter: 19491000/24576000\n",
      "current iter: 19492000/24576000\n",
      "current iter: 19493000/24576000\n",
      "current iter: 19494000/24576000\n",
      "current iter: 19495000/24576000\n",
      "current iter: 19496000/24576000\n",
      "current iter: 19497000/24576000\n",
      "current iter: 19498000/24576000\n",
      "current iter: 19499000/24576000\n",
      "current iter: 19500000/24576000\n",
      "current iter: 19501000/24576000\n",
      "current iter: 19502000/24576000\n",
      "current iter: 19503000/24576000\n",
      "current iter: 19504000/24576000\n",
      "current iter: 19505000/24576000\n",
      "current iter: 19506000/24576000\n",
      "current iter: 19507000/24576000\n",
      "current iter: 19508000/24576000\n",
      "current iter: 19509000/24576000\n",
      "current iter: 19510000/24576000\n",
      "current iter: 19511000/24576000\n",
      "current iter: 19512000/24576000\n",
      "current iter: 19513000/24576000\n",
      "current iter: 19514000/24576000\n",
      "current iter: 19515000/24576000\n",
      "current iter: 19516000/24576000\n",
      "current iter: 19517000/24576000\n",
      "current iter: 19518000/24576000\n",
      "current iter: 19519000/24576000\n",
      "current iter: 19520000/24576000\n",
      "current iter: 19521000/24576000\n",
      "current iter: 19522000/24576000\n",
      "current iter: 19523000/24576000\n",
      "current iter: 19524000/24576000\n",
      "current iter: 19525000/24576000\n",
      "current iter: 19526000/24576000\n",
      "current iter: 19527000/24576000\n",
      "current iter: 19528000/24576000\n",
      "current iter: 19529000/24576000\n",
      "current iter: 19530000/24576000\n",
      "current iter: 19531000/24576000\n",
      "current iter: 19532000/24576000\n",
      "current iter: 19533000/24576000\n",
      "current iter: 19534000/24576000\n",
      "current iter: 19535000/24576000\n",
      "current iter: 19536000/24576000\n",
      "current iter: 19537000/24576000\n",
      "current iter: 19538000/24576000\n",
      "current iter: 19539000/24576000\n",
      "current iter: 19540000/24576000\n",
      "current iter: 19541000/24576000\n",
      "current iter: 19542000/24576000\n",
      "current iter: 19543000/24576000\n",
      "current iter: 19544000/24576000\n",
      "current iter: 19545000/24576000\n",
      "current iter: 19546000/24576000\n",
      "current iter: 19547000/24576000\n",
      "current iter: 19548000/24576000\n",
      "current iter: 19549000/24576000\n",
      "current iter: 19550000/24576000\n",
      "current iter: 19551000/24576000\n",
      "current iter: 19552000/24576000\n",
      "current iter: 19553000/24576000\n",
      "current iter: 19554000/24576000\n",
      "current iter: 19555000/24576000\n",
      "current iter: 19556000/24576000\n",
      "current iter: 19557000/24576000\n",
      "current iter: 19558000/24576000\n",
      "current iter: 19559000/24576000\n",
      "current iter: 19560000/24576000\n",
      "current iter: 19561000/24576000\n",
      "current iter: 19562000/24576000\n",
      "current iter: 19563000/24576000\n",
      "current iter: 19564000/24576000\n",
      "current iter: 19565000/24576000\n",
      "current iter: 19566000/24576000\n",
      "current iter: 19567000/24576000\n",
      "current iter: 19568000/24576000\n",
      "current iter: 19569000/24576000\n",
      "current iter: 19570000/24576000\n",
      "current iter: 19571000/24576000\n",
      "current iter: 19572000/24576000\n",
      "current iter: 19573000/24576000\n",
      "current iter: 19574000/24576000\n",
      "current iter: 19575000/24576000\n",
      "current iter: 19576000/24576000\n",
      "current iter: 19577000/24576000\n",
      "current iter: 19578000/24576000\n",
      "current iter: 19579000/24576000\n",
      "current iter: 19580000/24576000\n",
      "current iter: 19581000/24576000\n",
      "current iter: 19582000/24576000\n",
      "current iter: 19583000/24576000\n",
      "current iter: 19584000/24576000\n",
      "current iter: 19585000/24576000\n",
      "current iter: 19586000/24576000\n",
      "current iter: 19587000/24576000\n",
      "current iter: 19588000/24576000\n",
      "current iter: 19589000/24576000\n",
      "current iter: 19590000/24576000\n",
      "current iter: 19591000/24576000\n",
      "current iter: 19592000/24576000\n",
      "current iter: 19593000/24576000\n",
      "current iter: 19594000/24576000\n",
      "current iter: 19595000/24576000\n",
      "current iter: 19596000/24576000\n",
      "current iter: 19597000/24576000\n",
      "current iter: 19598000/24576000\n",
      "current iter: 19599000/24576000\n",
      "current iter: 19600000/24576000\n",
      "current iter: 19601000/24576000\n",
      "current iter: 19602000/24576000\n",
      "current iter: 19603000/24576000\n",
      "current iter: 19604000/24576000\n",
      "current iter: 19605000/24576000\n",
      "current iter: 19606000/24576000\n",
      "current iter: 19607000/24576000\n",
      "current iter: 19608000/24576000\n",
      "current iter: 19609000/24576000\n",
      "current iter: 19610000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 19611000/24576000\n",
      "current iter: 19612000/24576000\n",
      "current iter: 19613000/24576000\n",
      "current iter: 19614000/24576000\n",
      "current iter: 19615000/24576000\n",
      "current iter: 19616000/24576000\n",
      "current iter: 19617000/24576000\n",
      "current iter: 19618000/24576000\n",
      "current iter: 19619000/24576000\n",
      "current iter: 19620000/24576000\n",
      "current iter: 19621000/24576000\n",
      "current iter: 19622000/24576000\n",
      "current iter: 19623000/24576000\n",
      "current iter: 19624000/24576000\n",
      "current iter: 19625000/24576000\n",
      "current iter: 19626000/24576000\n",
      "current iter: 19627000/24576000\n",
      "current iter: 19628000/24576000\n",
      "current iter: 19629000/24576000\n",
      "current iter: 19630000/24576000\n",
      "current iter: 19631000/24576000\n",
      "current iter: 19632000/24576000\n",
      "current iter: 19633000/24576000\n",
      "current iter: 19634000/24576000\n",
      "current iter: 19635000/24576000\n",
      "current iter: 19636000/24576000\n",
      "current iter: 19637000/24576000\n",
      "current iter: 19638000/24576000\n",
      "current iter: 19639000/24576000\n",
      "current iter: 19640000/24576000\n",
      "current iter: 19641000/24576000\n",
      "current iter: 19642000/24576000\n",
      "current iter: 19643000/24576000\n",
      "current iter: 19644000/24576000\n",
      "current iter: 19645000/24576000\n",
      "current iter: 19646000/24576000\n",
      "current iter: 19647000/24576000\n",
      "current iter: 19648000/24576000\n",
      "current iter: 19649000/24576000\n",
      "current iter: 19650000/24576000\n",
      "current iter: 19651000/24576000\n",
      "current iter: 19652000/24576000\n",
      "current iter: 19653000/24576000\n",
      "current iter: 19654000/24576000\n",
      "current iter: 19655000/24576000\n",
      "current iter: 19656000/24576000\n",
      "current iter: 19657000/24576000\n",
      "current iter: 19658000/24576000\n",
      "current iter: 19659000/24576000\n",
      "current iter: 19660000/24576000\n",
      "current iter: 19661000/24576000\n",
      "current iter: 19662000/24576000\n",
      "current iter: 19663000/24576000\n",
      "current iter: 19664000/24576000\n",
      "current iter: 19665000/24576000\n",
      "current iter: 19666000/24576000\n",
      "current iter: 19667000/24576000\n",
      "current iter: 19668000/24576000\n",
      "current iter: 19669000/24576000\n",
      "current iter: 19670000/24576000\n",
      "current iter: 19671000/24576000\n",
      "current iter: 19672000/24576000\n",
      "current iter: 19673000/24576000\n",
      "current iter: 19674000/24576000\n",
      "current iter: 19675000/24576000\n",
      "current iter: 19676000/24576000\n",
      "current iter: 19677000/24576000\n",
      "current iter: 19678000/24576000\n",
      "current iter: 19679000/24576000\n",
      "current iter: 19680000/24576000\n",
      "current iter: 19681000/24576000\n",
      "current iter: 19682000/24576000\n",
      "current iter: 19683000/24576000\n",
      "current iter: 19684000/24576000\n",
      "current iter: 19685000/24576000\n",
      "current iter: 19686000/24576000\n",
      "current iter: 19687000/24576000\n",
      "current iter: 19688000/24576000\n",
      "current iter: 19689000/24576000\n",
      "current iter: 19690000/24576000\n",
      "current iter: 19691000/24576000\n",
      "current iter: 19692000/24576000\n",
      "current iter: 19693000/24576000\n",
      "current iter: 19694000/24576000\n",
      "current iter: 19695000/24576000\n",
      "current iter: 19696000/24576000\n",
      "current iter: 19697000/24576000\n",
      "current iter: 19698000/24576000\n",
      "current iter: 19699000/24576000\n",
      "current iter: 19700000/24576000\n",
      "current iter: 19701000/24576000\n",
      "current iter: 19702000/24576000\n",
      "current iter: 19703000/24576000\n",
      "current iter: 19704000/24576000\n",
      "current iter: 19705000/24576000\n",
      "current iter: 19706000/24576000\n",
      "current iter: 19707000/24576000\n",
      "current iter: 19708000/24576000\n",
      "current iter: 19709000/24576000\n",
      "current iter: 19710000/24576000\n",
      "current iter: 19711000/24576000\n",
      "current iter: 19712000/24576000\n",
      "current iter: 19713000/24576000\n",
      "current iter: 19714000/24576000\n",
      "current iter: 19715000/24576000\n",
      "current iter: 19716000/24576000\n",
      "current iter: 19717000/24576000\n",
      "current iter: 19718000/24576000\n",
      "current iter: 19719000/24576000\n",
      "current iter: 19720000/24576000\n",
      "current iter: 19721000/24576000\n",
      "current iter: 19722000/24576000\n",
      "current iter: 19723000/24576000\n",
      "current iter: 19724000/24576000\n",
      "current iter: 19725000/24576000\n",
      "current iter: 19726000/24576000\n",
      "current iter: 19727000/24576000\n",
      "current iter: 19728000/24576000\n",
      "current iter: 19729000/24576000\n",
      "current iter: 19730000/24576000\n",
      "current iter: 19731000/24576000\n",
      "current iter: 19732000/24576000\n",
      "current iter: 19733000/24576000\n",
      "current iter: 19734000/24576000\n",
      "current iter: 19735000/24576000\n",
      "current iter: 19736000/24576000\n",
      "current iter: 19737000/24576000\n",
      "current iter: 19738000/24576000\n",
      "current iter: 19739000/24576000\n",
      "current iter: 19740000/24576000\n",
      "current iter: 19741000/24576000\n",
      "current iter: 19742000/24576000\n",
      "current iter: 19743000/24576000\n",
      "current iter: 19744000/24576000\n",
      "current iter: 19745000/24576000\n",
      "current iter: 19746000/24576000\n",
      "current iter: 19747000/24576000\n",
      "current iter: 19748000/24576000\n",
      "current iter: 19749000/24576000\n",
      "current iter: 19750000/24576000\n",
      "current iter: 19751000/24576000\n",
      "current iter: 19752000/24576000\n",
      "current iter: 19753000/24576000\n",
      "current iter: 19754000/24576000\n",
      "current iter: 19755000/24576000\n",
      "current iter: 19756000/24576000\n",
      "current iter: 19757000/24576000\n",
      "current iter: 19758000/24576000\n",
      "current iter: 19759000/24576000\n",
      "current iter: 19760000/24576000\n",
      "current iter: 19761000/24576000\n",
      "current iter: 19762000/24576000\n",
      "current iter: 19763000/24576000\n",
      "current iter: 19764000/24576000\n",
      "current iter: 19765000/24576000\n",
      "current iter: 19766000/24576000\n",
      "current iter: 19767000/24576000\n",
      "current iter: 19768000/24576000\n",
      "current iter: 19769000/24576000\n",
      "current iter: 19770000/24576000\n",
      "current iter: 19771000/24576000\n",
      "current iter: 19772000/24576000\n",
      "current iter: 19773000/24576000\n",
      "current iter: 19774000/24576000\n",
      "current iter: 19775000/24576000\n",
      "current iter: 19776000/24576000\n",
      "current iter: 19777000/24576000\n",
      "current iter: 19778000/24576000\n",
      "current iter: 19779000/24576000\n",
      "current iter: 19780000/24576000\n",
      "current iter: 19781000/24576000\n",
      "current iter: 19782000/24576000\n",
      "current iter: 19783000/24576000\n",
      "current iter: 19784000/24576000\n",
      "current iter: 19785000/24576000\n",
      "current iter: 19786000/24576000\n",
      "current iter: 19787000/24576000\n",
      "current iter: 19788000/24576000\n",
      "current iter: 19789000/24576000\n",
      "current iter: 19790000/24576000\n",
      "current iter: 19791000/24576000\n",
      "current iter: 19792000/24576000\n",
      "current iter: 19793000/24576000\n",
      "current iter: 19794000/24576000\n",
      "current iter: 19795000/24576000\n",
      "current iter: 19796000/24576000\n",
      "current iter: 19797000/24576000\n",
      "current iter: 19798000/24576000\n",
      "current iter: 19799000/24576000\n",
      "current iter: 19800000/24576000\n",
      "current iter: 19801000/24576000\n",
      "current iter: 19802000/24576000\n",
      "current iter: 19803000/24576000\n",
      "current iter: 19804000/24576000\n",
      "current iter: 19805000/24576000\n",
      "current iter: 19806000/24576000\n",
      "current iter: 19807000/24576000\n",
      "current iter: 19808000/24576000\n",
      "current iter: 19809000/24576000\n",
      "current iter: 19810000/24576000\n",
      "current iter: 19811000/24576000\n",
      "current iter: 19812000/24576000\n",
      "current iter: 19813000/24576000\n",
      "current iter: 19814000/24576000\n",
      "current iter: 19815000/24576000\n",
      "current iter: 19816000/24576000\n",
      "current iter: 19817000/24576000\n",
      "current iter: 19818000/24576000\n",
      "current iter: 19819000/24576000\n",
      "current iter: 19820000/24576000\n",
      "current iter: 19821000/24576000\n",
      "current iter: 19822000/24576000\n",
      "current iter: 19823000/24576000\n",
      "current iter: 19824000/24576000\n",
      "current iter: 19825000/24576000\n",
      "current iter: 19826000/24576000\n",
      "current iter: 19827000/24576000\n",
      "current iter: 19828000/24576000\n",
      "current iter: 19829000/24576000\n",
      "current iter: 19830000/24576000\n",
      "current iter: 19831000/24576000\n",
      "current iter: 19832000/24576000\n",
      "current iter: 19833000/24576000\n",
      "current iter: 19834000/24576000\n",
      "current iter: 19835000/24576000\n",
      "current iter: 19836000/24576000\n",
      "current iter: 19837000/24576000\n",
      "current iter: 19838000/24576000\n",
      "current iter: 19839000/24576000\n",
      "current iter: 19840000/24576000\n",
      "current iter: 19841000/24576000\n",
      "current iter: 19842000/24576000\n",
      "current iter: 19843000/24576000\n",
      "current iter: 19844000/24576000\n",
      "current iter: 19845000/24576000\n",
      "current iter: 19846000/24576000\n",
      "current iter: 19847000/24576000\n",
      "current iter: 19848000/24576000\n",
      "current iter: 19849000/24576000\n",
      "current iter: 19850000/24576000\n",
      "current iter: 19851000/24576000\n",
      "current iter: 19852000/24576000\n",
      "current iter: 19853000/24576000\n",
      "current iter: 19854000/24576000\n",
      "current iter: 19855000/24576000\n",
      "current iter: 19856000/24576000\n",
      "current iter: 19857000/24576000\n",
      "current iter: 19858000/24576000\n",
      "current iter: 19859000/24576000\n",
      "current iter: 19860000/24576000\n",
      "current iter: 19861000/24576000\n",
      "current iter: 19862000/24576000\n",
      "current iter: 19863000/24576000\n",
      "current iter: 19864000/24576000\n",
      "current iter: 19865000/24576000\n",
      "current iter: 19866000/24576000\n",
      "current iter: 19867000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 19868000/24576000\n",
      "current iter: 19869000/24576000\n",
      "current iter: 19870000/24576000\n",
      "current iter: 19871000/24576000\n",
      "current iter: 19872000/24576000\n",
      "current iter: 19873000/24576000\n",
      "current iter: 19874000/24576000\n",
      "current iter: 19875000/24576000\n",
      "current iter: 19876000/24576000\n",
      "current iter: 19877000/24576000\n",
      "current iter: 19878000/24576000\n",
      "current iter: 19879000/24576000\n",
      "current iter: 19880000/24576000\n",
      "current iter: 19881000/24576000\n",
      "current iter: 19882000/24576000\n",
      "current iter: 19883000/24576000\n",
      "current iter: 19884000/24576000\n",
      "current iter: 19885000/24576000\n",
      "current iter: 19886000/24576000\n",
      "current iter: 19887000/24576000\n",
      "current iter: 19888000/24576000\n",
      "current iter: 19889000/24576000\n",
      "current iter: 19890000/24576000\n",
      "current iter: 19891000/24576000\n",
      "current iter: 19892000/24576000\n",
      "current iter: 19893000/24576000\n",
      "current iter: 19894000/24576000\n",
      "current iter: 19895000/24576000\n",
      "current iter: 19896000/24576000\n",
      "current iter: 19897000/24576000\n",
      "current iter: 19898000/24576000\n",
      "current iter: 19899000/24576000\n",
      "current iter: 19900000/24576000\n",
      "current iter: 19901000/24576000\n",
      "current iter: 19902000/24576000\n",
      "current iter: 19903000/24576000\n",
      "current iter: 19904000/24576000\n",
      "current iter: 19905000/24576000\n",
      "current iter: 19906000/24576000\n",
      "current iter: 19907000/24576000\n",
      "current iter: 19908000/24576000\n",
      "current iter: 19909000/24576000\n",
      "current iter: 19910000/24576000\n",
      "current iter: 19911000/24576000\n",
      "current iter: 19912000/24576000\n",
      "current iter: 19913000/24576000\n",
      "current iter: 19914000/24576000\n",
      "current iter: 19915000/24576000\n",
      "current iter: 19916000/24576000\n",
      "current iter: 19917000/24576000\n",
      "current iter: 19918000/24576000\n",
      "current iter: 19919000/24576000\n",
      "current iter: 19920000/24576000\n",
      "current iter: 19921000/24576000\n",
      "current iter: 19922000/24576000\n",
      "current iter: 19923000/24576000\n",
      "current iter: 19924000/24576000\n",
      "current iter: 19925000/24576000\n",
      "current iter: 19926000/24576000\n",
      "current iter: 19927000/24576000\n",
      "current iter: 19928000/24576000\n",
      "current iter: 19929000/24576000\n",
      "current iter: 19930000/24576000\n",
      "current iter: 19931000/24576000\n",
      "current iter: 19932000/24576000\n",
      "current iter: 19933000/24576000\n",
      "current iter: 19934000/24576000\n",
      "current iter: 19935000/24576000\n",
      "current iter: 19936000/24576000\n",
      "current iter: 19937000/24576000\n",
      "current iter: 19938000/24576000\n",
      "current iter: 19939000/24576000\n",
      "current iter: 19940000/24576000\n",
      "current iter: 19941000/24576000\n",
      "current iter: 19942000/24576000\n",
      "current iter: 19943000/24576000\n",
      "current iter: 19944000/24576000\n",
      "current iter: 19945000/24576000\n",
      "current iter: 19946000/24576000\n",
      "current iter: 19947000/24576000\n",
      "current iter: 19948000/24576000\n",
      "current iter: 19949000/24576000\n",
      "current iter: 19950000/24576000\n",
      "current iter: 19951000/24576000\n",
      "current iter: 19952000/24576000\n",
      "current iter: 19953000/24576000\n",
      "current iter: 19954000/24576000\n",
      "current iter: 19955000/24576000\n",
      "current iter: 19956000/24576000\n",
      "current iter: 19957000/24576000\n",
      "current iter: 19958000/24576000\n",
      "current iter: 19959000/24576000\n",
      "current iter: 19960000/24576000\n",
      "current iter: 19961000/24576000\n",
      "current iter: 19962000/24576000\n",
      "current iter: 19963000/24576000\n",
      "current iter: 19964000/24576000\n",
      "current iter: 19965000/24576000\n",
      "current iter: 19966000/24576000\n",
      "current iter: 19967000/24576000\n",
      "current iter: 19968000/24576000\n",
      "current iter: 19969000/24576000\n",
      "current iter: 19970000/24576000\n",
      "current iter: 19971000/24576000\n",
      "current iter: 19972000/24576000\n",
      "current iter: 19973000/24576000\n",
      "current iter: 19974000/24576000\n",
      "current iter: 19975000/24576000\n",
      "current iter: 19976000/24576000\n",
      "current iter: 19977000/24576000\n",
      "current iter: 19978000/24576000\n",
      "current iter: 19979000/24576000\n",
      "current iter: 19980000/24576000\n",
      "current iter: 19981000/24576000\n",
      "current iter: 19982000/24576000\n",
      "current iter: 19983000/24576000\n",
      "current iter: 19984000/24576000\n",
      "current iter: 19985000/24576000\n",
      "current iter: 19986000/24576000\n",
      "current iter: 19987000/24576000\n",
      "current iter: 19988000/24576000\n",
      "current iter: 19989000/24576000\n",
      "current iter: 19990000/24576000\n",
      "current iter: 19991000/24576000\n",
      "current iter: 19992000/24576000\n",
      "current iter: 19993000/24576000\n",
      "current iter: 19994000/24576000\n",
      "current iter: 19995000/24576000\n",
      "current iter: 19996000/24576000\n",
      "current iter: 19997000/24576000\n",
      "current iter: 19998000/24576000\n",
      "current iter: 19999000/24576000\n",
      "current iter: 20000000/24576000\n",
      "current iter: 20001000/24576000\n",
      "current iter: 20002000/24576000\n",
      "current iter: 20003000/24576000\n",
      "current iter: 20004000/24576000\n",
      "current iter: 20005000/24576000\n",
      "current iter: 20006000/24576000\n",
      "current iter: 20007000/24576000\n",
      "current iter: 20008000/24576000\n",
      "current iter: 20009000/24576000\n",
      "current iter: 20010000/24576000\n",
      "current iter: 20011000/24576000\n",
      "current iter: 20012000/24576000\n",
      "current iter: 20013000/24576000\n",
      "current iter: 20014000/24576000\n",
      "current iter: 20015000/24576000\n",
      "current iter: 20016000/24576000\n",
      "current iter: 20017000/24576000\n",
      "current iter: 20018000/24576000\n",
      "current iter: 20019000/24576000\n",
      "current iter: 20020000/24576000\n",
      "current iter: 20021000/24576000\n",
      "current iter: 20022000/24576000\n",
      "current iter: 20023000/24576000\n",
      "current iter: 20024000/24576000\n",
      "current iter: 20025000/24576000\n",
      "current iter: 20026000/24576000\n",
      "current iter: 20027000/24576000\n",
      "current iter: 20028000/24576000\n",
      "current iter: 20029000/24576000\n",
      "current iter: 20030000/24576000\n",
      "current iter: 20031000/24576000\n",
      "current iter: 20032000/24576000\n",
      "current iter: 20033000/24576000\n",
      "current iter: 20034000/24576000\n",
      "current iter: 20035000/24576000\n",
      "current iter: 20036000/24576000\n",
      "current iter: 20037000/24576000\n",
      "current iter: 20038000/24576000\n",
      "current iter: 20039000/24576000\n",
      "current iter: 20040000/24576000\n",
      "current iter: 20041000/24576000\n",
      "current iter: 20042000/24576000\n",
      "current iter: 20043000/24576000\n",
      "current iter: 20044000/24576000\n",
      "current iter: 20045000/24576000\n",
      "current iter: 20046000/24576000\n",
      "current iter: 20047000/24576000\n",
      "current iter: 20048000/24576000\n",
      "current iter: 20049000/24576000\n",
      "current iter: 20050000/24576000\n",
      "current iter: 20051000/24576000\n",
      "current iter: 20052000/24576000\n",
      "current iter: 20053000/24576000\n",
      "current iter: 20054000/24576000\n",
      "current iter: 20055000/24576000\n",
      "current iter: 20056000/24576000\n",
      "current iter: 20057000/24576000\n",
      "current iter: 20058000/24576000\n",
      "current iter: 20059000/24576000\n",
      "current iter: 20060000/24576000\n",
      "current iter: 20061000/24576000\n",
      "current iter: 20062000/24576000\n",
      "current iter: 20063000/24576000\n",
      "current iter: 20064000/24576000\n",
      "current iter: 20065000/24576000\n",
      "current iter: 20066000/24576000\n",
      "current iter: 20067000/24576000\n",
      "current iter: 20068000/24576000\n",
      "current iter: 20069000/24576000\n",
      "current iter: 20070000/24576000\n",
      "current iter: 20071000/24576000\n",
      "current iter: 20072000/24576000\n",
      "current iter: 20073000/24576000\n",
      "current iter: 20074000/24576000\n",
      "current iter: 20075000/24576000\n",
      "current iter: 20076000/24576000\n",
      "current iter: 20077000/24576000\n",
      "current iter: 20078000/24576000\n",
      "current iter: 20079000/24576000\n",
      "current iter: 20080000/24576000\n",
      "current iter: 20081000/24576000\n",
      "current iter: 20082000/24576000\n",
      "current iter: 20083000/24576000\n",
      "current iter: 20084000/24576000\n",
      "current iter: 20085000/24576000\n",
      "current iter: 20086000/24576000\n",
      "current iter: 20087000/24576000\n",
      "current iter: 20088000/24576000\n",
      "current iter: 20089000/24576000\n",
      "current iter: 20090000/24576000\n",
      "current iter: 20091000/24576000\n",
      "current iter: 20092000/24576000\n",
      "current iter: 20093000/24576000\n",
      "current iter: 20094000/24576000\n",
      "current iter: 20095000/24576000\n",
      "current iter: 20096000/24576000\n",
      "current iter: 20097000/24576000\n",
      "current iter: 20098000/24576000\n",
      "current iter: 20099000/24576000\n",
      "current iter: 20100000/24576000\n",
      "current iter: 20101000/24576000\n",
      "current iter: 20102000/24576000\n",
      "current iter: 20103000/24576000\n",
      "current iter: 20104000/24576000\n",
      "current iter: 20105000/24576000\n",
      "current iter: 20106000/24576000\n",
      "current iter: 20107000/24576000\n",
      "current iter: 20108000/24576000\n",
      "current iter: 20109000/24576000\n",
      "current iter: 20110000/24576000\n",
      "current iter: 20111000/24576000\n",
      "current iter: 20112000/24576000\n",
      "current iter: 20113000/24576000\n",
      "current iter: 20114000/24576000\n",
      "current iter: 20115000/24576000\n",
      "current iter: 20116000/24576000\n",
      "current iter: 20117000/24576000\n",
      "current iter: 20118000/24576000\n",
      "current iter: 20119000/24576000\n",
      "current iter: 20120000/24576000\n",
      "current iter: 20121000/24576000\n",
      "current iter: 20122000/24576000\n",
      "current iter: 20123000/24576000\n",
      "current iter: 20124000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 20125000/24576000\n",
      "current iter: 20126000/24576000\n",
      "current iter: 20127000/24576000\n",
      "current iter: 20128000/24576000\n",
      "current iter: 20129000/24576000\n",
      "current iter: 20130000/24576000\n",
      "current iter: 20131000/24576000\n",
      "current iter: 20132000/24576000\n",
      "current iter: 20133000/24576000\n",
      "current iter: 20134000/24576000\n",
      "current iter: 20135000/24576000\n",
      "current iter: 20136000/24576000\n",
      "current iter: 20137000/24576000\n",
      "current iter: 20138000/24576000\n",
      "current iter: 20139000/24576000\n",
      "current iter: 20140000/24576000\n",
      "current iter: 20141000/24576000\n",
      "current iter: 20142000/24576000\n",
      "current iter: 20143000/24576000\n",
      "current iter: 20144000/24576000\n",
      "current iter: 20145000/24576000\n",
      "current iter: 20146000/24576000\n",
      "current iter: 20147000/24576000\n",
      "current iter: 20148000/24576000\n",
      "current iter: 20149000/24576000\n",
      "current iter: 20150000/24576000\n",
      "current iter: 20151000/24576000\n",
      "current iter: 20152000/24576000\n",
      "current iter: 20153000/24576000\n",
      "current iter: 20154000/24576000\n",
      "current iter: 20155000/24576000\n",
      "current iter: 20156000/24576000\n",
      "current iter: 20157000/24576000\n",
      "current iter: 20158000/24576000\n",
      "current iter: 20159000/24576000\n",
      "current iter: 20160000/24576000\n",
      "current iter: 20161000/24576000\n",
      "current iter: 20162000/24576000\n",
      "current iter: 20163000/24576000\n",
      "current iter: 20164000/24576000\n",
      "current iter: 20165000/24576000\n",
      "current iter: 20166000/24576000\n",
      "current iter: 20167000/24576000\n",
      "current iter: 20168000/24576000\n",
      "current iter: 20169000/24576000\n",
      "current iter: 20170000/24576000\n",
      "current iter: 20171000/24576000\n",
      "current iter: 20172000/24576000\n",
      "current iter: 20173000/24576000\n",
      "current iter: 20174000/24576000\n",
      "current iter: 20175000/24576000\n",
      "current iter: 20176000/24576000\n",
      "current iter: 20177000/24576000\n",
      "current iter: 20178000/24576000\n",
      "current iter: 20179000/24576000\n",
      "current iter: 20180000/24576000\n",
      "current iter: 20181000/24576000\n",
      "current iter: 20182000/24576000\n",
      "current iter: 20183000/24576000\n",
      "current iter: 20184000/24576000\n",
      "current iter: 20185000/24576000\n",
      "current iter: 20186000/24576000\n",
      "current iter: 20187000/24576000\n",
      "current iter: 20188000/24576000\n",
      "current iter: 20189000/24576000\n",
      "current iter: 20190000/24576000\n",
      "current iter: 20191000/24576000\n",
      "current iter: 20192000/24576000\n",
      "current iter: 20193000/24576000\n",
      "current iter: 20194000/24576000\n",
      "current iter: 20195000/24576000\n",
      "current iter: 20196000/24576000\n",
      "current iter: 20197000/24576000\n",
      "current iter: 20198000/24576000\n",
      "current iter: 20199000/24576000\n",
      "current iter: 20200000/24576000\n",
      "current iter: 20201000/24576000\n",
      "current iter: 20202000/24576000\n",
      "current iter: 20203000/24576000\n",
      "current iter: 20204000/24576000\n",
      "current iter: 20205000/24576000\n",
      "current iter: 20206000/24576000\n",
      "current iter: 20207000/24576000\n",
      "current iter: 20208000/24576000\n",
      "current iter: 20209000/24576000\n",
      "current iter: 20210000/24576000\n",
      "current iter: 20211000/24576000\n",
      "current iter: 20212000/24576000\n",
      "current iter: 20213000/24576000\n",
      "current iter: 20214000/24576000\n",
      "current iter: 20215000/24576000\n",
      "current iter: 20216000/24576000\n",
      "current iter: 20217000/24576000\n",
      "current iter: 20218000/24576000\n",
      "current iter: 20219000/24576000\n",
      "current iter: 20220000/24576000\n",
      "current iter: 20221000/24576000\n",
      "current iter: 20222000/24576000\n",
      "current iter: 20223000/24576000\n",
      "current iter: 20224000/24576000\n",
      "current iter: 20225000/24576000\n",
      "current iter: 20226000/24576000\n",
      "current iter: 20227000/24576000\n",
      "current iter: 20228000/24576000\n",
      "current iter: 20229000/24576000\n",
      "current iter: 20230000/24576000\n",
      "current iter: 20231000/24576000\n",
      "current iter: 20232000/24576000\n",
      "current iter: 20233000/24576000\n",
      "current iter: 20234000/24576000\n",
      "current iter: 20235000/24576000\n",
      "current iter: 20236000/24576000\n",
      "current iter: 20237000/24576000\n",
      "current iter: 20238000/24576000\n",
      "current iter: 20239000/24576000\n",
      "current iter: 20240000/24576000\n",
      "current iter: 20241000/24576000\n",
      "current iter: 20242000/24576000\n",
      "current iter: 20243000/24576000\n",
      "current iter: 20244000/24576000\n",
      "current iter: 20245000/24576000\n",
      "current iter: 20246000/24576000\n",
      "current iter: 20247000/24576000\n",
      "current iter: 20248000/24576000\n",
      "current iter: 20249000/24576000\n",
      "current iter: 20250000/24576000\n",
      "current iter: 20251000/24576000\n",
      "current iter: 20252000/24576000\n",
      "current iter: 20253000/24576000\n",
      "current iter: 20254000/24576000\n",
      "current iter: 20255000/24576000\n",
      "current iter: 20256000/24576000\n",
      "current iter: 20257000/24576000\n",
      "current iter: 20258000/24576000\n",
      "current iter: 20259000/24576000\n",
      "current iter: 20260000/24576000\n",
      "current iter: 20261000/24576000\n",
      "current iter: 20262000/24576000\n",
      "current iter: 20263000/24576000\n",
      "current iter: 20264000/24576000\n",
      "current iter: 20265000/24576000\n",
      "current iter: 20266000/24576000\n",
      "current iter: 20267000/24576000\n",
      "current iter: 20268000/24576000\n",
      "current iter: 20269000/24576000\n",
      "current iter: 20270000/24576000\n",
      "current iter: 20271000/24576000\n",
      "current iter: 20272000/24576000\n",
      "current iter: 20273000/24576000\n",
      "current iter: 20274000/24576000\n",
      "current iter: 20275000/24576000\n",
      "current iter: 20276000/24576000\n",
      "current iter: 20277000/24576000\n",
      "current iter: 20278000/24576000\n",
      "current iter: 20279000/24576000\n",
      "current iter: 20280000/24576000\n",
      "current iter: 20281000/24576000\n",
      "current iter: 20282000/24576000\n",
      "current iter: 20283000/24576000\n",
      "current iter: 20284000/24576000\n",
      "current iter: 20285000/24576000\n",
      "current iter: 20286000/24576000\n",
      "current iter: 20287000/24576000\n",
      "current iter: 20288000/24576000\n",
      "current iter: 20289000/24576000\n",
      "current iter: 20290000/24576000\n",
      "current iter: 20291000/24576000\n",
      "current iter: 20292000/24576000\n",
      "current iter: 20293000/24576000\n",
      "current iter: 20294000/24576000\n",
      "current iter: 20295000/24576000\n",
      "current iter: 20296000/24576000\n",
      "current iter: 20297000/24576000\n",
      "current iter: 20298000/24576000\n",
      "current iter: 20299000/24576000\n",
      "current iter: 20300000/24576000\n",
      "current iter: 20301000/24576000\n",
      "current iter: 20302000/24576000\n",
      "current iter: 20303000/24576000\n",
      "current iter: 20304000/24576000\n",
      "current iter: 20305000/24576000\n",
      "current iter: 20306000/24576000\n",
      "current iter: 20307000/24576000\n",
      "current iter: 20308000/24576000\n",
      "current iter: 20309000/24576000\n",
      "current iter: 20310000/24576000\n",
      "current iter: 20311000/24576000\n",
      "current iter: 20312000/24576000\n",
      "current iter: 20313000/24576000\n",
      "current iter: 20314000/24576000\n",
      "current iter: 20315000/24576000\n",
      "current iter: 20316000/24576000\n",
      "current iter: 20317000/24576000\n",
      "current iter: 20318000/24576000\n",
      "current iter: 20319000/24576000\n",
      "current iter: 20320000/24576000\n",
      "current iter: 20321000/24576000\n",
      "current iter: 20322000/24576000\n",
      "current iter: 20323000/24576000\n",
      "current iter: 20324000/24576000\n",
      "current iter: 20325000/24576000\n",
      "current iter: 20326000/24576000\n",
      "current iter: 20327000/24576000\n",
      "current iter: 20328000/24576000\n",
      "current iter: 20329000/24576000\n",
      "current iter: 20330000/24576000\n",
      "current iter: 20331000/24576000\n",
      "current iter: 20332000/24576000\n",
      "current iter: 20333000/24576000\n",
      "current iter: 20334000/24576000\n",
      "current iter: 20335000/24576000\n",
      "current iter: 20336000/24576000\n",
      "current iter: 20337000/24576000\n",
      "current iter: 20338000/24576000\n",
      "current iter: 20339000/24576000\n",
      "current iter: 20340000/24576000\n",
      "current iter: 20341000/24576000\n",
      "current iter: 20342000/24576000\n",
      "current iter: 20343000/24576000\n",
      "current iter: 20344000/24576000\n",
      "current iter: 20345000/24576000\n",
      "current iter: 20346000/24576000\n",
      "current iter: 20347000/24576000\n",
      "current iter: 20348000/24576000\n",
      "current iter: 20349000/24576000\n",
      "current iter: 20350000/24576000\n",
      "current iter: 20351000/24576000\n",
      "current iter: 20352000/24576000\n",
      "current iter: 20353000/24576000\n",
      "current iter: 20354000/24576000\n",
      "current iter: 20355000/24576000\n",
      "current iter: 20356000/24576000\n",
      "current iter: 20357000/24576000\n",
      "current iter: 20358000/24576000\n",
      "current iter: 20359000/24576000\n",
      "current iter: 20360000/24576000\n",
      "current iter: 20361000/24576000\n",
      "current iter: 20362000/24576000\n",
      "current iter: 20363000/24576000\n",
      "current iter: 20364000/24576000\n",
      "current iter: 20365000/24576000\n",
      "current iter: 20366000/24576000\n",
      "current iter: 20367000/24576000\n",
      "current iter: 20368000/24576000\n",
      "current iter: 20369000/24576000\n",
      "current iter: 20370000/24576000\n",
      "current iter: 20371000/24576000\n",
      "current iter: 20372000/24576000\n",
      "current iter: 20373000/24576000\n",
      "current iter: 20374000/24576000\n",
      "current iter: 20375000/24576000\n",
      "current iter: 20376000/24576000\n",
      "current iter: 20377000/24576000\n",
      "current iter: 20378000/24576000\n",
      "current iter: 20379000/24576000\n",
      "current iter: 20380000/24576000\n",
      "current iter: 20381000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 20382000/24576000\n",
      "current iter: 20383000/24576000\n",
      "current iter: 20384000/24576000\n",
      "current iter: 20385000/24576000\n",
      "current iter: 20386000/24576000\n",
      "current iter: 20387000/24576000\n",
      "current iter: 20388000/24576000\n",
      "current iter: 20389000/24576000\n",
      "current iter: 20390000/24576000\n",
      "current iter: 20391000/24576000\n",
      "current iter: 20392000/24576000\n",
      "current iter: 20393000/24576000\n",
      "current iter: 20394000/24576000\n",
      "current iter: 20395000/24576000\n",
      "current iter: 20396000/24576000\n",
      "current iter: 20397000/24576000\n",
      "current iter: 20398000/24576000\n",
      "current iter: 20399000/24576000\n",
      "current iter: 20400000/24576000\n",
      "current iter: 20401000/24576000\n",
      "current iter: 20402000/24576000\n",
      "current iter: 20403000/24576000\n",
      "current iter: 20404000/24576000\n",
      "current iter: 20405000/24576000\n",
      "current iter: 20406000/24576000\n",
      "current iter: 20407000/24576000\n",
      "current iter: 20408000/24576000\n",
      "current iter: 20409000/24576000\n",
      "current iter: 20410000/24576000\n",
      "current iter: 20411000/24576000\n",
      "current iter: 20412000/24576000\n",
      "current iter: 20413000/24576000\n",
      "current iter: 20414000/24576000\n",
      "current iter: 20415000/24576000\n",
      "current iter: 20416000/24576000\n",
      "current iter: 20417000/24576000\n",
      "current iter: 20418000/24576000\n",
      "current iter: 20419000/24576000\n",
      "current iter: 20420000/24576000\n",
      "current iter: 20421000/24576000\n",
      "current iter: 20422000/24576000\n",
      "current iter: 20423000/24576000\n",
      "current iter: 20424000/24576000\n",
      "current iter: 20425000/24576000\n",
      "current iter: 20426000/24576000\n",
      "current iter: 20427000/24576000\n",
      "current iter: 20428000/24576000\n",
      "current iter: 20429000/24576000\n",
      "current iter: 20430000/24576000\n",
      "current iter: 20431000/24576000\n",
      "current iter: 20432000/24576000\n",
      "current iter: 20433000/24576000\n",
      "current iter: 20434000/24576000\n",
      "current iter: 20435000/24576000\n",
      "current iter: 20436000/24576000\n",
      "current iter: 20437000/24576000\n",
      "current iter: 20438000/24576000\n",
      "current iter: 20439000/24576000\n",
      "current iter: 20440000/24576000\n",
      "current iter: 20441000/24576000\n",
      "current iter: 20442000/24576000\n",
      "current iter: 20443000/24576000\n",
      "current iter: 20444000/24576000\n",
      "current iter: 20445000/24576000\n",
      "current iter: 20446000/24576000\n",
      "current iter: 20447000/24576000\n",
      "current iter: 20448000/24576000\n",
      "current iter: 20449000/24576000\n",
      "current iter: 20450000/24576000\n",
      "current iter: 20451000/24576000\n",
      "current iter: 20452000/24576000\n",
      "current iter: 20453000/24576000\n",
      "current iter: 20454000/24576000\n",
      "current iter: 20455000/24576000\n",
      "current iter: 20456000/24576000\n",
      "current iter: 20457000/24576000\n",
      "current iter: 20458000/24576000\n",
      "current iter: 20459000/24576000\n",
      "current iter: 20460000/24576000\n",
      "current iter: 20461000/24576000\n",
      "current iter: 20462000/24576000\n",
      "current iter: 20463000/24576000\n",
      "current iter: 20464000/24576000\n",
      "current iter: 20465000/24576000\n",
      "current iter: 20466000/24576000\n",
      "current iter: 20467000/24576000\n",
      "current iter: 20468000/24576000\n",
      "current iter: 20469000/24576000\n",
      "current iter: 20470000/24576000\n",
      "current iter: 20471000/24576000\n",
      "current iter: 20472000/24576000\n",
      "current iter: 20473000/24576000\n",
      "current iter: 20474000/24576000\n",
      "current iter: 20475000/24576000\n",
      "current iter: 20476000/24576000\n",
      "current iter: 20477000/24576000\n",
      "current iter: 20478000/24576000\n",
      "current iter: 20479000/24576000\n",
      "current iter: 20480000/24576000\n",
      "current iter: 20481000/24576000\n",
      "current iter: 20482000/24576000\n",
      "current iter: 20483000/24576000\n",
      "current iter: 20484000/24576000\n",
      "current iter: 20485000/24576000\n",
      "current iter: 20486000/24576000\n",
      "current iter: 20487000/24576000\n",
      "current iter: 20488000/24576000\n",
      "current iter: 20489000/24576000\n",
      "current iter: 20490000/24576000\n",
      "current iter: 20491000/24576000\n",
      "current iter: 20492000/24576000\n",
      "current iter: 20493000/24576000\n",
      "current iter: 20494000/24576000\n",
      "current iter: 20495000/24576000\n",
      "current iter: 20496000/24576000\n",
      "current iter: 20497000/24576000\n",
      "current iter: 20498000/24576000\n",
      "current iter: 20499000/24576000\n",
      "current iter: 20500000/24576000\n",
      "current iter: 20501000/24576000\n",
      "current iter: 20502000/24576000\n",
      "current iter: 20503000/24576000\n",
      "current iter: 20504000/24576000\n",
      "current iter: 20505000/24576000\n",
      "current iter: 20506000/24576000\n",
      "current iter: 20507000/24576000\n",
      "current iter: 20508000/24576000\n",
      "current iter: 20509000/24576000\n",
      "current iter: 20510000/24576000\n",
      "current iter: 20511000/24576000\n",
      "current iter: 20512000/24576000\n",
      "current iter: 20513000/24576000\n",
      "current iter: 20514000/24576000\n",
      "current iter: 20515000/24576000\n",
      "current iter: 20516000/24576000\n",
      "current iter: 20517000/24576000\n",
      "current iter: 20518000/24576000\n",
      "current iter: 20519000/24576000\n",
      "current iter: 20520000/24576000\n",
      "current iter: 20521000/24576000\n",
      "current iter: 20522000/24576000\n",
      "current iter: 20523000/24576000\n",
      "current iter: 20524000/24576000\n",
      "current iter: 20525000/24576000\n",
      "current iter: 20526000/24576000\n",
      "current iter: 20527000/24576000\n",
      "current iter: 20528000/24576000\n",
      "current iter: 20529000/24576000\n",
      "current iter: 20530000/24576000\n",
      "current iter: 20531000/24576000\n",
      "current iter: 20532000/24576000\n",
      "current iter: 20533000/24576000\n",
      "current iter: 20534000/24576000\n",
      "current iter: 20535000/24576000\n",
      "current iter: 20536000/24576000\n",
      "current iter: 20537000/24576000\n",
      "current iter: 20538000/24576000\n",
      "current iter: 20539000/24576000\n",
      "current iter: 20540000/24576000\n",
      "current iter: 20541000/24576000\n",
      "current iter: 20542000/24576000\n",
      "current iter: 20543000/24576000\n",
      "current iter: 20544000/24576000\n",
      "current iter: 20545000/24576000\n",
      "current iter: 20546000/24576000\n",
      "current iter: 20547000/24576000\n",
      "current iter: 20548000/24576000\n",
      "current iter: 20549000/24576000\n",
      "current iter: 20550000/24576000\n",
      "current iter: 20551000/24576000\n",
      "current iter: 20552000/24576000\n",
      "current iter: 20553000/24576000\n",
      "current iter: 20554000/24576000\n",
      "current iter: 20555000/24576000\n",
      "current iter: 20556000/24576000\n",
      "current iter: 20557000/24576000\n",
      "current iter: 20558000/24576000\n",
      "current iter: 20559000/24576000\n",
      "current iter: 20560000/24576000\n",
      "current iter: 20561000/24576000\n",
      "current iter: 20562000/24576000\n",
      "current iter: 20563000/24576000\n",
      "current iter: 20564000/24576000\n",
      "current iter: 20565000/24576000\n",
      "current iter: 20566000/24576000\n",
      "current iter: 20567000/24576000\n",
      "current iter: 20568000/24576000\n",
      "current iter: 20569000/24576000\n",
      "current iter: 20570000/24576000\n",
      "current iter: 20571000/24576000\n",
      "current iter: 20572000/24576000\n",
      "current iter: 20573000/24576000\n",
      "current iter: 20574000/24576000\n",
      "current iter: 20575000/24576000\n",
      "current iter: 20576000/24576000\n",
      "current iter: 20577000/24576000\n",
      "current iter: 20578000/24576000\n",
      "current iter: 20579000/24576000\n",
      "current iter: 20580000/24576000\n",
      "current iter: 20581000/24576000\n",
      "current iter: 20582000/24576000\n",
      "current iter: 20583000/24576000\n",
      "current iter: 20584000/24576000\n",
      "current iter: 20585000/24576000\n",
      "current iter: 20586000/24576000\n",
      "current iter: 20587000/24576000\n",
      "current iter: 20588000/24576000\n",
      "current iter: 20589000/24576000\n",
      "current iter: 20590000/24576000\n",
      "current iter: 20591000/24576000\n",
      "current iter: 20592000/24576000\n",
      "current iter: 20593000/24576000\n",
      "current iter: 20594000/24576000\n",
      "current iter: 20595000/24576000\n",
      "current iter: 20596000/24576000\n",
      "current iter: 20597000/24576000\n",
      "current iter: 20598000/24576000\n",
      "current iter: 20599000/24576000\n",
      "current iter: 20600000/24576000\n",
      "current iter: 20601000/24576000\n",
      "current iter: 20602000/24576000\n",
      "current iter: 20603000/24576000\n",
      "current iter: 20604000/24576000\n",
      "current iter: 20605000/24576000\n",
      "current iter: 20606000/24576000\n",
      "current iter: 20607000/24576000\n",
      "current iter: 20608000/24576000\n",
      "current iter: 20609000/24576000\n",
      "current iter: 20610000/24576000\n",
      "current iter: 20611000/24576000\n",
      "current iter: 20612000/24576000\n",
      "current iter: 20613000/24576000\n",
      "current iter: 20614000/24576000\n",
      "current iter: 20615000/24576000\n",
      "current iter: 20616000/24576000\n",
      "current iter: 20617000/24576000\n",
      "current iter: 20618000/24576000\n",
      "current iter: 20619000/24576000\n",
      "current iter: 20620000/24576000\n",
      "current iter: 20621000/24576000\n",
      "current iter: 20622000/24576000\n",
      "current iter: 20623000/24576000\n",
      "current iter: 20624000/24576000\n",
      "current iter: 20625000/24576000\n",
      "current iter: 20626000/24576000\n",
      "current iter: 20627000/24576000\n",
      "current iter: 20628000/24576000\n",
      "current iter: 20629000/24576000\n",
      "current iter: 20630000/24576000\n",
      "current iter: 20631000/24576000\n",
      "current iter: 20632000/24576000\n",
      "current iter: 20633000/24576000\n",
      "current iter: 20634000/24576000\n",
      "current iter: 20635000/24576000\n",
      "current iter: 20636000/24576000\n",
      "current iter: 20637000/24576000\n",
      "current iter: 20638000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 20639000/24576000\n",
      "current iter: 20640000/24576000\n",
      "current iter: 20641000/24576000\n",
      "current iter: 20642000/24576000\n",
      "current iter: 20643000/24576000\n",
      "current iter: 20644000/24576000\n",
      "current iter: 20645000/24576000\n",
      "current iter: 20646000/24576000\n",
      "current iter: 20647000/24576000\n",
      "current iter: 20648000/24576000\n",
      "current iter: 20649000/24576000\n",
      "current iter: 20650000/24576000\n",
      "current iter: 20651000/24576000\n",
      "current iter: 20652000/24576000\n",
      "current iter: 20653000/24576000\n",
      "current iter: 20654000/24576000\n",
      "current iter: 20655000/24576000\n",
      "current iter: 20656000/24576000\n",
      "current iter: 20657000/24576000\n",
      "current iter: 20658000/24576000\n",
      "current iter: 20659000/24576000\n",
      "current iter: 20660000/24576000\n",
      "current iter: 20661000/24576000\n",
      "current iter: 20662000/24576000\n",
      "current iter: 20663000/24576000\n",
      "current iter: 20664000/24576000\n",
      "current iter: 20665000/24576000\n",
      "current iter: 20666000/24576000\n",
      "current iter: 20667000/24576000\n",
      "current iter: 20668000/24576000\n",
      "current iter: 20669000/24576000\n",
      "current iter: 20670000/24576000\n",
      "current iter: 20671000/24576000\n",
      "current iter: 20672000/24576000\n",
      "current iter: 20673000/24576000\n",
      "current iter: 20674000/24576000\n",
      "current iter: 20675000/24576000\n",
      "current iter: 20676000/24576000\n",
      "current iter: 20677000/24576000\n",
      "current iter: 20678000/24576000\n",
      "current iter: 20679000/24576000\n",
      "current iter: 20680000/24576000\n",
      "current iter: 20681000/24576000\n",
      "current iter: 20682000/24576000\n",
      "current iter: 20683000/24576000\n",
      "current iter: 20684000/24576000\n",
      "current iter: 20685000/24576000\n",
      "current iter: 20686000/24576000\n",
      "current iter: 20687000/24576000\n",
      "current iter: 20688000/24576000\n",
      "current iter: 20689000/24576000\n",
      "current iter: 20690000/24576000\n",
      "current iter: 20691000/24576000\n",
      "current iter: 20692000/24576000\n",
      "current iter: 20693000/24576000\n",
      "current iter: 20694000/24576000\n",
      "current iter: 20695000/24576000\n",
      "current iter: 20696000/24576000\n",
      "current iter: 20697000/24576000\n",
      "current iter: 20698000/24576000\n",
      "current iter: 20699000/24576000\n",
      "current iter: 20700000/24576000\n",
      "current iter: 20701000/24576000\n",
      "current iter: 20702000/24576000\n",
      "current iter: 20703000/24576000\n",
      "current iter: 20704000/24576000\n",
      "current iter: 20705000/24576000\n",
      "current iter: 20706000/24576000\n",
      "current iter: 20707000/24576000\n",
      "current iter: 20708000/24576000\n",
      "current iter: 20709000/24576000\n",
      "current iter: 20710000/24576000\n",
      "current iter: 20711000/24576000\n",
      "current iter: 20712000/24576000\n",
      "current iter: 20713000/24576000\n",
      "current iter: 20714000/24576000\n",
      "current iter: 20715000/24576000\n",
      "current iter: 20716000/24576000\n",
      "current iter: 20717000/24576000\n",
      "current iter: 20718000/24576000\n",
      "current iter: 20719000/24576000\n",
      "current iter: 20720000/24576000\n",
      "current iter: 20721000/24576000\n",
      "current iter: 20722000/24576000\n",
      "current iter: 20723000/24576000\n",
      "current iter: 20724000/24576000\n",
      "current iter: 20725000/24576000\n",
      "current iter: 20726000/24576000\n",
      "current iter: 20727000/24576000\n",
      "current iter: 20728000/24576000\n",
      "current iter: 20729000/24576000\n",
      "current iter: 20730000/24576000\n",
      "current iter: 20731000/24576000\n",
      "current iter: 20732000/24576000\n",
      "current iter: 20733000/24576000\n",
      "current iter: 20734000/24576000\n",
      "current iter: 20735000/24576000\n",
      "current iter: 20736000/24576000\n",
      "current iter: 20737000/24576000\n",
      "current iter: 20738000/24576000\n",
      "current iter: 20739000/24576000\n",
      "current iter: 20740000/24576000\n",
      "current iter: 20741000/24576000\n",
      "current iter: 20742000/24576000\n",
      "current iter: 20743000/24576000\n",
      "current iter: 20744000/24576000\n",
      "current iter: 20745000/24576000\n",
      "current iter: 20746000/24576000\n",
      "current iter: 20747000/24576000\n",
      "current iter: 20748000/24576000\n",
      "current iter: 20749000/24576000\n",
      "current iter: 20750000/24576000\n",
      "current iter: 20751000/24576000\n",
      "current iter: 20752000/24576000\n",
      "current iter: 20753000/24576000\n",
      "current iter: 20754000/24576000\n",
      "current iter: 20755000/24576000\n",
      "current iter: 20756000/24576000\n",
      "current iter: 20757000/24576000\n",
      "current iter: 20758000/24576000\n",
      "current iter: 20759000/24576000\n",
      "current iter: 20760000/24576000\n",
      "current iter: 20761000/24576000\n",
      "current iter: 20762000/24576000\n",
      "current iter: 20763000/24576000\n",
      "current iter: 20764000/24576000\n",
      "current iter: 20765000/24576000\n",
      "current iter: 20766000/24576000\n",
      "current iter: 20767000/24576000\n",
      "current iter: 20768000/24576000\n",
      "current iter: 20769000/24576000\n",
      "current iter: 20770000/24576000\n",
      "current iter: 20771000/24576000\n",
      "current iter: 20772000/24576000\n",
      "current iter: 20773000/24576000\n",
      "current iter: 20774000/24576000\n",
      "current iter: 20775000/24576000\n",
      "current iter: 20776000/24576000\n",
      "current iter: 20777000/24576000\n",
      "current iter: 20778000/24576000\n",
      "current iter: 20779000/24576000\n",
      "current iter: 20780000/24576000\n",
      "current iter: 20781000/24576000\n",
      "current iter: 20782000/24576000\n",
      "current iter: 20783000/24576000\n",
      "current iter: 20784000/24576000\n",
      "current iter: 20785000/24576000\n",
      "current iter: 20786000/24576000\n",
      "current iter: 20787000/24576000\n",
      "current iter: 20788000/24576000\n",
      "current iter: 20789000/24576000\n",
      "current iter: 20790000/24576000\n",
      "current iter: 20791000/24576000\n",
      "current iter: 20792000/24576000\n",
      "current iter: 20793000/24576000\n",
      "current iter: 20794000/24576000\n",
      "current iter: 20795000/24576000\n",
      "current iter: 20796000/24576000\n",
      "current iter: 20797000/24576000\n",
      "current iter: 20798000/24576000\n",
      "current iter: 20799000/24576000\n",
      "current iter: 20800000/24576000\n",
      "current iter: 20801000/24576000\n",
      "current iter: 20802000/24576000\n",
      "current iter: 20803000/24576000\n",
      "current iter: 20804000/24576000\n",
      "current iter: 20805000/24576000\n",
      "current iter: 20806000/24576000\n",
      "current iter: 20807000/24576000\n",
      "current iter: 20808000/24576000\n",
      "current iter: 20809000/24576000\n",
      "current iter: 20810000/24576000\n",
      "current iter: 20811000/24576000\n",
      "current iter: 20812000/24576000\n",
      "current iter: 20813000/24576000\n",
      "current iter: 20814000/24576000\n",
      "current iter: 20815000/24576000\n",
      "current iter: 20816000/24576000\n",
      "current iter: 20817000/24576000\n",
      "current iter: 20818000/24576000\n",
      "current iter: 20819000/24576000\n",
      "current iter: 20820000/24576000\n",
      "current iter: 20821000/24576000\n",
      "current iter: 20822000/24576000\n",
      "current iter: 20823000/24576000\n",
      "current iter: 20824000/24576000\n",
      "current iter: 20825000/24576000\n",
      "current iter: 20826000/24576000\n",
      "current iter: 20827000/24576000\n",
      "current iter: 20828000/24576000\n",
      "current iter: 20829000/24576000\n",
      "current iter: 20830000/24576000\n",
      "current iter: 20831000/24576000\n",
      "current iter: 20832000/24576000\n",
      "current iter: 20833000/24576000\n",
      "current iter: 20834000/24576000\n",
      "current iter: 20835000/24576000\n",
      "current iter: 20836000/24576000\n",
      "current iter: 20837000/24576000\n",
      "current iter: 20838000/24576000\n",
      "current iter: 20839000/24576000\n",
      "current iter: 20840000/24576000\n",
      "current iter: 20841000/24576000\n",
      "current iter: 20842000/24576000\n",
      "current iter: 20843000/24576000\n",
      "current iter: 20844000/24576000\n",
      "current iter: 20845000/24576000\n",
      "current iter: 20846000/24576000\n",
      "current iter: 20847000/24576000\n",
      "current iter: 20848000/24576000\n",
      "current iter: 20849000/24576000\n",
      "current iter: 20850000/24576000\n",
      "current iter: 20851000/24576000\n",
      "current iter: 20852000/24576000\n",
      "current iter: 20853000/24576000\n",
      "current iter: 20854000/24576000\n",
      "current iter: 20855000/24576000\n",
      "current iter: 20856000/24576000\n",
      "current iter: 20857000/24576000\n",
      "current iter: 20858000/24576000\n",
      "current iter: 20859000/24576000\n",
      "current iter: 20860000/24576000\n",
      "current iter: 20861000/24576000\n",
      "current iter: 20862000/24576000\n",
      "current iter: 20863000/24576000\n",
      "current iter: 20864000/24576000\n",
      "current iter: 20865000/24576000\n",
      "current iter: 20866000/24576000\n",
      "current iter: 20867000/24576000\n",
      "current iter: 20868000/24576000\n",
      "current iter: 20869000/24576000\n",
      "current iter: 20870000/24576000\n",
      "current iter: 20871000/24576000\n",
      "current iter: 20872000/24576000\n",
      "current iter: 20873000/24576000\n",
      "current iter: 20874000/24576000\n",
      "current iter: 20875000/24576000\n",
      "current iter: 20876000/24576000\n",
      "current iter: 20877000/24576000\n",
      "current iter: 20878000/24576000\n",
      "current iter: 20879000/24576000\n",
      "current iter: 20880000/24576000\n",
      "current iter: 20881000/24576000\n",
      "current iter: 20882000/24576000\n",
      "current iter: 20883000/24576000\n",
      "current iter: 20884000/24576000\n",
      "current iter: 20885000/24576000\n",
      "current iter: 20886000/24576000\n",
      "current iter: 20887000/24576000\n",
      "current iter: 20888000/24576000\n",
      "current iter: 20889000/24576000\n",
      "current iter: 20890000/24576000\n",
      "current iter: 20891000/24576000\n",
      "current iter: 20892000/24576000\n",
      "current iter: 20893000/24576000\n",
      "current iter: 20894000/24576000\n",
      "current iter: 20895000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 20896000/24576000\n",
      "current iter: 20897000/24576000\n",
      "current iter: 20898000/24576000\n",
      "current iter: 20899000/24576000\n",
      "current iter: 20900000/24576000\n",
      "current iter: 20901000/24576000\n",
      "current iter: 20902000/24576000\n",
      "current iter: 20903000/24576000\n",
      "current iter: 20904000/24576000\n",
      "current iter: 20905000/24576000\n",
      "current iter: 20906000/24576000\n",
      "current iter: 20907000/24576000\n",
      "current iter: 20908000/24576000\n",
      "current iter: 20909000/24576000\n",
      "current iter: 20910000/24576000\n",
      "current iter: 20911000/24576000\n",
      "current iter: 20912000/24576000\n",
      "current iter: 20913000/24576000\n",
      "current iter: 20914000/24576000\n",
      "current iter: 20915000/24576000\n",
      "current iter: 20916000/24576000\n",
      "current iter: 20917000/24576000\n",
      "current iter: 20918000/24576000\n",
      "current iter: 20919000/24576000\n",
      "current iter: 20920000/24576000\n",
      "current iter: 20921000/24576000\n",
      "current iter: 20922000/24576000\n",
      "current iter: 20923000/24576000\n",
      "current iter: 20924000/24576000\n",
      "current iter: 20925000/24576000\n",
      "current iter: 20926000/24576000\n",
      "current iter: 20927000/24576000\n",
      "current iter: 20928000/24576000\n",
      "current iter: 20929000/24576000\n",
      "current iter: 20930000/24576000\n",
      "current iter: 20931000/24576000\n",
      "current iter: 20932000/24576000\n",
      "current iter: 20933000/24576000\n",
      "current iter: 20934000/24576000\n",
      "current iter: 20935000/24576000\n",
      "current iter: 20936000/24576000\n",
      "current iter: 20937000/24576000\n",
      "current iter: 20938000/24576000\n",
      "current iter: 20939000/24576000\n",
      "current iter: 20940000/24576000\n",
      "current iter: 20941000/24576000\n",
      "current iter: 20942000/24576000\n",
      "current iter: 20943000/24576000\n",
      "current iter: 20944000/24576000\n",
      "current iter: 20945000/24576000\n",
      "current iter: 20946000/24576000\n",
      "current iter: 20947000/24576000\n",
      "current iter: 20948000/24576000\n",
      "current iter: 20949000/24576000\n",
      "current iter: 20950000/24576000\n",
      "current iter: 20951000/24576000\n",
      "current iter: 20952000/24576000\n",
      "current iter: 20953000/24576000\n",
      "current iter: 20954000/24576000\n",
      "current iter: 20955000/24576000\n",
      "current iter: 20956000/24576000\n",
      "current iter: 20957000/24576000\n",
      "current iter: 20958000/24576000\n",
      "current iter: 20959000/24576000\n",
      "current iter: 20960000/24576000\n",
      "current iter: 20961000/24576000\n",
      "current iter: 20962000/24576000\n",
      "current iter: 20963000/24576000\n",
      "current iter: 20964000/24576000\n",
      "current iter: 20965000/24576000\n",
      "current iter: 20966000/24576000\n",
      "current iter: 20967000/24576000\n",
      "current iter: 20968000/24576000\n",
      "current iter: 20969000/24576000\n",
      "current iter: 20970000/24576000\n",
      "current iter: 20971000/24576000\n",
      "current iter: 20972000/24576000\n",
      "current iter: 20973000/24576000\n",
      "current iter: 20974000/24576000\n",
      "current iter: 20975000/24576000\n",
      "current iter: 20976000/24576000\n",
      "current iter: 20977000/24576000\n",
      "current iter: 20978000/24576000\n",
      "current iter: 20979000/24576000\n",
      "current iter: 20980000/24576000\n",
      "current iter: 20981000/24576000\n",
      "current iter: 20982000/24576000\n",
      "current iter: 20983000/24576000\n",
      "current iter: 20984000/24576000\n",
      "current iter: 20985000/24576000\n",
      "current iter: 20986000/24576000\n",
      "current iter: 20987000/24576000\n",
      "current iter: 20988000/24576000\n",
      "current iter: 20989000/24576000\n",
      "current iter: 20990000/24576000\n",
      "current iter: 20991000/24576000\n",
      "current iter: 20992000/24576000\n",
      "current iter: 20993000/24576000\n",
      "current iter: 20994000/24576000\n",
      "current iter: 20995000/24576000\n",
      "current iter: 20996000/24576000\n",
      "current iter: 20997000/24576000\n",
      "current iter: 20998000/24576000\n",
      "current iter: 20999000/24576000\n",
      "current iter: 21000000/24576000\n",
      "current iter: 21001000/24576000\n",
      "current iter: 21002000/24576000\n",
      "current iter: 21003000/24576000\n",
      "current iter: 21004000/24576000\n",
      "current iter: 21005000/24576000\n",
      "current iter: 21006000/24576000\n",
      "current iter: 21007000/24576000\n",
      "current iter: 21008000/24576000\n",
      "current iter: 21009000/24576000\n",
      "current iter: 21010000/24576000\n",
      "current iter: 21011000/24576000\n",
      "current iter: 21012000/24576000\n",
      "current iter: 21013000/24576000\n",
      "current iter: 21014000/24576000\n",
      "current iter: 21015000/24576000\n",
      "current iter: 21016000/24576000\n",
      "current iter: 21017000/24576000\n",
      "current iter: 21018000/24576000\n",
      "current iter: 21019000/24576000\n",
      "current iter: 21020000/24576000\n",
      "current iter: 21021000/24576000\n",
      "current iter: 21022000/24576000\n",
      "current iter: 21023000/24576000\n",
      "current iter: 21024000/24576000\n",
      "current iter: 21025000/24576000\n",
      "current iter: 21026000/24576000\n",
      "current iter: 21027000/24576000\n",
      "current iter: 21028000/24576000\n",
      "current iter: 21029000/24576000\n",
      "current iter: 21030000/24576000\n",
      "current iter: 21031000/24576000\n",
      "current iter: 21032000/24576000\n",
      "current iter: 21033000/24576000\n",
      "current iter: 21034000/24576000\n",
      "current iter: 21035000/24576000\n",
      "current iter: 21036000/24576000\n",
      "current iter: 21037000/24576000\n",
      "current iter: 21038000/24576000\n",
      "current iter: 21039000/24576000\n",
      "current iter: 21040000/24576000\n",
      "current iter: 21041000/24576000\n",
      "current iter: 21042000/24576000\n",
      "current iter: 21043000/24576000\n",
      "current iter: 21044000/24576000\n",
      "current iter: 21045000/24576000\n",
      "current iter: 21046000/24576000\n",
      "current iter: 21047000/24576000\n",
      "current iter: 21048000/24576000\n",
      "current iter: 21049000/24576000\n",
      "current iter: 21050000/24576000\n",
      "current iter: 21051000/24576000\n",
      "current iter: 21052000/24576000\n",
      "current iter: 21053000/24576000\n",
      "current iter: 21054000/24576000\n",
      "current iter: 21055000/24576000\n",
      "current iter: 21056000/24576000\n",
      "current iter: 21057000/24576000\n",
      "current iter: 21058000/24576000\n",
      "current iter: 21059000/24576000\n",
      "current iter: 21060000/24576000\n",
      "current iter: 21061000/24576000\n",
      "current iter: 21062000/24576000\n",
      "current iter: 21063000/24576000\n",
      "current iter: 21064000/24576000\n",
      "current iter: 21065000/24576000\n",
      "current iter: 21066000/24576000\n",
      "current iter: 21067000/24576000\n",
      "current iter: 21068000/24576000\n",
      "current iter: 21069000/24576000\n",
      "current iter: 21070000/24576000\n",
      "current iter: 21071000/24576000\n",
      "current iter: 21072000/24576000\n",
      "current iter: 21073000/24576000\n",
      "current iter: 21074000/24576000\n",
      "current iter: 21075000/24576000\n",
      "current iter: 21076000/24576000\n",
      "current iter: 21077000/24576000\n",
      "current iter: 21078000/24576000\n",
      "current iter: 21079000/24576000\n",
      "current iter: 21080000/24576000\n",
      "current iter: 21081000/24576000\n",
      "current iter: 21082000/24576000\n",
      "current iter: 21083000/24576000\n",
      "current iter: 21084000/24576000\n",
      "current iter: 21085000/24576000\n",
      "current iter: 21086000/24576000\n",
      "current iter: 21087000/24576000\n",
      "current iter: 21088000/24576000\n",
      "current iter: 21089000/24576000\n",
      "current iter: 21090000/24576000\n",
      "current iter: 21091000/24576000\n",
      "current iter: 21092000/24576000\n",
      "current iter: 21093000/24576000\n",
      "current iter: 21094000/24576000\n",
      "current iter: 21095000/24576000\n",
      "current iter: 21096000/24576000\n",
      "current iter: 21097000/24576000\n",
      "current iter: 21098000/24576000\n",
      "current iter: 21099000/24576000\n",
      "current iter: 21100000/24576000\n",
      "current iter: 21101000/24576000\n",
      "current iter: 21102000/24576000\n",
      "current iter: 21103000/24576000\n",
      "current iter: 21104000/24576000\n",
      "current iter: 21105000/24576000\n",
      "current iter: 21106000/24576000\n",
      "current iter: 21107000/24576000\n",
      "current iter: 21108000/24576000\n",
      "current iter: 21109000/24576000\n",
      "current iter: 21110000/24576000\n",
      "current iter: 21111000/24576000\n",
      "current iter: 21112000/24576000\n",
      "current iter: 21113000/24576000\n",
      "current iter: 21114000/24576000\n",
      "current iter: 21115000/24576000\n",
      "current iter: 21116000/24576000\n",
      "current iter: 21117000/24576000\n",
      "current iter: 21118000/24576000\n",
      "current iter: 21119000/24576000\n",
      "current iter: 21120000/24576000\n",
      "current iter: 21121000/24576000\n",
      "current iter: 21122000/24576000\n",
      "current iter: 21123000/24576000\n",
      "current iter: 21124000/24576000\n",
      "current iter: 21125000/24576000\n",
      "current iter: 21126000/24576000\n",
      "current iter: 21127000/24576000\n",
      "current iter: 21128000/24576000\n",
      "current iter: 21129000/24576000\n",
      "current iter: 21130000/24576000\n",
      "current iter: 21131000/24576000\n",
      "current iter: 21132000/24576000\n",
      "current iter: 21133000/24576000\n",
      "current iter: 21134000/24576000\n",
      "current iter: 21135000/24576000\n",
      "current iter: 21136000/24576000\n",
      "current iter: 21137000/24576000\n",
      "current iter: 21138000/24576000\n",
      "current iter: 21139000/24576000\n",
      "current iter: 21140000/24576000\n",
      "current iter: 21141000/24576000\n",
      "current iter: 21142000/24576000\n",
      "current iter: 21143000/24576000\n",
      "current iter: 21144000/24576000\n",
      "current iter: 21145000/24576000\n",
      "current iter: 21146000/24576000\n",
      "current iter: 21147000/24576000\n",
      "current iter: 21148000/24576000\n",
      "current iter: 21149000/24576000\n",
      "current iter: 21150000/24576000\n",
      "current iter: 21151000/24576000\n",
      "current iter: 21152000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 21153000/24576000\n",
      "current iter: 21154000/24576000\n",
      "current iter: 21155000/24576000\n",
      "current iter: 21156000/24576000\n",
      "current iter: 21157000/24576000\n",
      "current iter: 21158000/24576000\n",
      "current iter: 21159000/24576000\n",
      "current iter: 21160000/24576000\n",
      "current iter: 21161000/24576000\n",
      "current iter: 21162000/24576000\n",
      "current iter: 21163000/24576000\n",
      "current iter: 21164000/24576000\n",
      "current iter: 21165000/24576000\n",
      "current iter: 21166000/24576000\n",
      "current iter: 21167000/24576000\n",
      "current iter: 21168000/24576000\n",
      "current iter: 21169000/24576000\n",
      "current iter: 21170000/24576000\n",
      "current iter: 21171000/24576000\n",
      "current iter: 21172000/24576000\n",
      "current iter: 21173000/24576000\n",
      "current iter: 21174000/24576000\n",
      "current iter: 21175000/24576000\n",
      "current iter: 21176000/24576000\n",
      "current iter: 21177000/24576000\n",
      "current iter: 21178000/24576000\n",
      "current iter: 21179000/24576000\n",
      "current iter: 21180000/24576000\n",
      "current iter: 21181000/24576000\n",
      "current iter: 21182000/24576000\n",
      "current iter: 21183000/24576000\n",
      "current iter: 21184000/24576000\n",
      "current iter: 21185000/24576000\n",
      "current iter: 21186000/24576000\n",
      "current iter: 21187000/24576000\n",
      "current iter: 21188000/24576000\n",
      "current iter: 21189000/24576000\n",
      "current iter: 21190000/24576000\n",
      "current iter: 21191000/24576000\n",
      "current iter: 21192000/24576000\n",
      "current iter: 21193000/24576000\n",
      "current iter: 21194000/24576000\n",
      "current iter: 21195000/24576000\n",
      "current iter: 21196000/24576000\n",
      "current iter: 21197000/24576000\n",
      "current iter: 21198000/24576000\n",
      "current iter: 21199000/24576000\n",
      "current iter: 21200000/24576000\n",
      "current iter: 21201000/24576000\n",
      "current iter: 21202000/24576000\n",
      "current iter: 21203000/24576000\n",
      "current iter: 21204000/24576000\n",
      "current iter: 21205000/24576000\n",
      "current iter: 21206000/24576000\n",
      "current iter: 21207000/24576000\n",
      "current iter: 21208000/24576000\n",
      "current iter: 21209000/24576000\n",
      "current iter: 21210000/24576000\n",
      "current iter: 21211000/24576000\n",
      "current iter: 21212000/24576000\n",
      "current iter: 21213000/24576000\n",
      "current iter: 21214000/24576000\n",
      "current iter: 21215000/24576000\n",
      "current iter: 21216000/24576000\n",
      "current iter: 21217000/24576000\n",
      "current iter: 21218000/24576000\n",
      "current iter: 21219000/24576000\n",
      "current iter: 21220000/24576000\n",
      "current iter: 21221000/24576000\n",
      "current iter: 21222000/24576000\n",
      "current iter: 21223000/24576000\n",
      "current iter: 21224000/24576000\n",
      "current iter: 21225000/24576000\n",
      "current iter: 21226000/24576000\n",
      "current iter: 21227000/24576000\n",
      "current iter: 21228000/24576000\n",
      "current iter: 21229000/24576000\n",
      "current iter: 21230000/24576000\n",
      "current iter: 21231000/24576000\n",
      "current iter: 21232000/24576000\n",
      "current iter: 21233000/24576000\n",
      "current iter: 21234000/24576000\n",
      "current iter: 21235000/24576000\n",
      "current iter: 21236000/24576000\n",
      "current iter: 21237000/24576000\n",
      "current iter: 21238000/24576000\n",
      "current iter: 21239000/24576000\n",
      "current iter: 21240000/24576000\n",
      "current iter: 21241000/24576000\n",
      "current iter: 21242000/24576000\n",
      "current iter: 21243000/24576000\n",
      "current iter: 21244000/24576000\n",
      "current iter: 21245000/24576000\n",
      "current iter: 21246000/24576000\n",
      "current iter: 21247000/24576000\n",
      "current iter: 21248000/24576000\n",
      "current iter: 21249000/24576000\n",
      "current iter: 21250000/24576000\n",
      "current iter: 21251000/24576000\n",
      "current iter: 21252000/24576000\n",
      "current iter: 21253000/24576000\n",
      "current iter: 21254000/24576000\n",
      "current iter: 21255000/24576000\n",
      "current iter: 21256000/24576000\n",
      "current iter: 21257000/24576000\n",
      "current iter: 21258000/24576000\n",
      "current iter: 21259000/24576000\n",
      "current iter: 21260000/24576000\n",
      "current iter: 21261000/24576000\n",
      "current iter: 21262000/24576000\n",
      "current iter: 21263000/24576000\n",
      "current iter: 21264000/24576000\n",
      "current iter: 21265000/24576000\n",
      "current iter: 21266000/24576000\n",
      "current iter: 21267000/24576000\n",
      "current iter: 21268000/24576000\n",
      "current iter: 21269000/24576000\n",
      "current iter: 21270000/24576000\n",
      "current iter: 21271000/24576000\n",
      "current iter: 21272000/24576000\n",
      "current iter: 21273000/24576000\n",
      "current iter: 21274000/24576000\n",
      "current iter: 21275000/24576000\n",
      "current iter: 21276000/24576000\n",
      "current iter: 21277000/24576000\n",
      "current iter: 21278000/24576000\n",
      "current iter: 21279000/24576000\n",
      "current iter: 21280000/24576000\n",
      "current iter: 21281000/24576000\n",
      "current iter: 21282000/24576000\n",
      "current iter: 21283000/24576000\n",
      "current iter: 21284000/24576000\n",
      "current iter: 21285000/24576000\n",
      "current iter: 21286000/24576000\n",
      "current iter: 21287000/24576000\n",
      "current iter: 21288000/24576000\n",
      "current iter: 21289000/24576000\n",
      "current iter: 21290000/24576000\n",
      "current iter: 21291000/24576000\n",
      "current iter: 21292000/24576000\n",
      "current iter: 21293000/24576000\n",
      "current iter: 21294000/24576000\n",
      "current iter: 21295000/24576000\n",
      "current iter: 21296000/24576000\n",
      "current iter: 21297000/24576000\n",
      "current iter: 21298000/24576000\n",
      "current iter: 21299000/24576000\n",
      "current iter: 21300000/24576000\n",
      "current iter: 21301000/24576000\n",
      "current iter: 21302000/24576000\n",
      "current iter: 21303000/24576000\n",
      "current iter: 21304000/24576000\n",
      "current iter: 21305000/24576000\n",
      "current iter: 21306000/24576000\n",
      "current iter: 21307000/24576000\n",
      "current iter: 21308000/24576000\n",
      "current iter: 21309000/24576000\n",
      "current iter: 21310000/24576000\n",
      "current iter: 21311000/24576000\n",
      "current iter: 21312000/24576000\n",
      "current iter: 21313000/24576000\n",
      "current iter: 21314000/24576000\n",
      "current iter: 21315000/24576000\n",
      "current iter: 21316000/24576000\n",
      "current iter: 21317000/24576000\n",
      "current iter: 21318000/24576000\n",
      "current iter: 21319000/24576000\n",
      "current iter: 21320000/24576000\n",
      "current iter: 21321000/24576000\n",
      "current iter: 21322000/24576000\n",
      "current iter: 21323000/24576000\n",
      "current iter: 21324000/24576000\n",
      "current iter: 21325000/24576000\n",
      "current iter: 21326000/24576000\n",
      "current iter: 21327000/24576000\n",
      "current iter: 21328000/24576000\n",
      "current iter: 21329000/24576000\n",
      "current iter: 21330000/24576000\n",
      "current iter: 21331000/24576000\n",
      "current iter: 21332000/24576000\n",
      "current iter: 21333000/24576000\n",
      "current iter: 21334000/24576000\n",
      "current iter: 21335000/24576000\n",
      "current iter: 21336000/24576000\n",
      "current iter: 21337000/24576000\n",
      "current iter: 21338000/24576000\n",
      "current iter: 21339000/24576000\n",
      "current iter: 21340000/24576000\n",
      "current iter: 21341000/24576000\n",
      "current iter: 21342000/24576000\n",
      "current iter: 21343000/24576000\n",
      "current iter: 21344000/24576000\n",
      "current iter: 21345000/24576000\n",
      "current iter: 21346000/24576000\n",
      "current iter: 21347000/24576000\n",
      "current iter: 21348000/24576000\n",
      "current iter: 21349000/24576000\n",
      "current iter: 21350000/24576000\n",
      "current iter: 21351000/24576000\n",
      "current iter: 21352000/24576000\n",
      "current iter: 21353000/24576000\n",
      "current iter: 21354000/24576000\n",
      "current iter: 21355000/24576000\n",
      "current iter: 21356000/24576000\n",
      "current iter: 21357000/24576000\n",
      "current iter: 21358000/24576000\n",
      "current iter: 21359000/24576000\n",
      "current iter: 21360000/24576000\n",
      "current iter: 21361000/24576000\n",
      "current iter: 21362000/24576000\n",
      "current iter: 21363000/24576000\n",
      "current iter: 21364000/24576000\n",
      "current iter: 21365000/24576000\n",
      "current iter: 21366000/24576000\n",
      "current iter: 21367000/24576000\n",
      "current iter: 21368000/24576000\n",
      "current iter: 21369000/24576000\n",
      "current iter: 21370000/24576000\n",
      "current iter: 21371000/24576000\n",
      "current iter: 21372000/24576000\n",
      "current iter: 21373000/24576000\n",
      "current iter: 21374000/24576000\n",
      "current iter: 21375000/24576000\n",
      "current iter: 21376000/24576000\n",
      "current iter: 21377000/24576000\n",
      "current iter: 21378000/24576000\n",
      "current iter: 21379000/24576000\n",
      "current iter: 21380000/24576000\n",
      "current iter: 21381000/24576000\n",
      "current iter: 21382000/24576000\n",
      "current iter: 21383000/24576000\n",
      "current iter: 21384000/24576000\n",
      "current iter: 21385000/24576000\n",
      "current iter: 21386000/24576000\n",
      "current iter: 21387000/24576000\n",
      "current iter: 21388000/24576000\n",
      "current iter: 21389000/24576000\n",
      "current iter: 21390000/24576000\n",
      "current iter: 21391000/24576000\n",
      "current iter: 21392000/24576000\n",
      "current iter: 21393000/24576000\n",
      "current iter: 21394000/24576000\n",
      "current iter: 21395000/24576000\n",
      "current iter: 21396000/24576000\n",
      "current iter: 21397000/24576000\n",
      "current iter: 21398000/24576000\n",
      "current iter: 21399000/24576000\n",
      "current iter: 21400000/24576000\n",
      "current iter: 21401000/24576000\n",
      "current iter: 21402000/24576000\n",
      "current iter: 21403000/24576000\n",
      "current iter: 21404000/24576000\n",
      "current iter: 21405000/24576000\n",
      "current iter: 21406000/24576000\n",
      "current iter: 21407000/24576000\n",
      "current iter: 21408000/24576000\n",
      "current iter: 21409000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 21410000/24576000\n",
      "current iter: 21411000/24576000\n",
      "current iter: 21412000/24576000\n",
      "current iter: 21413000/24576000\n",
      "current iter: 21414000/24576000\n",
      "current iter: 21415000/24576000\n",
      "current iter: 21416000/24576000\n",
      "current iter: 21417000/24576000\n",
      "current iter: 21418000/24576000\n",
      "current iter: 21419000/24576000\n",
      "current iter: 21420000/24576000\n",
      "current iter: 21421000/24576000\n",
      "current iter: 21422000/24576000\n",
      "current iter: 21423000/24576000\n",
      "current iter: 21424000/24576000\n",
      "current iter: 21425000/24576000\n",
      "current iter: 21426000/24576000\n",
      "current iter: 21427000/24576000\n",
      "current iter: 21428000/24576000\n",
      "current iter: 21429000/24576000\n",
      "current iter: 21430000/24576000\n",
      "current iter: 21431000/24576000\n",
      "current iter: 21432000/24576000\n",
      "current iter: 21433000/24576000\n",
      "current iter: 21434000/24576000\n",
      "current iter: 21435000/24576000\n",
      "current iter: 21436000/24576000\n",
      "current iter: 21437000/24576000\n",
      "current iter: 21438000/24576000\n",
      "current iter: 21439000/24576000\n",
      "current iter: 21440000/24576000\n",
      "current iter: 21441000/24576000\n",
      "current iter: 21442000/24576000\n",
      "current iter: 21443000/24576000\n",
      "current iter: 21444000/24576000\n",
      "current iter: 21445000/24576000\n",
      "current iter: 21446000/24576000\n",
      "current iter: 21447000/24576000\n",
      "current iter: 21448000/24576000\n",
      "current iter: 21449000/24576000\n",
      "current iter: 21450000/24576000\n",
      "current iter: 21451000/24576000\n",
      "current iter: 21452000/24576000\n",
      "current iter: 21453000/24576000\n",
      "current iter: 21454000/24576000\n",
      "current iter: 21455000/24576000\n",
      "current iter: 21456000/24576000\n",
      "current iter: 21457000/24576000\n",
      "current iter: 21458000/24576000\n",
      "current iter: 21459000/24576000\n",
      "current iter: 21460000/24576000\n",
      "current iter: 21461000/24576000\n",
      "current iter: 21462000/24576000\n",
      "current iter: 21463000/24576000\n",
      "current iter: 21464000/24576000\n",
      "current iter: 21465000/24576000\n",
      "current iter: 21466000/24576000\n",
      "current iter: 21467000/24576000\n",
      "current iter: 21468000/24576000\n",
      "current iter: 21469000/24576000\n",
      "current iter: 21470000/24576000\n",
      "current iter: 21471000/24576000\n",
      "current iter: 21472000/24576000\n",
      "current iter: 21473000/24576000\n",
      "current iter: 21474000/24576000\n",
      "current iter: 21475000/24576000\n",
      "current iter: 21476000/24576000\n",
      "current iter: 21477000/24576000\n",
      "current iter: 21478000/24576000\n",
      "current iter: 21479000/24576000\n",
      "current iter: 21480000/24576000\n",
      "current iter: 21481000/24576000\n",
      "current iter: 21482000/24576000\n",
      "current iter: 21483000/24576000\n",
      "current iter: 21484000/24576000\n",
      "current iter: 21485000/24576000\n",
      "current iter: 21486000/24576000\n",
      "current iter: 21487000/24576000\n",
      "current iter: 21488000/24576000\n",
      "current iter: 21489000/24576000\n",
      "current iter: 21490000/24576000\n",
      "current iter: 21491000/24576000\n",
      "current iter: 21492000/24576000\n",
      "current iter: 21493000/24576000\n",
      "current iter: 21494000/24576000\n",
      "current iter: 21495000/24576000\n",
      "current iter: 21496000/24576000\n",
      "current iter: 21497000/24576000\n",
      "current iter: 21498000/24576000\n",
      "current iter: 21499000/24576000\n",
      "current iter: 21500000/24576000\n",
      "current iter: 21501000/24576000\n",
      "current iter: 21502000/24576000\n",
      "current iter: 21503000/24576000\n",
      "current iter: 21504000/24576000\n",
      "current iter: 21505000/24576000\n",
      "current iter: 21506000/24576000\n",
      "current iter: 21507000/24576000\n",
      "current iter: 21508000/24576000\n",
      "current iter: 21509000/24576000\n",
      "current iter: 21510000/24576000\n",
      "current iter: 21511000/24576000\n",
      "current iter: 21512000/24576000\n",
      "current iter: 21513000/24576000\n",
      "current iter: 21514000/24576000\n",
      "current iter: 21515000/24576000\n",
      "current iter: 21516000/24576000\n",
      "current iter: 21517000/24576000\n",
      "current iter: 21518000/24576000\n",
      "current iter: 21519000/24576000\n",
      "current iter: 21520000/24576000\n",
      "current iter: 21521000/24576000\n",
      "current iter: 21522000/24576000\n",
      "current iter: 21523000/24576000\n",
      "current iter: 21524000/24576000\n",
      "current iter: 21525000/24576000\n",
      "current iter: 21526000/24576000\n",
      "current iter: 21527000/24576000\n",
      "current iter: 21528000/24576000\n",
      "current iter: 21529000/24576000\n",
      "current iter: 21530000/24576000\n",
      "current iter: 21531000/24576000\n",
      "current iter: 21532000/24576000\n",
      "current iter: 21533000/24576000\n",
      "current iter: 21534000/24576000\n",
      "current iter: 21535000/24576000\n",
      "current iter: 21536000/24576000\n",
      "current iter: 21537000/24576000\n",
      "current iter: 21538000/24576000\n",
      "current iter: 21539000/24576000\n",
      "current iter: 21540000/24576000\n",
      "current iter: 21541000/24576000\n",
      "current iter: 21542000/24576000\n",
      "current iter: 21543000/24576000\n",
      "current iter: 21544000/24576000\n",
      "current iter: 21545000/24576000\n",
      "current iter: 21546000/24576000\n",
      "current iter: 21547000/24576000\n",
      "current iter: 21548000/24576000\n",
      "current iter: 21549000/24576000\n",
      "current iter: 21550000/24576000\n",
      "current iter: 21551000/24576000\n",
      "current iter: 21552000/24576000\n",
      "current iter: 21553000/24576000\n",
      "current iter: 21554000/24576000\n",
      "current iter: 21555000/24576000\n",
      "current iter: 21556000/24576000\n",
      "current iter: 21557000/24576000\n",
      "current iter: 21558000/24576000\n",
      "current iter: 21559000/24576000\n",
      "current iter: 21560000/24576000\n",
      "current iter: 21561000/24576000\n",
      "current iter: 21562000/24576000\n",
      "current iter: 21563000/24576000\n",
      "current iter: 21564000/24576000\n",
      "current iter: 21565000/24576000\n",
      "current iter: 21566000/24576000\n",
      "current iter: 21567000/24576000\n",
      "current iter: 21568000/24576000\n",
      "current iter: 21569000/24576000\n",
      "current iter: 21570000/24576000\n",
      "current iter: 21571000/24576000\n",
      "current iter: 21572000/24576000\n",
      "current iter: 21573000/24576000\n",
      "current iter: 21574000/24576000\n",
      "current iter: 21575000/24576000\n",
      "current iter: 21576000/24576000\n",
      "current iter: 21577000/24576000\n",
      "current iter: 21578000/24576000\n",
      "current iter: 21579000/24576000\n",
      "current iter: 21580000/24576000\n",
      "current iter: 21581000/24576000\n",
      "current iter: 21582000/24576000\n",
      "current iter: 21583000/24576000\n",
      "current iter: 21584000/24576000\n",
      "current iter: 21585000/24576000\n",
      "current iter: 21586000/24576000\n",
      "current iter: 21587000/24576000\n",
      "current iter: 21588000/24576000\n",
      "current iter: 21589000/24576000\n",
      "current iter: 21590000/24576000\n",
      "current iter: 21591000/24576000\n",
      "current iter: 21592000/24576000\n",
      "current iter: 21593000/24576000\n",
      "current iter: 21594000/24576000\n",
      "current iter: 21595000/24576000\n",
      "current iter: 21596000/24576000\n",
      "current iter: 21597000/24576000\n",
      "current iter: 21598000/24576000\n",
      "current iter: 21599000/24576000\n",
      "current iter: 21600000/24576000\n",
      "current iter: 21601000/24576000\n",
      "current iter: 21602000/24576000\n",
      "current iter: 21603000/24576000\n",
      "current iter: 21604000/24576000\n",
      "current iter: 21605000/24576000\n",
      "current iter: 21606000/24576000\n",
      "current iter: 21607000/24576000\n",
      "current iter: 21608000/24576000\n",
      "current iter: 21609000/24576000\n",
      "current iter: 21610000/24576000\n",
      "current iter: 21611000/24576000\n",
      "current iter: 21612000/24576000\n",
      "current iter: 21613000/24576000\n",
      "current iter: 21614000/24576000\n",
      "current iter: 21615000/24576000\n",
      "current iter: 21616000/24576000\n",
      "current iter: 21617000/24576000\n",
      "current iter: 21618000/24576000\n",
      "current iter: 21619000/24576000\n",
      "current iter: 21620000/24576000\n",
      "current iter: 21621000/24576000\n",
      "current iter: 21622000/24576000\n",
      "current iter: 21623000/24576000\n",
      "current iter: 21624000/24576000\n",
      "current iter: 21625000/24576000\n",
      "current iter: 21626000/24576000\n",
      "current iter: 21627000/24576000\n",
      "current iter: 21628000/24576000\n",
      "current iter: 21629000/24576000\n",
      "current iter: 21630000/24576000\n",
      "current iter: 21631000/24576000\n",
      "current iter: 21632000/24576000\n",
      "current iter: 21633000/24576000\n",
      "current iter: 21634000/24576000\n",
      "current iter: 21635000/24576000\n",
      "current iter: 21636000/24576000\n",
      "current iter: 21637000/24576000\n",
      "current iter: 21638000/24576000\n",
      "current iter: 21639000/24576000\n",
      "current iter: 21640000/24576000\n",
      "current iter: 21641000/24576000\n",
      "current iter: 21642000/24576000\n",
      "current iter: 21643000/24576000\n",
      "current iter: 21644000/24576000\n",
      "current iter: 21645000/24576000\n",
      "current iter: 21646000/24576000\n",
      "current iter: 21647000/24576000\n",
      "current iter: 21648000/24576000\n",
      "current iter: 21649000/24576000\n",
      "current iter: 21650000/24576000\n",
      "current iter: 21651000/24576000\n",
      "current iter: 21652000/24576000\n",
      "current iter: 21653000/24576000\n",
      "current iter: 21654000/24576000\n",
      "current iter: 21655000/24576000\n",
      "current iter: 21656000/24576000\n",
      "current iter: 21657000/24576000\n",
      "current iter: 21658000/24576000\n",
      "current iter: 21659000/24576000\n",
      "current iter: 21660000/24576000\n",
      "current iter: 21661000/24576000\n",
      "current iter: 21662000/24576000\n",
      "current iter: 21663000/24576000\n",
      "current iter: 21664000/24576000\n",
      "current iter: 21665000/24576000\n",
      "current iter: 21666000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 21667000/24576000\n",
      "current iter: 21668000/24576000\n",
      "current iter: 21669000/24576000\n",
      "current iter: 21670000/24576000\n",
      "current iter: 21671000/24576000\n",
      "current iter: 21672000/24576000\n",
      "current iter: 21673000/24576000\n",
      "current iter: 21674000/24576000\n",
      "current iter: 21675000/24576000\n",
      "current iter: 21676000/24576000\n",
      "current iter: 21677000/24576000\n",
      "current iter: 21678000/24576000\n",
      "current iter: 21679000/24576000\n",
      "current iter: 21680000/24576000\n",
      "current iter: 21681000/24576000\n",
      "current iter: 21682000/24576000\n",
      "current iter: 21683000/24576000\n",
      "current iter: 21684000/24576000\n",
      "current iter: 21685000/24576000\n",
      "current iter: 21686000/24576000\n",
      "current iter: 21687000/24576000\n",
      "current iter: 21688000/24576000\n",
      "current iter: 21689000/24576000\n",
      "current iter: 21690000/24576000\n",
      "current iter: 21691000/24576000\n",
      "current iter: 21692000/24576000\n",
      "current iter: 21693000/24576000\n",
      "current iter: 21694000/24576000\n",
      "current iter: 21695000/24576000\n",
      "current iter: 21696000/24576000\n",
      "current iter: 21697000/24576000\n",
      "current iter: 21698000/24576000\n",
      "current iter: 21699000/24576000\n",
      "current iter: 21700000/24576000\n",
      "current iter: 21701000/24576000\n",
      "current iter: 21702000/24576000\n",
      "current iter: 21703000/24576000\n",
      "current iter: 21704000/24576000\n",
      "current iter: 21705000/24576000\n",
      "current iter: 21706000/24576000\n",
      "current iter: 21707000/24576000\n",
      "current iter: 21708000/24576000\n",
      "current iter: 21709000/24576000\n",
      "current iter: 21710000/24576000\n",
      "current iter: 21711000/24576000\n",
      "current iter: 21712000/24576000\n",
      "current iter: 21713000/24576000\n",
      "current iter: 21714000/24576000\n",
      "current iter: 21715000/24576000\n",
      "current iter: 21716000/24576000\n",
      "current iter: 21717000/24576000\n",
      "current iter: 21718000/24576000\n",
      "current iter: 21719000/24576000\n",
      "current iter: 21720000/24576000\n",
      "current iter: 21721000/24576000\n",
      "current iter: 21722000/24576000\n",
      "current iter: 21723000/24576000\n",
      "current iter: 21724000/24576000\n",
      "current iter: 21725000/24576000\n",
      "current iter: 21726000/24576000\n",
      "current iter: 21727000/24576000\n",
      "current iter: 21728000/24576000\n",
      "current iter: 21729000/24576000\n",
      "current iter: 21730000/24576000\n",
      "current iter: 21731000/24576000\n",
      "current iter: 21732000/24576000\n",
      "current iter: 21733000/24576000\n",
      "current iter: 21734000/24576000\n",
      "current iter: 21735000/24576000\n",
      "current iter: 21736000/24576000\n",
      "current iter: 21737000/24576000\n",
      "current iter: 21738000/24576000\n",
      "current iter: 21739000/24576000\n",
      "current iter: 21740000/24576000\n",
      "current iter: 21741000/24576000\n",
      "current iter: 21742000/24576000\n",
      "current iter: 21743000/24576000\n",
      "current iter: 21744000/24576000\n",
      "current iter: 21745000/24576000\n",
      "current iter: 21746000/24576000\n",
      "current iter: 21747000/24576000\n",
      "current iter: 21748000/24576000\n",
      "current iter: 21749000/24576000\n",
      "current iter: 21750000/24576000\n",
      "current iter: 21751000/24576000\n",
      "current iter: 21752000/24576000\n",
      "current iter: 21753000/24576000\n",
      "current iter: 21754000/24576000\n",
      "current iter: 21755000/24576000\n",
      "current iter: 21756000/24576000\n",
      "current iter: 21757000/24576000\n",
      "current iter: 21758000/24576000\n",
      "current iter: 21759000/24576000\n",
      "current iter: 21760000/24576000\n",
      "current iter: 21761000/24576000\n",
      "current iter: 21762000/24576000\n",
      "current iter: 21763000/24576000\n",
      "current iter: 21764000/24576000\n",
      "current iter: 21765000/24576000\n",
      "current iter: 21766000/24576000\n",
      "current iter: 21767000/24576000\n",
      "current iter: 21768000/24576000\n",
      "current iter: 21769000/24576000\n",
      "current iter: 21770000/24576000\n",
      "current iter: 21771000/24576000\n",
      "current iter: 21772000/24576000\n",
      "current iter: 21773000/24576000\n",
      "current iter: 21774000/24576000\n",
      "current iter: 21775000/24576000\n",
      "current iter: 21776000/24576000\n",
      "current iter: 21777000/24576000\n",
      "current iter: 21778000/24576000\n",
      "current iter: 21779000/24576000\n",
      "current iter: 21780000/24576000\n",
      "current iter: 21781000/24576000\n",
      "current iter: 21782000/24576000\n",
      "current iter: 21783000/24576000\n",
      "current iter: 21784000/24576000\n",
      "current iter: 21785000/24576000\n",
      "current iter: 21786000/24576000\n",
      "current iter: 21787000/24576000\n",
      "current iter: 21788000/24576000\n",
      "current iter: 21789000/24576000\n",
      "current iter: 21790000/24576000\n",
      "current iter: 21791000/24576000\n",
      "current iter: 21792000/24576000\n",
      "current iter: 21793000/24576000\n",
      "current iter: 21794000/24576000\n",
      "current iter: 21795000/24576000\n",
      "current iter: 21796000/24576000\n",
      "current iter: 21797000/24576000\n",
      "current iter: 21798000/24576000\n",
      "current iter: 21799000/24576000\n",
      "current iter: 21800000/24576000\n",
      "current iter: 21801000/24576000\n",
      "current iter: 21802000/24576000\n",
      "current iter: 21803000/24576000\n",
      "current iter: 21804000/24576000\n",
      "current iter: 21805000/24576000\n",
      "current iter: 21806000/24576000\n",
      "current iter: 21807000/24576000\n",
      "current iter: 21808000/24576000\n",
      "current iter: 21809000/24576000\n",
      "current iter: 21810000/24576000\n",
      "current iter: 21811000/24576000\n",
      "current iter: 21812000/24576000\n",
      "current iter: 21813000/24576000\n",
      "current iter: 21814000/24576000\n",
      "current iter: 21815000/24576000\n",
      "current iter: 21816000/24576000\n",
      "current iter: 21817000/24576000\n",
      "current iter: 21818000/24576000\n",
      "current iter: 21819000/24576000\n",
      "current iter: 21820000/24576000\n",
      "current iter: 21821000/24576000\n",
      "current iter: 21822000/24576000\n",
      "current iter: 21823000/24576000\n",
      "current iter: 21824000/24576000\n",
      "current iter: 21825000/24576000\n",
      "current iter: 21826000/24576000\n",
      "current iter: 21827000/24576000\n",
      "current iter: 21828000/24576000\n",
      "current iter: 21829000/24576000\n",
      "current iter: 21830000/24576000\n",
      "current iter: 21831000/24576000\n",
      "current iter: 21832000/24576000\n",
      "current iter: 21833000/24576000\n",
      "current iter: 21834000/24576000\n",
      "current iter: 21835000/24576000\n",
      "current iter: 21836000/24576000\n",
      "current iter: 21837000/24576000\n",
      "current iter: 21838000/24576000\n",
      "current iter: 21839000/24576000\n",
      "current iter: 21840000/24576000\n",
      "current iter: 21841000/24576000\n",
      "current iter: 21842000/24576000\n",
      "current iter: 21843000/24576000\n",
      "current iter: 21844000/24576000\n",
      "current iter: 21845000/24576000\n",
      "current iter: 21846000/24576000\n",
      "current iter: 21847000/24576000\n",
      "current iter: 21848000/24576000\n",
      "current iter: 21849000/24576000\n",
      "current iter: 21850000/24576000\n",
      "current iter: 21851000/24576000\n",
      "current iter: 21852000/24576000\n",
      "current iter: 21853000/24576000\n",
      "current iter: 21854000/24576000\n",
      "current iter: 21855000/24576000\n",
      "current iter: 21856000/24576000\n",
      "current iter: 21857000/24576000\n",
      "current iter: 21858000/24576000\n",
      "current iter: 21859000/24576000\n",
      "current iter: 21860000/24576000\n",
      "current iter: 21861000/24576000\n",
      "current iter: 21862000/24576000\n",
      "current iter: 21863000/24576000\n",
      "current iter: 21864000/24576000\n",
      "current iter: 21865000/24576000\n",
      "current iter: 21866000/24576000\n",
      "current iter: 21867000/24576000\n",
      "current iter: 21868000/24576000\n",
      "current iter: 21869000/24576000\n",
      "current iter: 21870000/24576000\n",
      "current iter: 21871000/24576000\n",
      "current iter: 21872000/24576000\n",
      "current iter: 21873000/24576000\n",
      "current iter: 21874000/24576000\n",
      "current iter: 21875000/24576000\n",
      "current iter: 21876000/24576000\n",
      "current iter: 21877000/24576000\n",
      "current iter: 21878000/24576000\n",
      "current iter: 21879000/24576000\n",
      "current iter: 21880000/24576000\n",
      "current iter: 21881000/24576000\n",
      "current iter: 21882000/24576000\n",
      "current iter: 21883000/24576000\n",
      "current iter: 21884000/24576000\n",
      "current iter: 21885000/24576000\n",
      "current iter: 21886000/24576000\n",
      "current iter: 21887000/24576000\n",
      "current iter: 21888000/24576000\n",
      "current iter: 21889000/24576000\n",
      "current iter: 21890000/24576000\n",
      "current iter: 21891000/24576000\n",
      "current iter: 21892000/24576000\n",
      "current iter: 21893000/24576000\n",
      "current iter: 21894000/24576000\n",
      "current iter: 21895000/24576000\n",
      "current iter: 21896000/24576000\n",
      "current iter: 21897000/24576000\n",
      "current iter: 21898000/24576000\n",
      "current iter: 21899000/24576000\n",
      "current iter: 21900000/24576000\n",
      "current iter: 21901000/24576000\n",
      "current iter: 21902000/24576000\n",
      "current iter: 21903000/24576000\n",
      "current iter: 21904000/24576000\n",
      "current iter: 21905000/24576000\n",
      "current iter: 21906000/24576000\n",
      "current iter: 21907000/24576000\n",
      "current iter: 21908000/24576000\n",
      "current iter: 21909000/24576000\n",
      "current iter: 21910000/24576000\n",
      "current iter: 21911000/24576000\n",
      "current iter: 21912000/24576000\n",
      "current iter: 21913000/24576000\n",
      "current iter: 21914000/24576000\n",
      "current iter: 21915000/24576000\n",
      "current iter: 21916000/24576000\n",
      "current iter: 21917000/24576000\n",
      "current iter: 21918000/24576000\n",
      "current iter: 21919000/24576000\n",
      "current iter: 21920000/24576000\n",
      "current iter: 21921000/24576000\n",
      "current iter: 21922000/24576000\n",
      "current iter: 21923000/24576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current iter: 21924000/24576000\n",
      "current iter: 21925000/24576000\n",
      "current iter: 21926000/24576000\n",
      "current iter: 21927000/24576000\n",
      "current iter: 21928000/24576000\n",
      "current iter: 21929000/24576000\n",
      "current iter: 21930000/24576000\n",
      "current iter: 21931000/24576000\n",
      "current iter: 21932000/24576000\n",
      "current iter: 21933000/24576000\n",
      "current iter: 21934000/24576000\n",
      "current iter: 21935000/24576000\n",
      "current iter: 21936000/24576000\n",
      "current iter: 21937000/24576000\n",
      "current iter: 21938000/24576000\n",
      "current iter: 21939000/24576000\n",
      "current iter: 21940000/24576000\n",
      "current iter: 21941000/24576000\n",
      "current iter: 21942000/24576000\n",
      "current iter: 21943000/24576000\n",
      "current iter: 21944000/24576000\n",
      "current iter: 21945000/24576000\n",
      "current iter: 21946000/24576000\n",
      "current iter: 21947000/24576000\n",
      "current iter: 21948000/24576000\n",
      "current iter: 21949000/24576000\n",
      "current iter: 21950000/24576000\n",
      "current iter: 21951000/24576000\n",
      "current iter: 21952000/24576000\n",
      "current iter: 21953000/24576000\n",
      "current iter: 21954000/24576000\n",
      "current iter: 21955000/24576000\n",
      "current iter: 21956000/24576000\n",
      "current iter: 21957000/24576000\n",
      "current iter: 21958000/24576000\n",
      "current iter: 21959000/24576000\n",
      "current iter: 21960000/24576000\n",
      "current iter: 21961000/24576000\n",
      "current iter: 21962000/24576000\n",
      "current iter: 21963000/24576000\n",
      "current iter: 21964000/24576000\n",
      "current iter: 21965000/24576000\n",
      "current iter: 21966000/24576000\n",
      "current iter: 21967000/24576000\n",
      "current iter: 21968000/24576000\n",
      "current iter: 21969000/24576000\n",
      "current iter: 21970000/24576000\n",
      "current iter: 21971000/24576000\n",
      "current iter: 21972000/24576000\n",
      "current iter: 21973000/24576000\n",
      "current iter: 21974000/24576000\n",
      "current iter: 21975000/24576000\n",
      "current iter: 21976000/24576000\n",
      "current iter: 21977000/24576000\n",
      "current iter: 21978000/24576000\n",
      "current iter: 21979000/24576000\n",
      "current iter: 21980000/24576000\n",
      "current iter: 21981000/24576000\n",
      "current iter: 21982000/24576000\n",
      "current iter: 21983000/24576000\n",
      "current iter: 21984000/24576000\n",
      "current iter: 21985000/24576000\n",
      "current iter: 21986000/24576000\n",
      "current iter: 21987000/24576000\n",
      "current iter: 21988000/24576000\n",
      "current iter: 21989000/24576000\n",
      "current iter: 21990000/24576000\n",
      "current iter: 21991000/24576000\n",
      "current iter: 21992000/24576000\n",
      "current iter: 21993000/24576000\n",
      "current iter: 21994000/24576000\n",
      "current iter: 21995000/24576000\n",
      "current iter: 21996000/24576000\n",
      "current iter: 21997000/24576000\n",
      "current iter: 21998000/24576000\n",
      "current iter: 21999000/24576000\n",
      "current iter: 22000000/24576000\n",
      "current iter: 22001000/24576000\n",
      "current iter: 22002000/24576000\n",
      "current iter: 22003000/24576000\n",
      "current iter: 22004000/24576000\n",
      "current iter: 22005000/24576000\n",
      "current iter: 22006000/24576000\n",
      "current iter: 22007000/24576000\n",
      "current iter: 22008000/24576000\n",
      "current iter: 22009000/24576000\n",
      "current iter: 22010000/24576000\n",
      "current iter: 22011000/24576000\n",
      "current iter: 22012000/24576000\n",
      "current iter: 22013000/24576000\n",
      "current iter: 22014000/24576000\n",
      "current iter: 22015000/24576000\n",
      "current iter: 22016000/24576000\n",
      "current iter: 22017000/24576000\n",
      "current iter: 22018000/24576000\n",
      "current iter: 22019000/24576000\n",
      "current iter: 22020000/24576000\n",
      "current iter: 22021000/24576000\n",
      "current iter: 22022000/24576000\n",
      "current iter: 22023000/24576000\n",
      "current iter: 22024000/24576000\n",
      "current iter: 22025000/24576000\n",
      "current iter: 22026000/24576000\n",
      "current iter: 22027000/24576000\n",
      "current iter: 22028000/24576000\n",
      "current iter: 22029000/24576000\n",
      "current iter: 22030000/24576000\n",
      "current iter: 22031000/24576000\n",
      "current iter: 22032000/24576000\n",
      "current iter: 22033000/24576000\n",
      "current iter: 22034000/24576000\n",
      "current iter: 22035000/24576000\n",
      "current iter: 22036000/24576000\n",
      "current iter: 22037000/24576000\n",
      "current iter: 22038000/24576000\n",
      "current iter: 22039000/24576000\n",
      "current iter: 22040000/24576000\n",
      "current iter: 22041000/24576000\n",
      "current iter: 22042000/24576000\n",
      "current iter: 22043000/24576000\n",
      "current iter: 22044000/24576000\n",
      "current iter: 22045000/24576000\n",
      "current iter: 22046000/24576000\n",
      "current iter: 22047000/24576000\n",
      "current iter: 22048000/24576000\n",
      "current iter: 22049000/24576000\n",
      "current iter: 22050000/24576000\n",
      "current iter: 22051000/24576000\n",
      "current iter: 22052000/24576000\n",
      "current iter: 22053000/24576000\n",
      "current iter: 22054000/24576000\n",
      "current iter: 22055000/24576000\n",
      "current iter: 22056000/24576000\n",
      "current iter: 22057000/24576000\n",
      "current iter: 22058000/24576000\n",
      "current iter: 22059000/24576000\n",
      "current iter: 22060000/24576000\n",
      "current iter: 22061000/24576000\n",
      "current iter: 22062000/24576000\n",
      "current iter: 22063000/24576000\n",
      "current iter: 22064000/24576000\n",
      "current iter: 22065000/24576000\n",
      "current iter: 22066000/24576000\n",
      "current iter: 22067000/24576000\n",
      "current iter: 22068000/24576000\n",
      "current iter: 22069000/24576000\n",
      "current iter: 22070000/24576000\n",
      "current iter: 22071000/24576000\n",
      "current iter: 22072000/24576000\n",
      "current iter: 22073000/24576000\n",
      "current iter: 22074000/24576000\n",
      "current iter: 22075000/24576000\n",
      "current iter: 22076000/24576000\n",
      "current iter: 22077000/24576000\n",
      "current iter: 22078000/24576000\n",
      "current iter: 22079000/24576000\n",
      "current iter: 22080000/24576000\n",
      "current iter: 22081000/24576000\n",
      "current iter: 22082000/24576000\n",
      "current iter: 22083000/24576000\n",
      "current iter: 22084000/24576000\n",
      "current iter: 22085000/24576000\n",
      "current iter: 22086000/24576000\n",
      "current iter: 22087000/24576000\n",
      "current iter: 22088000/24576000\n",
      "current iter: 22089000/24576000\n",
      "current iter: 22090000/24576000\n",
      "current iter: 22091000/24576000\n",
      "current iter: 22092000/24576000\n",
      "current iter: 22093000/24576000\n",
      "current iter: 22094000/24576000\n",
      "current iter: 22095000/24576000\n",
      "current iter: 22096000/24576000\n",
      "current iter: 22097000/24576000\n",
      "current iter: 22098000/24576000\n"
     ]
    }
   ],
   "source": [
    "# SAMPLING\n",
    "\n",
    "if not \"models\" in vars() or models is None or len(models) < 2:\n",
    "    mkdir(OUTPUT_PATH)\n",
    "    # file location, update to point to the correct file\n",
    "    MODELS_FILE_PATH = OUTPUT_PATH + \"/12-09_21-52-24_7D4325.models\"\n",
    "    # which epoch's models to use\n",
    "    NTH_EPOCH = val_weighted_losses.argmin()\n",
    "    \n",
    "    with open(MODELS_FILE_PATH, \"rb\") as file:\n",
    "        saved_models = pickle.load(file)\n",
    "        models = saved_models[NTH_EPOCH]\n",
    "        \n",
    "# how many ticks to sample, 16 ticks ~ 1 measure of music\n",
    "NUM_TICKS_TO_SAMPLE = 512\n",
    "# number of iterations to repeat the sampling process, one iteration\n",
    "# will run for NUM_PARTS * NUM_TICKS_TO_SAMPLE times.\n",
    "NUM_REPEATS = 12000\n",
    "        \n",
    "output = sample(models, \n",
    "                num_parts=NUM_PARTS,\n",
    "                num_ticks=NUM_TICKS_TO_SAMPLE,\n",
    "                num_dims=PITCH_VOCAB_SIZE,\n",
    "                seq_len=SEQ_LEN,\n",
    "                num_repeats=NUM_REPEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = OUTPUT_PATH + \"/{}_{}.sample\".format(RUN_ID, RUN_TIME)\n",
    "\n",
    "with open(output_path, \"wb\") as file:\n",
    "    pickle.dump(output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = haydn_dataset.matrix_to_score(output)\n",
    "\n",
    "SAVING = True\n",
    "\n",
    "if SAVING:\n",
    "    file_name = RUN_ID + \"_\" + RUN_TIME + \".pgz\"\n",
    "    output_path = OUTPUT_PATH + \"/\" + file_name\n",
    "    converter.freeze(score, fp=output_path)\n",
    "    \n",
    "# converter.thaw(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

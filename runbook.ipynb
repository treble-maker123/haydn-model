{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: test mode is ON.\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util.helpers import *\n",
    "from util.run import train, validate\n",
    "from util.sample import sample\n",
    "from util.dataset import HaydnDataset, ChunksDataset\n",
    "from util.models import PitchEmbedModel, HarmonyModel, JudgeModel, NoteModel\n",
    "\n",
    "from music21 import converter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# number of instrument parts\n",
    "NUM_PARTS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset...\n",
      "Serialized scores found, loading...\n",
      "Scores loaded in 1.21 seconds.\n"
     ]
    }
   ],
   "source": [
    "# SETUP DATA LOADER\n",
    "\n",
    "SEQ_LEN = 32\n",
    "STRIDE = 1\n",
    "BATCH_SIZE = {\n",
    "    \"train\": 64,\n",
    "    \"val\": 64\n",
    "}\n",
    "LOADER_PARAMS = {\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": multiprocessing.cpu_count() - 2\n",
    "}\n",
    "TRANSFORMS = []\n",
    "\n",
    "SKIP_DATA = False\n",
    "\n",
    "if not SKIP_DATA:\n",
    "    haydn_dataset = HaydnDataset()\n",
    "\n",
    "    data_train = ChunksDataset(seq_len=SEQ_LEN, \n",
    "                               stride=STRIDE, \n",
    "                               dataset=haydn_dataset,\n",
    "                               transforms=TRANSFORMS)\n",
    "    data_val = ChunksDataset(dataset=data_train.comp_set,\n",
    "                             transforms=TRANSFORMS)\n",
    "\n",
    "    loader_train = DataLoader(data_train,\n",
    "                              batch_size=BATCH_SIZE[\"train\"],\n",
    "                              **LOADER_PARAMS)\n",
    "    loader_val = DataLoader(data_val,\n",
    "                            batch_size=BATCH_SIZE[\"val\"],\n",
    "                            **LOADER_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "# number of epochs to run\n",
    "NUM_EPOCHS = 1\n",
    "# number of dimensions for the embedded pitch vectors\n",
    "EMBED_DIM = 5\n",
    "# dimension of the rhythm\n",
    "RHYTHM_DIM = 1\n",
    "# the total number of pitches plus rest\n",
    "PITCH_VOCAB_SIZE = 140\n",
    "# parameters for the optimizers\n",
    "OPTIM_PARAMS = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"weight_decay\": 1e-5\n",
    "}\n",
    "\n",
    "# weights applied to each of the loss functions\n",
    "# forward pitch\n",
    "fp_loss = 1.0\n",
    "# backward pitch\n",
    "bp_loss = 1.0\n",
    "# harmony pitch\n",
    "hp_loss = 1.0\n",
    "# foward rhythm\n",
    "fr_loss = 1.0\n",
    "# judge\n",
    "j_loss = 1.0\n",
    "# part\n",
    "p_loss = 1.0\n",
    "LOSS_WEIGHTS = [fp_loss, bp_loss, hp_loss, fr_loss, j_loss, p_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS AND OPTIMIZERS\n",
    "\n",
    "SKIP_MODELS = False\n",
    "\n",
    "if not SKIP_MODELS:\n",
    "    model_names = [\"forward_\", \"backward_\", \"harmony_\", \"judge_\"]\n",
    "\n",
    "    models = {\n",
    "        \"pitch_embed\": PitchEmbedModel(vocab_size=PITCH_VOCAB_SIZE,\n",
    "                                       embed_dim=EMBED_DIM)\n",
    "    }\n",
    "    optims = {}\n",
    "\n",
    "    for i in range(NUM_PARTS):\n",
    "        note_input_dim = EMBED_DIM + RHYTHM_DIM\n",
    "        note_hidden_dim = 64\n",
    "        note_num_layers = 1\n",
    "        models[model_names[0] + str(i)] = NoteModel(note_input_dim, \n",
    "                                                    note_hidden_dim,\n",
    "                                                    batch_size=BATCH_SIZE['train'],\n",
    "                                                    num_layers=note_num_layers,\n",
    "                                                    vocab_size=PITCH_VOCAB_SIZE)\n",
    "\n",
    "        models[model_names[1] + str(i)] = NoteModel(note_input_dim, \n",
    "                                                    note_hidden_dim,\n",
    "                                                    batch_size=BATCH_SIZE['train'],\n",
    "                                                    num_layers=note_num_layers,\n",
    "                                                    vocab_size=PITCH_VOCAB_SIZE)\n",
    "\n",
    "\n",
    "        harmony_input_shape = (NUM_PARTS, EMBED_DIM + NUM_PARTS)\n",
    "        harmony_hidden_dim = 4\n",
    "        models[model_names[2] + str(i)] = HarmonyModel(input_shape=harmony_input_shape,\n",
    "                                                       vocab_size=PITCH_VOCAB_SIZE,\n",
    "                                                       hidden_dim=harmony_hidden_dim)\n",
    "\n",
    "\n",
    "        judge_input_shape = (NUM_PARTS - 1, EMBED_DIM)\n",
    "        judge_hidden_dim = 64\n",
    "        output_dim = PITCH_VOCAB_SIZE\n",
    "        models[model_names[3] + str(i)] = JudgeModel(judge_input_shape,\n",
    "                                                     judge_hidden_dim,\n",
    "                                                     output_dim)\n",
    "\n",
    "        # jointly optimize all of the params, so weights can be assigned to different loss.\n",
    "        embed_params = list(models[\"pitch_embed\"].parameters())\n",
    "        forward_params = list(models[model_names[0] + str(i)].parameters())\n",
    "        backward_params = list(models[model_names[1] + str(i)].parameters())\n",
    "        harmony_params = list(models[model_names[2] + str(i)].parameters())\n",
    "        judge_params = list(models[model_names[3] + str(i)].parameters())\n",
    "        optims[i] = optim.Adam(forward_params + backward_params +\n",
    "                               harmony_params + judge_params, \n",
    "                               **OPTIM_PARAMS)\n",
    "\n",
    "    # send all models to the appropriate device\n",
    "    for key in models:\n",
    "        models[key].to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "-----------\n",
      "Train iter 0/1071:\n",
      "\tPart 1 - fp_loss: 1.75866/56.00%, bp_loss: 2.82775/25.00%, hp_loss: 3.00447/23.00%, j_loss: 2.33710/48.00%, \n",
      "\t\tfr_loss: 0.27260/71.00%, p_loss: 0.00045/100.00%, \n",
      "\t\ttotal weighted loss: 10.20103\n",
      "\tTraining time elapsed: 0.13 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 1.19426/68.00%, bp_loss: 2.31006/46.00%, hp_loss: 2.26373/46.00%, j_loss: 1.83701/70.00%, \n",
      "\t\tfr_loss: 0.27308/71.00%, p_loss: 0.00025/100.00%, \n",
      "\t\ttotal weighted loss: 7.87840\n",
      "\tTraining time elapsed: 0.21 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 1.19386/79.00%, bp_loss: 2.87863/34.00%, hp_loss: 2.12005/50.00%, j_loss: 1.11830/76.00%, \n",
      "\t\tfr_loss: 0.22638/78.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 7.53733\n",
      "\tTraining time elapsed: 0.29 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 0.87030/81.00%, bp_loss: 2.83120/25.00%, hp_loss: 2.05300/50.00%, j_loss: 0.80593/79.00%, \n",
      "\t\tfr_loss: 0.22876/78.00%, p_loss: 0.00035/100.00%, \n",
      "\t\ttotal weighted loss: 6.78954\n",
      "\tTraining time elapsed: 0.36 seconds\n",
      "\n",
      "Train iter 100/1071:\n",
      "\tPart 1 - fp_loss: 1.79695/50.00%, bp_loss: 2.86941/26.00%, hp_loss: 3.09087/21.00%, j_loss: 2.58521/43.00%, \n",
      "\t\tfr_loss: 0.11862/90.00%, p_loss: 0.00053/100.00%, \n",
      "\t\ttotal weighted loss: 10.46157\n",
      "\tTraining time elapsed: 23.62 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 1.37469/68.00%, bp_loss: 2.42337/43.00%, hp_loss: 2.42175/43.00%, j_loss: 1.62758/67.00%, \n",
      "\t\tfr_loss: 0.20115/81.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 8.04868\n",
      "\tTraining time elapsed: 23.68 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 1.08135/79.00%, bp_loss: 2.72815/37.00%, hp_loss: 2.14217/48.00%, j_loss: 1.19624/78.00%, \n",
      "\t\tfr_loss: 0.16820/84.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 7.31614\n",
      "\tTraining time elapsed: 23.73 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 1.32577/68.00%, bp_loss: 2.84452/23.00%, hp_loss: 2.42314/51.00%, j_loss: 1.33088/67.00%, \n",
      "\t\tfr_loss: 0.13565/87.00%, p_loss: 0.00037/100.00%, \n",
      "\t\ttotal weighted loss: 8.06033\n",
      "\tTraining time elapsed: 23.80 seconds\n",
      "\n",
      "Train iter 200/1071:\n",
      "\tPart 1 - fp_loss: 2.08570/39.00%, bp_loss: 3.03536/26.00%, hp_loss: 3.28559/23.00%, j_loss: 2.77492/35.00%, \n",
      "\t\tfr_loss: 0.17607/84.00%, p_loss: 0.00027/100.00%, \n",
      "\t\ttotal weighted loss: 11.35791\n",
      "\tTraining time elapsed: 47.61 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 1.14207/68.00%, bp_loss: 2.07058/53.00%, hp_loss: 2.17688/53.00%, j_loss: 1.48104/67.00%, \n",
      "\t\tfr_loss: 0.20959/78.00%, p_loss: 0.00021/100.00%, \n",
      "\t\ttotal weighted loss: 7.08037\n",
      "\tTraining time elapsed: 47.67 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 0.97684/79.00%, bp_loss: 2.57834/34.00%, hp_loss: 1.79948/46.00%, j_loss: 0.88474/75.00%, \n",
      "\t\tfr_loss: 0.14696/85.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.38638\n",
      "\tTraining time elapsed: 47.73 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 0.87148/76.00%, bp_loss: 2.43291/26.00%, hp_loss: 2.05980/57.00%, j_loss: 0.70296/78.00%, \n",
      "\t\tfr_loss: 0.06824/93.00%, p_loss: 0.00009/100.00%, \n",
      "\t\ttotal weighted loss: 6.13549\n",
      "\tTraining time elapsed: 47.79 seconds\n",
      "\n",
      "Train iter 300/1071:\n",
      "\tPart 1 - fp_loss: 1.57024/56.00%, bp_loss: 2.79404/26.00%, hp_loss: 2.91336/26.00%, j_loss: 2.07252/56.00%, \n",
      "\t\tfr_loss: 0.15524/85.00%, p_loss: 0.00028/100.00%, \n",
      "\t\ttotal weighted loss: 9.50568\n",
      "\tTraining time elapsed: 72.37 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 1.16291/67.00%, bp_loss: 2.35101/45.00%, hp_loss: 2.31462/45.00%, j_loss: 1.59688/67.00%, \n",
      "\t\tfr_loss: 0.18871/84.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 7.61428\n",
      "\tTraining time elapsed: 72.43 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 1.11404/73.00%, bp_loss: 2.28966/43.00%, hp_loss: 1.74874/60.00%, j_loss: 0.98247/79.00%, \n",
      "\t\tfr_loss: 0.14502/85.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.27995\n",
      "\tTraining time elapsed: 72.49 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 0.95783/75.00%, bp_loss: 2.54857/31.00%, hp_loss: 2.41157/46.00%, j_loss: 1.04103/84.00%, \n",
      "\t\tfr_loss: 0.11081/89.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 7.06990\n",
      "\tTraining time elapsed: 72.55 seconds\n",
      "\n",
      "Train iter 400/1071:\n",
      "\tPart 1 - fp_loss: 1.89047/46.00%, bp_loss: 2.82015/18.00%, hp_loss: 3.04561/10.00%, j_loss: 2.27106/45.00%, \n",
      "\t\tfr_loss: 0.13640/85.00%, p_loss: 0.00024/100.00%, \n",
      "\t\ttotal weighted loss: 10.16393\n",
      "\tTraining time elapsed: 97.45 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 1.20202/68.00%, bp_loss: 2.30129/39.00%, hp_loss: 2.35594/40.00%, j_loss: 1.42135/68.00%, \n",
      "\t\tfr_loss: 0.15591/85.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 7.43661\n",
      "\tTraining time elapsed: 97.50 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 0.99461/76.00%, bp_loss: 2.47549/32.00%, hp_loss: 1.89567/51.00%, j_loss: 1.15378/75.00%, \n",
      "\t\tfr_loss: 0.06030/95.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.57987\n",
      "\tTraining time elapsed: 97.56 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 0.77393/79.00%, bp_loss: 2.48094/29.00%, hp_loss: 1.77907/59.00%, j_loss: 0.78773/81.00%, \n",
      "\t\tfr_loss: 0.08335/92.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 5.90507\n",
      "\tTraining time elapsed: 97.63 seconds\n",
      "\n",
      "Train iter 500/1071:\n",
      "\tPart 1 - fp_loss: 1.61421/53.00%, bp_loss: 2.66889/28.00%, hp_loss: 3.11209/18.00%, j_loss: 2.20610/53.00%, \n",
      "\t\tfr_loss: 0.12526/87.00%, p_loss: 0.00027/100.00%, \n",
      "\t\ttotal weighted loss: 9.72683\n",
      "\tTraining time elapsed: 122.64 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 0.90683/75.00%, bp_loss: 1.83742/59.00%, hp_loss: 1.90953/59.00%, j_loss: 1.23817/76.00%, \n",
      "\t\tfr_loss: 0.15227/87.00%, p_loss: 0.00012/100.00%, \n",
      "\t\ttotal weighted loss: 6.04434\n",
      "\tTraining time elapsed: 122.71 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 1.16828/71.00%, bp_loss: 2.35222/34.00%, hp_loss: 1.89881/46.00%, j_loss: 1.37589/70.00%, \n",
      "\t\tfr_loss: 0.06800/93.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.86322\n",
      "\tTraining time elapsed: 122.77 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 0.98151/71.00%, bp_loss: 2.37162/26.00%, hp_loss: 1.99028/65.00%, j_loss: 0.77848/75.00%, \n",
      "\t\tfr_loss: 0.06626/93.00%, p_loss: 0.00014/100.00%, \n",
      "\t\ttotal weighted loss: 6.18830\n",
      "\tTraining time elapsed: 122.83 seconds\n",
      "\n",
      "Train iter 600/1071:\n",
      "\tPart 1 - fp_loss: 1.73093/48.00%, bp_loss: 2.53215/29.00%, hp_loss: 2.97609/23.00%, j_loss: 2.10019/46.00%, \n",
      "\t\tfr_loss: 0.13860/87.00%, p_loss: 0.00026/100.00%, \n",
      "\t\ttotal weighted loss: 9.47821\n",
      "\tTraining time elapsed: 146.62 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 0.75582/78.00%, bp_loss: 1.81927/59.00%, hp_loss: 1.77122/59.00%, j_loss: 1.08889/78.00%, \n",
      "\t\tfr_loss: 0.12127/89.00%, p_loss: 0.00016/100.00%, \n",
      "\t\ttotal weighted loss: 5.55664\n",
      "\tTraining time elapsed: 146.68 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 0.95905/73.00%, bp_loss: 2.27864/40.00%, hp_loss: 1.66374/51.00%, j_loss: 1.03902/75.00%, \n",
      "\t\tfr_loss: 0.09704/90.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.03750\n",
      "\tTraining time elapsed: 146.74 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 0.85662/71.00%, bp_loss: 2.27455/26.00%, hp_loss: 1.72173/65.00%, j_loss: 0.67814/84.00%, \n",
      "\t\tfr_loss: 0.05037/95.00%, p_loss: 0.00006/100.00%, \n",
      "\t\ttotal weighted loss: 5.58148\n",
      "\tTraining time elapsed: 146.80 seconds\n",
      "\n",
      "Train iter 700/1071:\n",
      "\tPart 1 - fp_loss: 1.63090/57.00%, bp_loss: 2.86418/21.00%, hp_loss: 3.10409/23.00%, j_loss: 1.94326/57.00%, \n",
      "\t\tfr_loss: 0.17137/82.00%, p_loss: 0.00022/100.00%, \n",
      "\t\ttotal weighted loss: 9.71402\n",
      "\tTraining time elapsed: 170.85 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 0.90523/68.00%, bp_loss: 2.12458/48.00%, hp_loss: 2.27637/45.00%, j_loss: 1.40394/67.00%, \n",
      "\t\tfr_loss: 0.15097/85.00%, p_loss: 0.00010/100.00%, \n",
      "\t\ttotal weighted loss: 6.86120\n",
      "\tTraining time elapsed: 170.91 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 1.00721/76.00%, bp_loss: 2.54300/31.00%, hp_loss: 2.06386/42.00%, j_loss: 1.25777/71.00%, \n",
      "\t\tfr_loss: 0.13357/87.00%, p_loss: 0.00003/100.00%, \n",
      "\t\ttotal weighted loss: 7.00543\n",
      "\tTraining time elapsed: 170.98 seconds\n",
      "\n",
      "\tPart 4 - fp_loss: 0.74951/81.00%, bp_loss: 2.28356/31.00%, hp_loss: 2.10712/57.00%, j_loss: 0.64349/89.00%, \n",
      "\t\tfr_loss: 0.12583/87.00%, p_loss: 0.00005/100.00%, \n",
      "\t\ttotal weighted loss: 5.90957\n",
      "\tTraining time elapsed: 171.04 seconds\n",
      "\n",
      "Train iter 800/1071:\n",
      "\tPart 1 - fp_loss: 1.62360/53.00%, bp_loss: 2.51525/20.00%, hp_loss: 2.89288/23.00%, j_loss: 2.31110/53.00%, \n",
      "\t\tfr_loss: 0.09477/90.00%, p_loss: 0.00015/100.00%, \n",
      "\t\ttotal weighted loss: 9.43776\n",
      "\tTraining time elapsed: 195.70 seconds\n",
      "\n",
      "\tPart 2 - fp_loss: 1.23149/62.00%, bp_loss: 2.54813/32.00%, hp_loss: 2.70657/35.00%, j_loss: 1.84393/62.00%, \n",
      "\t\tfr_loss: 0.16590/84.00%, p_loss: 0.00022/100.00%, \n",
      "\t\ttotal weighted loss: 8.49624\n",
      "\tTraining time elapsed: 195.76 seconds\n",
      "\n",
      "\tPart 3 - fp_loss: 0.94075/75.00%, bp_loss: 2.58560/28.00%, hp_loss: 1.79674/50.00%, j_loss: 0.96332/73.00%, \n",
      "\t\tfr_loss: 0.11462/89.00%, p_loss: 0.00002/100.00%, \n",
      "\t\ttotal weighted loss: 6.40105\n",
      "\tTraining time elapsed: 195.82 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPart 4 - fp_loss: 0.87103/79.00%, bp_loss: 2.16201/28.00%, hp_loss: 1.73984/67.00%, j_loss: 0.86546/79.00%, \n",
      "\t\tfr_loss: 0.04866/95.00%, p_loss: 0.00004/100.00%, \n",
      "\t\ttotal weighted loss: 5.68704\n",
      "\tTraining time elapsed: 195.88 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "\n",
    "SKIP_TRAIN = False\n",
    "\n",
    "if not SKIP_TRAIN:\n",
    "    train_stats = []\n",
    "    val_stats = []\n",
    "    saved_models = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(\"EPOCH {}\".format(epoch))\n",
    "        print(\"-----------\")\n",
    "        stats, models = train(models, optims, loader_train, \n",
    "                              model_names=model_names, \n",
    "                              loss_weights=LOSS_WEIGHTS,\n",
    "                              device=device,\n",
    "                              print_iter=100)\n",
    "\n",
    "        stats, models = validate(models, loader_val,\n",
    "                                 model_names=model_names,\n",
    "                                 device=device,\n",
    "                                 print_iter=100)\n",
    "\n",
    "        print(\"-----------\")\n",
    "        print(\"Completed epoch {}.\".format(epoch))\n",
    "        print(\"\")\n",
    "        train_stats.append(stats)\n",
    "        val_stats.append(stats)\n",
    "        saved_models.append(copy.deepcopy(models))\n",
    "\n",
    "\n",
    "    print(\"Training completed! Saving files.\")\n",
    "\n",
    "    # create a folder to store all of the stats and models\n",
    "    mkdir(OUTPUT_PATH)\n",
    "    stats_file_name = get_formatted_time() + \"_\" + get_unique_id() + \".stat\"\n",
    "    stats_file_path = OUTPUT_PATH + \"/\" + stats_file_name\n",
    "    models_file_name = get_formatted_time() + \"_\" + get_unique_id() + \".models\"\n",
    "    models_file_path = OUTPUT_PATH + \"/\" + models_file_name\n",
    "\n",
    "    with open(stats_file_path, \"wb\") as file:\n",
    "        pickle.dump((train_stats, val_stats), file)\n",
    "    with open(models_file_path, \"wb\") as file:\n",
    "        pickle.dump(saved_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLING\n",
    "\n",
    "if not \"models\" in vars() or models is None or len(models) < 2:\n",
    "    mkdir(OUTPUT_PATH)\n",
    "    # file location, update to point to the correct file\n",
    "    MODELS_FILE_PATH = OUTPUT_PATH + \"/12-09_03-06-47_04D328.models\"\n",
    "    # which epoch's models to use\n",
    "    NTH_EPOCH = 0\n",
    "    \n",
    "    with open(MODELS_FILE_PATH, \"rb\") as file:\n",
    "        saved_models = pickle.load(file)\n",
    "        models = saved_models[NTH_EPOCH]\n",
    "        \n",
    "# how many ticks to sample, 16 ticks ~ 1 measure of music\n",
    "NUM_TICKS_TO_SAMPLE = 256\n",
    "# number of iterations to repeat the sampling process, one iteration\n",
    "# will run for NUM_PARTS * NUM_TICKS_TO_SAMPLE times.\n",
    "NUM_REPEATS = 1\n",
    "        \n",
    "output = sample(models, \n",
    "                num_parts=NUM_PARTS,\n",
    "                num_ticks=NUM_TICKS_TO_SAMPLE,\n",
    "                num_dims=PITCH_VOCAB_SIZE,\n",
    "                seq_len=SEQ_LEN,\n",
    "                num_repeats=NUM_REPEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = haydn_dataset.matrix_to_score(output)\n",
    "\n",
    "SAVING = True\n",
    "\n",
    "if SAVING:\n",
    "    file_name = get_unique_id() + \"_\" + get_formatted_time() + \".pgz\"\n",
    "    mkdir(SAMPLE_PATH)\n",
    "    output_path = SAMPLE_PATH + \"/\" + file_name\n",
    "    converter.freeze(score, fp=output_path)\n",
    "    \n",
    "# converter.thaw(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util.helpers import *\n",
    "from util.run import train, validate\n",
    "from util.sample import sample\n",
    "from util.dataset import HaydnDataset, ChunksDataset\n",
    "from util.models import PitchEmbedModel, HarmonyModel, JudgeModel, NoteModel\n",
    "\n",
    "from music21 import converter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "# number of instrument parts\n",
    "NUM_PARTS = 4\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset...\n",
      "Serialized scores found, loading...\n",
      "Scores loaded in 21.26 seconds.\n"
     ]
    }
   ],
   "source": [
    "# SETUP DATA LOADER\n",
    "\n",
    "SEQ_LEN = 32\n",
    "STRIDE = 1\n",
    "BATCH_SIZE = {\n",
    "    \"train\": 64,\n",
    "    \"val\": 64\n",
    "}\n",
    "LOADER_PARAMS = {\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": multiprocessing.cpu_count() - 2\n",
    "}\n",
    "TRANSFORMS = []\n",
    "\n",
    "SKIP_DATA = False\n",
    "\n",
    "if not SKIP_DATA:\n",
    "    haydn_dataset = HaydnDataset()\n",
    "\n",
    "    data_train = ChunksDataset(seq_len=SEQ_LEN, \n",
    "                               stride=STRIDE, \n",
    "                               dataset=haydn_dataset,\n",
    "                               transforms=TRANSFORMS)\n",
    "    data_val = ChunksDataset(dataset=data_train.comp_set,\n",
    "                             transforms=TRANSFORMS)\n",
    "\n",
    "    loader_train = DataLoader(data_train,\n",
    "                              batch_size=BATCH_SIZE[\"train\"],\n",
    "                              **LOADER_PARAMS)\n",
    "    loader_val = DataLoader(data_val,\n",
    "                            batch_size=BATCH_SIZE[\"val\"],\n",
    "                            **LOADER_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "# number of epochs to run\n",
    "NUM_EPOCHS = 1\n",
    "# number of dimensions for the embedded pitch vectors\n",
    "EMBED_DIM = 5\n",
    "# dimension of the rhythm\n",
    "RHYTHM_DIM = 1\n",
    "# the total number of pitches plus rest\n",
    "PITCH_VOCAB_SIZE = 140\n",
    "# parameters for the optimizers\n",
    "OPTIM_PARAMS = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"weight_decay\": 1e-5\n",
    "}\n",
    "\n",
    "# weights applied to each of the loss functions\n",
    "# forward pitch\n",
    "fp_loss = 1.0\n",
    "# backward pitch\n",
    "bp_loss = 1.0\n",
    "# harmony pitch\n",
    "hp_loss = 1.0\n",
    "# foward rhythm\n",
    "fr_loss = 1.0\n",
    "# judge\n",
    "j_loss = 1.0\n",
    "# part\n",
    "p_loss = 1.0\n",
    "LOSS_WEIGHTS = [fp_loss, bp_loss, hp_loss, fr_loss, j_loss, p_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS AND OPTIMIZERS\n",
    "\n",
    "SKIP_MODELS = False\n",
    "\n",
    "if not SKIP_MODELS:\n",
    "    model_names = [\"forward_\", \"backward_\", \"harmony_\", \"judge_\"]\n",
    "\n",
    "    models = {\n",
    "        \"pitch_embed\": PitchEmbedModel(vocab_size=PITCH_VOCAB_SIZE,\n",
    "                                       embed_dim=EMBED_DIM)\n",
    "    }\n",
    "    optims = {}\n",
    "\n",
    "    for i in range(NUM_PARTS):\n",
    "        note_input_dim = EMBED_DIM + RHYTHM_DIM\n",
    "        note_hidden_dim = 64\n",
    "        note_num_layers = 1\n",
    "        models[model_names[0] + str(i)] = NoteModel(note_input_dim, \n",
    "                                                    note_hidden_dim,\n",
    "                                                    batch_size=BATCH_SIZE['train'],\n",
    "                                                    num_layers=note_num_layers,\n",
    "                                                    vocab_size=PITCH_VOCAB_SIZE)\n",
    "\n",
    "        models[model_names[1] + str(i)] = NoteModel(note_input_dim, \n",
    "                                                    note_hidden_dim,\n",
    "                                                    batch_size=BATCH_SIZE['train'],\n",
    "                                                    num_layers=note_num_layers,\n",
    "                                                    vocab_size=PITCH_VOCAB_SIZE)\n",
    "\n",
    "\n",
    "        harmony_input_shape = (NUM_PARTS, EMBED_DIM + NUM_PARTS)\n",
    "        harmony_hidden_dim = 4\n",
    "        models[model_names[2] + str(i)] = HarmonyModel(input_shape=harmony_input_shape,\n",
    "                                                       vocab_size=PITCH_VOCAB_SIZE,\n",
    "                                                       hidden_dim=harmony_hidden_dim)\n",
    "\n",
    "\n",
    "        judge_input_shape = (NUM_PARTS - 1, EMBED_DIM)\n",
    "        judge_hidden_dim = 64\n",
    "        output_dim = PITCH_VOCAB_SIZE\n",
    "        models[model_names[3] + str(i)] = JudgeModel(judge_input_shape,\n",
    "                                                     judge_hidden_dim,\n",
    "                                                     output_dim)\n",
    "\n",
    "        # jointly optimize all of the params, so weights can be assigned to different loss.\n",
    "        embed_params = list(models[\"pitch_embed\"].parameters())\n",
    "        forward_params = list(models[model_names[0] + str(i)].parameters())\n",
    "        backward_params = list(models[model_names[1] + str(i)].parameters())\n",
    "        harmony_params = list(models[model_names[2] + str(i)].parameters())\n",
    "        judge_params = list(models[model_names[3] + str(i)].parameters())\n",
    "        optims[i] = optim.Adam(forward_params + backward_params +\n",
    "                               harmony_params + judge_params, \n",
    "                               **OPTIM_PARAMS)\n",
    "\n",
    "    # send all models to the appropriate device\n",
    "    for key in models:\n",
    "        models[key].to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS BLOCK CLEAR GPU CACHE\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "-----------\n",
      "Train iter 0/20464:\n",
      "\tPart 1 - fp_loss: 4.94059/1.00%, bp_loss: 4.93277/0.00%, hp_loss: 5.01700/0.00%, j_loss: 5.74281/1.00%, \n",
      "\t\tfr_loss: 0.49820/59.00%, p_loss: 1.40450/14.00%, \n",
      "\t\ttotal weighted loss: 22.53587\n",
      "\tPart 2 - fp_loss: 4.93705/0.00%, bp_loss: 4.95520/0.00%, hp_loss: 4.96147/0.00%, j_loss: 5.58806/0.00%, \n",
      "\t\tfr_loss: 0.51947/26.00%, p_loss: 1.29751/20.00%, \n",
      "\t\ttotal weighted loss: 22.25874\n",
      "\tPart 3 - fp_loss: 4.97699/1.00%, bp_loss: 4.90287/0.00%, hp_loss: 5.25990/0.00%, j_loss: 5.37472/0.00%, \n",
      "\t\tfr_loss: 0.50010/46.00%, p_loss: 1.48758/9.00%, \n",
      "\t\ttotal weighted loss: 22.50216\n",
      "\tPart 4 - fp_loss: 5.02978/0.00%, bp_loss: 4.91078/0.00%, hp_loss: 4.93911/1.00%, j_loss: 6.19382/1.00%, \n",
      "\t\tfr_loss: 0.49851/62.00%, p_loss: 1.60489/6.00%, \n",
      "\t\ttotal weighted loss: 23.17690\n",
      "\tTraining time elapsed: 0.57 seconds\n",
      "\n",
      "Train iter 100/20464:\n",
      "\tPart 1 - fp_loss: 2.05946/50.00%, bp_loss: 3.08188/34.00%, hp_loss: 3.13300/34.00%, j_loss: 2.52828/42.00%, \n",
      "\t\tfr_loss: 0.44552/54.00%, p_loss: 0.00407/100.00%, \n",
      "\t\ttotal weighted loss: 11.25221\n",
      "\tPart 2 - fp_loss: 2.20828/42.00%, bp_loss: 2.70983/40.00%, hp_loss: 2.67042/40.00%, j_loss: 2.61269/40.00%, \n",
      "\t\tfr_loss: 0.46841/53.00%, p_loss: 0.00107/100.00%, \n",
      "\t\ttotal weighted loss: 10.67069\n",
      "\tPart 3 - fp_loss: 2.09698/46.00%, bp_loss: 2.95238/37.00%, hp_loss: 2.92527/37.00%, j_loss: 2.69635/42.00%, \n",
      "\t\tfr_loss: 0.34436/65.00%, p_loss: 0.00135/100.00%, \n",
      "\t\ttotal weighted loss: 11.01669\n",
      "\tPart 4 - fp_loss: 2.18120/51.00%, bp_loss: 2.77232/40.00%, hp_loss: 2.68277/39.00%, j_loss: 2.43096/46.00%, \n",
      "\t\tfr_loss: 0.39127/60.00%, p_loss: 0.00131/100.00%, \n",
      "\t\ttotal weighted loss: 10.45983\n",
      "\tTraining time elapsed: 5.05 seconds\n",
      "\n",
      "Train iter 200/20464:\n",
      "\tPart 1 - fp_loss: 2.25476/43.00%, bp_loss: 3.14161/29.00%, hp_loss: 3.19209/29.00%, j_loss: 2.66693/40.00%, \n",
      "\t\tfr_loss: 0.42555/59.00%, p_loss: 0.00165/100.00%, \n",
      "\t\ttotal weighted loss: 11.68260\n",
      "\tPart 2 - fp_loss: 1.74480/54.00%, bp_loss: 2.66667/39.00%, hp_loss: 2.61376/39.00%, j_loss: 2.13909/54.00%, \n",
      "\t\tfr_loss: 0.38095/62.00%, p_loss: 0.00069/100.00%, \n",
      "\t\ttotal weighted loss: 9.54595\n",
      "\tPart 3 - fp_loss: 1.41666/65.00%, bp_loss: 2.47819/46.00%, hp_loss: 2.28706/48.00%, j_loss: 1.74743/57.00%, \n",
      "\t\tfr_loss: 0.35933/64.00%, p_loss: 0.00040/100.00%, \n",
      "\t\ttotal weighted loss: 8.28909\n",
      "\tPart 4 - fp_loss: 1.75856/62.00%, bp_loss: 2.49971/39.00%, hp_loss: 2.45410/40.00%, j_loss: 2.14151/60.00%, \n",
      "\t\tfr_loss: 0.37436/62.00%, p_loss: 0.00055/100.00%, \n",
      "\t\ttotal weighted loss: 9.22880\n",
      "\tTraining time elapsed: 9.37 seconds\n",
      "\n",
      "Train iter 300/20464:\n",
      "\tPart 1 - fp_loss: 2.07720/42.00%, bp_loss: 3.02183/29.00%, hp_loss: 3.02259/29.00%, j_loss: 2.38936/40.00%, \n",
      "\t\tfr_loss: 0.33489/70.00%, p_loss: 0.00105/100.00%, \n",
      "\t\ttotal weighted loss: 10.84692\n",
      "\tPart 2 - fp_loss: 1.78717/56.00%, bp_loss: 2.84863/35.00%, hp_loss: 2.84944/35.00%, j_loss: 2.25333/53.00%, \n",
      "\t\tfr_loss: 0.32997/67.00%, p_loss: 0.00051/100.00%, \n",
      "\t\ttotal weighted loss: 10.06906\n",
      "\tPart 3 - fp_loss: 1.73591/56.00%, bp_loss: 2.65247/42.00%, hp_loss: 2.36595/43.00%, j_loss: 2.01424/56.00%, \n",
      "\t\tfr_loss: 0.39715/59.00%, p_loss: 0.00011/100.00%, \n",
      "\t\ttotal weighted loss: 9.16584\n",
      "\tPart 4 - fp_loss: 1.43941/62.00%, bp_loss: 2.63994/39.00%, hp_loss: 2.35641/40.00%, j_loss: 1.82350/59.00%, \n",
      "\t\tfr_loss: 0.39134/59.00%, p_loss: 0.00017/100.00%, \n",
      "\t\ttotal weighted loss: 8.65078\n",
      "\tTraining time elapsed: 13.67 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Process Process-10:\n",
      "Process Process-14:\n",
      "Process Process-6:\n",
      "Process Process-8:\n",
      "Process Process-4:\n",
      "Process Process-5:\n",
      "Process Process-11:\n",
      "Process Process-12:\n",
      "Process Process-7:\n",
      "Process Process-3:\n",
      "Process Process-13:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ubuntu/miniconda2/envs/cs682project/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c367fdfa5728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                               \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_WEIGHTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                               \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                               print_iter=100)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         stats, models = validate(models, loader_val,\n",
      "\u001b[0;32m~/cs682-project/util/run.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, optims, loader, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# time to learn stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0moptims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# detach the LSTM hidden states so don't need to retain graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs682project/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN LOOP\n",
    "\n",
    "SKIP_TRAIN = False\n",
    "\n",
    "if not SKIP_TRAIN:\n",
    "    train_stats = []\n",
    "    val_stats = []\n",
    "    saved_models = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(\"EPOCH {}\".format(epoch))\n",
    "        print(\"-----------\")\n",
    "        stats, models = train(models, optims, loader_train, \n",
    "                              model_names=model_names, \n",
    "                              loss_weights=LOSS_WEIGHTS,\n",
    "                              device=device,\n",
    "                              print_iter=100)\n",
    "\n",
    "        stats, models = validate(models, loader_val,\n",
    "                                 model_names=model_names,\n",
    "                                 device=device,\n",
    "                                 print_iter=100)\n",
    "\n",
    "        print(\"-----------\")\n",
    "        print(\"Completed epoch {}.\".format(epoch))\n",
    "        print(\"\")\n",
    "        train_stats.append(stats)\n",
    "        val_stats.append(stats)\n",
    "        saved_models.append(copy.deepcopy(models))\n",
    "\n",
    "\n",
    "    print(\"Training completed! Saving files.\")\n",
    "\n",
    "    # create a folder to store all of the stats and models\n",
    "    mkdir(OUTPUT_PATH)\n",
    "    stats_file_name = get_formatted_time() + \"_\" + get_unique_id() + \".stat\"\n",
    "    stats_file_path = OUTPUT_PATH + \"/\" + stats_file_name\n",
    "    models_file_name = get_formatted_time() + \"_\" + get_unique_id() + \".models\"\n",
    "    models_file_path = OUTPUT_PATH + \"/\" + models_file_name\n",
    "\n",
    "    with open(stats_file_path, \"wb\") as file:\n",
    "        pickle.dump((train_stats, val_stats), file)\n",
    "    with open(models_file_path, \"wb\") as file:\n",
    "        pickle.dump(saved_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLING\n",
    "\n",
    "if not \"models\" in vars() or models is None or len(models) < 2:\n",
    "    mkdir(OUTPUT_PATH)\n",
    "    # file location, update to point to the correct file\n",
    "    MODELS_FILE_PATH = OUTPUT_PATH + \"/12-09_03-06-47_04D328.models\"\n",
    "    # which epoch's models to use\n",
    "    NTH_EPOCH = 0\n",
    "    \n",
    "    with open(MODELS_FILE_PATH, \"rb\") as file:\n",
    "        saved_models = pickle.load(file)\n",
    "        models = saved_models[NTH_EPOCH]\n",
    "        \n",
    "# how many ticks to sample, 16 ticks ~ 1 measure of music\n",
    "NUM_TICKS_TO_SAMPLE = 256\n",
    "# number of iterations to repeat the sampling process, one iteration\n",
    "# will run for NUM_PARTS * NUM_TICKS_TO_SAMPLE times.\n",
    "NUM_REPEATS = 1\n",
    "        \n",
    "output = sample(models, \n",
    "                num_parts=NUM_PARTS,\n",
    "                num_ticks=NUM_TICKS_TO_SAMPLE,\n",
    "                num_dims=PITCH_VOCAB_SIZE,\n",
    "                seq_len=SEQ_LEN,\n",
    "                num_repeats=NUM_REPEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = haydn_dataset.matrix_to_score(output)\n",
    "\n",
    "SAVING = True\n",
    "\n",
    "if SAVING:\n",
    "    file_name = get_unique_id() + \"_\" + get_formatted_time() + \".pgz\"\n",
    "    mkdir(SAMPLE_PATH)\n",
    "    output_path = SAMPLE_PATH + \"/\" + file_name\n",
    "    converter.freeze(score, fp=output_path)\n",
    "    \n",
    "# converter.thaw(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
